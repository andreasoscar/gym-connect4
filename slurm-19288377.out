04/07/2022 10:41:59 AM [INFO]: Preparing model for MCTS...
04/07/2022 10:41:59 AM [INFO]: Loaded cc4_current_net__iter3.pth.tar model.
04/07/2022 10:41:59 AM [INFO]: [CPU: 0]: Starting MCTS self-play...
START TIME:  10:41:44
  0%|          | 0/4 [00:00<?, ?it/s]04/07/2022 10:41:59 AM [INFO]: [CPU: 0]: Game 0
 25%|██▌       | 1/4 [00:32<01:37, 32.37s/it]04/07/2022 10:42:32 AM [INFO]: [CPU: 0]: Game 1
 50%|█████     | 2/4 [01:27<01:31, 45.69s/it]04/07/2022 10:43:27 AM [INFO]: [CPU: 0]: Game 2
 75%|███████▌  | 3/4 [02:23<00:50, 50.57s/it]04/07/2022 10:44:23 AM [INFO]: [CPU: 0]: Game 3
100%|██████████| 4/4 [03:28<00:00, 56.02s/it]100%|██████████| 4/4 [03:28<00:00, 52.03s/it]
04/07/2022 10:45:27 AM [INFO]: Finished MCTS!
04/07/2022 10:45:27 AM [INFO]: Loading training data...
/home/x_aolss/gym_connect4/gym-connect4/train_c4.py:141: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  datasets = np.array(datasets)
04/07/2022 10:45:29 AM [INFO]: Loaded data from ./datasets/iter_3/.
04/07/2022 10:45:29 AM [INFO]: Loaded checkpoint model cc4_current_net__iter3.pth.tar.
04/07/2022 10:45:29 AM [INFO]: Starting training process...
04/07/2022 10:49:16 AM [INFO]: Finished Training!
FINISHED SELF PLAY:  10:45:27
Update step size: 18
[Iteration 3] Process ID: 216417 [Epoch: 1,   576/ 2309 points] total loss per batch: 0.931
Policy (actual, predicted): 1 1
Policy data: tensor([8.3617e-17, 1.0000e+00, 4.4536e-20, 1.1997e-17, 1.1716e-20, 1.1997e-17,
        8.5398e-15], device='cuda:0')
Policy pred: tensor([7.3066e-09, 9.9934e-01, 8.0488e-08, 2.6382e-06, 1.5897e-06, 4.9220e-05,
        6.0852e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998922348022461
 
[Iteration 3] Process ID: 216417 [Epoch: 1,  1152/ 2309 points] total loss per batch: 0.893
Policy (actual, predicted): 2 2
Policy data: tensor([3.1351e-06, 1.2084e-12, 9.9996e-01, 2.8722e-27, 0.0000e+00, 3.0117e-21,
        4.0425e-05], device='cuda:0')
Policy pred: tensor([3.1505e-03, 2.4496e-04, 9.9583e-01, 5.9638e-06, 1.8424e-07, 6.6144e-06,
        7.6533e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 1,  1728/ 2309 points] total loss per batch: 0.845
Policy (actual, predicted): 4 6
Policy data: tensor([0.0366, 0.0108, 0.0688, 0.0108, 0.4305, 0.0278, 0.4147],
       device='cuda:0')
Policy pred: tensor([0.0351, 0.0114, 0.0614, 0.0240, 0.3228, 0.0439, 0.5015],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.4361768364906311
 
[Iteration 3] Process ID: 216417 [Epoch: 1,  2304/ 2309 points] total loss per batch: 0.847
Policy (actual, predicted): 6 6
Policy data: tensor([2.2156e-08, 3.0151e-05, 7.8340e-08, 2.2813e-04, 7.8340e-08, 2.0635e-07,
        9.9974e-01], device='cuda:0')
Policy pred: tensor([5.2508e-05, 7.9614e-06, 3.3825e-05, 4.1928e-04, 3.6558e-07, 2.1220e-05,
        9.9946e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999986290931702
 
[Iteration 3] Process ID: 216417 [Epoch: 2,   576/ 2309 points] total loss per batch: 0.816
Policy (actual, predicted): 4 1
Policy data: tensor([0.1361, 0.2697, 0.0539, 0.0539, 0.3177, 0.0443, 0.1245],
       device='cuda:0')
Policy pred: tensor([0.1465, 0.2694, 0.0711, 0.0446, 0.2311, 0.0608, 0.1765],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998211860657
 
[Iteration 3] Process ID: 216417 [Epoch: 2,  1152/ 2309 points] total loss per batch: 0.870
Policy (actual, predicted): 6 4
Policy data: tensor([0.1430, 0.1466, 0.1384, 0.1454, 0.1360, 0.1313, 0.1594],
       device='cuda:0')
Policy pred: tensor([0.1306, 0.1636, 0.1626, 0.1192, 0.1726, 0.1177, 0.1337],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 2,  1728/ 2309 points] total loss per batch: 0.819
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 2.3201e-13, 0.0000e+00, 4.9603e-13,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.7916e-09, 9.1090e-01, 8.2659e-05, 3.5419e-03, 2.2557e-05, 8.5449e-02,
        7.5167e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 2,  2304/ 2309 points] total loss per batch: 0.822
Policy (actual, predicted): 1 1
Policy data: tensor([0.0710, 0.3182, 0.0710, 0.1237, 0.0645, 0.1237, 0.2280],
       device='cuda:0')
Policy pred: tensor([0.0953, 0.2782, 0.0760, 0.1264, 0.0816, 0.1026, 0.2398],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999855756759644
 
[Iteration 3] Process ID: 216417 [Epoch: 3,   576/ 2309 points] total loss per batch: 0.791
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 4.0043e-11, 6.6386e-05, 6.1676e-28, 9.9993e-01, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.0976e-06, 2.1497e-03, 3.2841e-03, 4.0128e-05, 9.9452e-01, 1.1926e-07,
        3.7485e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 3,  1152/ 2309 points] total loss per batch: 0.868
Policy (actual, predicted): 1 1
Policy data: tensor([1.7938e-06, 1.0000e+00, 2.4718e-11, 5.2486e-17, 0.0000e+00, 4.1861e-16,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.4523e-02, 9.8249e-01, 1.6349e-03, 1.4595e-05, 8.8475e-07, 1.3336e-03,
        4.5217e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.996878981590271
 
[Iteration 3] Process ID: 216417 [Epoch: 3,  1728/ 2309 points] total loss per batch: 0.799
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000, 0.0000, 0.2239, 0.2699, 0.1427, 0.0584, 0.3051],
       device='cuda:0')
Policy pred: tensor([1.7276e-05, 2.1617e-04, 2.0097e-01, 2.4126e-01, 1.5132e-01, 3.7323e-02,
        3.6889e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 3,  2304/ 2309 points] total loss per batch: 0.812
Policy (actual, predicted): 2 2
Policy data: tensor([8.1243e-14, 4.0601e-18, 1.0000e+00, 3.0158e-26, 8.3193e-21, 3.0158e-26,
        3.0882e-23], device='cuda:0')
Policy pred: tensor([6.3548e-05, 2.8694e-05, 9.9794e-01, 3.5784e-06, 1.3149e-03, 1.4232e-04,
        5.1001e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999989867210388
 
[Iteration 3] Process ID: 216417 [Epoch: 4,   576/ 2309 points] total loss per batch: 0.779
Policy (actual, predicted): 1 2
Policy data: tensor([0.1336, 0.1489, 0.1489, 0.1454, 0.1407, 0.1372, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1423, 0.1494, 0.1605, 0.1378, 0.1310, 0.1248, 0.1543],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999942779541016
 
[Iteration 3] Process ID: 216417 [Epoch: 4,  1152/ 2309 points] total loss per batch: 0.875
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 3.7077e-01, 8.4812e-11, 6.2923e-01, 0.0000e+00, 1.9755e-10,
        3.4481e-08], device='cuda:0')
Policy pred: tensor([1.6185e-07, 9.8127e-02, 4.1693e-03, 8.7236e-01, 1.0042e-08, 9.0190e-04,
        2.4443e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 4,  1728/ 2309 points] total loss per batch: 0.780
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 2.6700e-04, 4.3122e-05, 1.1445e-16, 6.5352e-03, 2.7647e-15,
        9.9315e-01], device='cuda:0')
Policy pred: tensor([3.8609e-08, 6.6924e-03, 1.4848e-03, 4.1283e-07, 2.5442e-02, 5.9490e-04,
        9.6579e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 4,  2304/ 2309 points] total loss per batch: 0.775
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0304e-09, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([8.5259e-09, 1.4671e-07, 9.9981e-01, 1.9319e-04, 9.6185e-12, 7.7958e-08,
        1.5988e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999528527259827
 
[Iteration 3] Process ID: 216417 [Epoch: 5,   576/ 2309 points] total loss per batch: 0.724
Policy (actual, predicted): 6 6
Policy data: tensor([3.5358e-17, 6.1316e-19, 0.0000e+00, 1.7320e-10, 8.5835e-02, 2.9332e-15,
        9.1416e-01], device='cuda:0')
Policy pred: tensor([3.0574e-04, 1.2150e-07, 3.2653e-09, 1.5769e-05, 4.8101e-02, 3.5113e-04,
        9.5123e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998211860657
 
[Iteration 3] Process ID: 216417 [Epoch: 5,  1152/ 2309 points] total loss per batch: 0.797
Policy (actual, predicted): 6 6
Policy data: tensor([1.0693e-14, 1.7418e-14, 6.1661e-23, 1.0693e-24, 0.0000e+00, 4.5177e-04,
        9.9955e-01], device='cuda:0')
Policy pred: tensor([4.9552e-05, 3.1590e-03, 2.6613e-07, 1.7336e-08, 2.2177e-07, 7.4738e-05,
        9.9672e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 5,  1728/ 2309 points] total loss per batch: 0.828
Policy (actual, predicted): 6 6
Policy data: tensor([1.9468e-13, 3.5401e-19, 9.5367e-17, 3.2197e-21, 2.8143e-06, 1.9468e-23,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([2.5246e-08, 2.7689e-07, 1.2306e-05, 2.7602e-04, 3.6705e-04, 3.7303e-05,
        9.9931e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999301433563232
 
[Iteration 3] Process ID: 216417 [Epoch: 5,  2304/ 2309 points] total loss per batch: 0.856
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 8.7583e-11, 1.4138e-02, 3.1006e-19, 0.0000e+00, 4.8902e-13,
        9.8586e-01], device='cuda:0')
Policy pred: tensor([2.9419e-06, 3.7345e-04, 3.2507e-03, 4.3574e-04, 3.3831e-08, 1.9488e-02,
        9.7645e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999601244926453
 
[Iteration 3] Process ID: 216417 [Epoch: 6,   576/ 2309 points] total loss per batch: 0.824
Policy (actual, predicted): 6 6
Policy data: tensor([0.0238, 0.0374, 0.0284, 0.0605, 0.0159, 0.1096, 0.7244],
       device='cuda:0')
Policy pred: tensor([0.0460, 0.0500, 0.0440, 0.0851, 0.0383, 0.1483, 0.5882],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.054320044815540314
 
[Iteration 3] Process ID: 216417 [Epoch: 6,  1152/ 2309 points] total loss per batch: 0.824
Policy (actual, predicted): 6 6
Policy data: tensor([6.8773e-07, 7.7869e-14, 8.1652e-18, 7.9738e-21, 3.9061e-03, 7.6044e-27,
        9.9609e-01], device='cuda:0')
Policy pred: tensor([1.6694e-04, 2.7376e-09, 3.0970e-05, 3.9178e-08, 4.2927e-06, 1.3727e-05,
        9.9978e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999988079071045
 
[Iteration 3] Process ID: 216417 [Epoch: 6,  1728/ 2309 points] total loss per batch: 0.748
Policy (actual, predicted): 5 5
Policy data: tensor([0.0151, 0.0043, 0.0080, 0.0168, 0.0251, 0.9155, 0.0151],
       device='cuda:0')
Policy pred: tensor([0.0105, 0.0023, 0.0054, 0.0133, 0.0174, 0.9382, 0.0130],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.15544475615024567
 
[Iteration 3] Process ID: 216417 [Epoch: 6,  2304/ 2309 points] total loss per batch: 0.796
Policy (actual, predicted): 0 0
Policy data: tensor([0.2507, 0.1776, 0.1360, 0.1360, 0.0780, 0.0858, 0.1360],
       device='cuda:0')
Policy pred: tensor([0.2590, 0.2112, 0.1418, 0.1391, 0.0480, 0.0962, 0.1048],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 7,   576/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 6 1
Policy data: tensor([0.1419, 0.1419, 0.1465, 0.1442, 0.1419, 0.1336, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1723, 0.2056, 0.1019, 0.1080, 0.1762, 0.1301, 0.1059],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9702378511428833
 
[Iteration 3] Process ID: 216417 [Epoch: 7,  1152/ 2309 points] total loss per batch: 0.807
Policy (actual, predicted): 4 4
Policy data: tensor([6.3865e-13, 1.3574e-09, 1.2062e-16, 4.0722e-21, 1.0000e+00, 2.5819e-17,
        2.2460e-08], device='cuda:0')
Policy pred: tensor([1.0370e-06, 4.2453e-04, 6.4342e-06, 6.7569e-07, 9.9955e-01, 3.5003e-06,
        1.4502e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9997795820236206
 
[Iteration 3] Process ID: 216417 [Epoch: 7,  1728/ 2309 points] total loss per batch: 0.770
Policy (actual, predicted): 1 1
Policy data: tensor([1.5772e-14, 1.0000e+00, 1.9468e-13, 5.4526e-26, 0.0000e+00, 7.3408e-18,
        5.0782e-15], device='cuda:0')
Policy pred: tensor([2.2824e-03, 9.9663e-01, 3.5573e-05, 3.0964e-04, 5.4318e-07, 7.1771e-04,
        2.3901e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999010562896729
 
[Iteration 3] Process ID: 216417 [Epoch: 7,  2304/ 2309 points] total loss per batch: 0.828
Policy (actual, predicted): 6 6
Policy data: tensor([3.5792e-10, 3.1058e-20, 2.2166e-16, 6.4925e-14, 1.1529e-22, 2.9203e-15,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([2.7401e-03, 1.9988e-03, 5.3827e-04, 3.1592e-04, 6.2670e-03, 3.2402e-03,
        9.8490e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9997783303260803
 
[Iteration 3] Process ID: 216417 [Epoch: 8,   576/ 2309 points] total loss per batch: 0.791
Policy (actual, predicted): 6 4
Policy data: tensor([0.1395, 0.1465, 0.1348, 0.1489, 0.1407, 0.1383, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1656, 0.1344, 0.1324, 0.1529, 0.1667, 0.1095, 0.1386],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9989014863967896
 
[Iteration 3] Process ID: 216417 [Epoch: 8,  1152/ 2309 points] total loss per batch: 0.842
Policy (actual, predicted): 4 4
Policy data: tensor([0.0225, 0.0094, 0.0177, 0.0094, 0.7021, 0.0145, 0.2243],
       device='cuda:0')
Policy pred: tensor([0.0260, 0.0135, 0.0216, 0.0108, 0.6317, 0.0170, 0.2794],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.5289595723152161
 
[Iteration 3] Process ID: 216417 [Epoch: 8,  1728/ 2309 points] total loss per batch: 0.773
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 9.9090e-01, 0.0000e+00, 3.3593e-08, 9.0964e-03, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.1854e-06, 9.9404e-01, 4.5004e-06, 2.0847e-04, 5.7229e-03, 1.5446e-05,
        5.4908e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998211860657
 
[Iteration 3] Process ID: 216417 [Epoch: 8,  2304/ 2309 points] total loss per batch: 0.759
Policy (actual, predicted): 1 1
Policy data: tensor([0.0950, 0.6641, 0.0311, 0.0141, 0.0340, 0.0340, 0.1277],
       device='cuda:0')
Policy pred: tensor([0.0957, 0.6644, 0.0283, 0.0156, 0.0303, 0.0443, 0.1214],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9792789816856384
 
[Iteration 3] Process ID: 216417 [Epoch: 9,   576/ 2309 points] total loss per batch: 0.749
Policy (actual, predicted): 4 4
Policy data: tensor([1.7112e-22, 4.9497e-21, 1.7523e-29, 1.7112e-22, 1.0000e+00, 1.7523e-29,
        1.0595e-21], device='cuda:0')
Policy pred: tensor([2.5820e-05, 1.1279e-04, 1.1224e-05, 2.1786e-04, 9.9958e-01, 2.2244e-05,
        2.6590e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.989919900894165
 
[Iteration 3] Process ID: 216417 [Epoch: 9,  1152/ 2309 points] total loss per batch: 0.767
Policy (actual, predicted): 3 3
Policy data: tensor([0., 0., 0., 1., 0., 0., 0.], device='cuda:0')
Policy pred: tensor([1.5304e-09, 1.3586e-09, 4.9638e-07, 9.9985e-01, 7.5686e-07, 3.0143e-06,
        1.4445e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 9,  1728/ 2309 points] total loss per batch: 0.839
Policy (actual, predicted): 2 2
Policy data: tensor([0.0547, 0.0159, 0.6857, 0.0041, 0.0852, 0.0059, 0.1485],
       device='cuda:0')
Policy pred: tensor([0.0635, 0.0097, 0.7259, 0.0034, 0.0780, 0.0086, 0.1108],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9990091323852539
 
[Iteration 3] Process ID: 216417 [Epoch: 9,  2304/ 2309 points] total loss per batch: 0.806
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 1.0995e-18, 1.0995e-18, 1.0000e+00, 0.0000e+00, 1.8184e-26,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.1483e-07, 3.4055e-04, 1.8419e-05, 9.9964e-01, 1.4025e-08, 1.0642e-06,
        9.4728e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999951124191284
 
[Iteration 3] Process ID: 216417 [Epoch: 10,   576/ 2309 points] total loss per batch: 0.786
Policy (actual, predicted): 0 0
Policy data: tensor([7.5001e-01, 1.0635e-16, 6.4476e-08, 3.1232e-23, 2.4999e-01, 8.4137e-11,
        1.8442e-18], device='cuda:0')
Policy pred: tensor([7.1693e-01, 1.3837e-04, 7.2825e-05, 5.9616e-06, 2.8281e-01, 2.2086e-05,
        2.6498e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.031162796542048454
 
[Iteration 3] Process ID: 216417 [Epoch: 10,  1152/ 2309 points] total loss per batch: 0.818
Policy (actual, predicted): 1 1
Policy data: tensor([9.6565e-22, 1.0000e+00, 1.5970e-29, 1.6746e-23, 1.6353e-26, 1.5970e-29,
        1.6746e-23], device='cuda:0')
Policy pred: tensor([3.0035e-06, 9.9940e-01, 1.4331e-06, 9.6891e-06, 2.3026e-04, 3.0531e-04,
        4.9638e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999991059303284
 
[Iteration 3] Process ID: 216417 [Epoch: 10,  1728/ 2309 points] total loss per batch: 0.743
Policy (actual, predicted): 0 6
Policy data: tensor([0.2094, 0.1496, 0.1425, 0.1235, 0.0734, 0.1103, 0.1912],
       device='cuda:0')
Policy pred: tensor([0.1953, 0.1773, 0.1226, 0.1044, 0.0868, 0.1002, 0.2135],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9823545813560486
 
[Iteration 3] Process ID: 216417 [Epoch: 10,  2304/ 2309 points] total loss per batch: 0.810
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 7.4638e-12, 0.0000e+00, 1.0000e+00, 9.4026e-16, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([7.4459e-10, 1.9136e-07, 2.9696e-07, 9.9997e-01, 3.3920e-05, 1.5517e-08,
        5.1361e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 11,   576/ 2309 points] total loss per batch: 0.801
Policy (actual, predicted): 6 6
Policy data: tensor([0.1656, 0.0513, 0.1333, 0.0378, 0.1284, 0.0976, 0.3859],
       device='cuda:0')
Policy pred: tensor([0.1937, 0.0799, 0.1324, 0.0376, 0.1359, 0.0854, 0.3351],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9969165325164795
 
[Iteration 3] Process ID: 216417 [Epoch: 11,  1152/ 2309 points] total loss per batch: 0.758
Policy (actual, predicted): 0 0
Policy data: tensor([0.6968, 0.0379, 0.2347, 0.0041, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6070, 0.0565, 0.2265, 0.0233, 0.0262, 0.0309, 0.0296],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.02640579268336296
 
[Iteration 3] Process ID: 216417 [Epoch: 11,  1728/ 2309 points] total loss per batch: 0.821
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 3.3603e-03, 2.6748e-13, 1.9403e-24, 0.0000e+00, 1.1732e-16,
        9.9664e-01], device='cuda:0')
Policy pred: tensor([3.9315e-07, 9.2785e-04, 1.1770e-05, 6.3311e-07, 9.7221e-12, 2.4727e-05,
        9.9903e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9997462630271912
 
[Iteration 3] Process ID: 216417 [Epoch: 11,  2304/ 2309 points] total loss per batch: 0.784
Policy (actual, predicted): 2 2
Policy data: tensor([0.0809, 0.0116, 0.8847, 0.0043, 0.0062, 0.0062, 0.0062],
       device='cuda:0')
Policy pred: tensor([0.0632, 0.0059, 0.9118, 0.0018, 0.0061, 0.0052, 0.0061],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9889755845069885
 
[Iteration 3] Process ID: 216417 [Epoch: 12,   576/ 2309 points] total loss per batch: 0.820
Policy (actual, predicted): 0 0
Policy data: tensor([9.6982e-01, 1.5738e-17, 3.0178e-02, 9.0755e-16, 1.4657e-16, 9.2933e-13,
        4.1404e-08], device='cuda:0')
Policy pred: tensor([9.3060e-01, 1.3351e-03, 4.9775e-02, 2.0472e-03, 5.5365e-03, 3.1907e-04,
        1.0386e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9947605729103088
 
[Iteration 3] Process ID: 216417 [Epoch: 12,  1152/ 2309 points] total loss per batch: 0.794
Policy (actual, predicted): 6 6
Policy data: tensor([0.1419, 0.1454, 0.1348, 0.1465, 0.1430, 0.1383, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1411, 0.1488, 0.1320, 0.1558, 0.1261, 0.1273, 0.1689],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.982610285282135
 
[Iteration 3] Process ID: 216417 [Epoch: 12,  1728/ 2309 points] total loss per batch: 0.786
Policy (actual, predicted): 2 2
Policy data: tensor([0.0825, 0.0594, 0.6190, 0.0092, 0.1712, 0.0092, 0.0496],
       device='cuda:0')
Policy pred: tensor([0.0969, 0.0535, 0.5483, 0.0059, 0.2697, 0.0067, 0.0189],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 12,  2304/ 2309 points] total loss per batch: 0.837
Policy (actual, predicted): 6 6
Policy data: tensor([1.2579e-13, 3.9562e-12, 1.7213e-20, 6.3895e-23, 1.2284e-16, 3.5981e-24,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([2.2976e-06, 4.0852e-05, 9.5732e-09, 5.5383e-10, 2.1588e-05, 4.1124e-07,
        9.9993e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999927878379822
 
[Iteration 3] Process ID: 216417 [Epoch: 13,   576/ 2309 points] total loss per batch: 0.814
Policy (actual, predicted): 0 0
Policy data: tensor([0.9000, 0.0062, 0.0062, 0.0043, 0.0080, 0.0315, 0.0440],
       device='cuda:0')
Policy pred: tensor([0.8910, 0.0057, 0.0072, 0.0092, 0.0123, 0.0382, 0.0364],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9968962669372559
 
[Iteration 3] Process ID: 216417 [Epoch: 13,  1152/ 2309 points] total loss per batch: 0.838
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 4.2208e-03, 3.0258e-12, 2.0716e-21, 9.9578e-01, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.9241e-09, 6.8956e-03, 6.3685e-05, 1.6752e-04, 9.9287e-01, 6.6403e-06,
        1.8745e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 13,  1728/ 2309 points] total loss per batch: 0.778
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 4.1378e-08, 9.7179e-07, 5.6112e-28, 0.0000e+00, 1.0000e+00,
        1.6231e-16], device='cuda:0')
Policy pred: tensor([6.5054e-13, 2.7410e-03, 3.8166e-04, 1.7712e-07, 2.0387e-12, 9.9688e-01,
        1.2058e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 13,  2304/ 2309 points] total loss per batch: 0.834
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 3.9480e-18, 2.0984e-17, 2.6622e-09, 1.6344e-19, 0.0000e+00,
        3.8554e-11], device='cuda:0')
Policy pred: tensor([1.0000e+00, 9.1062e-10, 2.9584e-08, 7.0961e-13, 3.0266e-07, 1.2523e-11,
        4.3666e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 14,   576/ 2309 points] total loss per batch: 0.855
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 7.9033e-01, 0.0000e+00, 3.5082e-05, 2.0964e-01, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.3489e-03, 4.9981e-01, 7.0024e-08, 1.5861e-03, 4.9725e-01, 2.7826e-07,
        5.4200e-14], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 14,  1152/ 2309 points] total loss per batch: 0.826
Policy (actual, predicted): 5 5
Policy data: tensor([0.0147, 0.0079, 0.0131, 0.0060, 0.0308, 0.8202, 0.1073],
       device='cuda:0')
Policy pred: tensor([0.0109, 0.0095, 0.0132, 0.0070, 0.0172, 0.8562, 0.0858],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.39939749240875244
 
[Iteration 3] Process ID: 216417 [Epoch: 14,  1728/ 2309 points] total loss per batch: 0.855
Policy (actual, predicted): 6 6
Policy data: tensor([0.1441, 0.0000, 0.1638, 0.2384, 0.0000, 0.0213, 0.4324],
       device='cuda:0')
Policy pred: tensor([1.7497e-01, 8.8432e-06, 2.1617e-01, 1.7255e-01, 3.1124e-04, 6.1552e-02,
        3.7444e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.99994957447052
 
[Iteration 3] Process ID: 216417 [Epoch: 14,  2304/ 2309 points] total loss per batch: 0.821
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1172e-04, 0.0000e+00, 9.9959e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([6.3323e-11, 5.9949e-12, 1.2477e-10, 1.7834e-02, 6.8895e-06, 9.8092e-01,
        1.2390e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9996694326400757
 
[Iteration 3] Process ID: 216417 [Epoch: 15,   576/ 2309 points] total loss per batch: 0.861
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 9.9620e-01, 2.9259e-03, 0.0000e+00, 8.7467e-04,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([8.1488e-08, 5.0174e-05, 9.8457e-01, 7.6878e-03, 7.5389e-06, 7.6547e-03,
        3.0192e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 15,  1152/ 2309 points] total loss per batch: 0.750
Policy (actual, predicted): 6 6
Policy data: tensor([0.0664, 0.0080, 0.0062, 0.0062, 0.0150, 0.0062, 0.8920],
       device='cuda:0')
Policy pred: tensor([0.0876, 0.0082, 0.0050, 0.0198, 0.0305, 0.0246, 0.8243],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.8840949535369873
 
[Iteration 3] Process ID: 216417 [Epoch: 15,  1728/ 2309 points] total loss per batch: 0.894
Policy (actual, predicted): 5 5
Policy data: tensor([0.0116, 0.0098, 0.0043, 0.0201, 0.0485, 0.8978, 0.0080],
       device='cuda:0')
Policy pred: tensor([0.0118, 0.0126, 0.0036, 0.0236, 0.0652, 0.8742, 0.0090],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.1883143186569214
 
[Iteration 3] Process ID: 216417 [Epoch: 15,  2304/ 2309 points] total loss per batch: 0.845
Policy (actual, predicted): 6 6
Policy data: tensor([0.0291, 0.0163, 0.0113, 0.0163, 0.0130, 0.1041, 0.8098],
       device='cuda:0')
Policy pred: tensor([0.0098, 0.0077, 0.0022, 0.0081, 0.0029, 0.0969, 0.8723],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999756813049316
 
[Iteration 3] Process ID: 216417 [Epoch: 16,   576/ 2309 points] total loss per batch: 0.778
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 0.0000e+00, 3.9705e-10, 9.2319e-05, 0.0000e+00, 9.9991e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.8424e-09, 2.8321e-13, 7.2038e-04, 3.6175e-04, 4.4256e-08, 9.9892e-01,
        5.0023e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 16,  1152/ 2309 points] total loss per batch: 0.891
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 3.5393e-05, 9.9996e-01, 2.3740e-23, 3.8341e-14, 4.1168e-25,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.2516e-08, 1.5901e-04, 9.9981e-01, 6.1480e-07, 1.4756e-05, 1.6880e-05,
        1.5068e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9903360605239868
 
[Iteration 3] Process ID: 216417 [Epoch: 16,  1728/ 2309 points] total loss per batch: 0.784
Policy (actual, predicted): 0 0
Policy data: tensor([0.5124, 0.0000, 0.0489, 0.0000, 0.0000, 0.3183, 0.1203],
       device='cuda:0')
Policy pred: tensor([4.7800e-01, 1.0958e-04, 8.2306e-02, 7.7631e-04, 1.2346e-06, 3.0032e-01,
        1.3848e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999996423721313
 
[Iteration 3] Process ID: 216417 [Epoch: 16,  2304/ 2309 points] total loss per batch: 0.805
Policy (actual, predicted): 5 5
Policy data: tensor([6.7363e-11, 0.0000e+00, 3.7842e-26, 3.6955e-19, 0.0000e+00, 1.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([8.5444e-06, 5.9338e-11, 7.6079e-06, 1.2299e-05, 1.6122e-12, 9.9997e-01,
        3.2385e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 17,   576/ 2309 points] total loss per batch: 0.843
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 1.0116e-05, 1.4199e-05, 2.7073e-15, 6.9553e-19, 9.9998e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.6463e-06, 2.6894e-05, 3.4167e-05, 2.7150e-03, 7.5693e-07, 9.9721e-01,
        9.4223e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 17,  1152/ 2309 points] total loss per batch: 0.784
Policy (actual, predicted): 4 4
Policy data: tensor([3.0517e-01, 6.2266e-03, 1.9517e-01, 7.7792e-15, 4.9323e-01, 4.3807e-16,
        2.0177e-04], device='cuda:0')
Policy pred: tensor([2.4587e-01, 1.0307e-02, 1.7172e-01, 9.7988e-04, 5.6111e-01, 3.5997e-04,
        9.6499e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999992251396179
 
[Iteration 3] Process ID: 216417 [Epoch: 17,  1728/ 2309 points] total loss per batch: 0.746
Policy (actual, predicted): 3 3
Policy data: tensor([0.0303, 0.0145, 0.0257, 0.7716, 0.0641, 0.0059, 0.0879],
       device='cuda:0')
Policy pred: tensor([0.0286, 0.0148, 0.0199, 0.8018, 0.0584, 0.0049, 0.0715],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.96803218126297
 
[Iteration 3] Process ID: 216417 [Epoch: 17,  2304/ 2309 points] total loss per batch: 0.815
Policy (actual, predicted): 6 6
Policy data: tensor([2.3068e-15, 1.5730e-20, 6.6289e-12, 3.3671e-21, 5.5685e-19, 5.5685e-19,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([1.1317e-07, 3.8982e-09, 4.8577e-07, 3.3949e-09, 1.6297e-06, 2.0379e-08,
        1.0000e+00], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999874234199524
 
[Iteration 3] Process ID: 216417 [Epoch: 18,   576/ 2309 points] total loss per batch: 0.793
Policy (actual, predicted): 6 6
Policy data: tensor([2.9934e-09, 6.9365e-11, 2.5361e-05, 2.6367e-20, 7.2735e-15, 1.0592e-03,
        9.9892e-01], device='cuda:0')
Policy pred: tensor([2.4705e-03, 9.5981e-04, 1.8574e-04, 1.3729e-03, 4.8769e-05, 8.2144e-05,
        9.9488e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999997615814209
 
[Iteration 3] Process ID: 216417 [Epoch: 18,  1152/ 2309 points] total loss per batch: 0.805
Policy (actual, predicted): 4 4
Policy data: tensor([2.5212e-05, 1.5478e-15, 0.0000e+00, 5.0395e-14, 9.6602e-01, 3.3955e-02,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.1478e-01, 1.0482e-03, 2.7833e-07, 1.6969e-03, 8.0215e-01, 8.0318e-02,
        3.1410e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 18,  1728/ 2309 points] total loss per batch: 0.749
Policy (actual, predicted): 2 2
Policy data: tensor([0.0581, 0.0728, 0.5311, 0.0288, 0.1711, 0.0316, 0.1065],
       device='cuda:0')
Policy pred: tensor([0.0465, 0.0908, 0.5652, 0.0394, 0.1195, 0.0419, 0.0966],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999925494194031
 
[Iteration 3] Process ID: 216417 [Epoch: 18,  2304/ 2309 points] total loss per batch: 0.840
Policy (actual, predicted): 4 4
Policy data: tensor([0.1584, 0.1010, 0.1252, 0.0724, 0.2831, 0.1490, 0.1108],
       device='cuda:0')
Policy pred: tensor([0.1519, 0.0753, 0.1515, 0.0588, 0.2986, 0.1604, 0.1034],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9994935989379883
 
[Iteration 3] Process ID: 216417 [Epoch: 19,   576/ 2309 points] total loss per batch: 0.805
Policy (actual, predicted): 1 1
Policy data: tensor([0.0998, 0.6876, 0.0159, 0.0000, 0.0000, 0.1552, 0.0416],
       device='cuda:0')
Policy pred: tensor([7.7448e-02, 7.7137e-01, 2.0078e-02, 1.2089e-04, 2.6288e-06, 9.4100e-02,
        3.6879e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998211860657
 
[Iteration 3] Process ID: 216417 [Epoch: 19,  1152/ 2309 points] total loss per batch: 0.774
Policy (actual, predicted): 4 4
Policy data: tensor([0.0184, 0.0133, 0.0116, 0.0062, 0.9007, 0.0201, 0.0298],
       device='cuda:0')
Policy pred: tensor([0.0177, 0.0120, 0.0157, 0.0113, 0.8805, 0.0321, 0.0307],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9995596408843994
 
[Iteration 3] Process ID: 216417 [Epoch: 19,  1728/ 2309 points] total loss per batch: 0.768
Policy (actual, predicted): 1 1
Policy data: tensor([4.8699e-11, 1.0000e+00, 1.7654e-16, 2.9897e-21, 0.0000e+00, 3.0614e-18,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([7.9581e-07, 9.9974e-01, 6.4970e-07, 1.7569e-10, 1.2749e-07, 3.8003e-05,
        2.2518e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999997615814209
 
[Iteration 3] Process ID: 216417 [Epoch: 19,  2304/ 2309 points] total loss per batch: 0.801
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 7.8222e-16, 1.0269e-19, 8.5189e-18, 1.0515e-16,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.6928e-09, 9.9979e-01, 3.0650e-05, 1.7319e-04, 6.4122e-06, 3.0893e-07,
        3.1762e-12], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 20,   576/ 2309 points] total loss per batch: 0.785
Policy (actual, predicted): 4 4
Policy data: tensor([1.7112e-22, 4.9497e-21, 1.7523e-29, 1.7112e-22, 1.0000e+00, 1.7523e-29,
        1.0595e-21], device='cuda:0')
Policy pred: tensor([3.7584e-05, 1.2339e-04, 1.5090e-05, 1.1242e-04, 9.9943e-01, 4.9860e-05,
        2.3294e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9727782607078552
 
[Iteration 3] Process ID: 216417 [Epoch: 20,  1152/ 2309 points] total loss per batch: 0.799
Policy (actual, predicted): 0 0
Policy data: tensor([0.8180, 0.0196, 0.0180, 0.0022, 0.0459, 0.0228, 0.0735],
       device='cuda:0')
Policy pred: tensor([0.8122, 0.0185, 0.0228, 0.0028, 0.0457, 0.0254, 0.0725],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.5288403034210205
 
[Iteration 3] Process ID: 216417 [Epoch: 20,  1728/ 2309 points] total loss per batch: 0.799
Policy (actual, predicted): 6 6
Policy data: tensor([0.1465, 0.1419, 0.1442, 0.1383, 0.1395, 0.1348, 0.1547],
       device='cuda:0')
Policy pred: tensor([0.1444, 0.1503, 0.1341, 0.1477, 0.1569, 0.1057, 0.1610],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998970031738281
 
[Iteration 3] Process ID: 216417 [Epoch: 20,  2304/ 2309 points] total loss per batch: 0.763
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 1.0290e-20, 0.0000e+00, 3.6429e-19, 4.0054e-17, 1.0000e+00,
        1.2404e-12], device='cuda:0')
Policy pred: tensor([3.9412e-09, 1.6444e-03, 5.2751e-07, 1.7299e-04, 1.1569e-03, 9.9464e-01,
        2.3807e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999818801879883
 
[Iteration 3] Process ID: 216417 [Epoch: 21,   576/ 2309 points] total loss per batch: 0.777
Policy (actual, predicted): 6 5
Policy data: tensor([0.1430, 0.1466, 0.1384, 0.1454, 0.1360, 0.1313, 0.1594],
       device='cuda:0')
Policy pred: tensor([0.1397, 0.1459, 0.1103, 0.1558, 0.1397, 0.1657, 0.1429],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999989867210388
 
[Iteration 3] Process ID: 216417 [Epoch: 21,  1152/ 2309 points] total loss per batch: 0.795
Policy (actual, predicted): 1 1
Policy data: tensor([0.1501, 0.1512, 0.1466, 0.1277, 0.1454, 0.1372, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1442, 0.1719, 0.1457, 0.1196, 0.1502, 0.1266, 0.1418],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999883770942688
 
[Iteration 3] Process ID: 216417 [Epoch: 21,  1728/ 2309 points] total loss per batch: 0.734
Policy (actual, predicted): 6 2
Policy data: tensor([0.1430, 0.1442, 0.1348, 0.1454, 0.1407, 0.1454, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1383, 0.1493, 0.1591, 0.1446, 0.1385, 0.1258, 0.1445],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9997601509094238
 
[Iteration 3] Process ID: 216417 [Epoch: 21,  2304/ 2309 points] total loss per batch: 0.829
Policy (actual, predicted): 3 3
Policy data: tensor([0., 0., 0., 1., 0., 0., 0.], device='cuda:0')
Policy pred: tensor([1.0845e-09, 5.3763e-08, 7.5395e-07, 9.9992e-01, 2.2291e-08, 1.6888e-05,
        5.7636e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 22,   576/ 2309 points] total loss per batch: 0.786
Policy (actual, predicted): 1 1
Policy data: tensor([0.2790, 0.3923, 0.0901, 0.0341, 0.0534, 0.0197, 0.1314],
       device='cuda:0')
Policy pred: tensor([0.2496, 0.4252, 0.1020, 0.0428, 0.0532, 0.0119, 0.1153],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999458193778992
 
[Iteration 3] Process ID: 216417 [Epoch: 22,  1152/ 2309 points] total loss per batch: 0.742
Policy (actual, predicted): 0 0
Policy data: tensor([0.3022, 0.1275, 0.1665, 0.0604, 0.1665, 0.0604, 0.1165],
       device='cuda:0')
Policy pred: tensor([0.2885, 0.1193, 0.1372, 0.0745, 0.1739, 0.0760, 0.1307],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 22,  1728/ 2309 points] total loss per batch: 0.797
Policy (actual, predicted): 1 1
Policy data: tensor([0.0023, 0.9141, 0.0023, 0.0023, 0.0043, 0.0062, 0.0685],
       device='cuda:0')
Policy pred: tensor([0.0029, 0.9235, 0.0033, 0.0036, 0.0088, 0.0084, 0.0496],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9601662755012512
 
[Iteration 3] Process ID: 216417 [Epoch: 22,  2304/ 2309 points] total loss per batch: 0.811
Policy (actual, predicted): 1 1
Policy data: tensor([8.1359e-06, 9.9716e-01, 2.8324e-03, 8.2520e-07, 7.9452e-09, 1.0937e-06,
        1.7664e-07], device='cuda:0')
Policy pred: tensor([1.2617e-04, 9.9599e-01, 1.7109e-03, 3.2490e-04, 5.9399e-04, 1.1782e-03,
        7.7538e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999902844429016
 
[Iteration 3] Process ID: 216417 [Epoch: 23,   576/ 2309 points] total loss per batch: 0.729
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 3.2784e-13, 0.0000e+00, 8.7882e-06, 0.0000e+00, 9.9999e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.6442e-12, 1.3796e-03, 1.5191e-09, 7.5772e-04, 2.6285e-07, 9.9786e-01,
        7.8411e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 23,  1152/ 2309 points] total loss per batch: 0.815
Policy (actual, predicted): 4 4
Policy data: tensor([2.2497e-18, 3.0969e-16, 5.5762e-10, 9.0949e-23, 1.0000e+00, 3.0243e-19,
        3.0969e-16], device='cuda:0')
Policy pred: tensor([9.2363e-04, 2.1076e-05, 3.4537e-04, 1.1081e-04, 9.9826e-01, 5.3974e-05,
        2.8819e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999997019767761
 
[Iteration 3] Process ID: 216417 [Epoch: 23,  1728/ 2309 points] total loss per batch: 0.855
Policy (actual, predicted): 0 0
Policy data: tensor([0.6019, 0.0000, 0.1298, 0.0000, 0.0000, 0.0708, 0.1974],
       device='cuda:0')
Policy pred: tensor([6.1470e-01, 2.5059e-04, 9.5292e-02, 3.6636e-05, 1.5931e-08, 9.0125e-02,
        1.9959e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999995827674866
 
[Iteration 3] Process ID: 216417 [Epoch: 23,  2304/ 2309 points] total loss per batch: 0.732
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 9.9998e-01, 2.3810e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.3161e-10, 3.7073e-13, 9.9942e-01, 5.7859e-04, 3.0226e-09, 4.9931e-09,
        6.4353e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 24,   576/ 2309 points] total loss per batch: 0.821
Policy (actual, predicted): 2 3
Policy data: tensor([0.1419, 0.1477, 0.1489, 0.1442, 0.1336, 0.1372, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1389, 0.1508, 0.1493, 0.1585, 0.1343, 0.1140, 0.1542],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 24,  1152/ 2309 points] total loss per batch: 0.779
Policy (actual, predicted): 4 4
Policy data: tensor([0.1501, 0.1442, 0.1454, 0.1325, 0.1512, 0.1360, 0.1407],
       device='cuda:0')
Policy pred: tensor([0.1423, 0.1462, 0.1506, 0.1283, 0.1661, 0.1392, 0.1273],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9935910701751709
 
[Iteration 3] Process ID: 216417 [Epoch: 24,  1728/ 2309 points] total loss per batch: 0.796
Policy (actual, predicted): 6 6
Policy data: tensor([3.0476e-03, 2.6844e-14, 2.4415e-16, 1.4417e-21, 8.8390e-09, 1.7834e-05,
        9.9693e-01], device='cuda:0')
Policy pred: tensor([3.1113e-04, 2.8655e-06, 1.8808e-04, 5.5132e-05, 3.8430e-04, 5.5780e-04,
        9.9850e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9989461898803711
 
[Iteration 3] Process ID: 216417 [Epoch: 24,  2304/ 2309 points] total loss per batch: 0.741
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 8.2529e-22, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([6.8604e-10, 9.9991e-01, 3.3527e-09, 8.7679e-05, 1.6902e-10, 1.3750e-07,
        2.5349e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999908208847046
 
[Iteration 3] Process ID: 216417 [Epoch: 25,   576/ 2309 points] total loss per batch: 0.720
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 1.7574e-22, 1.0378e-17, 1.8428e-26, 0.0000e+00, 1.7574e-22,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9870e-01, 3.0873e-06, 1.9325e-06, 1.3829e-06, 1.9230e-10, 2.2745e-07,
        1.2952e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 25,  1152/ 2309 points] total loss per batch: 0.805
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0274, 0.1153, 0.3215, 0.0092, 0.0083, 0.0134, 0.5049],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.033866994082927704
 
[Iteration 3] Process ID: 216417 [Epoch: 25,  1728/ 2309 points] total loss per batch: 0.844
Policy (actual, predicted): 6 6
Policy data: tensor([0.0146, 0.0228, 0.0427, 0.0195, 0.0321, 0.0531, 0.8151],
       device='cuda:0')
Policy pred: tensor([0.0172, 0.0255, 0.0404, 0.0250, 0.0356, 0.0458, 0.8106],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9942036867141724
 
[Iteration 3] Process ID: 216417 [Epoch: 25,  2304/ 2309 points] total loss per batch: 0.756
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0839, 0.0231, 0.0243, 0.0240, 0.0607, 0.0558, 0.7281],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.019356204196810722
 
[Iteration 3] Process ID: 216417 [Epoch: 26,   576/ 2309 points] total loss per batch: 0.789
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 6.7347e-11, 4.6272e-17, 0.0000e+00, 8.2168e-26,
        1.1599e-11], device='cuda:0')
Policy pred: tensor([7.6327e-10, 9.9913e-01, 5.0490e-04, 3.2214e-05, 3.1589e-13, 1.8354e-06,
        3.3417e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 26,  1152/ 2309 points] total loss per batch: 0.759
Policy (actual, predicted): 3 3
Policy data: tensor([0.1524, 0.1524, 0.0799, 0.2164, 0.1162, 0.1162, 0.1666],
       device='cuda:0')
Policy pred: tensor([0.1555, 0.1713, 0.0781, 0.2147, 0.0999, 0.1277, 0.1528],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998211860657
 
[Iteration 3] Process ID: 216417 [Epoch: 26,  1728/ 2309 points] total loss per batch: 0.785
Policy (actual, predicted): 6 6
Policy data: tensor([0.0255, 0.0144, 0.0128, 0.0128, 0.2737, 0.0077, 0.6531],
       device='cuda:0')
Policy pred: tensor([0.0286, 0.0160, 0.0162, 0.0117, 0.2530, 0.0081, 0.6665],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.7682330012321472
 
[Iteration 3] Process ID: 216417 [Epoch: 26,  2304/ 2309 points] total loss per batch: 0.798
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0650e-25, 1.0000e+00, 1.5720e-26,
        1.5352e-19], device='cuda:0')
Policy pred: tensor([2.0687e-12, 1.1038e-13, 9.3659e-11, 9.9845e-06, 9.9998e-01, 2.0543e-07,
        6.3406e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 27,   576/ 2309 points] total loss per batch: 0.792
Policy (actual, predicted): 6 6
Policy data: tensor([7.6505e-11, 3.8265e-07, 4.4117e-09, 2.8150e-12, 2.0665e-02, 3.5741e-09,
        9.7933e-01], device='cuda:0')
Policy pred: tensor([1.2484e-03, 3.5954e-05, 6.3753e-05, 1.9978e-04, 1.0210e-02, 2.3920e-04,
        9.8800e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 27,  1152/ 2309 points] total loss per batch: 0.765
Policy (actual, predicted): 5 5
Policy data: tensor([0.0500, 0.1306, 0.0458, 0.0444, 0.1130, 0.5567, 0.0595],
       device='cuda:0')
Policy pred: tensor([0.0348, 0.1278, 0.0514, 0.0341, 0.1000, 0.6029, 0.0489],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999629259109497
 
[Iteration 3] Process ID: 216417 [Epoch: 27,  1728/ 2309 points] total loss per batch: 0.811
Policy (actual, predicted): 3 4
Policy data: tensor([0.0000, 0.1798, 0.0882, 0.2429, 0.2255, 0.1318, 0.1318],
       device='cuda:0')
Policy pred: tensor([3.3600e-06, 1.5031e-01, 8.9962e-02, 2.3776e-01, 2.4415e-01, 1.4616e-01,
        1.3166e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 27,  2304/ 2309 points] total loss per batch: 0.753
Policy (actual, predicted): 0 0
Policy data: tensor([9.3255e-01, 8.5882e-14, 1.0790e-08, 9.2065e-10, 1.2618e-11, 1.2618e-11,
        6.7448e-02], device='cuda:0')
Policy pred: tensor([0.8324, 0.0049, 0.0204, 0.0014, 0.0042, 0.0150, 0.1219],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9995099902153015
 
[Iteration 3] Process ID: 216417 [Epoch: 28,   576/ 2309 points] total loss per batch: 0.772
Policy (actual, predicted): 6 6
Policy data: tensor([3.5792e-10, 3.1058e-20, 2.2166e-16, 6.4925e-14, 1.1529e-22, 2.9203e-15,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([4.4387e-05, 1.8810e-04, 2.3941e-05, 2.4088e-05, 7.1034e-05, 2.8209e-05,
        9.9962e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999861717224121
 
[Iteration 3] Process ID: 216417 [Epoch: 28,  1152/ 2309 points] total loss per batch: 0.801
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 3.8003e-08, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.2464e-09, 9.9988e-01, 8.7054e-12, 1.1541e-04, 5.6824e-11, 2.5342e-09,
        3.5161e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 28,  1728/ 2309 points] total loss per batch: 0.795
Policy (actual, predicted): 1 1
Policy data: tensor([1.8456e-16, 1.0000e+00, 5.1689e-19, 3.0522e-24, 1.0671e-13, 1.4601e-20,
        3.0522e-14], device='cuda:0')
Policy pred: tensor([1.1293e-05, 9.9945e-01, 2.4289e-05, 1.9118e-08, 4.3654e-05, 1.3051e-04,
        3.4525e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999025464057922
 
[Iteration 3] Process ID: 216417 [Epoch: 28,  2304/ 2309 points] total loss per batch: 0.776
Policy (actual, predicted): 2 2
Policy data: tensor([0.0289, 0.0336, 0.7968, 0.0095, 0.0095, 0.0572, 0.0644],
       device='cuda:0')
Policy pred: tensor([0.0355, 0.0300, 0.7502, 0.0109, 0.0218, 0.0469, 0.1047],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9843546152114868
 
[Iteration 3] Process ID: 216417 [Epoch: 29,   576/ 2309 points] total loss per batch: 0.808
Policy (actual, predicted): 1 1
Policy data: tensor([0.0093, 0.5251, 0.3807, 0.0093, 0.0206, 0.0076, 0.0474],
       device='cuda:0')
Policy pred: tensor([0.0084, 0.5075, 0.3901, 0.0096, 0.0312, 0.0077, 0.0454],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.1889476478099823
 
[Iteration 3] Process ID: 216417 [Epoch: 29,  1152/ 2309 points] total loss per batch: 0.803
Policy (actual, predicted): 0 2
Policy data: tensor([0.1547, 0.1466, 0.1466, 0.1265, 0.1489, 0.1372, 0.1395],
       device='cuda:0')
Policy pred: tensor([0.1507, 0.1491, 0.1654, 0.1140, 0.1436, 0.1374, 0.1398],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999886751174927
 
[Iteration 3] Process ID: 216417 [Epoch: 29,  1728/ 2309 points] total loss per batch: 0.751
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000, 0.0000, 0.1698, 0.0400, 0.1593, 0.2055, 0.4254],
       device='cuda:0')
Policy pred: tensor([1.7186e-05, 2.5398e-05, 1.7408e-01, 4.3559e-02, 2.0915e-01, 1.7700e-01,
        3.9617e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998185038566589
 
[Iteration 3] Process ID: 216417 [Epoch: 29,  2304/ 2309 points] total loss per batch: 0.766
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5482e-18, 1.9847e-20, 1.9847e-20,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([6.9938e-09, 2.7314e-09, 8.6981e-08, 9.0092e-05, 1.1347e-04, 6.1727e-05,
        9.9973e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 30,   576/ 2309 points] total loss per batch: 0.767
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 0.0000e+00, 1.7930e-22, 3.8750e-06, 0.0000e+00, 1.7510e-25,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9989e-01, 1.4755e-06, 1.3469e-05, 9.2984e-05, 1.1710e-07, 3.5297e-06,
        9.7798e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999976754188538
 
[Iteration 3] Process ID: 216417 [Epoch: 30,  1152/ 2309 points] total loss per batch: 0.812
Policy (actual, predicted): 6 0
Policy data: tensor([0.4201, 0.0126, 0.0221, 0.0058, 0.0190, 0.0386, 0.4818],
       device='cuda:0')
Policy pred: tensor([0.4694, 0.0111, 0.0238, 0.0095, 0.0378, 0.0509, 0.3975],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.013880184851586819
 
[Iteration 3] Process ID: 216417 [Epoch: 30,  1728/ 2309 points] total loss per batch: 0.810
Policy (actual, predicted): 3 3
Policy data: tensor([0., 0., 0., 1., 0., 0., 0.], device='cuda:0')
Policy pred: tensor([1.1482e-10, 4.8806e-09, 8.4502e-08, 9.9997e-01, 3.2021e-09, 2.3072e-05,
        1.1690e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 30,  2304/ 2309 points] total loss per batch: 0.740
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 2.8964e-22, 2.7622e-18, 2.8285e-25, 2.4981e-08, 2.8285e-25,
        8.6129e-09], device='cuda:0')
Policy pred: tensor([9.9478e-01, 3.6978e-04, 5.9135e-04, 1.2956e-04, 2.2623e-03, 4.2088e-05,
        1.8227e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999361634254456
 
[Iteration 3] Process ID: 216417 [Epoch: 31,   576/ 2309 points] total loss per batch: 0.767
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 3.2790e-16, 1.3290e-08, 1.6655e-15, 1.5884e-21, 4.4868e-13,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9941e-01, 3.6884e-05, 4.7524e-04, 7.8846e-05, 1.7830e-06, 2.0918e-06,
        5.8675e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999994039535522
 
[Iteration 3] Process ID: 216417 [Epoch: 31,  1152/ 2309 points] total loss per batch: 0.808
Policy (actual, predicted): 1 1
Policy data: tensor([1.1599e-18, 1.0000e+00, 1.8733e-19, 1.8733e-29, 1.8733e-29, 1.1062e-24,
        1.1062e-24], device='cuda:0')
Policy pred: tensor([7.5737e-08, 9.9959e-01, 2.5929e-04, 5.1394e-07, 1.6402e-06, 1.3526e-04,
        8.4932e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999999463558197
 
[Iteration 3] Process ID: 216417 [Epoch: 31,  1728/ 2309 points] total loss per batch: 0.773
Policy (actual, predicted): 0 0
Policy data: tensor([0.5124, 0.0000, 0.0489, 0.0000, 0.0000, 0.3183, 0.1203],
       device='cuda:0')
Policy pred: tensor([5.3701e-01, 9.0496e-05, 5.8515e-02, 1.0885e-04, 2.3909e-07, 2.6233e-01,
        1.4194e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999992251396179
 
[Iteration 3] Process ID: 216417 [Epoch: 31,  2304/ 2309 points] total loss per batch: 0.778
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 1.8443e-17, 2.2232e-19, 6.6859e-23, 6.2267e-22, 7.3512e-11,
        6.5292e-16], device='cuda:0')
Policy pred: tensor([9.9995e-01, 7.1473e-06, 4.7511e-07, 6.5397e-08, 3.4209e-06, 1.1177e-05,
        2.4183e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999403953552246
 
[Iteration 3] Process ID: 216417 [Epoch: 32,   576/ 2309 points] total loss per batch: 0.774
Policy (actual, predicted): 4 4
Policy data: tensor([0.0598, 0.0114, 0.0403, 0.0079, 0.8565, 0.0042, 0.0198],
       device='cuda:0')
Policy pred: tensor([0.0499, 0.0103, 0.0330, 0.0068, 0.8616, 0.0191, 0.0194],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999951720237732
 
[Iteration 3] Process ID: 216417 [Epoch: 32,  1152/ 2309 points] total loss per batch: 0.775
Policy (actual, predicted): 0 0
Policy data: tensor([0.5905, 0.0234, 0.0381, 0.0021, 0.0648, 0.0648, 0.2163],
       device='cuda:0')
Policy pred: tensor([0.6295, 0.0280, 0.0344, 0.0027, 0.0548, 0.0407, 0.2098],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9989652037620544
 
[Iteration 3] Process ID: 216417 [Epoch: 32,  1728/ 2309 points] total loss per batch: 0.755
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000, 0.0000, 0.9981, 0.0019, 0.0000, 0.0000, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.0901e-07, 7.4881e-08, 9.9820e-01, 1.7930e-03, 1.2576e-06, 7.5161e-07,
        2.2396e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 32,  2304/ 2309 points] total loss per batch: 0.826
Policy (actual, predicted): 6 6
Policy data: tensor([0.2143, 0.1154, 0.0388, 0.0039, 0.0000, 0.2096, 0.4181],
       device='cuda:0')
Policy pred: tensor([2.1698e-01, 1.1587e-01, 6.1199e-02, 3.2196e-03, 2.1258e-07, 1.7964e-01,
        4.2309e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 33,   576/ 2309 points] total loss per batch: 0.802
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 4.0505e-12, 1.9945e-13, 1.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.8243e-07, 3.1350e-03, 1.9315e-04, 9.9666e-01, 8.4383e-06, 4.4047e-08,
        4.4189e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999987483024597
 
[Iteration 3] Process ID: 216417 [Epoch: 33,  1152/ 2309 points] total loss per batch: 0.778
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 1.0000e+00, 8.6941e-22, 1.5077e-23, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.0558e-10, 5.9470e-14, 9.9994e-01, 5.5184e-06, 5.0619e-05, 6.7213e-09,
        1.5472e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 33,  1728/ 2309 points] total loss per batch: 0.741
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 8.2438e-15, 1.0000e+00, 1.9900e-18, 0.0000e+00, 7.1051e-16,
        4.3076e-07], device='cuda:0')
Policy pred: tensor([1.1276e-06, 1.0757e-03, 9.9793e-01, 7.7729e-05, 3.1602e-10, 1.7913e-05,
        8.9346e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 33,  2304/ 2309 points] total loss per batch: 0.804
Policy (actual, predicted): 4 4
Policy data: tensor([0.0167, 0.0080, 0.0133, 0.0080, 0.8862, 0.0513, 0.0167],
       device='cuda:0')
Policy pred: tensor([0.0919, 0.0854, 0.0834, 0.0995, 0.4416, 0.1107, 0.0875],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.4089096486568451
 
[Iteration 3] Process ID: 216417 [Epoch: 34,   576/ 2309 points] total loss per batch: 0.863
Policy (actual, predicted): 1 1
Policy data: tensor([2.9868e-19, 1.0000e+00, 8.4369e-21, 3.2840e-17, 1.0664e-16, 4.1175e-18,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.1124e-06, 9.9994e-01, 2.3632e-07, 2.2138e-05, 3.0566e-05, 1.5835e-06,
        6.6236e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999905228614807
 
[Iteration 3] Process ID: 216417 [Epoch: 34,  1152/ 2309 points] total loss per batch: 0.727
Policy (actual, predicted): 1 1
Policy data: tensor([1.8732e-16, 1.0000e+00, 1.3607e-18, 5.5011e-23, 1.0830e-13, 3.1722e-21,
        3.0979e-14], device='cuda:0')
Policy pred: tensor([6.4858e-09, 1.0000e+00, 1.1533e-07, 2.3563e-12, 3.2632e-07, 2.1680e-07,
        2.5051e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999852776527405
 
[Iteration 3] Process ID: 216417 [Epoch: 34,  1728/ 2309 points] total loss per batch: 0.760
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 4.6105e-14, 0.0000e+00, 7.7873e-20, 1.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.9077e-06, 1.2862e-03, 1.9532e-08, 2.2831e-04, 9.9848e-01, 2.2894e-07,
        1.5174e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999971985816956
 
[Iteration 3] Process ID: 216417 [Epoch: 34,  2304/ 2309 points] total loss per batch: 0.780
Policy (actual, predicted): 0 0
Policy data: tensor([0.6989, 0.0379, 0.2309, 0.0059, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6588, 0.0465, 0.2147, 0.0154, 0.0196, 0.0248, 0.0202],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.0007553918985649943
 
[Iteration 3] Process ID: 216417 [Epoch: 35,   576/ 2309 points] total loss per batch: 0.749
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 3.2784e-13, 0.0000e+00, 8.7882e-06, 0.0000e+00, 9.9999e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.7549e-11, 1.7829e-03, 7.6469e-08, 2.9437e-03, 7.4171e-06, 9.9526e-01,
        5.4664e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 35,  1152/ 2309 points] total loss per batch: 0.833
Policy (actual, predicted): 0 0
Policy data: tensor([0.6989, 0.0379, 0.2309, 0.0059, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6216, 0.0413, 0.2676, 0.0144, 0.0142, 0.0207, 0.0204],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.006727931089699268
 
[Iteration 3] Process ID: 216417 [Epoch: 35,  1728/ 2309 points] total loss per batch: 0.781
Policy (actual, predicted): 0 0
Policy data: tensor([0.6993, 0.0379, 0.2323, 0.0041, 0.0041, 0.0129, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6210, 0.0626, 0.2298, 0.0181, 0.0200, 0.0251, 0.0233],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.00437561422586441
 
[Iteration 3] Process ID: 216417 [Epoch: 35,  2304/ 2309 points] total loss per batch: 0.770
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 8.2013e-08, 1.6742e-14, 2.9034e-16, 1.0525e-11, 5.1303e-10,
        2.1692e-11], device='cuda:0')
Policy pred: tensor([9.9990e-01, 7.8854e-08, 8.3554e-05, 6.6559e-07, 8.1393e-06, 3.9429e-06,
        5.2042e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999996423721313
 
[Iteration 3] Process ID: 216417 [Epoch: 36,   576/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 4 4
Policy data: tensor([0.1283, 0.0486, 0.0837, 0.0566, 0.3217, 0.2737, 0.0875],
       device='cuda:0')
Policy pred: tensor([0.1068, 0.0482, 0.0821, 0.0589, 0.3344, 0.2676, 0.1020],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9844382405281067
 
[Iteration 3] Process ID: 216417 [Epoch: 36,  1152/ 2309 points] total loss per batch: 0.811
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 8.9935e-17, 1.2601e-20, 0.0000e+00, 4.5681e-26,
        6.9965e-11], device='cuda:0')
Policy pred: tensor([4.2115e-08, 9.9711e-01, 2.3444e-04, 6.9501e-05, 4.9062e-10, 1.3664e-04,
        2.4481e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 36,  1728/ 2309 points] total loss per batch: 0.803
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0197, 0.0947, 0.3709, 0.0062, 0.0046, 0.0093, 0.4946],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.05690367892384529
 
[Iteration 3] Process ID: 216417 [Epoch: 36,  2304/ 2309 points] total loss per batch: 0.748
Policy (actual, predicted): 3 3
Policy data: tensor([3.2016e-06, 2.7770e-14, 1.8462e-14, 1.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.5306e-05, 2.6140e-05, 5.0917e-07, 9.9993e-01, 1.0455e-10, 7.0748e-09,
        1.0835e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999040961265564
 
[Iteration 3] Process ID: 216417 [Epoch: 37,   576/ 2309 points] total loss per batch: 0.798
Policy (actual, predicted): 4 4
Policy data: tensor([0.1853, 0.1698, 0.1188, 0.0374, 0.2397, 0.1188, 0.1301],
       device='cuda:0')
Policy pred: tensor([0.1761, 0.1565, 0.1302, 0.0345, 0.2645, 0.0924, 0.1458],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 37,  1152/ 2309 points] total loss per batch: 0.801
Policy (actual, predicted): 5 5
Policy data: tensor([3.3594e-11, 1.9012e-17, 6.8919e-23, 3.9742e-21, 1.8566e-20, 1.0000e+00,
        1.9468e-14], device='cuda:0')
Policy pred: tensor([9.0241e-05, 3.6692e-07, 2.4381e-06, 2.0941e-07, 2.5217e-05, 9.9971e-01,
        1.6813e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 37,  1728/ 2309 points] total loss per batch: 0.786
Policy (actual, predicted): 4 4
Policy data: tensor([8.0209e-08, 7.0959e-12, 6.1771e-05, 2.5723e-27, 9.9994e-01, 2.6341e-24,
        2.6341e-14], device='cuda:0')
Policy pred: tensor([1.0458e-03, 1.3329e-05, 7.9547e-05, 2.4118e-07, 9.9884e-01, 3.9299e-06,
        2.0878e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998422861099243
 
[Iteration 3] Process ID: 216417 [Epoch: 37,  2304/ 2309 points] total loss per batch: 0.764
Policy (actual, predicted): 6 6
Policy data: tensor([0.0238, 0.0374, 0.0284, 0.0591, 0.0159, 0.1096, 0.7257],
       device='cuda:0')
Policy pred: tensor([0.0520, 0.0701, 0.0569, 0.1242, 0.0649, 0.1399, 0.4920],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.053083598613739014
 
[Iteration 3] Process ID: 216417 [Epoch: 38,   576/ 2309 points] total loss per batch: 0.865
Policy (actual, predicted): 2 5
Policy data: tensor([0.1465, 0.1360, 0.1489, 0.1348, 0.1477, 0.1372, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1542, 0.1163, 0.1213, 0.1426, 0.1602, 0.1659, 0.1395],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9991278052330017
 
[Iteration 3] Process ID: 216417 [Epoch: 38,  1152/ 2309 points] total loss per batch: 0.767
Policy (actual, predicted): 5 5
Policy data: tensor([2.3739e-07, 0.0000e+00, 4.8307e-11, 1.1621e-13, 0.0000e+00, 1.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.0767e-05, 1.2167e-06, 4.5051e-06, 1.0598e-06, 1.5953e-07, 9.9997e-01,
        6.2435e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 38,  1728/ 2309 points] total loss per batch: 0.761
Policy (actual, predicted): 4 4
Policy data: tensor([0.0331, 0.0080, 0.0098, 0.0080, 0.9093, 0.0116, 0.0201],
       device='cuda:0')
Policy pred: tensor([0.0402, 0.0117, 0.0117, 0.0146, 0.8688, 0.0199, 0.0331],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9300245046615601
 
[Iteration 3] Process ID: 216417 [Epoch: 38,  2304/ 2309 points] total loss per batch: 0.755
Policy (actual, predicted): 4 1
Policy data: tensor([0.1372, 0.1465, 0.1442, 0.1313, 0.1535, 0.1419, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1472, 0.1602, 0.1391, 0.1080, 0.1551, 0.1440, 0.1463],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999833703041077
 
[Iteration 3] Process ID: 216417 [Epoch: 39,   576/ 2309 points] total loss per batch: 0.805
Policy (actual, predicted): 5 5
Policy data: tensor([0.0043, 0.0269, 0.0081, 0.0043, 0.0043, 0.9253, 0.0269],
       device='cuda:0')
Policy pred: tensor([0.0042, 0.0226, 0.0095, 0.0047, 0.0104, 0.9283, 0.0203],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.5605055093765259
 
[Iteration 3] Process ID: 216417 [Epoch: 39,  1152/ 2309 points] total loss per batch: 0.772
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000, 0.0406, 0.4221, 0.0021, 0.0881, 0.3462, 0.1011],
       device='cuda:0')
Policy pred: tensor([5.5180e-06, 2.9728e-02, 5.8305e-01, 2.0011e-03, 4.9933e-02, 2.7039e-01,
        6.4892e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9990022778511047
 
[Iteration 3] Process ID: 216417 [Epoch: 39,  1728/ 2309 points] total loss per batch: 0.782
Policy (actual, predicted): 0 4
Policy data: tensor([7.5666e-01, 1.1044e-16, 1.0311e-07, 3.2435e-23, 2.4334e-01, 8.7375e-11,
        1.9152e-18], device='cuda:0')
Policy pred: tensor([4.3014e-01, 7.7091e-04, 6.5816e-04, 2.1942e-05, 5.6821e-01, 7.6751e-05,
        1.2221e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.014187825843691826
 
[Iteration 3] Process ID: 216417 [Epoch: 39,  2304/ 2309 points] total loss per batch: 0.780
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 8.0649e-11, 3.3760e-26, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([5.5827e-06, 9.9739e-01, 2.5371e-03, 6.7244e-05, 5.3039e-08, 2.0887e-07,
        3.7319e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 40,   576/ 2309 points] total loss per batch: 0.758
Policy (actual, predicted): 6 6
Policy data: tensor([0.0238, 0.0374, 0.0284, 0.0605, 0.0159, 0.1096, 0.7244],
       device='cuda:0')
Policy pred: tensor([0.0501, 0.0590, 0.0472, 0.1050, 0.0417, 0.1454, 0.5516],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.07590288668870926
 
[Iteration 3] Process ID: 216417 [Epoch: 40,  1152/ 2309 points] total loss per batch: 0.784
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 7.9325e-10, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.6978e-08, 9.9979e-01, 1.3795e-05, 1.8347e-04, 1.1139e-05, 4.6566e-06,
        1.7630e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999994039535522
 
[Iteration 3] Process ID: 216417 [Epoch: 40,  1728/ 2309 points] total loss per batch: 0.802
Policy (actual, predicted): 5 5
Policy data: tensor([0.2198, 0.1275, 0.0487, 0.0620, 0.0646, 0.3834, 0.0940],
       device='cuda:0')
Policy pred: tensor([0.2026, 0.1118, 0.0394, 0.0663, 0.0676, 0.4190, 0.0933],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9872456192970276
 
[Iteration 3] Process ID: 216417 [Epoch: 40,  2304/ 2309 points] total loss per batch: 0.776
Policy (actual, predicted): 0 0
Policy data: tensor([0.3022, 0.0105, 0.2620, 0.0089, 0.0105, 0.2516, 0.1542],
       device='cuda:0')
Policy pred: tensor([0.3188, 0.0178, 0.2810, 0.0089, 0.0124, 0.1703, 0.1908],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9984920620918274
 
[Iteration 3] Process ID: 216417 [Epoch: 41,   576/ 2309 points] total loss per batch: 0.777
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000, 0.3818, 0.0441, 0.3392, 0.0833, 0.1516, 0.0000],
       device='cuda:0')
Policy pred: tensor([3.6372e-04, 4.1921e-01, 4.0227e-02, 3.3122e-01, 6.1397e-02, 1.4722e-01,
        3.7128e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999879002571106
 
[Iteration 3] Process ID: 216417 [Epoch: 41,  1152/ 2309 points] total loss per batch: 0.811
Policy (actual, predicted): 4 4
Policy data: tensor([1.5130e-24, 5.2894e-14, 7.2376e-21, 2.6867e-23, 1.0000e+00, 2.6237e-26,
        1.5130e-24], device='cuda:0')
Policy pred: tensor([2.8690e-04, 2.1375e-03, 1.4530e-04, 8.1172e-05, 9.9726e-01, 1.8041e-05,
        7.2198e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999995827674866
 
[Iteration 3] Process ID: 216417 [Epoch: 41,  1728/ 2309 points] total loss per batch: 0.716
Policy (actual, predicted): 4 4
Policy data: tensor([1.7223e-17, 4.1175e-18, 1.8937e-15, 2.9168e-22, 1.0000e+00, 8.4369e-21,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([8.7834e-05, 1.0788e-02, 3.1296e-06, 8.5268e-06, 9.8852e-01, 1.1059e-04,
        4.8492e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999979734420776
 
[Iteration 3] Process ID: 216417 [Epoch: 41,  2304/ 2309 points] total loss per batch: 0.836
Policy (actual, predicted): 4 4
Policy data: tensor([7.2755e-20, 2.2942e-17, 2.1367e-26, 2.2405e-20, 1.0000e+00, 1.2321e-24,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.7039e-04, 1.3822e-03, 3.7566e-05, 3.3240e-04, 9.9801e-01, 6.1944e-05,
        9.7933e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9733167886734009
 
[Iteration 3] Process ID: 216417 [Epoch: 42,   576/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 6 6
Policy data: tensor([0.3521, 0.0059, 0.0145, 0.0059, 0.0041, 0.0059, 0.6114],
       device='cuda:0')
Policy pred: tensor([0.3651, 0.0097, 0.0176, 0.0098, 0.0082, 0.0102, 0.5794],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.029187217354774475
 
[Iteration 3] Process ID: 216417 [Epoch: 42,  1152/ 2309 points] total loss per batch: 0.751
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0670, 0.0150, 0.0158, 0.0154, 0.0365, 0.0470, 0.8033],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.023534579202532768
 
[Iteration 3] Process ID: 216417 [Epoch: 42,  1728/ 2309 points] total loss per batch: 0.807
Policy (actual, predicted): 6 6
Policy data: tensor([0.0238, 0.0374, 0.0284, 0.0605, 0.0159, 0.1096, 0.7244],
       device='cuda:0')
Policy pred: tensor([0.0357, 0.0496, 0.0436, 0.1012, 0.0362, 0.1450, 0.5887],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.041127245873212814
 
[Iteration 3] Process ID: 216417 [Epoch: 42,  2304/ 2309 points] total loss per batch: 0.789
Policy (actual, predicted): 6 6
Policy data: tensor([1.2258e-01, 1.1500e-19, 7.0865e-03, 1.0967e-25, 2.2110e-13, 0.0000e+00,
        8.7033e-01], device='cuda:0')
Policy pred: tensor([1.4222e-01, 7.5450e-04, 1.2340e-02, 7.9817e-05, 5.8240e-04, 8.0289e-05,
        8.4395e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999702572822571
 
[Iteration 3] Process ID: 216417 [Epoch: 43,   576/ 2309 points] total loss per batch: 0.759
Policy (actual, predicted): 6 6
Policy data: tensor([6.3593e-20, 1.1028e-21, 1.7811e-22, 1.8676e-26, 0.0000e+00, 1.1028e-21,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([8.1757e-04, 1.0121e-07, 1.7039e-07, 4.7979e-07, 5.0557e-10, 1.0740e-06,
        9.9918e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 43,  1152/ 2309 points] total loss per batch: 0.795
Policy (actual, predicted): 0 0
Policy data: tensor([0.2710, 0.1486, 0.1135, 0.0484, 0.1931, 0.0484, 0.1771],
       device='cuda:0')
Policy pred: tensor([0.2739, 0.1522, 0.1029, 0.0433, 0.1926, 0.0520, 0.1831],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 43,  1728/ 2309 points] total loss per batch: 0.749
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000, 0.0000, 0.2250, 0.0784, 0.3889, 0.0682, 0.2395],
       device='cuda:0')
Policy pred: tensor([9.2731e-06, 1.1529e-05, 2.1175e-01, 7.8785e-02, 4.5089e-01, 5.4733e-02,
        2.0382e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9992308020591736
 
[Iteration 3] Process ID: 216417 [Epoch: 43,  2304/ 2309 points] total loss per batch: 0.825
Policy (actual, predicted): 4 4
Policy data: tensor([0.0225, 0.0094, 0.0177, 0.0094, 0.6985, 0.0145, 0.2279],
       device='cuda:0')
Policy pred: tensor([0.0229, 0.0110, 0.0195, 0.0100, 0.6672, 0.0176, 0.2518],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.6031841039657593
 
[Iteration 3] Process ID: 216417 [Epoch: 44,   576/ 2309 points] total loss per batch: 0.818
Policy (actual, predicted): 0 0
Policy data: tensor([0.5684, 0.0190, 0.0312, 0.0076, 0.0093, 0.0357, 0.3288],
       device='cuda:0')
Policy pred: tensor([0.5653, 0.0160, 0.0242, 0.0096, 0.0072, 0.0305, 0.3471],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9766747355461121
 
[Iteration 3] Process ID: 216417 [Epoch: 44,  1152/ 2309 points] total loss per batch: 0.752
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 8.2554e-01, 1.7446e-01, 2.1937e-09, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([5.1163e-05, 8.0102e-01, 1.9632e-01, 2.5713e-03, 2.2046e-06, 2.3763e-05,
        1.1281e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999997615814209
 
[Iteration 3] Process ID: 216417 [Epoch: 44,  1728/ 2309 points] total loss per batch: 0.753
Policy (actual, predicted): 5 5
Policy data: tensor([0.0116, 0.0098, 0.0043, 0.0201, 0.0485, 0.8978, 0.0080],
       device='cuda:0')
Policy pred: tensor([0.0105, 0.0089, 0.0047, 0.0222, 0.0521, 0.8918, 0.0098],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.20322702825069427
 
[Iteration 3] Process ID: 216417 [Epoch: 44,  2304/ 2309 points] total loss per batch: 0.804
Policy (actual, predicted): 0 0
Policy data: tensor([0.4948, 0.0300, 0.0827, 0.0328, 0.1183, 0.1626, 0.0788],
       device='cuda:0')
Policy pred: tensor([0.4883, 0.0295, 0.0890, 0.0255, 0.1429, 0.1670, 0.0579],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.997015655040741
 
[Iteration 3] Process ID: 216417 [Epoch: 45,   576/ 2309 points] total loss per batch: 0.777
Policy (actual, predicted): 0 0
Policy data: tensor([0.9586, 0.0063, 0.0063, 0.0043, 0.0082, 0.0063, 0.0100],
       device='cuda:0')
Policy pred: tensor([0.9469, 0.0046, 0.0098, 0.0034, 0.0186, 0.0051, 0.0116],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9884495139122009
 
[Iteration 3] Process ID: 216417 [Epoch: 45,  1152/ 2309 points] total loss per batch: 0.754
Policy (actual, predicted): 1 1
Policy data: tensor([0.0943, 0.2116, 0.1628, 0.1940, 0.0710, 0.1035, 0.1628],
       device='cuda:0')
Policy pred: tensor([0.0960, 0.1995, 0.1645, 0.1742, 0.0770, 0.1145, 0.1743],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999963641166687
 
[Iteration 3] Process ID: 216417 [Epoch: 45,  1728/ 2309 points] total loss per batch: 0.809
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 3.0169e-10, 0.0000e+00, 3.2086e-15, 1.6035e-09, 1.9698e-15,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([4.1907e-10, 6.7191e-05, 3.5849e-08, 6.1530e-08, 2.5852e-04, 2.2434e-05,
        9.9965e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998869299888611
 
[Iteration 3] Process ID: 216417 [Epoch: 45,  2304/ 2309 points] total loss per batch: 0.789
Policy (actual, predicted): 2 2
Policy data: tensor([7.0756e-02, 2.0566e-04, 9.2904e-01, 3.5665e-26, 0.0000e+00, 3.8295e-17,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.3441e-02, 3.7889e-04, 9.6143e-01, 8.8891e-04, 1.1792e-05, 3.8522e-03,
        1.3583e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999980330467224
 
[Iteration 3] Process ID: 216417 [Epoch: 46,   576/ 2309 points] total loss per batch: 0.806
Policy (actual, predicted): 1 1
Policy data: tensor([0.2790, 0.3923, 0.0901, 0.0341, 0.0534, 0.0197, 0.1314],
       device='cuda:0')
Policy pred: tensor([0.2551, 0.4588, 0.0827, 0.0345, 0.0452, 0.0212, 0.1025],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9987311959266663
 
[Iteration 3] Process ID: 216417 [Epoch: 46,  1152/ 2309 points] total loss per batch: 0.813
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 0.0000e+00, 2.0503e-16, 8.8818e-16, 0.0000e+00, 2.7409e-14,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9930e-01, 2.1939e-09, 7.8016e-06, 2.8497e-05, 1.7181e-11, 6.6421e-04,
        3.3804e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999995827674866
 
[Iteration 3] Process ID: 216417 [Epoch: 46,  1728/ 2309 points] total loss per batch: 0.797
Policy (actual, predicted): 4 0
Policy data: tensor([0.1466, 0.1466, 0.1477, 0.1325, 0.1524, 0.1325, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.5766, 0.0486, 0.2815, 0.0188, 0.0216, 0.0271, 0.0258],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.003942467272281647
 
[Iteration 3] Process ID: 216417 [Epoch: 46,  2304/ 2309 points] total loss per batch: 0.716
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 7.2202e-01, 6.7654e-03, 3.7775e-25, 0.0000e+00, 2.7119e-01,
        2.5114e-05], device='cuda:0')
Policy pred: tensor([6.0466e-09, 7.4508e-01, 9.3773e-03, 1.5688e-03, 9.3627e-10, 2.4324e-01,
        7.2628e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 47,   576/ 2309 points] total loss per batch: 0.812
Policy (actual, predicted): 6 6
Policy data: tensor([0.0238, 0.0374, 0.0284, 0.0605, 0.0159, 0.1096, 0.7244],
       device='cuda:0')
Policy pred: tensor([0.0461, 0.0536, 0.0458, 0.1175, 0.0492, 0.1578, 0.5300],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.07730469852685928
 
[Iteration 3] Process ID: 216417 [Epoch: 47,  1152/ 2309 points] total loss per batch: 0.777
Policy (actual, predicted): 6 6
Policy data: tensor([4.8724e-03, 5.6492e-17, 1.1370e-09, 5.2612e-16, 1.1247e-03, 1.8345e-16,
        9.9400e-01], device='cuda:0')
Policy pred: tensor([6.7109e-03, 5.3586e-05, 7.9025e-04, 2.3485e-05, 2.0923e-03, 6.4583e-04,
        9.8968e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 47,  1728/ 2309 points] total loss per batch: 0.751
Policy (actual, predicted): 5 5
Policy data: tensor([0.0043, 0.0268, 0.0134, 0.0043, 0.0043, 0.9217, 0.0252],
       device='cuda:0')
Policy pred: tensor([0.0024, 0.0205, 0.0087, 0.0030, 0.0049, 0.9403, 0.0203],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.6329917907714844
 
[Iteration 3] Process ID: 216417 [Epoch: 47,  2304/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 0 0
Policy data: tensor([0.8559, 0.0246, 0.0181, 0.0198, 0.0230, 0.0356, 0.0230],
       device='cuda:0')
Policy pred: tensor([0.8706, 0.0153, 0.0117, 0.0151, 0.0313, 0.0304, 0.0255],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9874738454818726
 
[Iteration 3] Process ID: 216417 [Epoch: 48,   576/ 2309 points] total loss per batch: 0.811
Policy (actual, predicted): 4 0
Policy data: tensor([0.1454, 0.1489, 0.1477, 0.1301, 0.1559, 0.1325, 0.1395],
       device='cuda:0')
Policy pred: tensor([0.6126, 0.0548, 0.2376, 0.0203, 0.0219, 0.0288, 0.0240],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.004778687842190266
 
[Iteration 3] Process ID: 216417 [Epoch: 48,  1152/ 2309 points] total loss per batch: 0.813
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000, 0.1610, 0.3009, 0.0376, 0.3395, 0.1610, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.5782e-03, 1.7693e-01, 2.7499e-01, 4.4402e-02, 3.4453e-01, 1.5741e-01,
        1.6530e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999999463558197
 
[Iteration 3] Process ID: 216417 [Epoch: 48,  1728/ 2309 points] total loss per batch: 0.768
Policy (actual, predicted): 6 6
Policy data: tensor([0.0714, 0.0146, 0.0146, 0.0146, 0.0440, 0.0528, 0.7882],
       device='cuda:0')
Policy pred: tensor([0.0831, 0.0241, 0.0255, 0.0239, 0.0606, 0.0625, 0.7202],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.01595294661819935
 
[Iteration 3] Process ID: 216417 [Epoch: 48,  2304/ 2309 points] total loss per batch: 0.748
Policy (actual, predicted): 6 6
Policy data: tensor([0.2143, 0.1154, 0.0388, 0.0039, 0.0000, 0.2096, 0.4181],
       device='cuda:0')
Policy pred: tensor([2.3510e-01, 1.0139e-01, 3.5423e-02, 4.5141e-03, 1.0814e-05, 2.2457e-01,
        3.9899e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999997615814209
 
[Iteration 3] Process ID: 216417 [Epoch: 49,   576/ 2309 points] total loss per batch: 0.783
Policy (actual, predicted): 6 6
Policy data: tensor([0.0340, 0.0250, 0.0189, 0.0141, 0.4056, 0.0204, 0.4819],
       device='cuda:0')
Policy pred: tensor([0.0390, 0.0243, 0.0199, 0.0128, 0.4079, 0.0197, 0.4764],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.8492331504821777
 
[Iteration 3] Process ID: 216417 [Epoch: 49,  1152/ 2309 points] total loss per batch: 0.766
Policy (actual, predicted): 2 2
Policy data: tensor([1.4348e-11, 6.2698e-19, 1.0000e+00, 1.7982e-18, 0.0000e+00, 1.1134e-17,
        1.9863e-08], device='cuda:0')
Policy pred: tensor([4.7873e-05, 5.5255e-04, 9.9889e-01, 6.4316e-06, 6.4068e-06, 2.7754e-04,
        2.2319e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999992847442627
 
[Iteration 3] Process ID: 216417 [Epoch: 49,  1728/ 2309 points] total loss per batch: 0.795
Policy (actual, predicted): 1 1
Policy data: tensor([1.8792e-22, 1.0000e+00, 2.0178e-23, 2.6528e-18, 0.0000e+00, 1.9243e-19,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.1598e-07, 1.0000e+00, 1.2793e-10, 9.2540e-08, 2.2416e-16, 2.7388e-06,
        1.8178e-13], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 49,  2304/ 2309 points] total loss per batch: 0.793
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 0.0000e+00, 1.5125e-05, 8.3180e-10, 0.0000e+00, 9.9998e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.3457e-10, 3.0367e-10, 1.5722e-06, 2.8061e-07, 3.4064e-08, 1.0000e+00,
        3.9736e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 50,   576/ 2309 points] total loss per batch: 0.794
Policy (actual, predicted): 0 0
Policy data: tensor([0.9586, 0.0063, 0.0063, 0.0043, 0.0082, 0.0063, 0.0100],
       device='cuda:0')
Policy pred: tensor([0.9487, 0.0040, 0.0089, 0.0057, 0.0107, 0.0057, 0.0164],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9729169011116028
 
[Iteration 3] Process ID: 216417 [Epoch: 50,  1152/ 2309 points] total loss per batch: 0.771
Policy (actual, predicted): 4 4
Policy data: tensor([0.2228, 0.1722, 0.1008, 0.1104, 0.2863, 0.0314, 0.0762],
       device='cuda:0')
Policy pred: tensor([0.2031, 0.1561, 0.0824, 0.1354, 0.2718, 0.0297, 0.1216],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 50,  1728/ 2309 points] total loss per batch: 0.785
Policy (actual, predicted): 2 2
Policy data: tensor([2.2110e-05, 1.2451e-06, 9.9998e-01, 3.3586e-27, 2.0308e-19, 2.0796e-16,
        1.7666e-10], device='cuda:0')
Policy pred: tensor([3.5651e-04, 1.4591e-04, 9.9939e-01, 2.3433e-06, 7.4370e-05, 3.1608e-07,
        3.3499e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 50,  2304/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 2.1751e-09, 0.0000e+00, 2.1751e-09,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.1356e-13, 1.0000e+00, 2.7563e-12, 7.7897e-09, 3.3762e-11, 6.1213e-07,
        1.2283e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 51,   576/ 2309 points] total loss per batch: 0.782
Policy (actual, predicted): 4 4
Policy data: tensor([2.4962e-14, 3.3005e-07, 1.7682e-28, 1.9442e-16, 1.0000e+00, 1.0441e-23,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.0303e-07, 3.2880e-09, 5.0417e-08, 2.8833e-07, 1.0000e+00, 6.9997e-07,
        1.0767e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999884963035583
 
[Iteration 3] Process ID: 216417 [Epoch: 51,  1152/ 2309 points] total loss per batch: 0.813
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000, 0.0000, 0.1196, 0.0000, 0.0000, 0.7558, 0.1246],
       device='cuda:0')
Policy pred: tensor([4.2440e-06, 2.6150e-07, 1.0914e-01, 7.0395e-05, 1.1399e-06, 7.9438e-01,
        9.6403e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999984502792358
 
[Iteration 3] Process ID: 216417 [Epoch: 51,  1728/ 2309 points] total loss per batch: 0.747
Policy (actual, predicted): 3 3
Policy data: tensor([7.7754e-16, 2.6881e-17, 9.5977e-15, 1.0000e+00, 1.6644e-16, 2.7526e-24,
        1.2091e-18], device='cuda:0')
Policy pred: tensor([1.8892e-04, 4.0579e-05, 1.8357e-06, 9.9844e-01, 9.5916e-04, 5.8439e-05,
        3.1339e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 51,  2304/ 2309 points] total loss per batch: 0.785
Policy (actual, predicted): 0 0
Policy data: tensor([0.9247, 0.0062, 0.0062, 0.0062, 0.0252, 0.0062, 0.0252],
       device='cuda:0')
Policy pred: tensor([0.9252, 0.0034, 0.0051, 0.0040, 0.0205, 0.0049, 0.0369],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.013486433774232864
 
[Iteration 3] Process ID: 216417 [Epoch: 52,   576/ 2309 points] total loss per batch: 0.773
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 4.2951e-18, 0.0000e+00, 1.8839e-21, 9.0119e-18, 1.0000e+00,
        6.4317e-14], device='cuda:0')
Policy pred: tensor([1.1324e-08, 1.1247e-03, 4.1231e-08, 4.7898e-05, 2.3519e-04, 9.9834e-01,
        2.5699e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 52,  1152/ 2309 points] total loss per batch: 0.816
Policy (actual, predicted): 5 6
Policy data: tensor([0.0138, 0.0107, 0.0107, 0.2710, 0.0361, 0.3369, 0.3208],
       device='cuda:0')
Policy pred: tensor([0.0396, 0.0537, 0.0468, 0.1041, 0.0416, 0.1493, 0.5649],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.07875333726406097
 
[Iteration 3] Process ID: 216417 [Epoch: 52,  1728/ 2309 points] total loss per batch: 0.785
Policy (actual, predicted): 0 0
Policy data: tensor([0.6981, 0.0379, 0.2335, 0.0041, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.5985, 0.0497, 0.2601, 0.0197, 0.0212, 0.0257, 0.0250],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.012325216084718704
 
[Iteration 3] Process ID: 216417 [Epoch: 52,  2304/ 2309 points] total loss per batch: 0.741
Policy (actual, predicted): 0 0
Policy data: tensor([0.1911, 0.1774, 0.1401, 0.0784, 0.0981, 0.1808, 0.1342],
       device='cuda:0')
Policy pred: tensor([0.2104, 0.1736, 0.1389, 0.0761, 0.1162, 0.1580, 0.1267],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999767541885376
 
[Iteration 3] Process ID: 216417 [Epoch: 53,   576/ 2309 points] total loss per batch: 0.780
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 3.7165e-18, 6.1464e-26, 6.1464e-26, 9.3132e-10, 6.1464e-26,
        1.5568e-18], device='cuda:0')
Policy pred: tensor([9.9997e-01, 2.7240e-06, 2.0541e-07, 8.0543e-09, 2.2778e-05, 4.8738e-09,
        5.0910e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999993443489075
 
[Iteration 3] Process ID: 216417 [Epoch: 53,  1152/ 2309 points] total loss per batch: 0.804
Policy (actual, predicted): 5 5
Policy data: tensor([0.0217, 0.0115, 0.0098, 0.0167, 0.0438, 0.8904, 0.0061],
       device='cuda:0')
Policy pred: tensor([0.0285, 0.0096, 0.0106, 0.0235, 0.0415, 0.8785, 0.0079],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9945926666259766
 
[Iteration 3] Process ID: 216417 [Epoch: 53,  1728/ 2309 points] total loss per batch: 0.770
Policy (actual, predicted): 4 4
Policy data: tensor([0.0081, 0.0062, 0.0219, 0.0062, 0.9256, 0.0134, 0.0186],
       device='cuda:0')
Policy pred: tensor([0.0046, 0.0031, 0.0132, 0.0041, 0.9563, 0.0078, 0.0109],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.006993794348090887
 
[Iteration 3] Process ID: 216417 [Epoch: 53,  2304/ 2309 points] total loss per batch: 0.758
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 3.3761e-15, 1.3791e-17, 1.0000e+00, 0.0000e+00, 6.7556e-21,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([7.9383e-12, 1.7385e-05, 3.2781e-06, 9.9998e-01, 3.5549e-12, 3.0694e-07,
        1.0998e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998211860657
 
[Iteration 3] Process ID: 216417 [Epoch: 54,   576/ 2309 points] total loss per batch: 0.787
Policy (actual, predicted): 6 6
Policy data: tensor([0.1894, 0.1941, 0.1762, 0.0073, 0.0152, 0.0198, 0.3980],
       device='cuda:0')
Policy pred: tensor([0.1582, 0.2165, 0.1470, 0.0142, 0.0130, 0.0221, 0.4289],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9889617562294006
 
[Iteration 3] Process ID: 216417 [Epoch: 54,  1152/ 2309 points] total loss per batch: 0.747
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 6.8637e-08, 2.3729e-09, 5.4539e-11, 8.2035e-11, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9987e-01, 1.2150e-11, 1.2369e-04, 5.1538e-11, 2.1638e-06, 2.9699e-12,
        3.4412e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999945163726807
 
[Iteration 3] Process ID: 216417 [Epoch: 54,  1728/ 2309 points] total loss per batch: 0.778
Policy (actual, predicted): 0 0
Policy data: tensor([0.5066, 0.0453, 0.1017, 0.0668, 0.0548, 0.1130, 0.1118],
       device='cuda:0')
Policy pred: tensor([0.4788, 0.0545, 0.1168, 0.0763, 0.0452, 0.1342, 0.0943],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999978542327881
 
[Iteration 3] Process ID: 216417 [Epoch: 54,  2304/ 2309 points] total loss per batch: 0.803
Policy (actual, predicted): 4 4
Policy data: tensor([0.2204, 0.0357, 0.0252, 0.0058, 0.6448, 0.0444, 0.0237],
       device='cuda:0')
Policy pred: tensor([0.1845, 0.0192, 0.0174, 0.0040, 0.6896, 0.0604, 0.0249],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9612064361572266
 
[Iteration 3] Process ID: 216417 [Epoch: 55,   576/ 2309 points] total loss per batch: 0.767
Policy (actual, predicted): 0 0
Policy data: tensor([0.2442, 0.1105, 0.2058, 0.0569, 0.1584, 0.0918, 0.1325],
       device='cuda:0')
Policy pred: tensor([0.2410, 0.1101, 0.2102, 0.0565, 0.1654, 0.0998, 0.1172],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 55,  1152/ 2309 points] total loss per batch: 0.778
Policy (actual, predicted): 5 5
Policy data: tensor([6.2725e-15, 2.4764e-22, 1.7718e-06, 2.3616e-28, 1.4623e-17, 1.0000e+00,
        2.4764e-22], device='cuda:0')
Policy pred: tensor([5.9639e-04, 6.2299e-05, 9.8048e-04, 4.2668e-05, 3.1713e-05, 9.9828e-01,
        8.3942e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9985454678535461
 
[Iteration 3] Process ID: 216417 [Epoch: 55,  1728/ 2309 points] total loss per batch: 0.787
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000, 0.0000, 0.1570, 0.0857, 0.1471, 0.3144, 0.2958],
       device='cuda:0')
Policy pred: tensor([3.5544e-06, 6.8704e-06, 1.6655e-01, 7.9773e-02, 1.3753e-01, 3.1310e-01,
        3.0304e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 55,  2304/ 2309 points] total loss per batch: 0.783
Policy (actual, predicted): 5 5
Policy data: tensor([0.0313, 0.0133, 0.0233, 0.0061, 0.0200, 0.8943, 0.0115],
       device='cuda:0')
Policy pred: tensor([0.0121, 0.0068, 0.0122, 0.0050, 0.0073, 0.9530, 0.0036],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999523401260376
 
[Iteration 3] Process ID: 216417 [Epoch: 56,   576/ 2309 points] total loss per batch: 0.820
Policy (actual, predicted): 5 5
Policy data: tensor([0.0763, 0.0577, 0.0229, 0.0042, 0.0042, 0.8152, 0.0196],
       device='cuda:0')
Policy pred: tensor([0.0622, 0.0433, 0.0169, 0.0028, 0.0041, 0.8555, 0.0151],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9662804007530212
 
[Iteration 3] Process ID: 216417 [Epoch: 56,  1152/ 2309 points] total loss per batch: 0.707
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 2.5214e-14, 1.0000e+00, 1.0816e-11, 4.4775e-23, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.8531e-08, 5.9355e-06, 9.9983e-01, 1.1329e-04, 4.8673e-05, 1.7099e-07,
        2.1097e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 56,  1728/ 2309 points] total loss per batch: 0.808
Policy (actual, predicted): 6 6
Policy data: tensor([0.0023, 0.0043, 0.0567, 0.0023, 0.0023, 0.0043, 0.9277],
       device='cuda:0')
Policy pred: tensor([0.0024, 0.0054, 0.0487, 0.0017, 0.0027, 0.0040, 0.9351],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.6632583141326904
 
[Iteration 3] Process ID: 216417 [Epoch: 56,  2304/ 2309 points] total loss per batch: 0.787
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000, 0.0000, 0.0229, 0.9771, 0.0000, 0.0000, 0.0000],
       device='cuda:0')
Policy pred: tensor([4.9073e-07, 6.7250e-08, 1.7048e-02, 9.8295e-01, 5.5141e-07, 2.4975e-07,
        1.4962e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999996423721313
 
[Iteration 3] Process ID: 216417 [Epoch: 57,   576/ 2309 points] total loss per batch: 0.739
Policy (actual, predicted): 4 4
Policy data: tensor([0.0982, 0.0041, 0.0259, 0.0041, 0.7900, 0.0130, 0.0646],
       device='cuda:0')
Policy pred: tensor([0.0796, 0.0041, 0.0269, 0.0035, 0.8051, 0.0129, 0.0678],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.12628129124641418
 
[Iteration 3] Process ID: 216417 [Epoch: 57,  1152/ 2309 points] total loss per batch: 0.808
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 0.0000e+00, 3.3890e-18, 3.3890e-18, 0.0000e+00, 1.5586e-15,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9987e-01, 7.7135e-06, 2.7614e-06, 3.7160e-07, 5.1050e-11, 1.2030e-04,
        1.1565e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 57,  1728/ 2309 points] total loss per batch: 0.706
Policy (actual, predicted): 5 5
Policy data: tensor([6.3487e-20, 6.1999e-23, 6.1999e-23, 9.1741e-10, 3.4914e-24, 1.0000e+00,
        2.0616e-19], device='cuda:0')
Policy pred: tensor([5.6419e-07, 9.7800e-08, 1.0751e-08, 2.5305e-05, 2.2317e-05, 9.9995e-01,
        3.2275e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 57,  2304/ 2309 points] total loss per batch: 0.859
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 7.9587e-12, 0.0000e+00, 1.1202e-09,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([4.1621e-09, 2.1872e-07, 8.3247e-09, 7.9691e-04, 1.1459e-08, 7.4239e-06,
        9.9920e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 58,   576/ 2309 points] total loss per batch: 0.786
Policy (actual, predicted): 5 5
Policy data: tensor([0.0483, 0.0394, 0.0527, 0.0060, 0.0242, 0.7856, 0.0439],
       device='cuda:0')
Policy pred: tensor([0.0461, 0.0321, 0.0429, 0.0048, 0.0216, 0.8198, 0.0327],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.2994523346424103
 
[Iteration 3] Process ID: 216417 [Epoch: 58,  1152/ 2309 points] total loss per batch: 0.852
Policy (actual, predicted): 0 0
Policy data: tensor([0.2930, 0.1495, 0.1777, 0.0334, 0.2487, 0.0179, 0.0798],
       device='cuda:0')
Policy pred: tensor([0.2575, 0.1920, 0.1689, 0.0250, 0.2400, 0.0100, 0.1067],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999992251396179
 
[Iteration 3] Process ID: 216417 [Epoch: 58,  1728/ 2309 points] total loss per batch: 0.833
Policy (actual, predicted): 0 0
Policy data: tensor([0.8569, 0.0061, 0.0042, 0.0042, 0.0658, 0.0042, 0.0585],
       device='cuda:0')
Policy pred: tensor([0.8164, 0.0048, 0.0040, 0.0054, 0.1002, 0.0092, 0.0600],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9160847067832947
 
[Iteration 3] Process ID: 216417 [Epoch: 58,  2304/ 2309 points] total loss per batch: 0.830
Policy (actual, predicted): 6 6
Policy data: tensor([0.0023, 0.0043, 0.0567, 0.0023, 0.0023, 0.0043, 0.9277],
       device='cuda:0')
Policy pred: tensor([0.0031, 0.0047, 0.0573, 0.0027, 0.0017, 0.0046, 0.9260],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.6047153472900391
 
[Iteration 3] Process ID: 216417 [Epoch: 59,   576/ 2309 points] total loss per batch: 0.937
Policy (actual, predicted): 6 6
Policy data: tensor([1.1381e-03, 8.5400e-11, 8.4224e-16, 1.3603e-26, 1.8752e-05, 1.8752e-15,
        9.9884e-01], device='cuda:0')
Policy pred: tensor([1.9942e-02, 1.0602e-02, 3.9323e-04, 3.7435e-04, 7.2180e-03, 2.2832e-02,
        9.3864e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9989793300628662
 
[Iteration 3] Process ID: 216417 [Epoch: 59,  1152/ 2309 points] total loss per batch: 0.871
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.1120, 0.0355, 0.0342, 0.0376, 0.0603, 0.0676, 0.6529],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.001022632815875113
 
[Iteration 3] Process ID: 216417 [Epoch: 59,  1728/ 2309 points] total loss per batch: 0.820
Policy (actual, predicted): 4 4
Policy data: tensor([0.0225, 0.0094, 0.0177, 0.0094, 0.6997, 0.0145, 0.2267],
       device='cuda:0')
Policy pred: tensor([0.0164, 0.0039, 0.0109, 0.0044, 0.7417, 0.0050, 0.2176],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.5079283118247986
 
[Iteration 3] Process ID: 216417 [Epoch: 59,  2304/ 2309 points] total loss per batch: 0.855
Policy (actual, predicted): 1 1
Policy data: tensor([2.6182e-04, 9.9938e-01, 8.3028e-07, 3.0573e-14, 3.8788e-06, 5.6173e-08,
        3.5616e-04], device='cuda:0')
Policy pred: tensor([9.4080e-05, 9.6596e-01, 5.3967e-04, 8.6716e-05, 7.8697e-03, 2.4793e-02,
        6.5392e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 60,   576/ 2309 points] total loss per batch: 0.835
Policy (actual, predicted): 0 0
Policy data: tensor([0.9118, 0.0099, 0.0503, 0.0023, 0.0081, 0.0043, 0.0134],
       device='cuda:0')
Policy pred: tensor([0.8871, 0.0068, 0.0678, 0.0021, 0.0264, 0.0030, 0.0069],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9992787837982178
 
[Iteration 3] Process ID: 216417 [Epoch: 60,  1152/ 2309 points] total loss per batch: 0.835
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0650e-25, 1.0000e+00, 1.5720e-26,
        1.5352e-19], device='cuda:0')
Policy pred: tensor([8.1944e-08, 8.7215e-08, 3.5685e-08, 3.1092e-04, 9.9943e-01, 1.5520e-05,
        2.4239e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 60,  1728/ 2309 points] total loss per batch: 0.824
Policy (actual, predicted): 4 4
Policy data: tensor([0.0364, 0.0169, 0.0062, 0.0062, 0.9219, 0.0043, 0.0081],
       device='cuda:0')
Policy pred: tensor([0.0399, 0.0259, 0.0125, 0.0099, 0.8218, 0.0863, 0.0037],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 60,  2304/ 2309 points] total loss per batch: 0.810
Policy (actual, predicted): 0 0
Policy data: tensor([0.6083, 0.0869, 0.2885, 0.0022, 0.0041, 0.0041, 0.0059],
       device='cuda:0')
Policy pred: tensor([0.5925, 0.0844, 0.2973, 0.0042, 0.0089, 0.0057, 0.0070],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9968924522399902
 
[Iteration 3] Process ID: 216417 [Epoch: 61,   576/ 2309 points] total loss per batch: 0.800
Policy (actual, predicted): 4 4
Policy data: tensor([0.0305, 0.0351, 0.0146, 0.0179, 0.8029, 0.0146, 0.0843],
       device='cuda:0')
Policy pred: tensor([0.0542, 0.0112, 0.0205, 0.0234, 0.7816, 0.0084, 0.1006],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9924123287200928
 
[Iteration 3] Process ID: 216417 [Epoch: 61,  1152/ 2309 points] total loss per batch: 0.766
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 3.9480e-18, 2.0984e-17, 2.6622e-09, 1.6344e-19, 0.0000e+00,
        3.8554e-11], device='cuda:0')
Policy pred: tensor([9.9998e-01, 7.8508e-09, 1.6731e-05, 6.8222e-11, 6.3414e-09, 2.1546e-12,
        2.1523e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 61,  1728/ 2309 points] total loss per batch: 0.808
Policy (actual, predicted): 4 4
Policy data: tensor([0.0167, 0.0080, 0.0133, 0.0080, 0.8862, 0.0513, 0.0167],
       device='cuda:0')
Policy pred: tensor([0.0991, 0.0969, 0.0812, 0.1118, 0.4229, 0.0935, 0.0946],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.008860034868121147
 
[Iteration 3] Process ID: 216417 [Epoch: 61,  2304/ 2309 points] total loss per batch: 0.823
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 2.4388e-06, 2.6590e-13, 1.4280e-20, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([8.5637e-08, 9.8630e-01, 8.6356e-07, 9.1271e-03, 4.5737e-03, 2.0283e-06,
        6.0856e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 62,   576/ 2309 points] total loss per batch: 0.792
Policy (actual, predicted): 2 2
Policy data: tensor([1.2402e-04, 1.6798e-13, 6.6123e-01, 8.7371e-20, 8.5323e-23, 5.2830e-12,
        3.3865e-01], device='cuda:0')
Policy pred: tensor([6.2930e-05, 2.8645e-04, 9.8511e-01, 2.1679e-04, 3.8256e-04, 1.8420e-03,
        1.2096e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999988079071045
 
[Iteration 3] Process ID: 216417 [Epoch: 62,  1152/ 2309 points] total loss per batch: 0.854
Policy (actual, predicted): 5 5
Policy data: tensor([0.0151, 0.0043, 0.0080, 0.0168, 0.0251, 0.9155, 0.0151],
       device='cuda:0')
Policy pred: tensor([0.0096, 0.0041, 0.0079, 0.0133, 0.0260, 0.9237, 0.0153],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.25747808814048767
 
[Iteration 3] Process ID: 216417 [Epoch: 62,  1728/ 2309 points] total loss per batch: 0.722
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 3.0564e-15, 0.0000e+00, 2.0320e-15, 3.2818e-16, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9793e-01, 3.0063e-04, 1.5221e-09, 1.5149e-03, 2.5692e-04, 1.7879e-10,
        2.6226e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999996423721313
 
[Iteration 3] Process ID: 216417 [Epoch: 62,  2304/ 2309 points] total loss per batch: 0.787
Policy (actual, predicted): 4 4
Policy data: tensor([0.0222, 0.0093, 0.0222, 0.0714, 0.6617, 0.0093, 0.2039],
       device='cuda:0')
Policy pred: tensor([0.0274, 0.0151, 0.0362, 0.0628, 0.5215, 0.0112, 0.3258],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9491429924964905
 
[Iteration 3] Process ID: 216417 [Epoch: 63,   576/ 2309 points] total loss per batch: 0.793
Policy (actual, predicted): 1 1
Policy data: tensor([2.9606e-20, 1.0000e+00, 5.4856e-08, 2.7185e-18, 0.0000e+00, 6.4896e-18,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.8130e-05, 9.9910e-01, 8.0756e-06, 2.3544e-04, 4.8345e-11, 6.3096e-04,
        3.6650e-11], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 63,  1152/ 2309 points] total loss per batch: 0.780
Policy (actual, predicted): 5 5
Policy data: tensor([0.0151, 0.0043, 0.0080, 0.0168, 0.0251, 0.9155, 0.0151],
       device='cuda:0')
Policy pred: tensor([0.0135, 0.0043, 0.0081, 0.0169, 0.0199, 0.9226, 0.0147],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.3372059464454651
 
[Iteration 3] Process ID: 216417 [Epoch: 63,  1728/ 2309 points] total loss per batch: 0.816
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 9.9999e-01, 5.8720e-06, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.4745e-11, 5.8180e-14, 9.9981e-01, 1.8610e-04, 8.0031e-10, 9.2265e-08,
        1.5739e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999649524688721
 
[Iteration 3] Process ID: 216417 [Epoch: 63,  2304/ 2309 points] total loss per batch: 0.742
Policy (actual, predicted): 4 4
Policy data: tensor([1.8162e-08, 9.9636e-17, 1.0203e-23, 1.0203e-23, 9.9368e-01, 3.6072e-09,
        6.3173e-03], device='cuda:0')
Policy pred: tensor([2.7945e-05, 2.0049e-06, 2.1414e-05, 9.1784e-08, 9.9989e-01, 1.3805e-05,
        4.4002e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999798536300659
 
[Iteration 3] Process ID: 216417 [Epoch: 64,   576/ 2309 points] total loss per batch: 0.754
Policy (actual, predicted): 1 1
Policy data: tensor([2.9868e-19, 1.0000e+00, 8.4369e-21, 3.2840e-17, 1.0664e-16, 4.1175e-18,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.1945e-04, 9.9907e-01, 7.4947e-07, 4.1714e-05, 7.6345e-04, 9.0789e-06,
        5.4735e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999979138374329
 
[Iteration 3] Process ID: 216417 [Epoch: 64,  1152/ 2309 points] total loss per batch: 0.762
Policy (actual, predicted): 6 4
Policy data: tensor([0.0340, 0.0250, 0.0189, 0.0141, 0.4056, 0.0204, 0.4819],
       device='cuda:0')
Policy pred: tensor([0.0336, 0.0209, 0.0208, 0.0133, 0.4455, 0.0206, 0.4453],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.7666382789611816
 
[Iteration 3] Process ID: 216417 [Epoch: 64,  1728/ 2309 points] total loss per batch: 0.810
Policy (actual, predicted): 4 4
Policy data: tensor([0.0457, 0.0429, 0.0567, 0.0727, 0.5490, 0.1316, 0.1013],
       device='cuda:0')
Policy pred: tensor([0.0430, 0.0441, 0.0497, 0.0735, 0.5512, 0.1362, 0.1022],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.6907362937927246
 
[Iteration 3] Process ID: 216417 [Epoch: 64,  2304/ 2309 points] total loss per batch: 0.797
Policy (actual, predicted): 6 6
Policy data: tensor([0.0296, 0.0251, 0.0189, 0.0142, 0.4072, 0.0205, 0.4846],
       device='cuda:0')
Policy pred: tensor([0.0305, 0.0211, 0.0159, 0.0122, 0.3827, 0.0147, 0.5229],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.8061196804046631
 
[Iteration 3] Process ID: 216417 [Epoch: 65,   576/ 2309 points] total loss per batch: 0.755
Policy (actual, predicted): 6 6
Policy data: tensor([0.0240, 0.0144, 0.0128, 0.0128, 0.2750, 0.0077, 0.6534],
       device='cuda:0')
Policy pred: tensor([0.0261, 0.0151, 0.0133, 0.0115, 0.2844, 0.0057, 0.6440],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.8556878566741943
 
[Iteration 3] Process ID: 216417 [Epoch: 65,  1152/ 2309 points] total loss per batch: 0.778
Policy (actual, predicted): 6 6
Policy data: tensor([0.2864, 0.0041, 0.0646, 0.0093, 0.0059, 0.0175, 0.6121],
       device='cuda:0')
Policy pred: tensor([0.2599, 0.0063, 0.0639, 0.0132, 0.0066, 0.0262, 0.6239],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.01222946960479021
 
[Iteration 3] Process ID: 216417 [Epoch: 65,  1728/ 2309 points] total loss per batch: 0.787
Policy (actual, predicted): 6 6
Policy data: tensor([0.0332, 0.0062, 0.0043, 0.0151, 0.0062, 0.0202, 0.9148],
       device='cuda:0')
Policy pred: tensor([0.0429, 0.0078, 0.0062, 0.0137, 0.0057, 0.0193, 0.9044],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.7789313197135925
 
[Iteration 3] Process ID: 216417 [Epoch: 65,  2304/ 2309 points] total loss per batch: 0.796
Policy (actual, predicted): 0 0
Policy data: tensor([0.3022, 0.1275, 0.1665, 0.0604, 0.1665, 0.0604, 0.1165],
       device='cuda:0')
Policy pred: tensor([0.3057, 0.1156, 0.1653, 0.0641, 0.1732, 0.0562, 0.1199],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 66,   576/ 2309 points] total loss per batch: 0.821
Policy (actual, predicted): 1 1
Policy data: tensor([9.2252e-13, 1.0000e+00, 0.0000e+00, 3.4733e-26, 3.3124e-22, 0.0000e+00,
        9.0089e-16], device='cuda:0')
Policy pred: tensor([3.2851e-04, 9.9958e-01, 1.5425e-05, 4.0897e-07, 3.0253e-05, 1.2079e-05,
        2.8638e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999989867210388
 
[Iteration 3] Process ID: 216417 [Epoch: 66,  1152/ 2309 points] total loss per batch: 0.739
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 0.0000e+00, 4.4273e-05, 1.8085e-07, 0.0000e+00, 7.4354e-03,
        9.9252e-01], device='cuda:0')
Policy pred: tensor([6.2839e-10, 3.9374e-08, 1.5526e-04, 2.3988e-06, 6.5540e-11, 3.3581e-03,
        9.9648e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9997913241386414
 
[Iteration 3] Process ID: 216417 [Epoch: 66,  1728/ 2309 points] total loss per batch: 0.809
Policy (actual, predicted): 5 5
Policy data: tensor([9.7469e-09, 3.3592e-15, 1.7787e-11, 1.5588e-10, 6.8575e-22, 9.9498e-01,
        5.0243e-03], device='cuda:0')
Policy pred: tensor([1.1316e-04, 1.2772e-04, 3.1617e-04, 2.0760e-04, 4.7821e-06, 9.9543e-01,
        3.8003e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998323321342468
 
[Iteration 3] Process ID: 216417 [Epoch: 66,  2304/ 2309 points] total loss per batch: 0.739
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 6.3047e-07, 5.4710e-17, 1.0000e+00, 0.0000e+00, 5.6023e-14,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([7.2702e-15, 4.2678e-06, 1.3174e-06, 9.9997e-01, 4.7910e-10, 2.7454e-05,
        8.7666e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 67,   576/ 2309 points] total loss per batch: 0.777
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 6.1577e-13, 6.3054e-10, 0.0000e+00,
        4.7465e-07], device='cuda:0')
Policy pred: tensor([6.3433e-12, 9.9991e-01, 1.4419e-11, 1.3368e-08, 1.1971e-05, 3.3809e-11,
        7.9464e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999970555305481
 
[Iteration 3] Process ID: 216417 [Epoch: 67,  1152/ 2309 points] total loss per batch: 0.743
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 6.9964e-16, 2.6342e-19, 1.5928e-21, 0.0000e+00, 2.7621e-23,
        3.6315e-18], device='cuda:0')
Policy pred: tensor([9.9996e-01, 1.6252e-07, 2.1312e-05, 7.1756e-08, 4.6058e-11, 1.6071e-07,
        1.5391e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999989867210388
 
[Iteration 3] Process ID: 216417 [Epoch: 67,  1728/ 2309 points] total loss per batch: 0.804
Policy (actual, predicted): 1 1
Policy data: tensor([1.6724e-02, 8.8238e-01, 4.4557e-03, 6.6212e-03, 4.4557e-03, 3.5145e-05,
        8.5326e-02], device='cuda:0')
Policy pred: tensor([0.0243, 0.8400, 0.0041, 0.0182, 0.0050, 0.0014, 0.1069],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9988627433776855
 
[Iteration 3] Process ID: 216417 [Epoch: 67,  2304/ 2309 points] total loss per batch: 0.796
Policy (actual, predicted): 4 6
Policy data: tensor([0.1501, 0.1501, 0.1442, 0.1266, 0.1571, 0.1230, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1590, 0.1454, 0.1254, 0.1325, 0.1493, 0.1250, 0.1634],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9982244372367859
 
[Iteration 3] Process ID: 216417 [Epoch: 68,   576/ 2309 points] total loss per batch: 0.755
Policy (actual, predicted): 4 4
Policy data: tensor([4.3940e-04, 1.8605e-04, 7.7822e-04, 5.2837e-03, 9.4013e-01, 5.1985e-02,
        1.2021e-03], device='cuda:0')
Policy pred: tensor([3.5533e-04, 7.7371e-05, 6.5826e-05, 2.5745e-03, 9.7219e-01, 2.3843e-02,
        8.9886e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999890923500061
 
[Iteration 3] Process ID: 216417 [Epoch: 68,  1152/ 2309 points] total loss per batch: 0.705
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 6.9976e-23, 6.8335e-26, 6.6734e-29, 1.8949e-08, 6.6734e-29,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([9.7092e-11, 1.1085e-04, 1.4765e-03, 1.7071e-04, 8.5403e-04, 5.4957e-04,
        9.9684e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998050332069397
 
[Iteration 3] Process ID: 216417 [Epoch: 68,  1728/ 2309 points] total loss per batch: 0.782
Policy (actual, predicted): 3 3
Policy data: tensor([1.4219e-14, 5.1547e-20, 8.0075e-16, 1.0000e+00, 2.9433e-16, 8.0075e-16,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([6.8730e-05, 8.9945e-04, 1.5499e-06, 9.9891e-01, 5.2923e-05, 6.3431e-05,
        1.7873e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 68,  2304/ 2309 points] total loss per batch: 0.872
Policy (actual, predicted): 5 5
Policy data: tensor([2.6180e-07, 0.0000e+00, 4.0636e-11, 1.6599e-13, 0.0000e+00, 1.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.1158e-05, 1.3102e-07, 3.8051e-05, 2.0105e-07, 7.1526e-08, 9.9993e-01,
        2.8198e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 69,   576/ 2309 points] total loss per batch: 0.809
Policy (actual, predicted): 4 4
Policy data: tensor([0.0710, 0.0131, 0.0042, 0.0810, 0.8225, 0.0022, 0.0061],
       device='cuda:0')
Policy pred: tensor([0.0608, 0.0136, 0.0046, 0.0878, 0.8230, 0.0035, 0.0067],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.49430590867996216
 
[Iteration 3] Process ID: 216417 [Epoch: 69,  1152/ 2309 points] total loss per batch: 0.751
Policy (actual, predicted): 3 5
Policy data: tensor([0.1407, 0.1465, 0.1372, 0.1512, 0.1372, 0.1383, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.0826, 0.0628, 0.0731, 0.0833, 0.0723, 0.5508, 0.0750],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9996340870857239
 
[Iteration 3] Process ID: 216417 [Epoch: 69,  1728/ 2309 points] total loss per batch: 0.796
Policy (actual, predicted): 2 2
Policy data: tensor([2.2797e-07, 8.9025e-08, 9.9989e-01, 1.0485e-04, 2.7348e-16, 2.6936e-08,
        2.6707e-09], device='cuda:0')
Policy pred: tensor([4.1375e-04, 1.8438e-05, 9.9924e-01, 1.0897e-04, 2.4318e-05, 1.3164e-04,
        6.6979e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999933838844299
 
[Iteration 3] Process ID: 216417 [Epoch: 69,  2304/ 2309 points] total loss per batch: 0.760
Policy (actual, predicted): 0 0
Policy data: tensor([0.6968, 0.0379, 0.2347, 0.0041, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.5828, 0.0568, 0.2532, 0.0221, 0.0252, 0.0287, 0.0312],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.008128492161631584
 
[Iteration 3] Process ID: 216417 [Epoch: 70,   576/ 2309 points] total loss per batch: 0.794
Policy (actual, predicted): 0 0
Policy data: tensor([9.9950e-01, 3.1690e-15, 4.9993e-04, 9.5047e-20, 2.6849e-11, 1.5719e-27,
        4.4403e-19], device='cuda:0')
Policy pred: tensor([9.9689e-01, 9.9494e-06, 2.9148e-03, 3.4696e-06, 1.4342e-04, 1.6848e-05,
        2.2754e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999973177909851
 
[Iteration 3] Process ID: 216417 [Epoch: 70,  1152/ 2309 points] total loss per batch: 0.801
Policy (actual, predicted): 3 1
Policy data: tensor([0.0000e+00, 3.7077e-01, 8.4812e-11, 6.2923e-01, 0.0000e+00, 1.9755e-10,
        3.4481e-08], device='cuda:0')
Policy pred: tensor([1.1338e-08, 5.3876e-01, 1.0354e-03, 4.5392e-01, 9.3367e-10, 7.5510e-04,
        5.5264e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 70,  1728/ 2309 points] total loss per batch: 0.744
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000, 0.0000, 0.1570, 0.0857, 0.1471, 0.3144, 0.2958],
       device='cuda:0')
Policy pred: tensor([1.6909e-04, 3.7635e-05, 1.6793e-01, 1.0459e-01, 1.5532e-01, 2.9600e-01,
        2.7596e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 70,  2304/ 2309 points] total loss per batch: 0.774
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 0.0000e+00, 8.0810e-19, 3.3453e-20, 1.1124e-16, 3.2669e-23,
        4.3982e-15], device='cuda:0')
Policy pred: tensor([9.9921e-01, 7.0078e-10, 3.4443e-04, 2.1012e-07, 5.4335e-06, 7.3459e-07,
        4.3479e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 71,   576/ 2309 points] total loss per batch: 0.696
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0741, 0.0235, 0.0247, 0.0227, 0.0518, 0.0631, 0.7401],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.013249053619801998
 
[Iteration 3] Process ID: 216417 [Epoch: 71,  1152/ 2309 points] total loss per batch: 0.869
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 3.0720e-19, 3.4587e-14, 8.1591e-16, 3.1457e-26, 0.0000e+00,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([4.4398e-09, 1.1660e-04, 1.5508e-06, 1.2233e-04, 6.7016e-09, 2.7220e-07,
        9.9976e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 71,  1728/ 2309 points] total loss per batch: 0.763
Policy (actual, predicted): 4 4
Policy data: tensor([0.0891, 0.0786, 0.0200, 0.0260, 0.4807, 0.0170, 0.2887],
       device='cuda:0')
Policy pred: tensor([0.0874, 0.0737, 0.0198, 0.0358, 0.4664, 0.0133, 0.3035],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9997742176055908
 
[Iteration 3] Process ID: 216417 [Epoch: 71,  2304/ 2309 points] total loss per batch: 0.796
Policy (actual, predicted): 3 3
Policy data: tensor([0., 0., 0., 1., 0., 0., 0.], device='cuda:0')
Policy pred: tensor([1.8058e-10, 3.1123e-10, 3.3864e-09, 1.0000e+00, 1.4764e-09, 1.4739e-09,
        3.7172e-11], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 72,   576/ 2309 points] total loss per batch: 0.782
Policy (actual, predicted): 4 4
Policy data: tensor([0.1908, 0.1168, 0.0596, 0.1047, 0.2586, 0.1264, 0.1431],
       device='cuda:0')
Policy pred: tensor([0.2015, 0.1086, 0.0574, 0.0872, 0.2897, 0.1108, 0.1448],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9986622333526611
 
[Iteration 3] Process ID: 216417 [Epoch: 72,  1152/ 2309 points] total loss per batch: 0.742
Policy (actual, predicted): 6 6
Policy data: tensor([0.0238, 0.0374, 0.0284, 0.0591, 0.0159, 0.1096, 0.7257],
       device='cuda:0')
Policy pred: tensor([0.0349, 0.0456, 0.0392, 0.1023, 0.0327, 0.1419, 0.6033],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.07970747351646423
 
[Iteration 3] Process ID: 216417 [Epoch: 72,  1728/ 2309 points] total loss per batch: 0.840
Policy (actual, predicted): 4 4
Policy data: tensor([3.8398e-07, 2.3218e-09, 1.7219e-06, 2.4718e-21, 1.0000e+00, 6.2611e-14,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.4664e-04, 5.8336e-05, 2.3667e-05, 1.5179e-06, 9.9941e-01, 5.5767e-05,
        2.0177e-13], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9992901682853699
 
[Iteration 3] Process ID: 216417 [Epoch: 72,  2304/ 2309 points] total loss per batch: 0.752
Policy (actual, predicted): 0 0
Policy data: tensor([6.4212e-01, 3.5788e-01, 3.2961e-09, 6.2664e-26, 2.1850e-16, 6.2664e-26,
        7.6388e-06], device='cuda:0')
Policy pred: tensor([7.5940e-01, 2.3811e-01, 9.7732e-04, 5.0523e-04, 5.0794e-04, 5.6545e-05,
        4.4881e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998211860657
 
[Iteration 3] Process ID: 216417 [Epoch: 73,   576/ 2309 points] total loss per batch: 0.725
Policy (actual, predicted): 6 6
Policy data: tensor([8.2349e-08, 3.1339e-22, 3.3650e-03, 5.3073e-27, 5.0615e-13, 0.0000e+00,
        9.9663e-01], device='cuda:0')
Policy pred: tensor([2.9001e-03, 1.8326e-05, 4.4489e-04, 3.9131e-06, 3.5506e-06, 8.1026e-07,
        9.9663e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999881982803345
 
[Iteration 3] Process ID: 216417 [Epoch: 73,  1152/ 2309 points] total loss per batch: 0.811
Policy (actual, predicted): 6 6
Policy data: tensor([7.0308e-02, 1.4174e-12, 6.5303e-17, 2.3673e-22, 1.4058e-01, 2.3673e-22,
        7.8911e-01], device='cuda:0')
Policy pred: tensor([5.6589e-02, 2.5109e-05, 7.5883e-04, 2.8144e-04, 1.8346e-01, 1.1041e-03,
        7.5779e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999893307685852
 
[Iteration 3] Process ID: 216417 [Epoch: 73,  1728/ 2309 points] total loss per batch: 0.802
Policy (actual, predicted): 5 5
Policy data: tensor([4.2726e-06, 4.4817e-01, 1.4043e-08, 1.4178e-04, 1.6572e-05, 5.4795e-01,
        3.7186e-03], device='cuda:0')
Policy pred: tensor([0.0006, 0.4104, 0.0051, 0.0036, 0.0027, 0.5718, 0.0058],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999773502349854
 
[Iteration 3] Process ID: 216417 [Epoch: 73,  2304/ 2309 points] total loss per batch: 0.774
Policy (actual, predicted): 6 6
Policy data: tensor([6.8773e-07, 7.7869e-14, 8.1652e-18, 7.9738e-21, 3.9061e-03, 7.6044e-27,
        9.9609e-01], device='cuda:0')
Policy pred: tensor([9.0387e-04, 8.1368e-07, 6.8146e-05, 2.8377e-07, 1.3795e-03, 1.3148e-05,
        9.9763e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999961256980896
 
[Iteration 3] Process ID: 216417 [Epoch: 74,   576/ 2309 points] total loss per batch: 0.771
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0714, 0.0184, 0.0205, 0.0217, 0.0464, 0.0539, 0.7678],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.0078012458980083466
 
[Iteration 3] Process ID: 216417 [Epoch: 74,  1152/ 2309 points] total loss per batch: 0.763
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 8.6580e-18, 2.1898e-19, 6.5854e-23, 6.1332e-22, 7.2408e-11,
        6.4311e-16], device='cuda:0')
Policy pred: tensor([9.9988e-01, 2.3285e-05, 2.3192e-06, 5.4931e-08, 1.9478e-06, 1.4886e-06,
        8.9995e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999950528144836
 
[Iteration 3] Process ID: 216417 [Epoch: 74,  1728/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 4 4
Policy data: tensor([1.2746e-18, 1.1870e-17, 2.1079e-26, 2.1079e-26, 1.0000e+00, 2.0585e-29,
        2.0103e-22], device='cuda:0')
Policy pred: tensor([7.3797e-06, 2.2504e-04, 1.3744e-05, 2.1266e-04, 9.9932e-01, 5.6256e-06,
        2.1797e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9968443512916565
 
[Iteration 3] Process ID: 216417 [Epoch: 74,  2304/ 2309 points] total loss per batch: 0.792
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 5.1547e-10, 5.0339e-23, 1.2452e-18, 0.0000e+00, 4.9159e-26,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9995e-01, 4.6434e-05, 2.7975e-08, 8.1280e-09, 1.8171e-16, 3.5650e-07,
        5.2921e-12], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999994039535522
 
[Iteration 3] Process ID: 216417 [Epoch: 75,   576/ 2309 points] total loss per batch: 0.758
Policy (actual, predicted): 0 0
Policy data: tensor([0.7593, 0.0255, 0.0376, 0.0270, 0.0361, 0.0636, 0.0508],
       device='cuda:0')
Policy pred: tensor([0.7671, 0.0309, 0.0394, 0.0222, 0.0430, 0.0590, 0.0383],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9963809847831726
 
[Iteration 3] Process ID: 216417 [Epoch: 75,  1152/ 2309 points] total loss per batch: 0.770
Policy (actual, predicted): 0 0
Policy data: tensor([0.8625, 0.0555, 0.0540, 0.0061, 0.0097, 0.0042, 0.0079],
       device='cuda:0')
Policy pred: tensor([0.8524, 0.0623, 0.0492, 0.0087, 0.0122, 0.0043, 0.0110],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9854462742805481
 
[Iteration 3] Process ID: 216417 [Epoch: 75,  1728/ 2309 points] total loss per batch: 0.843
Policy (actual, predicted): 6 6
Policy data: tensor([5.3287e-09, 4.0652e-22, 6.0154e-09, 7.8158e-16, 3.9699e-25, 1.8642e-12,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([3.5041e-05, 7.9702e-06, 7.3625e-06, 2.6416e-04, 1.2508e-07, 1.1040e-03,
        9.9858e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9991903305053711
 
[Iteration 3] Process ID: 216417 [Epoch: 75,  2304/ 2309 points] total loss per batch: 0.743
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 0.0000e+00, 4.9497e-21, 4.9497e-21, 0.0000e+00, 4.5449e-19,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9902e-01, 8.0984e-05, 4.5983e-04, 2.0723e-04, 5.5598e-06, 2.2117e-04,
        5.6132e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.991594672203064
 
[Iteration 3] Process ID: 216417 [Epoch: 76,   576/ 2309 points] total loss per batch: 0.783
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 1.3640e-06, 1.0000e+00, 6.5064e-09, 1.0940e-08, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.2435e-08, 1.8214e-07, 9.9999e-01, 1.1053e-06, 5.1671e-06, 1.9464e-07,
        6.7127e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 76,  1152/ 2309 points] total loss per batch: 0.773
Policy (actual, predicted): 5 5
Policy data: tensor([4.2065e-17, 2.1879e-23, 2.1879e-23, 2.0866e-29, 2.0377e-22, 1.0000e+00,
        5.8941e-21], device='cuda:0')
Policy pred: tensor([5.3224e-04, 2.2556e-05, 3.9571e-05, 7.9011e-07, 7.0139e-06, 9.9888e-01,
        5.1813e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 76,  1728/ 2309 points] total loss per batch: 0.788
Policy (actual, predicted): 5 5
Policy data: tensor([6.3485e-03, 4.2188e-17, 2.7170e-05, 4.4237e-11, 4.4855e-06, 9.8493e-01,
        8.6861e-03], device='cuda:0')
Policy pred: tensor([1.3002e-02, 1.3600e-03, 6.8544e-04, 1.8567e-04, 3.0162e-04, 9.5947e-01,
        2.4997e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999992847442627
 
[Iteration 3] Process ID: 216417 [Epoch: 76,  2304/ 2309 points] total loss per batch: 0.769
Policy (actual, predicted): 3 3
Policy data: tensor([0., 0., 0., 1., 0., 0., 0.], device='cuda:0')
Policy pred: tensor([4.4737e-08, 4.8710e-07, 2.9843e-05, 9.9995e-01, 3.3154e-07, 3.0703e-07,
        1.4476e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 77,   576/ 2309 points] total loss per batch: 0.778
Policy (actual, predicted): 5 5
Policy data: tensor([1.0633e-05, 5.5765e-16, 2.2048e-14, 2.1983e-06, 5.5594e-02, 9.4439e-01,
        1.5619e-08], device='cuda:0')
Policy pred: tensor([1.4151e-03, 1.8533e-03, 2.3733e-04, 1.7888e-03, 4.4851e-02, 9.4922e-01,
        6.3076e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9944536089897156
 
[Iteration 3] Process ID: 216417 [Epoch: 77,  1152/ 2309 points] total loss per batch: 0.780
Policy (actual, predicted): 0 0
Policy data: tensor([0.6112, 0.1131, 0.0602, 0.0378, 0.0519, 0.0217, 0.1040],
       device='cuda:0')
Policy pred: tensor([0.6968, 0.0729, 0.0529, 0.0326, 0.0452, 0.0169, 0.0827],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9844576716423035
 
[Iteration 3] Process ID: 216417 [Epoch: 77,  1728/ 2309 points] total loss per batch: 0.810
Policy (actual, predicted): 6 4
Policy data: tensor([0.1454, 0.1372, 0.1360, 0.1360, 0.1489, 0.1430, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1405, 0.1488, 0.1259, 0.1215, 0.1746, 0.1387, 0.1500],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998258948326111
 
[Iteration 3] Process ID: 216417 [Epoch: 77,  2304/ 2309 points] total loss per batch: 0.740
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0201, 0.0958, 0.3626, 0.0066, 0.0053, 0.0101, 0.4995],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.04381966218352318
 
[Iteration 3] Process ID: 216417 [Epoch: 78,   576/ 2309 points] total loss per batch: 0.773
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000, 0.0000, 0.1698, 0.0400, 0.1593, 0.2055, 0.4254],
       device='cuda:0')
Policy pred: tensor([4.2615e-06, 5.9534e-06, 1.6380e-01, 3.9504e-02, 1.5469e-01, 1.9479e-01,
        4.4720e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9996330142021179
 
[Iteration 3] Process ID: 216417 [Epoch: 78,  1152/ 2309 points] total loss per batch: 0.763
Policy (actual, predicted): 5 5
Policy data: tensor([9.7469e-09, 3.3592e-15, 1.7787e-11, 1.5588e-10, 6.8575e-22, 9.9498e-01,
        5.0243e-03], device='cuda:0')
Policy pred: tensor([2.1724e-04, 2.3766e-04, 2.4558e-04, 6.6681e-04, 1.7402e-05, 9.9410e-01,
        4.5170e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999293863773346
 
[Iteration 3] Process ID: 216417 [Epoch: 78,  1728/ 2309 points] total loss per batch: 0.800
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 1.5172e-13, 4.0604e-13, 2.0796e-16, 0.0000e+00, 2.1295e-23,
        1.2021e-06], device='cuda:0')
Policy pred: tensor([9.9945e-01, 3.6290e-04, 4.7690e-05, 3.1451e-06, 9.8997e-11, 6.4345e-05,
        7.6971e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 78,  2304/ 2309 points] total loss per batch: 0.775
Policy (actual, predicted): 4 4
Policy data: tensor([0.2228, 0.1722, 0.1008, 0.1104, 0.2863, 0.0314, 0.0762],
       device='cuda:0')
Policy pred: tensor([0.2284, 0.1908, 0.1147, 0.0979, 0.2690, 0.0359, 0.0632],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 79,   576/ 2309 points] total loss per batch: 0.740
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0282, 0.1072, 0.3524, 0.0099, 0.0090, 0.0150, 0.4785],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.03623487055301666
 
[Iteration 3] Process ID: 216417 [Epoch: 79,  1152/ 2309 points] total loss per batch: 0.767
Policy (actual, predicted): 5 5
Policy data: tensor([1.8877e-02, 0.0000e+00, 4.5044e-07, 1.4446e-26, 4.9188e-10, 9.8112e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.7562e-02, 3.6412e-09, 3.9451e-04, 9.0897e-04, 5.1347e-04, 9.8062e-01,
        1.8152e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999991059303284
 
[Iteration 3] Process ID: 216417 [Epoch: 79,  1728/ 2309 points] total loss per batch: 0.785
Policy (actual, predicted): 0 0
Policy data: tensor([0.9266, 0.0043, 0.0062, 0.0062, 0.0252, 0.0062, 0.0252],
       device='cuda:0')
Policy pred: tensor([0.9181, 0.0060, 0.0057, 0.0067, 0.0292, 0.0068, 0.0275],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.016245504841208458
 
[Iteration 3] Process ID: 216417 [Epoch: 79,  2304/ 2309 points] total loss per batch: 0.820
Policy (actual, predicted): 4 4
Policy data: tensor([5.3195e-05, 1.4550e-20, 2.6457e-16, 9.9682e-05, 5.4617e-01, 1.4550e-20,
        4.5368e-01], device='cuda:0')
Policy pred: tensor([0.0075, 0.0010, 0.0036, 0.0037, 0.5439, 0.0007, 0.4396],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999977350234985
 
[Iteration 3] Process ID: 216417 [Epoch: 80,   576/ 2309 points] total loss per batch: 0.796
Policy (actual, predicted): 1 1
Policy data: tensor([0.0135, 0.9420, 0.0081, 0.0043, 0.0000, 0.0100, 0.0221],
       device='cuda:0')
Policy pred: tensor([1.6881e-02, 9.2425e-01, 1.0544e-02, 3.7435e-03, 2.8913e-08, 1.5585e-02,
        2.9001e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999963641166687
 
[Iteration 3] Process ID: 216417 [Epoch: 80,  1152/ 2309 points] total loss per batch: 0.808
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0454, 0.0527, 0.7853],
       device='cuda:0')
Policy pred: tensor([0.0895, 0.0283, 0.0310, 0.0290, 0.0622, 0.0701, 0.6899],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.00640910305082798
 
[Iteration 3] Process ID: 216417 [Epoch: 80,  1728/ 2309 points] total loss per batch: 0.774
Policy (actual, predicted): 1 1
Policy data: tensor([5.7937e-20, 1.0000e+00, 1.6616e-29, 1.7423e-23, 1.7015e-26, 1.6616e-29,
        1.7423e-23], device='cuda:0')
Policy pred: tensor([1.0080e-07, 9.9992e-01, 5.9659e-07, 1.0286e-06, 1.8534e-05, 4.4773e-05,
        1.4187e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999969601631165
 
[Iteration 3] Process ID: 216417 [Epoch: 80,  2304/ 2309 points] total loss per batch: 0.725
Policy (actual, predicted): 0 0
Policy data: tensor([7.5666e-01, 1.1044e-16, 1.0311e-07, 3.2435e-23, 2.4334e-01, 8.7375e-11,
        1.9152e-18], device='cuda:0')
Policy pred: tensor([7.2558e-01, 5.8795e-04, 1.3424e-04, 5.8478e-06, 2.7362e-01, 2.2484e-05,
        4.4646e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.0009558756719343364
 
[Iteration 3] Process ID: 216417 [Epoch: 81,   576/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 6 6
Policy data: tensor([0.3521, 0.0059, 0.0145, 0.0059, 0.0041, 0.0059, 0.6114],
       device='cuda:0')
Policy pred: tensor([0.3377, 0.0059, 0.0168, 0.0078, 0.0054, 0.0062, 0.6202],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.008184410631656647
 
[Iteration 3] Process ID: 216417 [Epoch: 81,  1152/ 2309 points] total loss per batch: 0.753
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 8.5827e-13, 2.4933e-13, 2.3450e-24, 0.0000e+00, 0.0000e+00,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([2.4248e-08, 3.8673e-05, 1.8082e-04, 9.4434e-05, 1.4153e-09, 3.8442e-04,
        9.9930e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999532103538513
 
[Iteration 3] Process ID: 216417 [Epoch: 81,  1728/ 2309 points] total loss per batch: 0.764
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 1.0000e+00, 1.5041e-20, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.0529e-07, 4.8813e-09, 9.9995e-01, 4.6835e-05, 2.0579e-09, 3.1037e-10,
        1.3841e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 81,  2304/ 2309 points] total loss per batch: 0.801
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0283, 0.1070, 0.3524, 0.0119, 0.0128, 0.0161, 0.4714],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.009289986453950405
 
[Iteration 3] Process ID: 216417 [Epoch: 82,   576/ 2309 points] total loss per batch: 0.814
Policy (actual, predicted): 0 6
Policy data: tensor([0.2094, 0.1496, 0.1425, 0.1235, 0.0734, 0.1103, 0.1912],
       device='cuda:0')
Policy pred: tensor([0.1849, 0.1532, 0.1802, 0.1134, 0.0598, 0.1178, 0.1906],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.996656596660614
 
[Iteration 3] Process ID: 216417 [Epoch: 82,  1152/ 2309 points] total loss per batch: 0.761
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 2.6700e-04, 4.3122e-05, 1.1445e-16, 6.5352e-03, 2.7647e-15,
        9.9315e-01], device='cuda:0')
Policy pred: tensor([7.0048e-10, 1.5790e-03, 1.0254e-03, 2.7258e-07, 1.0155e-02, 2.5057e-04,
        9.8699e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 82,  1728/ 2309 points] total loss per batch: 0.749
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 5.0296e-17, 1.1179e-09, 1.6981e-21, 0.0000e+00, 1.0514e-20,
        1.4494e-09], device='cuda:0')
Policy pred: tensor([9.9976e-01, 8.8101e-06, 1.0216e-07, 1.1814e-07, 1.1092e-12, 4.6400e-06,
        2.2523e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998856782913208
 
[Iteration 3] Process ID: 216417 [Epoch: 82,  2304/ 2309 points] total loss per batch: 0.794
Policy (actual, predicted): 2 2
Policy data: tensor([1.2566e-14, 3.1318e-23, 1.0000e+00, 7.7469e-19, 2.9168e-22, 1.7223e-17,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.1991e-06, 5.6445e-09, 9.9985e-01, 3.8574e-06, 3.4519e-06, 1.3945e-04,
        7.5690e-11], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 83,   576/ 2309 points] total loss per batch: 0.780
Policy (actual, predicted): 0 0
Policy data: tensor([9.9405e-01, 2.8405e-06, 5.8862e-03, 9.3283e-23, 6.1285e-05, 9.3283e-23,
        1.3168e-08], device='cuda:0')
Policy pred: tensor([9.8995e-01, 2.2115e-03, 5.3689e-03, 5.9990e-05, 1.6173e-03, 1.6538e-05,
        7.7746e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999956488609314
 
[Iteration 3] Process ID: 216417 [Epoch: 83,  1152/ 2309 points] total loss per batch: 0.812
Policy (actual, predicted): 6 6
Policy data: tensor([0.0039, 0.0822, 0.0008, 0.3249, 0.0011, 0.0009, 0.5863],
       device='cuda:0')
Policy pred: tensor([0.0073, 0.0925, 0.0055, 0.3457, 0.0031, 0.0010, 0.5449],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999993443489075
 
[Iteration 3] Process ID: 216417 [Epoch: 83,  1728/ 2309 points] total loss per batch: 0.731
Policy (actual, predicted): 0 0
Policy data: tensor([9.6982e-01, 1.5738e-17, 3.0178e-02, 9.0755e-16, 1.4657e-16, 9.2933e-13,
        4.1404e-08], device='cuda:0')
Policy pred: tensor([9.7271e-01, 2.9194e-04, 2.4492e-02, 2.1912e-04, 6.9934e-04, 4.4446e-05,
        1.5479e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9985267519950867
 
[Iteration 3] Process ID: 216417 [Epoch: 83,  2304/ 2309 points] total loss per batch: 0.793
Policy (actual, predicted): 6 6
Policy data: tensor([1.0261e-04, 7.5204e-02, 1.4865e-02, 1.8402e-05, 7.5204e-02, 9.4249e-09,
        8.3461e-01], device='cuda:0')
Policy pred: tensor([2.6379e-03, 6.8211e-02, 1.7358e-02, 1.4335e-04, 9.9614e-02, 2.3026e-05,
        8.1201e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999991059303284
 
[Iteration 3] Process ID: 216417 [Epoch: 84,   576/ 2309 points] total loss per batch: 0.718
Policy (actual, predicted): 4 4
Policy data: tensor([1.7363e-08, 3.3510e-18, 7.9211e-16, 1.2920e-28, 1.0000e+00, 7.4501e-17,
        7.9995e-18], device='cuda:0')
Policy pred: tensor([8.9859e-05, 1.0605e-06, 1.0261e-05, 5.9131e-09, 9.9961e-01, 3.4990e-06,
        2.8230e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999991655349731
 
[Iteration 3] Process ID: 216417 [Epoch: 84,  1152/ 2309 points] total loss per batch: 0.813
Policy (actual, predicted): 5 5
Policy data: tensor([9.6523e-20, 2.0177e-23, 3.5830e-22, 3.4170e-18, 1.9873e-05, 9.9998e-01,
        3.3369e-21], device='cuda:0')
Policy pred: tensor([2.9674e-04, 8.4046e-06, 6.2034e-05, 1.0931e-05, 3.5485e-04, 9.9897e-01,
        2.9295e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998845458030701
 
[Iteration 3] Process ID: 216417 [Epoch: 84,  1728/ 2309 points] total loss per batch: 0.776
Policy (actual, predicted): 4 4
Policy data: tensor([1.2361e-08, 1.6112e-06, 1.2151e-03, 6.5192e-10, 9.9877e-01, 9.9028e-12,
        1.3955e-05], device='cuda:0')
Policy pred: tensor([1.5612e-04, 1.6270e-04, 1.8604e-04, 2.8549e-06, 9.9930e-01, 1.8544e-08,
        1.9353e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999667406082153
 
[Iteration 3] Process ID: 216417 [Epoch: 84,  2304/ 2309 points] total loss per batch: 0.808
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 8.6124e-08, 8.9541e-23, 0.0000e+00, 8.3391e-22,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.3107e-12, 9.9999e-01, 9.3687e-11, 6.5496e-07, 1.1312e-17, 8.3335e-06,
        6.0840e-14], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 85,   576/ 2309 points] total loss per batch: 0.810
Policy (actual, predicted): 4 4
Policy data: tensor([0.0710, 0.0131, 0.0042, 0.0810, 0.8225, 0.0022, 0.0061],
       device='cuda:0')
Policy pred: tensor([0.0829, 0.0111, 0.0043, 0.0996, 0.7925, 0.0026, 0.0070],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.4794813096523285
 
[Iteration 3] Process ID: 216417 [Epoch: 85,  1152/ 2309 points] total loss per batch: 0.756
Policy (actual, predicted): 4 4
Policy data: tensor([0.0225, 0.0094, 0.0177, 0.0094, 0.6925, 0.0145, 0.2340],
       device='cuda:0')
Policy pred: tensor([0.0204, 0.0087, 0.0172, 0.0086, 0.7275, 0.0146, 0.2030],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.44512102007865906
 
[Iteration 3] Process ID: 216417 [Epoch: 85,  1728/ 2309 points] total loss per batch: 0.722
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 9.3203e-15, 0.0000e+00, 4.6355e-26, 4.7467e-13, 1.0000e+00,
        2.8702e-15], device='cuda:0')
Policy pred: tensor([7.0007e-11, 6.4174e-06, 6.6247e-11, 2.8762e-08, 4.4937e-07, 9.9999e-01,
        4.9738e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 85,  2304/ 2309 points] total loss per batch: 0.831
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 5.8745e-07, 5.4710e-17, 1.0000e+00, 0.0000e+00, 7.9572e-14,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.6429e-12, 9.5814e-06, 6.5699e-06, 9.9987e-01, 1.2091e-08, 1.0921e-04,
        1.4394e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 86,   576/ 2309 points] total loss per batch: 0.822
Policy (actual, predicted): 4 6
Policy data: tensor([0.1419, 0.1465, 0.1419, 0.1383, 0.1489, 0.1372, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.0792, 0.0267, 0.0290, 0.0261, 0.0587, 0.0624, 0.7178],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.008323080837726593
 
[Iteration 3] Process ID: 216417 [Epoch: 86,  1152/ 2309 points] total loss per batch: 0.784
Policy (actual, predicted): 5 6
Policy data: tensor([0.1426, 0.1296, 0.1579, 0.0759, 0.0896, 0.2107, 0.1936],
       device='cuda:0')
Policy pred: tensor([0.1462, 0.1129, 0.1798, 0.0582, 0.0981, 0.1811, 0.2237],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999292492866516
 
[Iteration 3] Process ID: 216417 [Epoch: 86,  1728/ 2309 points] total loss per batch: 0.729
Policy (actual, predicted): 5 5
Policy data: tensor([9.6523e-20, 2.0177e-23, 3.5830e-22, 3.4170e-18, 1.9873e-05, 9.9998e-01,
        3.3369e-21], device='cuda:0')
Policy pred: tensor([3.2548e-04, 1.2176e-06, 7.4610e-05, 1.8925e-05, 8.1447e-04, 9.9840e-01,
        3.6255e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999646008014679
 
[Iteration 3] Process ID: 216417 [Epoch: 86,  2304/ 2309 points] total loss per batch: 0.780
Policy (actual, predicted): 4 4
Policy data: tensor([0.0280, 0.0280, 0.0199, 0.0166, 0.8745, 0.0166, 0.0166],
       device='cuda:0')
Policy pred: tensor([0.0292, 0.0332, 0.0198, 0.0181, 0.8589, 0.0211, 0.0198],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9947028160095215
 
[Iteration 3] Process ID: 216417 [Epoch: 87,   576/ 2309 points] total loss per batch: 0.777
Policy (actual, predicted): 6 6
Policy data: tensor([0.0201, 0.0201, 0.0098, 0.0133, 0.0218, 0.0098, 0.9051],
       device='cuda:0')
Policy pred: tensor([0.1077, 0.1014, 0.1115, 0.0943, 0.1444, 0.1062, 0.3346],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.14796245098114014
 
[Iteration 3] Process ID: 216417 [Epoch: 87,  1152/ 2309 points] total loss per batch: 0.740
Policy (actual, predicted): 4 4
Policy data: tensor([0.0060, 0.0275, 0.0442, 0.0060, 0.7810, 0.0060, 0.1294],
       device='cuda:0')
Policy pred: tensor([0.0087, 0.0247, 0.0444, 0.0054, 0.7922, 0.0066, 0.1180],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.0783815085887909
 
[Iteration 3] Process ID: 216417 [Epoch: 87,  1728/ 2309 points] total loss per batch: 0.852
Policy (actual, predicted): 2 2
Policy data: tensor([2.1408e-01, 5.3253e-09, 7.8592e-01, 9.0957e-13, 0.0000e+00, 1.7004e-06,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.7436e-01, 3.6770e-04, 8.2470e-01, 1.4941e-06, 2.3704e-07, 5.6904e-04,
        2.5943e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998211860657
 
[Iteration 3] Process ID: 216417 [Epoch: 87,  2304/ 2309 points] total loss per batch: 0.750
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 9.5053e-19, 9.0650e-25, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([7.2096e-08, 9.9994e-01, 1.6140e-05, 4.4054e-05, 2.1354e-09, 5.6554e-07,
        4.3529e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 88,   576/ 2309 points] total loss per batch: 0.776
Policy (actual, predicted): 4 4
Policy data: tensor([0.0710, 0.0131, 0.0042, 0.0810, 0.8225, 0.0022, 0.0061],
       device='cuda:0')
Policy pred: tensor([0.0646, 0.0108, 0.0032, 0.0869, 0.8285, 0.0017, 0.0044],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.4826723635196686
 
[Iteration 3] Process ID: 216417 [Epoch: 88,  1152/ 2309 points] total loss per batch: 0.760
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 6.1074e-23, 3.5218e-21, 0.0000e+00, 1.0000e+00, 0.0000e+00,
        5.8245e-09], device='cuda:0')
Policy pred: tensor([1.6504e-05, 1.4921e-06, 1.5303e-04, 2.5832e-07, 9.9946e-01, 1.2897e-06,
        3.7073e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999918937683105
 
[Iteration 3] Process ID: 216417 [Epoch: 88,  1728/ 2309 points] total loss per batch: 0.776
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0361, 0.1099, 0.3332, 0.0111, 0.0113, 0.0170, 0.4813],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.009729363024234772
 
[Iteration 3] Process ID: 216417 [Epoch: 88,  2304/ 2309 points] total loss per batch: 0.804
Policy (actual, predicted): 6 6
Policy data: tensor([0.0240, 0.0144, 0.0128, 0.0128, 0.2738, 0.0077, 0.6546],
       device='cuda:0')
Policy pred: tensor([0.0295, 0.0170, 0.0150, 0.0127, 0.2294, 0.0092, 0.6872],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.7741722464561462
 
[Iteration 3] Process ID: 216417 [Epoch: 89,   576/ 2309 points] total loss per batch: 0.773
Policy (actual, predicted): 0 2
Policy data: tensor([0.4704, 0.0174, 0.4406, 0.0076, 0.0342, 0.0076, 0.0221],
       device='cuda:0')
Policy pred: tensor([0.3238, 0.0175, 0.6039, 0.0104, 0.0258, 0.0031, 0.0156],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9995478391647339
 
[Iteration 3] Process ID: 216417 [Epoch: 89,  1152/ 2309 points] total loss per batch: 0.756
Policy (actual, predicted): 6 6
Policy data: tensor([0.1121, 0.0077, 0.1386, 0.0059, 0.0059, 0.0077, 0.7221],
       device='cuda:0')
Policy pred: tensor([0.1321, 0.0080, 0.1524, 0.0046, 0.0041, 0.0086, 0.6901],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9982823133468628
 
[Iteration 3] Process ID: 216417 [Epoch: 89,  1728/ 2309 points] total loss per batch: 0.763
Policy (actual, predicted): 4 4
Policy data: tensor([0.0642, 0.0357, 0.0312, 0.0174, 0.6840, 0.0236, 0.1438],
       device='cuda:0')
Policy pred: tensor([0.0746, 0.0405, 0.0329, 0.0161, 0.6456, 0.0286, 0.1617],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9986326694488525
 
[Iteration 3] Process ID: 216417 [Epoch: 89,  2304/ 2309 points] total loss per batch: 0.818
Policy (actual, predicted): 2 2
Policy data: tensor([0.2227, 0.2262, 0.2706, 0.0071, 0.0459, 0.1075, 0.1198],
       device='cuda:0')
Policy pred: tensor([0.2455, 0.2353, 0.2727, 0.0112, 0.0448, 0.0874, 0.1030],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9970501661300659
 
[Iteration 3] Process ID: 216417 [Epoch: 90,   576/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 1 1
Policy data: tensor([0.0023, 0.9141, 0.0023, 0.0023, 0.0043, 0.0062, 0.0685],
       device='cuda:0')
Policy pred: tensor([0.0024, 0.9158, 0.0032, 0.0024, 0.0070, 0.0084, 0.0608],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9664506316184998
 
[Iteration 3] Process ID: 216417 [Epoch: 90,  1152/ 2309 points] total loss per batch: 0.746
Policy (actual, predicted): 2 2
Policy data: tensor([2.2797e-07, 8.9025e-08, 9.9989e-01, 1.0485e-04, 2.7348e-16, 2.6936e-08,
        2.6707e-09], device='cuda:0')
Policy pred: tensor([3.5922e-04, 1.4536e-05, 9.9953e-01, 5.0005e-05, 5.6357e-06, 1.7719e-05,
        1.8150e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999898374080658
 
[Iteration 3] Process ID: 216417 [Epoch: 90,  1728/ 2309 points] total loss per batch: 0.814
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 9.7557e-01, 2.4434e-02, 2.8158e-18, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.0132e-08, 9.9036e-01, 9.5370e-03, 1.0432e-04, 4.2533e-08, 1.5659e-06,
        1.1048e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999799728393555
 
[Iteration 3] Process ID: 216417 [Epoch: 90,  2304/ 2309 points] total loss per batch: 0.783
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 4.8704e-09, 4.2587e-12, 1.0000e+00, 5.1812e-15, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.2597e-08, 1.3377e-04, 7.9639e-04, 9.9890e-01, 1.5094e-04, 3.5652e-06,
        1.0886e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 91,   576/ 2309 points] total loss per batch: 0.744
Policy (actual, predicted): 0 0
Policy data: tensor([0.1949, 0.1949, 0.1462, 0.0722, 0.1261, 0.1823, 0.0835],
       device='cuda:0')
Policy pred: tensor([0.2075, 0.1911, 0.1301, 0.0910, 0.1284, 0.1787, 0.0732],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9797096848487854
 
[Iteration 3] Process ID: 216417 [Epoch: 91,  1152/ 2309 points] total loss per batch: 0.789
Policy (actual, predicted): 1 1
Policy data: tensor([8.1901e-12, 1.0000e+00, 7.0451e-26, 4.1601e-21, 6.7187e-22, 6.7187e-22,
        9.9454e-12], device='cuda:0')
Policy pred: tensor([9.2454e-10, 9.9999e-01, 8.9583e-10, 1.5276e-08, 2.7614e-07, 4.2941e-08,
        4.8502e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999228119850159
 
[Iteration 3] Process ID: 216417 [Epoch: 91,  1728/ 2309 points] total loss per batch: 0.791
Policy (actual, predicted): 6 6
Policy data: tensor([5.8104e-12, 5.5412e-18, 9.1642e-26, 9.1642e-26, 3.3506e-10, 9.1642e-26,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([9.0618e-04, 1.3228e-04, 9.2673e-06, 7.8108e-06, 4.2230e-03, 2.8888e-05,
        9.9469e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999492764472961
 
[Iteration 3] Process ID: 216417 [Epoch: 91,  2304/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 0 0
Policy data: tensor([9.9555e-01, 3.6605e-17, 3.8383e-11, 3.4091e-16, 3.9893e-04, 3.4091e-16,
        4.0513e-03], device='cuda:0')
Policy pred: tensor([9.9169e-01, 6.4754e-06, 1.0610e-04, 5.9391e-06, 2.3309e-03, 5.2545e-05,
        5.8056e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 92,   576/ 2309 points] total loss per batch: 0.762
Policy (actual, predicted): 4 4
Policy data: tensor([8.3003e-16, 1.9567e-22, 2.0517e-26, 2.0517e-26, 1.0000e+00, 2.0036e-29,
        2.0517e-26], device='cuda:0')
Policy pred: tensor([1.4140e-04, 1.7330e-04, 9.2750e-06, 9.3512e-07, 9.9958e-01, 1.0737e-06,
        9.0653e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 92,  1152/ 2309 points] total loss per batch: 0.765
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 6.9976e-23, 6.8335e-26, 6.6734e-29, 1.8949e-08, 6.6734e-29,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([5.9075e-10, 1.5860e-04, 3.1265e-03, 1.6180e-04, 8.1314e-04, 9.7999e-04,
        9.9476e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999436736106873
 
[Iteration 3] Process ID: 216417 [Epoch: 92,  1728/ 2309 points] total loss per batch: 0.766
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 3.3893e-12, 2.4044e-07, 1.1270e-08,
        2.5212e-11], device='cuda:0')
Policy pred: tensor([1.0393e-10, 9.9972e-01, 6.9619e-10, 1.0497e-07, 3.5264e-05, 1.6462e-05,
        2.2465e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999949932098389
 
[Iteration 3] Process ID: 216417 [Epoch: 92,  2304/ 2309 points] total loss per batch: 0.828
Policy (actual, predicted): 2 2
Policy data: tensor([8.3299e-03, 9.3513e-15, 9.9164e-01, 1.6606e-23, 3.5103e-05, 5.6544e-17,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([7.8045e-02, 4.0789e-04, 9.1951e-01, 1.9214e-05, 5.0698e-04, 1.0281e-03,
        4.8785e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999808669090271
 
[Iteration 3] Process ID: 216417 [Epoch: 93,   576/ 2309 points] total loss per batch: 0.785
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 1.3640e-06, 1.0000e+00, 6.5064e-09, 1.0940e-08, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([5.8251e-10, 8.0416e-09, 1.0000e+00, 1.2543e-07, 2.9743e-06, 1.1481e-08,
        8.0675e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 93,  1152/ 2309 points] total loss per batch: 0.768
Policy (actual, predicted): 3 3
Policy data: tensor([1.4219e-14, 5.1547e-20, 8.0075e-16, 1.0000e+00, 2.9433e-16, 8.0075e-16,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([6.2407e-05, 3.2447e-04, 7.5500e-07, 9.9960e-01, 2.2492e-06, 1.1906e-05,
        1.6091e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999992847442627
 
[Iteration 3] Process ID: 216417 [Epoch: 93,  1728/ 2309 points] total loss per batch: 0.780
Policy (actual, predicted): 1 1
Policy data: tensor([3.2773e-08, 9.9890e-01, 1.1015e-03, 7.2726e-13, 1.5701e-12, 2.1541e-18,
        2.2588e-12], device='cuda:0')
Policy pred: tensor([2.5959e-05, 9.9937e-01, 1.8959e-04, 5.3553e-05, 2.0477e-05, 1.7304e-04,
        1.6771e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9954842329025269
 
[Iteration 3] Process ID: 216417 [Epoch: 93,  2304/ 2309 points] total loss per batch: 0.788
Policy (actual, predicted): 5 5
Policy data: tensor([0.0976, 0.0472, 0.0702, 0.0416, 0.0976, 0.5650, 0.0808],
       device='cuda:0')
Policy pred: tensor([0.0900, 0.0535, 0.0767, 0.0603, 0.1165, 0.4974, 0.1056],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999995231628418
 
[Iteration 3] Process ID: 216417 [Epoch: 94,   576/ 2309 points] total loss per batch: 0.768
Policy (actual, predicted): 2 4
Policy data: tensor([0.1489, 0.1395, 0.1501, 0.1336, 0.1465, 0.1348, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1409, 0.1419, 0.1450, 0.1563, 0.1588, 0.1439, 0.1132],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998211860657
 
[Iteration 3] Process ID: 216417 [Epoch: 94,  1152/ 2309 points] total loss per batch: 0.803
Policy (actual, predicted): 5 5
Policy data: tensor([0.0483, 0.0394, 0.0527, 0.0060, 0.0242, 0.7856, 0.0439],
       device='cuda:0')
Policy pred: tensor([0.0408, 0.0381, 0.0444, 0.0048, 0.0201, 0.8126, 0.0392],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.293222576379776
 
[Iteration 3] Process ID: 216417 [Epoch: 94,  1728/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 6 6
Policy data: tensor([8.2883e-02, 1.6709e-12, 7.6983e-17, 2.7907e-22, 1.6573e-01, 2.9263e-16,
        7.5139e-01], device='cuda:0')
Policy pred: tensor([4.9621e-02, 8.3650e-06, 1.3267e-03, 1.2985e-04, 9.6677e-02, 4.0401e-04,
        8.5183e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999992847442627
 
[Iteration 3] Process ID: 216417 [Epoch: 94,  2304/ 2309 points] total loss per batch: 0.752
Policy (actual, predicted): 5 5
Policy data: tensor([7.3440e-17, 0.0000e+00, 2.1511e-24, 1.5694e-11, 0.0000e+00, 1.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9183e-05, 4.2818e-07, 3.4939e-07, 6.3031e-06, 3.9488e-07, 9.9989e-01,
        3.2108e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9997860193252563
 
[Iteration 3] Process ID: 216417 [Epoch: 95,   576/ 2309 points] total loss per batch: 0.745
Policy (actual, predicted): 0 0
Policy data: tensor([0.6989, 0.0379, 0.2309, 0.0059, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6501, 0.0380, 0.2448, 0.0144, 0.0153, 0.0195, 0.0180],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.007539134938269854
 
[Iteration 3] Process ID: 216417 [Epoch: 95,  1152/ 2309 points] total loss per batch: 0.819
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 6.1577e-13, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.8202e-06, 9.9999e-01, 1.6147e-07, 2.4581e-06, 1.5512e-09, 1.6838e-09,
        9.6598e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999985098838806
 
[Iteration 3] Process ID: 216417 [Epoch: 95,  1728/ 2309 points] total loss per batch: 0.747
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0300, 0.1116, 0.2813, 0.0117, 0.0108, 0.0142, 0.5404],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.00509565370157361
 
[Iteration 3] Process ID: 216417 [Epoch: 95,  2304/ 2309 points] total loss per batch: 0.802
Policy (actual, predicted): 3 3
Policy data: tensor([0.1043, 0.1954, 0.0787, 0.2321, 0.1253, 0.1143, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1096, 0.1938, 0.0774, 0.2234, 0.1226, 0.0993, 0.1739],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 96,   576/ 2309 points] total loss per batch: 0.766
Policy (actual, predicted): 6 6
Policy data: tensor([0.1827, 0.2834, 0.0499, 0.0000, 0.0000, 0.1827, 0.3013],
       device='cuda:0')
Policy pred: tensor([1.9203e-01, 2.5862e-01, 5.9883e-02, 2.8398e-04, 1.9853e-07, 2.2970e-01,
        2.5948e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999240040779114
 
[Iteration 3] Process ID: 216417 [Epoch: 96,  1152/ 2309 points] total loss per batch: 0.806
Policy (actual, predicted): 4 6
Policy data: tensor([0.1419, 0.1465, 0.1419, 0.1383, 0.1489, 0.1372, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.0828, 0.0233, 0.0233, 0.0219, 0.0479, 0.0609, 0.7398],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.013332175090909004
 
[Iteration 3] Process ID: 216417 [Epoch: 96,  1728/ 2309 points] total loss per batch: 0.748
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 0.0000e+00, 1.4482e-03, 9.9855e-01, 0.0000e+00, 1.1238e-09,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.5799e-10, 4.2637e-06, 5.2396e-04, 9.9937e-01, 7.2860e-08, 7.8587e-05,
        1.8814e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999992847442627
 
[Iteration 3] Process ID: 216417 [Epoch: 96,  2304/ 2309 points] total loss per batch: 0.807
Policy (actual, predicted): 4 4
Policy data: tensor([0.0588, 0.0167, 0.0098, 0.0042, 0.8842, 0.0080, 0.0183],
       device='cuda:0')
Policy pred: tensor([0.0490, 0.0135, 0.0059, 0.0021, 0.9085, 0.0084, 0.0126],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.007571451831609011
 
[Iteration 3] Process ID: 216417 [Epoch: 97,   576/ 2309 points] total loss per batch: 0.736
Policy (actual, predicted): 2 2
Policy data: tensor([1.1137e-10, 1.3294e-10, 1.0000e+00, 9.3010e-11, 7.7418e-11, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([8.5152e-03, 6.2861e-03, 9.7487e-01, 5.3907e-03, 4.9046e-03, 3.3213e-06,
        3.2230e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 97,  1152/ 2309 points] total loss per batch: 0.828
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0182, 0.0858, 0.3154, 0.0069, 0.0054, 0.0124, 0.5560],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.026781991124153137
 
[Iteration 3] Process ID: 216417 [Epoch: 97,  1728/ 2309 points] total loss per batch: 0.762
Policy (actual, predicted): 6 6
Policy data: tensor([0.0332, 0.0062, 0.0043, 0.0134, 0.0062, 0.0202, 0.9165],
       device='cuda:0')
Policy pred: tensor([0.0335, 0.0077, 0.0072, 0.0140, 0.0127, 0.0224, 0.9024],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.7945109605789185
 
[Iteration 3] Process ID: 216417 [Epoch: 97,  2304/ 2309 points] total loss per batch: 0.844
Policy (actual, predicted): 0 0
Policy data: tensor([0.7593, 0.0255, 0.0376, 0.0270, 0.0361, 0.0636, 0.0508],
       device='cuda:0')
Policy pred: tensor([0.8197, 0.0276, 0.0289, 0.0132, 0.0211, 0.0374, 0.0521],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9917275309562683
 
[Iteration 3] Process ID: 216417 [Epoch: 98,   576/ 2309 points] total loss per batch: 0.768
Policy (actual, predicted): 1 1
Policy data: tensor([4.3439e-11, 1.0000e+00, 4.3439e-11, 3.4868e-11, 2.7850e-11, 3.4868e-11,
        1.0000e-10], device='cuda:0')
Policy pred: tensor([4.0687e-07, 9.9974e-01, 4.7428e-05, 3.0031e-05, 2.5720e-07, 3.5168e-06,
        1.8229e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 98,  1152/ 2309 points] total loss per batch: 0.813
Policy (actual, predicted): 3 3
Policy data: tensor([0., 0., 0., 1., 0., 0., 0.], device='cuda:0')
Policy pred: tensor([5.3718e-06, 3.0379e-05, 5.9440e-06, 9.9975e-01, 2.0618e-04, 6.2946e-07,
        3.4175e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 98,  1728/ 2309 points] total loss per batch: 0.800
Policy (actual, predicted): 5 5
Policy data: tensor([0.0147, 0.0078, 0.0130, 0.0060, 0.0308, 0.8149, 0.1127],
       device='cuda:0')
Policy pred: tensor([0.0233, 0.0099, 0.0196, 0.0102, 0.0388, 0.7683, 0.1299],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.4030610918998718
 
[Iteration 3] Process ID: 216417 [Epoch: 98,  2304/ 2309 points] total loss per batch: 0.852
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 6.9964e-16, 2.6342e-19, 1.5928e-21, 0.0000e+00, 2.7621e-23,
        3.6315e-18], device='cuda:0')
Policy pred: tensor([9.8020e-01, 8.9851e-03, 1.2636e-03, 7.1025e-06, 3.5315e-09, 4.5440e-04,
        9.0885e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999614953994751
 
[Iteration 3] Process ID: 216417 [Epoch: 99,   576/ 2309 points] total loss per batch: 0.845
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 1.0948e-17, 4.9245e-19, 1.1211e-24, 1.9442e-26, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9973e-01, 2.5472e-04, 8.1031e-06, 8.4558e-07, 5.9680e-07, 9.9600e-09,
        3.3243e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999863505363464
 
[Iteration 3] Process ID: 216417 [Epoch: 99,  1152/ 2309 points] total loss per batch: 0.846
Policy (actual, predicted): 4 4
Policy data: tensor([0.1489, 0.1430, 0.1489, 0.1360, 0.1500, 0.1348, 0.1383],
       device='cuda:0')
Policy pred: tensor([0.2182, 0.1129, 0.0861, 0.1212, 0.2486, 0.0800, 0.1331],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9979550242424011
 
[Iteration 3] Process ID: 216417 [Epoch: 99,  1728/ 2309 points] total loss per batch: 0.870
Policy (actual, predicted): 2 0
Policy data: tensor([0.1454, 0.1442, 0.1524, 0.1313, 0.1512, 0.1348, 0.1407],
       device='cuda:0')
Policy pred: tensor([0.5493, 0.0706, 0.2548, 0.0267, 0.0271, 0.0358, 0.0357],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.0028556117322295904
 
[Iteration 3] Process ID: 216417 [Epoch: 99,  2304/ 2309 points] total loss per batch: 0.833
Policy (actual, predicted): 5 6
Policy data: tensor([0.0138, 0.0107, 0.0107, 0.2710, 0.0361, 0.3369, 0.3208],
       device='cuda:0')
Policy pred: tensor([0.0451, 0.0544, 0.0494, 0.1047, 0.0515, 0.1615, 0.5334],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.053993403911590576
 
[Iteration 3] Process ID: 216417 [Epoch: 100,   576/ 2309 points] total loss per batch: 0.797
Policy (actual, predicted): 4 4
Policy data: tensor([2.6084e-22, 4.0520e-08, 2.5473e-25, 2.6710e-19, 1.0000e+00, 1.0465e-13,
        3.5959e-11], device='cuda:0')
Policy pred: tensor([2.4080e-06, 1.3560e-02, 2.9853e-07, 1.2877e-05, 9.8636e-01, 8.0936e-06,
        6.0011e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9988968372344971
 
[Iteration 3] Process ID: 216417 [Epoch: 100,  1152/ 2309 points] total loss per batch: 0.772
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 3.7165e-18, 6.1464e-26, 6.1464e-26, 9.3132e-10, 6.1464e-26,
        1.5568e-18], device='cuda:0')
Policy pred: tensor([9.9946e-01, 3.6569e-05, 2.3911e-06, 1.9667e-06, 4.9181e-04, 3.8286e-07,
        6.1568e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999692440032959
 
[Iteration 3] Process ID: 216417 [Epoch: 100,  1728/ 2309 points] total loss per batch: 0.839
Policy (actual, predicted): 5 5
Policy data: tensor([3.9849e-10, 2.1401e-17, 1.0238e-13, 6.2850e-24, 7.4620e-08, 9.9946e-01,
        5.4034e-04], device='cuda:0')
Policy pred: tensor([1.8270e-04, 6.2720e-04, 1.6080e-04, 5.7151e-05, 3.0716e-04, 9.9750e-01,
        1.1651e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999999463558197
 
[Iteration 3] Process ID: 216417 [Epoch: 100,  2304/ 2309 points] total loss per batch: 0.833
Policy (actual, predicted): 1 1
Policy data: tensor([7.4114e-18, 1.0000e+00, 2.7512e-20, 2.6237e-26, 0.0000e+00, 1.5493e-21,
        1.0614e-15], device='cuda:0')
Policy pred: tensor([4.2545e-04, 9.9832e-01, 5.0873e-05, 1.2373e-05, 9.3845e-13, 4.3867e-04,
        7.4969e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 101,   576/ 2309 points] total loss per batch: 0.788
Policy (actual, predicted): 4 4
Policy data: tensor([0.0147, 0.0060, 0.1342, 0.0096, 0.8016, 0.0078, 0.0261],
       device='cuda:0')
Policy pred: tensor([0.0377, 0.0126, 0.0906, 0.0285, 0.7871, 0.0119, 0.0316],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9614180326461792
 
[Iteration 3] Process ID: 216417 [Epoch: 101,  1152/ 2309 points] total loss per batch: 0.774
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 1.7574e-22, 1.0378e-17, 1.8428e-26, 0.0000e+00, 1.7574e-22,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.0000e+00, 7.1248e-09, 8.3201e-07, 4.0235e-11, 7.8782e-15, 1.9179e-08,
        6.2161e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 101,  1728/ 2309 points] total loss per batch: 0.786
Policy (actual, predicted): 4 4
Policy data: tensor([0.0222, 0.0093, 0.0222, 0.0714, 0.6617, 0.0093, 0.2039],
       device='cuda:0')
Policy pred: tensor([0.0230, 0.0151, 0.0359, 0.0732, 0.5365, 0.0114, 0.3049],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9097784161567688
 
[Iteration 3] Process ID: 216417 [Epoch: 101,  2304/ 2309 points] total loss per batch: 0.808
Policy (actual, predicted): 4 4
Policy data: tensor([0.0259, 0.0211, 0.0060, 0.0078, 0.7551, 0.0078, 0.1764],
       device='cuda:0')
Policy pred: tensor([0.0577, 0.0570, 0.0082, 0.0108, 0.6900, 0.0104, 0.1659],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.1003412976861
 
[Iteration 3] Process ID: 216417 [Epoch: 102,   576/ 2309 points] total loss per batch: 0.780
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0805, 0.0256, 0.0264, 0.0237, 0.0582, 0.0603, 0.7255],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.020970696583390236
 
[Iteration 3] Process ID: 216417 [Epoch: 102,  1152/ 2309 points] total loss per batch: 0.781
Policy (actual, predicted): 0 0
Policy data: tensor([0.6966, 0.0317, 0.0022, 0.0022, 0.2013, 0.0022, 0.0639],
       device='cuda:0')
Policy pred: tensor([7.6450e-01, 1.0025e-02, 2.6961e-03, 2.3304e-04, 1.6729e-01, 3.7524e-04,
        5.4872e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9800733327865601
 
[Iteration 3] Process ID: 216417 [Epoch: 102,  1728/ 2309 points] total loss per batch: 0.798
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 9.6702e-17, 0.0000e+00, 2.2047e-13, 1.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.4554e-08, 1.1726e-04, 2.0365e-10, 2.1922e-05, 9.9986e-01, 4.5605e-10,
        1.2018e-12], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999985098838806
 
[Iteration 3] Process ID: 216417 [Epoch: 102,  2304/ 2309 points] total loss per batch: 0.763
Policy (actual, predicted): 0 0
Policy data: tensor([0.5216, 0.0022, 0.3725, 0.0022, 0.0531, 0.0040, 0.0445],
       device='cuda:0')
Policy pred: tensor([0.5262, 0.0064, 0.3733, 0.0040, 0.0585, 0.0053, 0.0262],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999017119407654
 
[Iteration 3] Process ID: 216417 [Epoch: 103,   576/ 2309 points] total loss per batch: 0.775
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 9.3656e-09, 1.0000e+00, 1.7388e-28, 1.4155e-12, 1.0268e-23,
        2.9700e-12], device='cuda:0')
Policy pred: tensor([4.7177e-10, 9.6729e-06, 9.9998e-01, 4.3489e-08, 2.1348e-07, 1.2716e-07,
        1.2195e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 103,  1152/ 2309 points] total loss per batch: 0.726
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 8.8525e-18, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.6857e-09, 1.3300e-04, 1.0271e-08, 9.9987e-01, 4.0780e-09, 1.2178e-06,
        3.2420e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 103,  1728/ 2309 points] total loss per batch: 0.827
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000, 0.0000, 0.0000, 0.9989, 0.0000, 0.0011, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.5904e-08, 2.4688e-06, 2.1526e-07, 9.9860e-01, 2.5647e-06, 1.3759e-03,
        1.8071e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 103,  2304/ 2309 points] total loss per batch: 0.789
Policy (actual, predicted): 5 5
Policy data: tensor([0.0503, 0.0113, 0.0180, 0.0042, 0.0791, 0.8158, 0.0212],
       device='cuda:0')
Policy pred: tensor([0.0630, 0.0146, 0.0168, 0.0043, 0.0850, 0.7965, 0.0198],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999791979789734
 
[Iteration 3] Process ID: 216417 [Epoch: 104,   576/ 2309 points] total loss per batch: 0.810
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 1.0995e-18, 1.0995e-18, 1.0000e+00, 0.0000e+00, 1.8184e-26,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.4558e-09, 5.0921e-07, 8.9551e-07, 1.0000e+00, 1.9825e-10, 1.1870e-07,
        7.5258e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999983012676239
 
[Iteration 3] Process ID: 216417 [Epoch: 104,  1152/ 2309 points] total loss per batch: 0.784
Policy (actual, predicted): 6 6
Policy data: tensor([0.0719, 0.0383, 0.0280, 0.0092, 0.1691, 0.0469, 0.6368],
       device='cuda:0')
Policy pred: tensor([0.0683, 0.0519, 0.0339, 0.0060, 0.1591, 0.0668, 0.6140],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9768127202987671
 
[Iteration 3] Process ID: 216417 [Epoch: 104,  1728/ 2309 points] total loss per batch: 0.762
Policy (actual, predicted): 4 4
Policy data: tensor([0.1501, 0.1501, 0.1442, 0.1266, 0.1571, 0.1230, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1420, 0.1240, 0.1451, 0.1469, 0.1558, 0.1321, 0.1540],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9959673881530762
 
[Iteration 3] Process ID: 216417 [Epoch: 104,  2304/ 2309 points] total loss per batch: 0.758
Policy (actual, predicted): 0 0
Policy data: tensor([9.9885e-01, 0.0000e+00, 5.1978e-21, 3.0693e-06, 1.1477e-03, 5.0760e-24,
        2.9973e-19], device='cuda:0')
Policy pred: tensor([9.9901e-01, 5.3494e-05, 1.0424e-05, 3.7573e-06, 8.6492e-04, 1.0976e-05,
        4.6391e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998804926872253
 
[Iteration 3] Process ID: 216417 [Epoch: 105,   576/ 2309 points] total loss per batch: 0.759
Policy (actual, predicted): 6 6
Policy data: tensor([0.0699, 0.0145, 0.0162, 0.0145, 0.0440, 0.0528, 0.7881],
       device='cuda:0')
Policy pred: tensor([0.0731, 0.0217, 0.0228, 0.0196, 0.0498, 0.0564, 0.7565],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.012501615099608898
 
[Iteration 3] Process ID: 216417 [Epoch: 105,  1152/ 2309 points] total loss per batch: 0.836
Policy (actual, predicted): 6 6
Policy data: tensor([3.5792e-10, 3.1058e-20, 2.2166e-16, 6.4925e-14, 1.1529e-22, 2.9203e-15,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([1.3587e-04, 1.0084e-04, 1.1434e-05, 7.2008e-06, 4.2489e-05, 4.2471e-04,
        9.9928e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999997079372406
 
[Iteration 3] Process ID: 216417 [Epoch: 105,  1728/ 2309 points] total loss per batch: 0.777
Policy (actual, predicted): 1 1
Policy data: tensor([9.2252e-13, 1.0000e+00, 0.0000e+00, 3.4733e-26, 3.3124e-22, 0.0000e+00,
        9.0089e-16], device='cuda:0')
Policy pred: tensor([6.0973e-05, 9.9984e-01, 1.7668e-05, 2.6821e-06, 2.2594e-05, 5.0795e-05,
        5.2900e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999986290931702
 
[Iteration 3] Process ID: 216417 [Epoch: 105,  2304/ 2309 points] total loss per batch: 0.741
Policy (actual, predicted): 3 3
Policy data: tensor([2.0242e-09, 3.6585e-09, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.3816e-11, 3.1596e-07, 6.0772e-10, 1.0000e+00, 8.4862e-07, 2.3360e-09,
        2.4396e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998211860657
 
[Iteration 3] Process ID: 216417 [Epoch: 106,   576/ 2309 points] total loss per batch: 0.705
Policy (actual, predicted): 4 4
Policy data: tensor([0.1118, 0.1901, 0.0525, 0.0431, 0.2454, 0.1118, 0.2454],
       device='cuda:0')
Policy pred: tensor([0.1104, 0.1862, 0.0547, 0.0324, 0.2557, 0.1068, 0.2539],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999985694885254
 
[Iteration 3] Process ID: 216417 [Epoch: 106,  1152/ 2309 points] total loss per batch: 0.834
Policy (actual, predicted): 4 4
Policy data: tensor([0.1501, 0.1454, 0.1501, 0.1242, 0.1524, 0.1337, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1588, 0.1515, 0.1479, 0.1118, 0.1601, 0.1201, 0.1497],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9985978007316589
 
[Iteration 3] Process ID: 216417 [Epoch: 106,  1728/ 2309 points] total loss per batch: 0.860
Policy (actual, predicted): 4 4
Policy data: tensor([0.0289, 0.0211, 0.0060, 0.0078, 0.7494, 0.0095, 0.1774],
       device='cuda:0')
Policy pred: tensor([0.0550, 0.0529, 0.0085, 0.0086, 0.6968, 0.0102, 0.1680],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.11134619265794754
 
[Iteration 3] Process ID: 216417 [Epoch: 106,  2304/ 2309 points] total loss per batch: 0.711
Policy (actual, predicted): 0 0
Policy data: tensor([6.4212e-01, 3.5788e-01, 3.2961e-09, 6.2664e-26, 2.1850e-16, 6.2664e-26,
        7.6388e-06], device='cuda:0')
Policy pred: tensor([6.9032e-01, 3.0749e-01, 1.1770e-03, 1.4923e-04, 6.5198e-04, 6.8118e-05,
        1.4992e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 107,   576/ 2309 points] total loss per batch: 0.766
Policy (actual, predicted): 3 3
Policy data: tensor([6.9636e-17, 1.1517e-24, 1.9972e-26, 1.0000e+00, 0.0000e+00, 1.9972e-26,
        2.0942e-20], device='cuda:0')
Policy pred: tensor([4.4836e-07, 6.4631e-05, 5.1243e-06, 9.9951e-01, 2.7206e-09, 2.9945e-04,
        1.2208e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999992311000824
 
[Iteration 3] Process ID: 216417 [Epoch: 107,  1152/ 2309 points] total loss per batch: 0.816
Policy (actual, predicted): 4 4
Policy data: tensor([0.1831, 0.0060, 0.0130, 0.0022, 0.7751, 0.0042, 0.0164],
       device='cuda:0')
Policy pred: tensor([0.1482, 0.0088, 0.0087, 0.0025, 0.7971, 0.0081, 0.0266],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999534487724304
 
[Iteration 3] Process ID: 216417 [Epoch: 107,  1728/ 2309 points] total loss per batch: 0.776
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 9.9846e-01, 1.5388e-03, 3.1175e-07, 0.0000e+00, 1.0778e-08,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.5773e-08, 9.9655e-01, 2.5197e-03, 8.1843e-04, 1.7645e-06, 1.1258e-04,
        2.7934e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 107,  2304/ 2309 points] total loss per batch: 0.752
Policy (actual, predicted): 4 4
Policy data: tensor([0.1821, 0.0657, 0.0880, 0.0550, 0.5073, 0.0550, 0.0468],
       device='cuda:0')
Policy pred: tensor([0.1738, 0.0707, 0.0956, 0.0586, 0.4972, 0.0539, 0.0501],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999803304672241
 
[Iteration 3] Process ID: 216417 [Epoch: 108,   576/ 2309 points] total loss per batch: 0.775
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 4.0043e-11, 6.6386e-05, 6.1676e-28, 9.9993e-01, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.4486e-06, 3.0765e-04, 1.7608e-05, 8.1363e-08, 9.9967e-01, 6.3732e-09,
        2.4360e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 108,  1152/ 2309 points] total loss per batch: 0.814
Policy (actual, predicted): 2 2
Policy data: tensor([0.1910, 0.0201, 0.3882, 0.0039, 0.3495, 0.0139, 0.0334],
       device='cuda:0')
Policy pred: tensor([0.2086, 0.0210, 0.4090, 0.0028, 0.3140, 0.0136, 0.0309],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9997588396072388
 
[Iteration 3] Process ID: 216417 [Epoch: 108,  1728/ 2309 points] total loss per batch: 0.741
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 1.1431e-13, 1.0000e+00, 1.4677e-11, 3.5401e-19, 0.0000e+00,
        1.7756e-11], device='cuda:0')
Policy pred: tensor([8.5019e-10, 1.2790e-08, 9.9953e-01, 2.0040e-09, 1.6624e-06, 5.4423e-07,
        4.6356e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 108,  2304/ 2309 points] total loss per batch: 0.771
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 4.0505e-12, 1.9945e-13, 1.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.4084e-07, 1.5446e-03, 1.6858e-04, 9.9829e-01, 2.3603e-10, 2.1543e-07,
        1.5270e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 109,   576/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 5 5
Policy data: tensor([3.7544e-05, 1.2123e-09, 1.9580e-10, 1.1839e-12, 1.4946e-04, 9.9981e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.9049e-06, 2.3297e-05, 7.9231e-06, 7.1712e-06, 1.5608e-05, 9.9994e-01,
        5.1551e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 109,  1152/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 4 6
Policy data: tensor([0.1118, 0.1901, 0.0525, 0.0431, 0.2454, 0.1118, 0.2454],
       device='cuda:0')
Policy pred: tensor([0.1050, 0.1857, 0.0494, 0.0400, 0.2275, 0.1222, 0.2702],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999998152256012
 
[Iteration 3] Process ID: 216417 [Epoch: 109,  1728/ 2309 points] total loss per batch: 0.776
Policy (actual, predicted): 4 0
Policy data: tensor([0.1512, 0.1489, 0.1454, 0.1336, 0.1524, 0.1325, 0.1360],
       device='cuda:0')
Policy pred: tensor([0.1750, 0.1327, 0.1332, 0.1299, 0.1502, 0.1345, 0.1445],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9989250898361206
 
[Iteration 3] Process ID: 216417 [Epoch: 109,  2304/ 2309 points] total loss per batch: 0.752
Policy (actual, predicted): 4 4
Policy data: tensor([0.0809, 0.0424, 0.0564, 0.0494, 0.6497, 0.0323, 0.0889],
       device='cuda:0')
Policy pred: tensor([0.0798, 0.0413, 0.0682, 0.0479, 0.6364, 0.0370, 0.0894],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.5775726437568665
 
[Iteration 3] Process ID: 216417 [Epoch: 110,   576/ 2309 points] total loss per batch: 0.805
Policy (actual, predicted): 0 0
Policy data: tensor([0.7972, 0.0972, 0.0762, 0.0096, 0.0042, 0.0078, 0.0078],
       device='cuda:0')
Policy pred: tensor([0.8045, 0.0800, 0.0858, 0.0078, 0.0048, 0.0076, 0.0096],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9974979758262634
 
[Iteration 3] Process ID: 216417 [Epoch: 110,  1152/ 2309 points] total loss per batch: 0.728
Policy (actual, predicted): 0 0
Policy data: tensor([0.4393, 0.0189, 0.0058, 0.0540, 0.0173, 0.4382, 0.0265],
       device='cuda:0')
Policy pred: tensor([0.4513, 0.0193, 0.0080, 0.0506, 0.0126, 0.4313, 0.0270],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999985933303833
 
[Iteration 3] Process ID: 216417 [Epoch: 110,  1728/ 2309 points] total loss per batch: 0.792
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 1.2023e-15, 4.5268e-19, 1.1741e-18, 1.5784e-19, 1.0000e+00,
        6.0762e-13], device='cuda:0')
Policy pred: tensor([2.7210e-08, 7.9682e-05, 2.2751e-04, 4.5865e-06, 4.8476e-07, 9.9855e-01,
        1.1397e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9973660111427307
 
[Iteration 3] Process ID: 216417 [Epoch: 110,  2304/ 2309 points] total loss per batch: 0.780
Policy (actual, predicted): 6 6
Policy data: tensor([0.3521, 0.0059, 0.0145, 0.0059, 0.0041, 0.0059, 0.6114],
       device='cuda:0')
Policy pred: tensor([0.3785, 0.0072, 0.0137, 0.0059, 0.0049, 0.0060, 0.5839],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.023327581584453583
 
[Iteration 3] Process ID: 216417 [Epoch: 111,   576/ 2309 points] total loss per batch: 0.799
Policy (actual, predicted): 0 0
Policy data: tensor([7.7539e-01, 1.7372e-10, 9.7829e-12, 4.2972e-16, 0.0000e+00, 2.2461e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([7.9446e-01, 2.5054e-03, 2.1835e-03, 8.8821e-04, 2.3757e-08, 1.9988e-01,
        8.2367e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9989820122718811
 
[Iteration 3] Process ID: 216417 [Epoch: 111,  1152/ 2309 points] total loss per batch: 0.822
Policy (actual, predicted): 4 6
Policy data: tensor([5.3195e-05, 1.4550e-20, 2.6457e-16, 9.9682e-05, 5.4617e-01, 1.4550e-20,
        4.5368e-01], device='cuda:0')
Policy pred: tensor([2.0680e-03, 1.0874e-04, 1.3671e-03, 3.1624e-03, 4.3437e-01, 7.5853e-04,
        5.5817e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999882578849792
 
[Iteration 3] Process ID: 216417 [Epoch: 111,  1728/ 2309 points] total loss per batch: 0.760
Policy (actual, predicted): 2 2
Policy data: tensor([0.1282, 0.1678, 0.1833, 0.1536, 0.0732, 0.1536, 0.1404],
       device='cuda:0')
Policy pred: tensor([0.1194, 0.1438, 0.1971, 0.1541, 0.0699, 0.1673, 0.1483],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 111,  2304/ 2309 points] total loss per batch: 0.725
Policy (actual, predicted): 6 6
Policy data: tensor([3.0476e-03, 2.6844e-14, 2.4415e-16, 1.4417e-21, 8.8390e-09, 1.7834e-05,
        9.9693e-01], device='cuda:0')
Policy pred: tensor([3.5943e-04, 8.0874e-07, 1.0138e-04, 2.6342e-06, 3.3677e-03, 7.9696e-04,
        9.9537e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998906850814819
 
[Iteration 3] Process ID: 216417 [Epoch: 112,   576/ 2309 points] total loss per batch: 0.796
Policy (actual, predicted): 3 3
Policy data: tensor([2.4470e-14, 0.0000e+00, 1.3141e-21, 1.0000e+00, 0.0000e+00, 1.2833e-24,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.1955e-05, 4.2787e-11, 1.9035e-07, 9.9999e-01, 7.1217e-08, 6.8808e-07,
        3.3609e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 112,  1152/ 2309 points] total loss per batch: 0.787
Policy (actual, predicted): 1 4
Policy data: tensor([0.1336, 0.1489, 0.1489, 0.1454, 0.1407, 0.1372, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1313, 0.1485, 0.1495, 0.1356, 0.1663, 0.1310, 0.1378],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999899864196777
 
[Iteration 3] Process ID: 216417 [Epoch: 112,  1728/ 2309 points] total loss per batch: 0.737
Policy (actual, predicted): 6 6
Policy data: tensor([4.3486e-09, 9.0904e-13, 1.5764e-14, 2.6697e-19, 4.9941e-04, 1.3078e-12,
        9.9950e-01], device='cuda:0')
Policy pred: tensor([1.2973e-05, 3.5254e-05, 2.9544e-05, 1.7292e-05, 1.3607e-04, 8.9790e-06,
        9.9976e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9902521967887878
 
[Iteration 3] Process ID: 216417 [Epoch: 112,  2304/ 2309 points] total loss per batch: 0.804
Policy (actual, predicted): 6 6
Policy data: tensor([1.2579e-13, 3.9562e-12, 1.7213e-20, 6.3895e-23, 1.2284e-16, 3.5981e-24,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([3.7558e-11, 7.8322e-07, 5.0149e-13, 1.4999e-17, 3.1816e-08, 2.0320e-11,
        1.0000e+00], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 113,   576/ 2309 points] total loss per batch: 0.781
Policy (actual, predicted): 4 4
Policy data: tensor([3.7141e-22, 3.8032e-19, 3.7141e-22, 2.2458e-24, 1.0000e+00, 1.0101e-15,
        1.3905e-13], device='cuda:0')
Policy pred: tensor([2.3461e-04, 9.7367e-08, 9.6806e-05, 3.0057e-05, 9.9400e-01, 6.1469e-04,
        5.0251e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999651908874512
 
[Iteration 3] Process ID: 216417 [Epoch: 113,  1152/ 2309 points] total loss per batch: 0.809
Policy (actual, predicted): 4 4
Policy data: tensor([0.1780, 0.0060, 0.0130, 0.0022, 0.7801, 0.0042, 0.0164],
       device='cuda:0')
Policy pred: tensor([0.1720, 0.0060, 0.0092, 0.0013, 0.7880, 0.0035, 0.0200],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9993357062339783
 
[Iteration 3] Process ID: 216417 [Epoch: 113,  1728/ 2309 points] total loss per batch: 0.794
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 8.1264e-16, 2.3427e-13, 2.8768e-24, 2.9459e-21, 4.6463e-15,
        2.9459e-21], device='cuda:0')
Policy pred: tensor([9.9962e-01, 9.5513e-06, 1.7888e-04, 1.9628e-06, 9.6676e-05, 7.1243e-05,
        2.4842e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999898374080658
 
[Iteration 3] Process ID: 216417 [Epoch: 113,  2304/ 2309 points] total loss per batch: 0.733
Policy (actual, predicted): 0 0
Policy data: tensor([0.7959, 0.0972, 0.0776, 0.0096, 0.0042, 0.0078, 0.0078],
       device='cuda:0')
Policy pred: tensor([0.8273, 0.0706, 0.0725, 0.0073, 0.0040, 0.0074, 0.0109],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9937334060668945
 
[Iteration 3] Process ID: 216417 [Epoch: 114,   576/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 7.1536e-26, 4.3255e-08, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.6034e-07, 9.9998e-01, 3.8403e-10, 1.5594e-07, 1.5000e-05, 7.0862e-09,
        1.7552e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 114,  1152/ 2309 points] total loss per batch: 0.735
Policy (actual, predicted): 0 0
Policy data: tensor([0.6968, 0.0379, 0.2347, 0.0041, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6040, 0.0614, 0.2375, 0.0204, 0.0243, 0.0272, 0.0253],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.0018400584813207388
 
[Iteration 3] Process ID: 216417 [Epoch: 114,  1728/ 2309 points] total loss per batch: 0.789
Policy (actual, predicted): 2 0
Policy data: tensor([0.0381, 0.0043, 0.9264, 0.0023, 0.0043, 0.0203, 0.0043],
       device='cuda:0')
Policy pred: tensor([0.6156, 0.0562, 0.2343, 0.0200, 0.0216, 0.0278, 0.0245],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.002195317531004548
 
[Iteration 3] Process ID: 216417 [Epoch: 114,  2304/ 2309 points] total loss per batch: 0.793
Policy (actual, predicted): 2 2
Policy data: tensor([5.7022e-13, 5.7022e-13, 1.0000e+00, 2.3025e-09, 1.6702e-10, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.0610e-04, 9.6814e-07, 9.9989e-01, 2.6164e-07, 1.0807e-07, 1.2468e-07,
        1.4292e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 115,   576/ 2309 points] total loss per batch: 0.813
Policy (actual, predicted): 0 0
Policy data: tensor([0.6650, 0.0059, 0.0076, 0.0022, 0.0254, 0.1857, 0.1083],
       device='cuda:0')
Policy pred: tensor([0.6517, 0.0066, 0.0103, 0.0016, 0.0316, 0.1684, 0.1297],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9986968636512756
 
[Iteration 3] Process ID: 216417 [Epoch: 115,  1152/ 2309 points] total loss per batch: 0.785
Policy (actual, predicted): 4 4
Policy data: tensor([0.1821, 0.0657, 0.0880, 0.0550, 0.5073, 0.0550, 0.0468],
       device='cuda:0')
Policy pred: tensor([0.1764, 0.0674, 0.0827, 0.0448, 0.5311, 0.0492, 0.0484],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999980330467224
 
[Iteration 3] Process ID: 216417 [Epoch: 115,  1728/ 2309 points] total loss per batch: 0.732
Policy (actual, predicted): 0 0
Policy data: tensor([9.8535e-01, 3.7990e-21, 2.7067e-11, 1.7498e-09, 6.5880e-23, 4.2353e-04,
        1.4223e-02], device='cuda:0')
Policy pred: tensor([9.8173e-01, 2.1978e-05, 6.0338e-07, 2.1462e-05, 2.0586e-05, 2.3524e-03,
        1.5849e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 115,  2304/ 2309 points] total loss per batch: 0.767
Policy (actual, predicted): 5 5
Policy data: tensor([0.0483, 0.0394, 0.0527, 0.0060, 0.0242, 0.7856, 0.0439],
       device='cuda:0')
Policy pred: tensor([0.0448, 0.0377, 0.0526, 0.0064, 0.0215, 0.7921, 0.0450],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.30478131771087646
 
[Iteration 3] Process ID: 216417 [Epoch: 116,   576/ 2309 points] total loss per batch: 0.766
Policy (actual, predicted): 2 1
Policy data: tensor([0.1419, 0.1477, 0.1489, 0.1442, 0.1336, 0.1372, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1353, 0.1525, 0.1508, 0.1458, 0.1432, 0.1382, 0.1341],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 116,  1152/ 2309 points] total loss per batch: 0.774
Policy (actual, predicted): 0 0
Policy data: tensor([0.8967, 0.0200, 0.0167, 0.0115, 0.0184, 0.0233, 0.0133],
       device='cuda:0')
Policy pred: tensor([0.8798, 0.0241, 0.0174, 0.0137, 0.0199, 0.0270, 0.0181],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9996227025985718
 
[Iteration 3] Process ID: 216417 [Epoch: 116,  1728/ 2309 points] total loss per batch: 0.782
Policy (actual, predicted): 1 1
Policy data: tensor([0.1810, 0.3465, 0.1893, 0.0120, 0.0182, 0.0284, 0.2246],
       device='cuda:0')
Policy pred: tensor([0.1772, 0.3434, 0.1929, 0.0124, 0.0211, 0.0286, 0.2243],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.99692702293396
 
[Iteration 3] Process ID: 216417 [Epoch: 116,  2304/ 2309 points] total loss per batch: 0.782
Policy (actual, predicted): 6 6
Policy data: tensor([0.0267, 0.0234, 0.0116, 0.0080, 0.0080, 0.0151, 0.9072],
       device='cuda:0')
Policy pred: tensor([0.0279, 0.0202, 0.0142, 0.0055, 0.0093, 0.0155, 0.9074],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998303055763245
 
[Iteration 3] Process ID: 216417 [Epoch: 117,   576/ 2309 points] total loss per batch: 0.799
Policy (actual, predicted): 0 0
Policy data: tensor([0.7889, 0.0113, 0.0078, 0.0042, 0.0399, 0.0060, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.8059, 0.0076, 0.0065, 0.0027, 0.0307, 0.0041, 0.1424],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9967464804649353
 
[Iteration 3] Process ID: 216417 [Epoch: 117,  1152/ 2309 points] total loss per batch: 0.772
Policy (actual, predicted): 1 1
Policy data: tensor([3.1691e-16, 1.0000e+00, 5.1689e-19, 3.0522e-24, 1.0671e-13, 3.1255e-21,
        3.0522e-14], device='cuda:0')
Policy pred: tensor([7.1784e-08, 9.9999e-01, 7.0693e-08, 3.5797e-11, 2.3011e-07, 3.4608e-06,
        1.7312e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999996542930603
 
[Iteration 3] Process ID: 216417 [Epoch: 117,  1728/ 2309 points] total loss per batch: 0.805
Policy (actual, predicted): 5 5
Policy data: tensor([9.7469e-09, 3.3592e-15, 1.7787e-11, 1.5588e-10, 6.8575e-22, 9.9498e-01,
        5.0243e-03], device='cuda:0')
Policy pred: tensor([2.1544e-04, 2.9145e-04, 2.5379e-04, 4.4435e-04, 6.5233e-06, 9.9515e-01,
        3.6375e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9997615218162537
 
[Iteration 3] Process ID: 216417 [Epoch: 117,  2304/ 2309 points] total loss per batch: 0.733
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 5.0794e-20, 1.8855e-22, 1.8413e-25, 2.7900e-09, 5.3261e-14,
        6.5100e-11], device='cuda:0')
Policy pred: tensor([9.9964e-01, 3.4076e-08, 1.5632e-04, 1.1767e-08, 1.9385e-07, 1.9902e-04,
        1.2475e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999996423721313
 
[Iteration 3] Process ID: 216417 [Epoch: 118,   576/ 2309 points] total loss per batch: 0.778
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 1.0000e+00, 9.0438e-08, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.1515e-05, 2.3677e-09, 9.9933e-01, 2.8441e-04, 7.6276e-07, 4.9638e-07,
        3.7650e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9997817277908325
 
[Iteration 3] Process ID: 216417 [Epoch: 118,  1152/ 2309 points] total loss per batch: 0.781
Policy (actual, predicted): 4 4
Policy data: tensor([0.0169, 0.0081, 0.0099, 0.0043, 0.9326, 0.0062, 0.0220],
       device='cuda:0')
Policy pred: tensor([0.0121, 0.0062, 0.0066, 0.0028, 0.9507, 0.0048, 0.0169],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.5276915431022644
 
[Iteration 3] Process ID: 216417 [Epoch: 118,  1728/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 6 6
Policy data: tensor([2.8799e-02, 0.0000e+00, 1.1262e-03, 4.3835e-20, 0.0000e+00, 1.0843e-15,
        9.7008e-01], device='cuda:0')
Policy pred: tensor([1.7070e-02, 8.7042e-07, 3.9482e-05, 1.5718e-06, 6.8188e-07, 4.6728e-04,
        9.8242e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 118,  2304/ 2309 points] total loss per batch: 0.758
Policy (actual, predicted): 0 0
Policy data: tensor([0.9472, 0.0043, 0.0118, 0.0023, 0.0238, 0.0043, 0.0063],
       device='cuda:0')
Policy pred: tensor([0.4897, 0.0778, 0.0831, 0.0801, 0.1004, 0.0760, 0.0927],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.603978157043457
 
[Iteration 3] Process ID: 216417 [Epoch: 119,   576/ 2309 points] total loss per batch: 0.819
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 2.7518e-09, 0.0000e+00, 4.9060e-09,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.9652e-08, 9.9998e-01, 1.3570e-08, 2.1964e-07, 1.1810e-05, 4.0120e-06,
        1.0849e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 119,  1152/ 2309 points] total loss per batch: 0.766
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0251, 0.1059, 0.3415, 0.0090, 0.0075, 0.0133, 0.4979],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.05158938840031624
 
[Iteration 3] Process ID: 216417 [Epoch: 119,  1728/ 2309 points] total loss per batch: 0.721
Policy (actual, predicted): 1 1
Policy data: tensor([0.1674, 0.2364, 0.1992, 0.0499, 0.1827, 0.0669, 0.0975],
       device='cuda:0')
Policy pred: tensor([0.1620, 0.2492, 0.2055, 0.0573, 0.1694, 0.0640, 0.0926],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 119,  2304/ 2309 points] total loss per batch: 0.796
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 8.0030e-20, 3.1642e-18, 2.3503e-26, 2.4067e-23, 1.3878e-21,
        5.9532e-19], device='cuda:0')
Policy pred: tensor([9.9978e-01, 1.1585e-04, 7.8419e-06, 3.2099e-09, 2.3625e-06, 1.8752e-08,
        9.7371e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 120,   576/ 2309 points] total loss per batch: 0.745
Policy (actual, predicted): 5 5
Policy data: tensor([0.0483, 0.0394, 0.0527, 0.0060, 0.0242, 0.7856, 0.0439],
       device='cuda:0')
Policy pred: tensor([0.0358, 0.0366, 0.0418, 0.0040, 0.0160, 0.8353, 0.0305],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.30732017755508423
 
[Iteration 3] Process ID: 216417 [Epoch: 120,  1152/ 2309 points] total loss per batch: 0.842
Policy (actual, predicted): 4 0
Policy data: tensor([0.1454, 0.1501, 0.1489, 0.1301, 0.1524, 0.1336, 0.1395],
       device='cuda:0')
Policy pred: tensor([0.5658, 0.0700, 0.2520, 0.0248, 0.0263, 0.0323, 0.0289],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.004009743221104145
 
[Iteration 3] Process ID: 216417 [Epoch: 120,  1728/ 2309 points] total loss per batch: 0.766
Policy (actual, predicted): 4 4
Policy data: tensor([0.0289, 0.0211, 0.0060, 0.0078, 0.7522, 0.0078, 0.1762],
       device='cuda:0')
Policy pred: tensor([0.0562, 0.0523, 0.0072, 0.0069, 0.7165, 0.0083, 0.1526],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.10462241619825363
 
[Iteration 3] Process ID: 216417 [Epoch: 120,  2304/ 2309 points] total loss per batch: 0.769
Policy (actual, predicted): 3 3
Policy data: tensor([1.4219e-14, 5.1547e-20, 8.0075e-16, 1.0000e+00, 2.9433e-16, 8.0075e-16,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.8152e-05, 1.8529e-04, 6.5447e-08, 9.9978e-01, 1.1043e-05, 1.5614e-06,
        2.2900e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999992251396179
 
[Iteration 3] Process ID: 216417 [Epoch: 121,   576/ 2309 points] total loss per batch: 0.770
Policy (actual, predicted): 2 2
Policy data: tensor([1.2402e-04, 1.6798e-13, 6.6123e-01, 8.7371e-20, 8.5323e-23, 5.2830e-12,
        3.3865e-01], device='cuda:0')
Policy pred: tensor([1.4644e-04, 2.9320e-04, 8.2495e-01, 4.4311e-04, 5.9171e-04, 1.9455e-03,
        1.7163e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999975562095642
 
[Iteration 3] Process ID: 216417 [Epoch: 121,  1152/ 2309 points] total loss per batch: 0.730
Policy (actual, predicted): 3 3
Policy data: tensor([7.5624e-05, 0.0000e+00, 2.4764e-03, 7.6434e-01, 3.5328e-09, 2.3311e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.5709e-04, 6.2136e-05, 1.0612e-03, 7.6423e-01, 1.7104e-04, 2.3422e-01,
        3.5585e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 121,  1728/ 2309 points] total loss per batch: 0.819
Policy (actual, predicted): 4 4
Policy data: tensor([0.0183, 0.0200, 0.0280, 0.0132, 0.8839, 0.0166, 0.0200],
       device='cuda:0')
Policy pred: tensor([0.0132, 0.0181, 0.0272, 0.0165, 0.8845, 0.0160, 0.0245],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9896288514137268
 
[Iteration 3] Process ID: 216417 [Epoch: 121,  2304/ 2309 points] total loss per batch: 0.788
Policy (actual, predicted): 0 0
Policy data: tensor([0.6976, 0.0379, 0.2321, 0.0059, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.5933, 0.0553, 0.2605, 0.0190, 0.0208, 0.0262, 0.0248],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.001220043166540563
 
[Iteration 3] Process ID: 216417 [Epoch: 122,   576/ 2309 points] total loss per batch: 0.752
Policy (actual, predicted): 6 6
Policy data: tensor([5.0053e-16, 1.5414e-16, 1.5485e-08, 1.3690e-21, 2.3383e-15, 1.3690e-21,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([4.4791e-05, 4.2301e-10, 3.7798e-09, 2.1491e-11, 4.0846e-05, 9.5130e-08,
        9.9991e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999935030937195
 
[Iteration 3] Process ID: 216417 [Epoch: 122,  1152/ 2309 points] total loss per batch: 0.780
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 2.1751e-09, 0.0000e+00, 2.1751e-09,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.9506e-11, 1.0000e+00, 1.0853e-10, 1.6532e-08, 1.9445e-08, 8.6663e-07,
        4.2647e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 122,  1728/ 2309 points] total loss per batch: 0.779
Policy (actual, predicted): 0 0
Policy data: tensor([0.6993, 0.0379, 0.2323, 0.0041, 0.0041, 0.0129, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.5732, 0.0610, 0.2306, 0.0281, 0.0328, 0.0366, 0.0375],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.009458581916987896
 
[Iteration 3] Process ID: 216417 [Epoch: 122,  2304/ 2309 points] total loss per batch: 0.829
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 1.6127e-20, 1.0958e-06, 2.7967e-22, 1.1314e-11, 1.5749e-23,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9819e-01, 7.9552e-04, 5.5998e-04, 4.9358e-05, 3.0052e-04, 9.2406e-05,
        7.2914e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999992251396179
 
[Iteration 3] Process ID: 216417 [Epoch: 123,   576/ 2309 points] total loss per batch: 0.747
Policy (actual, predicted): 2 2
Policy data: tensor([3.3701e-01, 4.6409e-04, 6.6252e-01, 8.9885e-19, 9.2042e-16, 5.5654e-18,
        5.3076e-14], device='cuda:0')
Policy pred: tensor([3.1639e-01, 5.3195e-03, 6.7749e-01, 1.2345e-04, 1.6530e-04, 6.1075e-05,
        4.4592e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 123,  1152/ 2309 points] total loss per batch: 0.750
Policy (actual, predicted): 1 1
Policy data: tensor([0.0998, 0.6876, 0.0159, 0.0000, 0.0000, 0.1552, 0.0416],
       device='cuda:0')
Policy pred: tensor([1.2695e-01, 6.3239e-01, 3.5664e-02, 3.8903e-05, 2.5222e-07, 1.2922e-01,
        7.5746e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 123,  1728/ 2309 points] total loss per batch: 0.882
Policy (actual, predicted): 5 5
Policy data: tensor([0.0043, 0.0268, 0.0134, 0.0043, 0.0043, 0.9217, 0.0252],
       device='cuda:0')
Policy pred: tensor([0.0021, 0.0156, 0.0063, 0.0028, 0.0027, 0.9516, 0.0189],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.620211124420166
 
[Iteration 3] Process ID: 216417 [Epoch: 123,  2304/ 2309 points] total loss per batch: 0.731
Policy (actual, predicted): 2 2
Policy data: tensor([7.6365e-12, 3.4798e-09, 1.0000e+00, 2.2427e-28, 6.3351e-20, 9.2907e-15,
        6.1866e-13], device='cuda:0')
Policy pred: tensor([2.7357e-06, 5.1144e-04, 9.9931e-01, 5.3790e-07, 7.2335e-06, 6.2942e-05,
        1.0491e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 124,   576/ 2309 points] total loss per batch: 0.795
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 7.9865e-13, 1.0689e-17, 0.0000e+00, 9.8152e-16,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.1348e-12, 1.0000e+00, 4.5132e-08, 1.2237e-06, 1.5955e-15, 2.7341e-06,
        2.9741e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 124,  1152/ 2309 points] total loss per batch: 0.808
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 7.9033e-01, 0.0000e+00, 3.5082e-05, 2.0964e-01, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([5.4787e-05, 8.0533e-01, 8.4248e-06, 2.3809e-03, 1.9219e-01, 1.9692e-05,
        1.8600e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 124,  1728/ 2309 points] total loss per batch: 0.760
Policy (actual, predicted): 4 4
Policy data: tensor([3.0517e-01, 6.2266e-03, 1.9517e-01, 7.7792e-15, 4.9323e-01, 4.3807e-16,
        2.0177e-04], device='cuda:0')
Policy pred: tensor([2.1777e-01, 8.7372e-03, 2.0989e-01, 2.5990e-04, 5.6197e-01, 1.3859e-04,
        1.2307e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 124,  2304/ 2309 points] total loss per batch: 0.758
Policy (actual, predicted): 6 6
Policy data: tensor([2.9557e-18, 6.0562e-21, 7.4756e-20, 2.1440e-29, 2.1440e-19, 0.0000e+00,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([8.6720e-05, 2.0782e-09, 7.6863e-04, 6.4319e-08, 1.5039e-05, 8.5528e-11,
        9.9913e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 125,   576/ 2309 points] total loss per batch: 0.773
Policy (actual, predicted): 5 5
Policy data: tensor([6.2725e-15, 2.4764e-22, 1.7718e-06, 2.3616e-28, 1.4623e-17, 1.0000e+00,
        2.4764e-22], device='cuda:0')
Policy pred: tensor([1.3955e-03, 3.6907e-05, 6.2400e-04, 8.7516e-06, 3.8898e-05, 9.9789e-01,
        6.5024e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999347925186157
 
[Iteration 3] Process ID: 216417 [Epoch: 125,  1152/ 2309 points] total loss per batch: 0.787
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 6.9976e-23, 6.8335e-26, 6.6734e-29, 1.8949e-08, 6.6734e-29,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([1.6253e-09, 9.6273e-05, 4.4199e-04, 6.3963e-05, 6.7549e-04, 4.4313e-04,
        9.9828e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999682307243347
 
[Iteration 3] Process ID: 216417 [Epoch: 125,  1728/ 2309 points] total loss per batch: 0.822
Policy (actual, predicted): 3 3
Policy data: tensor([1.1775e-03, 4.6651e-08, 1.6701e-04, 9.8355e-01, 1.5064e-02, 3.9629e-13,
        3.8156e-05], device='cuda:0')
Policy pred: tensor([3.6221e-04, 6.6202e-05, 1.1109e-04, 9.8848e-01, 9.4841e-03, 1.1361e-04,
        1.3801e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 125,  2304/ 2309 points] total loss per batch: 0.724
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 9.9846e-01, 1.5388e-03, 3.1175e-07, 0.0000e+00, 1.0778e-08,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.5557e-08, 9.8882e-01, 8.2849e-03, 2.2728e-03, 7.3131e-06, 6.1550e-04,
        9.6030e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 126,   576/ 2309 points] total loss per batch: 0.770
Policy (actual, predicted): 4 4
Policy data: tensor([0.1442, 0.1395, 0.1501, 0.1336, 0.1535, 0.1325, 0.1466],
       device='cuda:0')
Policy pred: tensor([0.1416, 0.1414, 0.1551, 0.1428, 0.1564, 0.1220, 0.1407],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999192953109741
 
[Iteration 3] Process ID: 216417 [Epoch: 126,  1152/ 2309 points] total loss per batch: 0.746
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000, 0.0000, 0.0737, 0.0000, 0.0000, 0.4631, 0.4631],
       device='cuda:0')
Policy pred: tensor([2.1889e-04, 2.6284e-05, 7.1588e-02, 2.7727e-04, 6.5310e-07, 5.1107e-01,
        4.1682e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9920462965965271
 
[Iteration 3] Process ID: 216417 [Epoch: 126,  1728/ 2309 points] total loss per batch: 0.797
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 1.0116e-05, 1.4199e-05, 2.7073e-15, 6.9553e-19, 9.9998e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([6.7986e-08, 5.6815e-09, 6.1582e-09, 3.5216e-07, 2.5377e-11, 1.0000e+00,
        6.7426e-11], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 126,  2304/ 2309 points] total loss per batch: 0.791
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9989e-01, 0.0000e+00, 1.1370e-04,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.9444e-08, 4.4801e-09, 1.3146e-08, 9.9992e-01, 1.4465e-06, 7.3313e-05,
        7.2250e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 127,   576/ 2309 points] total loss per batch: 0.729
Policy (actual, predicted): 6 6
Policy data: tensor([2.7000e-06, 2.2718e-18, 4.5799e-06, 1.7341e-12, 5.9765e-19, 0.0000e+00,
        9.9999e-01], device='cuda:0')
Policy pred: tensor([3.2018e-04, 6.2804e-08, 2.2341e-04, 7.7069e-08, 3.0709e-07, 1.2181e-08,
        9.9946e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 127,  1152/ 2309 points] total loss per batch: 0.822
Policy (actual, predicted): 4 4
Policy data: tensor([8.2253e-20, 8.2253e-20, 1.3603e-17, 1.3930e-24, 1.0000e+00, 2.4156e-26,
        8.2253e-20], device='cuda:0')
Policy pred: tensor([1.8221e-03, 3.4147e-04, 1.1224e-03, 2.1292e-05, 9.9571e-01, 1.4318e-05,
        9.7082e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9991397857666016
 
[Iteration 3] Process ID: 216417 [Epoch: 127,  1728/ 2309 points] total loss per batch: 0.741
Policy (actual, predicted): 2 2
Policy data: tensor([4.9871e-03, 1.0167e-12, 9.9354e-01, 1.6855e-06, 1.3762e-03, 9.2466e-05,
        5.5911e-07], device='cuda:0')
Policy pred: tensor([7.5148e-03, 4.4565e-06, 9.9171e-01, 5.1319e-07, 7.1883e-04, 4.2221e-05,
        1.3020e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 127,  2304/ 2309 points] total loss per batch: 0.814
Policy (actual, predicted): 5 5
Policy data: tensor([1.2302e-17, 0.0000e+00, 3.0794e-11, 2.8007e-23, 1.3398e-19, 9.9999e-01,
        8.0025e-06], device='cuda:0')
Policy pred: tensor([1.2076e-06, 7.7017e-05, 3.7039e-04, 4.7023e-06, 1.7452e-05, 9.9948e-01,
        5.0900e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999971330165863
 
[Iteration 3] Process ID: 216417 [Epoch: 128,   576/ 2309 points] total loss per batch: 0.799
Policy (actual, predicted): 0 2
Policy data: tensor([0.1535, 0.1430, 0.1430, 0.1336, 0.1501, 0.1348, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.0786, 0.0862, 0.5223, 0.0613, 0.0767, 0.0738, 0.1010],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.005429750774055719
 
[Iteration 3] Process ID: 216417 [Epoch: 128,  1152/ 2309 points] total loss per batch: 0.749
Policy (actual, predicted): 2 0
Policy data: tensor([0.0381, 0.0043, 0.9264, 0.0023, 0.0043, 0.0203, 0.0043],
       device='cuda:0')
Policy pred: tensor([0.6505, 0.0480, 0.2222, 0.0165, 0.0185, 0.0239, 0.0204],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.009509701281785965
 
[Iteration 3] Process ID: 216417 [Epoch: 128,  1728/ 2309 points] total loss per batch: 0.787
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 4.5112e-21, 1.0000e+00, 1.5970e-29, 1.5970e-19, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([7.1029e-07, 6.7244e-04, 9.9929e-01, 4.0179e-08, 3.8832e-05, 9.9678e-10,
        3.3950e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 128,  2304/ 2309 points] total loss per batch: 0.770
Policy (actual, predicted): 1 1
Policy data: tensor([5.7180e-18, 1.0000e+00, 1.9768e-29, 2.0728e-23, 1.9305e-22, 2.0242e-26,
        2.1226e-20], device='cuda:0')
Policy pred: tensor([1.6618e-08, 9.9985e-01, 1.6750e-12, 3.8734e-11, 1.5055e-04, 1.3884e-09,
        4.9283e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999940812587738
 
[Iteration 3] Process ID: 216417 [Epoch: 129,   576/ 2309 points] total loss per batch: 0.729
Policy (actual, predicted): 6 6
Policy data: tensor([0.1407, 0.1383, 0.1383, 0.1489, 0.1383, 0.1430, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1522, 0.1417, 0.1324, 0.1446, 0.1350, 0.1359, 0.1582],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 129,  1152/ 2309 points] total loss per batch: 0.817
Policy (actual, predicted): 2 2
Policy data: tensor([1.5156e-05, 1.5863e-11, 7.1788e-01, 1.5533e-13, 2.8211e-01, 7.3477e-12,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.0529e-03, 4.4050e-04, 7.5596e-01, 4.5939e-04, 2.4134e-01, 7.3818e-04,
        1.1860e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.2898622453212738
 
[Iteration 3] Process ID: 216417 [Epoch: 129,  1728/ 2309 points] total loss per batch: 0.761
Policy (actual, predicted): 1 1
Policy data: tensor([1.7078e-10, 8.4768e-01, 3.4803e-11, 6.7804e-11, 4.8849e-11, 1.7488e-07,
        1.5232e-01], device='cuda:0')
Policy pred: tensor([1.4680e-03, 8.2996e-01, 1.3597e-03, 2.0342e-04, 1.6526e-05, 6.1627e-04,
        1.6638e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999991655349731
 
[Iteration 3] Process ID: 216417 [Epoch: 129,  2304/ 2309 points] total loss per batch: 0.789
Policy (actual, predicted): 4 4
Policy data: tensor([1.7112e-22, 4.9497e-21, 1.7523e-29, 1.7112e-22, 1.0000e+00, 1.7523e-29,
        1.0595e-21], device='cuda:0')
Policy pred: tensor([1.3727e-05, 3.0592e-05, 1.2657e-05, 2.6711e-05, 9.9982e-01, 3.4704e-06,
        9.3335e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9928855895996094
 
[Iteration 3] Process ID: 216417 [Epoch: 130,   576/ 2309 points] total loss per batch: 0.789
Policy (actual, predicted): 4 4
Policy data: tensor([0.1501, 0.1466, 0.1442, 0.1254, 0.1512, 0.1348, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1477, 0.1497, 0.1354, 0.1274, 0.1566, 0.1388, 0.1443],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 130,  1152/ 2309 points] total loss per batch: 0.750
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 1.3658e-14, 9.0949e-13, 3.2970e-28, 1.3338e-07, 3.3761e-25,
        3.4572e-12], device='cuda:0')
Policy pred: tensor([9.9847e-01, 1.8019e-05, 5.9889e-05, 3.3266e-06, 1.3189e-03, 7.1852e-08,
        1.2533e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 130,  1728/ 2309 points] total loss per batch: 0.778
Policy (actual, predicted): 5 5
Policy data: tensor([7.6196e-09, 4.1903e-13, 2.3105e-06, 7.1954e-13, 2.4163e-11, 6.2674e-01,
        3.7326e-01], device='cuda:0')
Policy pred: tensor([1.3531e-03, 2.1161e-04, 5.3551e-04, 7.9538e-05, 2.4569e-05, 7.0500e-01,
        2.9279e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 3] Process ID: 216417 [Epoch: 130,  2304/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 4 4
Policy data: tensor([3.0073e-14, 8.7523e-07, 2.1303e-28, 2.3423e-16, 1.0000e+00, 1.2579e-23,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.7460e-08, 8.9255e-09, 9.0392e-10, 1.6739e-09, 1.0000e+00, 2.0213e-07,
        1.3271e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999951720237732
 
[Iteration 3] Process ID: 216417 [Epoch: 131,   576/ 2309 points] total loss per batch: 0.739
Policy (actual, predicted): 4 4
Policy data: tensor([8.5339e-06, 6.5758e-04, 7.0607e-05, 2.0355e-02, 9.7864e-01, 1.4615e-06,
        2.6839e-04], device='cuda:0')
Policy pred: tensor([1.3353e-07, 8.0537e-04, 6.5422e-04, 1.4159e-02, 9.8236e-01, 4.2633e-05,
        1.9807e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999874234199524
 
[Iteration 3] Process ID: 216417 [Epoch: 131,  1152/ 2309 points] total loss per batch: 0.770
Policy (actual, predicted): 4 4
Policy data: tensor([4.6139e-10, 2.9182e-10, 0.0000e+00, 7.1499e-10, 1.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.5213e-12, 5.0916e-11, 9.3985e-11, 2.6285e-05, 9.9997e-01, 2.1196e-10,
        1.0517e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 131,  1728/ 2309 points] total loss per batch: 0.796
Policy (actual, predicted): 6 6
Policy data: tensor([0.0220, 0.0081, 0.0117, 0.0043, 0.0043, 0.0081, 0.9413],
       device='cuda:0')
Policy pred: tensor([0.0218, 0.0059, 0.0063, 0.0042, 0.0027, 0.0048, 0.9544],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999755620956421
 
[Iteration 3] Process ID: 216417 [Epoch: 131,  2304/ 2309 points] total loss per batch: 0.801
Policy (actual, predicted): 3 3
Policy data: tensor([1.1775e-03, 4.6651e-08, 1.6701e-04, 9.8355e-01, 1.5064e-02, 3.9629e-13,
        3.8156e-05], device='cuda:0')
Policy pred: tensor([6.3524e-04, 1.1610e-04, 1.5936e-04, 9.5685e-01, 4.0576e-02, 1.1604e-04,
        1.5424e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999999463558197
 
[Iteration 3] Process ID: 216417 [Epoch: 132,   576/ 2309 points] total loss per batch: 0.802
Policy (actual, predicted): 5 5
Policy data: tensor([8.1228e-13, 5.5612e-22, 4.6691e-05, 5.3036e-28, 3.1317e-23, 9.9995e-01,
        5.5612e-22], device='cuda:0')
Policy pred: tensor([1.3056e-04, 6.0892e-06, 1.0210e-06, 4.3510e-07, 1.4743e-05, 9.9980e-01,
        4.8843e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999927282333374
 
[Iteration 3] Process ID: 216417 [Epoch: 132,  1152/ 2309 points] total loss per batch: 0.759
Policy (actual, predicted): 4 4
Policy data: tensor([2.1714e-21, 2.1205e-14, 3.6773e-26, 3.6773e-26, 1.0000e+00, 9.5380e-16,
        2.0708e-17], device='cuda:0')
Policy pred: tensor([1.4071e-06, 2.1379e-04, 1.2339e-05, 9.0109e-07, 9.9974e-01, 7.6329e-07,
        3.0479e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 132,  1728/ 2309 points] total loss per batch: 0.825
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 2.4850e-24, 4.4128e-23, 4.4128e-23, 7.6712e-11, 4.4128e-23,
        2.5447e-21], device='cuda:0')
Policy pred: tensor([9.9963e-01, 1.2726e-05, 3.7167e-05, 1.5663e-06, 3.6270e-05, 2.7436e-04,
        1.0129e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999112486839294
 
[Iteration 3] Process ID: 216417 [Epoch: 132,  2304/ 2309 points] total loss per batch: 0.717
Policy (actual, predicted): 0 0
Policy data: tensor([0.6989, 0.0379, 0.2309, 0.0059, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.5752, 0.0559, 0.2745, 0.0194, 0.0221, 0.0252, 0.0277],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.0006896032718941569
 
[Iteration 3] Process ID: 216417 [Epoch: 133,   576/ 2309 points] total loss per batch: 0.716
Policy (actual, predicted): 6 6
Policy data: tensor([0.0690, 0.0042, 0.0344, 0.0061, 0.0080, 0.0061, 0.8722],
       device='cuda:0')
Policy pred: tensor([0.0756, 0.0055, 0.0281, 0.0083, 0.0078, 0.0071, 0.8677],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9997246861457825
 
[Iteration 3] Process ID: 216417 [Epoch: 133,  1152/ 2309 points] total loss per batch: 0.827
Policy (actual, predicted): 1 1
Policy data: tensor([7.1369e-05, 9.9993e-01, 1.6151e-19, 1.6151e-19, 0.0000e+00, 1.6151e-19,
        9.5368e-15], device='cuda:0')
Policy pred: tensor([8.6314e-05, 9.9968e-01, 1.4372e-08, 1.8445e-10, 4.9855e-13, 1.2807e-06,
        2.3542e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 133,  1728/ 2309 points] total loss per batch: 0.814
Policy (actual, predicted): 6 6
Policy data: tensor([0.0098, 0.0098, 0.0249, 0.0115, 0.0542, 0.0098, 0.8802],
       device='cuda:0')
Policy pred: tensor([0.0120, 0.0104, 0.0268, 0.0114, 0.0399, 0.0128, 0.8868],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.4440695345401764
 
[Iteration 3] Process ID: 216417 [Epoch: 133,  2304/ 2309 points] total loss per batch: 0.808
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 9.8190e-01, 5.2340e-07, 0.0000e+00, 1.8103e-02,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([5.1137e-08, 1.0617e-05, 9.8713e-01, 1.6443e-03, 7.9923e-05, 1.1067e-02,
        6.6088e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998211860657
 
[Iteration 3] Process ID: 216417 [Epoch: 134,   576/ 2309 points] total loss per batch: 0.829
Policy (actual, predicted): 6 6
Policy data: tensor([0.1441, 0.0000, 0.1638, 0.2384, 0.0000, 0.0213, 0.4324],
       device='cuda:0')
Policy pred: tensor([1.4315e-01, 1.3493e-07, 1.7410e-01, 2.4919e-01, 4.9955e-05, 2.4998e-02,
        4.0852e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 134,  1152/ 2309 points] total loss per batch: 0.721
Policy (actual, predicted): 2 2
Policy data: tensor([0.1925, 0.1132, 0.2284, 0.0322, 0.1925, 0.0646, 0.1766],
       device='cuda:0')
Policy pred: tensor([0.1820, 0.1228, 0.2365, 0.0461, 0.1868, 0.0761, 0.1498],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 134,  1728/ 2309 points] total loss per batch: 0.783
Policy (actual, predicted): 1 1
Policy data: tensor([1.5648e-22, 9.8585e-01, 2.7136e-24, 2.7788e-21, 0.0000e+00, 2.9137e-15,
        1.4152e-02], device='cuda:0')
Policy pred: tensor([2.3000e-04, 9.9478e-01, 2.0523e-06, 7.7183e-06, 9.1634e-10, 1.0551e-06,
        4.9800e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 134,  2304/ 2309 points] total loss per batch: 0.811
Policy (actual, predicted): 4 4
Policy data: tensor([0.2322, 0.0128, 0.0161, 0.0077, 0.7011, 0.0059, 0.0241],
       device='cuda:0')
Policy pred: tensor([0.2472, 0.0176, 0.0223, 0.0102, 0.6500, 0.0086, 0.0441],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9990164041519165
 
[Iteration 3] Process ID: 216417 [Epoch: 135,   576/ 2309 points] total loss per batch: 0.742
Policy (actual, predicted): 2 2
Policy data: tensor([0.0547, 0.0159, 0.6857, 0.0041, 0.0852, 0.0059, 0.1485],
       device='cuda:0')
Policy pred: tensor([0.0662, 0.0135, 0.6774, 0.0063, 0.0838, 0.0073, 0.1455],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9992064833641052
 
[Iteration 3] Process ID: 216417 [Epoch: 135,  1152/ 2309 points] total loss per batch: 0.854
Policy (actual, predicted): 6 6
Policy data: tensor([1.1944e-06, 2.7142e-18, 7.6669e-20, 2.5884e-14, 9.4638e-19, 2.9143e-19,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([1.2228e-03, 1.7417e-03, 9.0612e-05, 3.4833e-04, 2.3422e-04, 2.5276e-04,
        9.9611e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999682903289795
 
[Iteration 3] Process ID: 216417 [Epoch: 135,  1728/ 2309 points] total loss per batch: 0.755
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7021e-17, 0.0000e+00, 1.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.6991e-10, 6.1394e-11, 1.8158e-12, 2.0699e-05, 4.1055e-07, 9.9998e-01,
        1.2881e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 135,  2304/ 2309 points] total loss per batch: 0.779
Policy (actual, predicted): 0 0
Policy data: tensor([0.5985, 0.0143, 0.3169, 0.0041, 0.0059, 0.0477, 0.0127],
       device='cuda:0')
Policy pred: tensor([0.5838, 0.0142, 0.3162, 0.0057, 0.0081, 0.0477, 0.0243],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9913588762283325
 
[Iteration 3] Process ID: 216417 [Epoch: 136,   576/ 2309 points] total loss per batch: 0.768
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 2.0878e-10, 2.7351e-16, 1.0000e+00, 2.5473e-25, 1.5402e-07,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.6625e-07, 5.4824e-07, 1.5973e-06, 9.9966e-01, 2.5262e-06, 2.6900e-04,
        6.3583e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999994039535522
 
[Iteration 3] Process ID: 216417 [Epoch: 136,  1152/ 2309 points] total loss per batch: 0.816
Policy (actual, predicted): 6 6
Policy data: tensor([6.6087e-06, 1.8909e-01, 1.3771e-06, 3.8109e-04, 8.1315e-02, 4.9435e-08,
        7.2921e-01], device='cuda:0')
Policy pred: tensor([0.0023, 0.1103, 0.0008, 0.0021, 0.1443, 0.0017, 0.7384],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999994039535522
 
[Iteration 3] Process ID: 216417 [Epoch: 136,  1728/ 2309 points] total loss per batch: 0.712
Policy (actual, predicted): 2 2
Policy data: tensor([0.1925, 0.1132, 0.2284, 0.0322, 0.1925, 0.0646, 0.1766],
       device='cuda:0')
Policy pred: tensor([0.1747, 0.1139, 0.2391, 0.0571, 0.1705, 0.0727, 0.1720],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 136,  2304/ 2309 points] total loss per batch: 0.827
Policy (actual, predicted): 6 6
Policy data: tensor([5.6309e-03, 1.3368e-05, 8.1960e-13, 8.1960e-13, 2.1469e-04, 1.4698e-13,
        9.9414e-01], device='cuda:0')
Policy pred: tensor([7.3403e-03, 6.5979e-06, 9.2372e-06, 4.2025e-09, 7.7224e-05, 7.5693e-05,
        9.9249e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999755620956421
 
[Iteration 3] Process ID: 216417 [Epoch: 137,   576/ 2309 points] total loss per batch: 0.839
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 6.3762e-09, 8.4974e-12, 0.0000e+00, 1.0400e-21,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.9564e-10, 9.9937e-01, 4.8472e-04, 5.3031e-05, 6.8159e-08, 9.3110e-05,
        2.9610e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998211860657
 
[Iteration 3] Process ID: 216417 [Epoch: 137,  1152/ 2309 points] total loss per batch: 0.749
Policy (actual, predicted): 1 1
Policy data: tensor([1.5772e-14, 1.0000e+00, 1.9468e-13, 5.4526e-26, 0.0000e+00, 7.3408e-18,
        5.0782e-15], device='cuda:0')
Policy pred: tensor([3.8654e-05, 9.9909e-01, 3.0873e-04, 2.5070e-04, 1.2511e-08, 1.9642e-04,
        1.1739e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999957084655762
 
[Iteration 3] Process ID: 216417 [Epoch: 137,  1728/ 2309 points] total loss per batch: 0.788
Policy (actual, predicted): 4 4
Policy data: tensor([0.0225, 0.0094, 0.0177, 0.0094, 0.6925, 0.0145, 0.2340],
       device='cuda:0')
Policy pred: tensor([0.0265, 0.0115, 0.0187, 0.0118, 0.7132, 0.0177, 0.2007],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.5066893696784973
 
[Iteration 3] Process ID: 216417 [Epoch: 137,  2304/ 2309 points] total loss per batch: 0.756
Policy (actual, predicted): 2 2
Policy data: tensor([1.1137e-10, 1.3294e-10, 1.0000e+00, 9.3010e-11, 7.7418e-11, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([8.5956e-07, 6.8488e-10, 1.0000e+00, 3.4581e-09, 1.2014e-07, 3.7095e-10,
        8.8946e-11], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 138,   576/ 2309 points] total loss per batch: 0.760
Policy (actual, predicted): 2 2
Policy data: tensor([1.7979e-12, 1.1340e-10, 1.0000e+00, 3.8287e-15, 1.6069e-09, 3.8287e-15,
        7.5377e-16], device='cuda:0')
Policy pred: tensor([8.9321e-04, 8.3341e-04, 9.9438e-01, 1.0104e-03, 1.6800e-03, 5.0383e-04,
        6.9934e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999976754188538
 
[Iteration 3] Process ID: 216417 [Epoch: 138,  1152/ 2309 points] total loss per batch: 0.732
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 0.0000e+00, 9.6827e-25, 1.6791e-26, 0.0000e+00, 1.0000e+00,
        9.4557e-18], device='cuda:0')
Policy pred: tensor([4.7372e-08, 7.8774e-07, 4.1731e-05, 3.2342e-06, 1.6922e-06, 9.9993e-01,
        2.5088e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 138,  1728/ 2309 points] total loss per batch: 0.868
Policy (actual, predicted): 6 6
Policy data: tensor([0.0714, 0.0146, 0.0146, 0.0146, 0.0440, 0.0528, 0.7882],
       device='cuda:0')
Policy pred: tensor([0.0753, 0.0202, 0.0218, 0.0187, 0.0464, 0.0526, 0.7650],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.017203528434038162
 
[Iteration 3] Process ID: 216417 [Epoch: 138,  2304/ 2309 points] total loss per batch: 0.780
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0145, 0.0145, 0.0454, 0.0527, 0.7868],
       device='cuda:0')
Policy pred: tensor([0.0747, 0.0245, 0.0252, 0.0212, 0.0532, 0.0579, 0.7433],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.012654469348490238
 
[Iteration 3] Process ID: 216417 [Epoch: 139,   576/ 2309 points] total loss per batch: 0.799
Policy (actual, predicted): 2 2
Policy data: tensor([1.4955e-05, 1.5652e-11, 7.3121e-01, 1.5326e-13, 2.6877e-01, 7.2500e-12,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([5.4852e-04, 2.1196e-04, 6.6999e-01, 3.3153e-04, 3.2836e-01, 5.4263e-04,
        1.4650e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.3848201334476471
 
[Iteration 3] Process ID: 216417 [Epoch: 139,  1152/ 2309 points] total loss per batch: 0.748
Policy (actual, predicted): 5 5
Policy data: tensor([0.0147, 0.0079, 0.0131, 0.0060, 0.0308, 0.8202, 0.1073],
       device='cuda:0')
Policy pred: tensor([0.0120, 0.0060, 0.0113, 0.0046, 0.0279, 0.8401, 0.0981],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.46032124757766724
 
[Iteration 3] Process ID: 216417 [Epoch: 139,  1728/ 2309 points] total loss per batch: 0.820
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 1.2023e-15, 4.5268e-19, 1.1741e-18, 1.5784e-19, 1.0000e+00,
        6.0762e-13], device='cuda:0')
Policy pred: tensor([6.0159e-08, 2.4198e-04, 4.1141e-05, 4.1057e-07, 2.7762e-09, 9.9967e-01,
        4.4141e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999992847442627
 
[Iteration 3] Process ID: 216417 [Epoch: 139,  2304/ 2309 points] total loss per batch: 0.753
Policy (actual, predicted): 4 4
Policy data: tensor([0.0366, 0.0108, 0.0688, 0.0108, 0.4305, 0.0278, 0.4147],
       device='cuda:0')
Policy pred: tensor([0.0373, 0.0106, 0.0596, 0.0147, 0.4338, 0.0264, 0.4176],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.38043802976608276
 
[Iteration 3] Process ID: 216417 [Epoch: 140,   576/ 2309 points] total loss per batch: 0.787
Policy (actual, predicted): 0 0
Policy data: tensor([0.6993, 0.0379, 0.2323, 0.0041, 0.0041, 0.0129, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.5475, 0.0703, 0.2392, 0.0303, 0.0352, 0.0395, 0.0380],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.004774183966219425
 
[Iteration 3] Process ID: 216417 [Epoch: 140,  1152/ 2309 points] total loss per batch: 0.730
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 3.7165e-18, 6.1464e-26, 6.1464e-26, 9.3132e-10, 6.1464e-26,
        1.5568e-18], device='cuda:0')
Policy pred: tensor([9.9999e-01, 8.2633e-07, 9.2217e-08, 1.9197e-08, 1.0441e-05, 4.3384e-08,
        1.7440e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999775290489197
 
[Iteration 3] Process ID: 216417 [Epoch: 140,  1728/ 2309 points] total loss per batch: 0.797
Policy (actual, predicted): 6 0
Policy data: tensor([0.1407, 0.1442, 0.1442, 0.1407, 0.1465, 0.1360, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.5572, 0.0687, 0.0749, 0.0751, 0.0877, 0.0675, 0.0690],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.6993666291236877
 
[Iteration 3] Process ID: 216417 [Epoch: 140,  2304/ 2309 points] total loss per batch: 0.787
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 6.4556e-09, 0.0000e+00, 8.4835e-20, 5.0094e-15, 1.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([5.9133e-08, 1.8106e-04, 7.8370e-09, 4.4261e-05, 5.5457e-06, 9.9977e-01,
        6.3653e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 141,   576/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 2 2
Policy data: tensor([0.0458, 0.0117, 0.9216, 0.0023, 0.0081, 0.0062, 0.0043],
       device='cuda:0')
Policy pred: tensor([0.0339, 0.0136, 0.9359, 0.0030, 0.0054, 0.0054, 0.0028],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999996423721313
 
[Iteration 3] Process ID: 216417 [Epoch: 141,  1152/ 2309 points] total loss per batch: 0.774
Policy (actual, predicted): 2 2
Policy data: tensor([0.4272, 0.0286, 0.5207, 0.0041, 0.0041, 0.0077, 0.0077],
       device='cuda:0')
Policy pred: tensor([0.4141, 0.0277, 0.5378, 0.0027, 0.0033, 0.0073, 0.0070],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.6173437237739563
 
[Iteration 3] Process ID: 216417 [Epoch: 141,  1728/ 2309 points] total loss per batch: 0.736
Policy (actual, predicted): 4 4
Policy data: tensor([0.0149, 0.0115, 0.0079, 0.0097, 0.8568, 0.0061, 0.0930],
       device='cuda:0')
Policy pred: tensor([0.0123, 0.0105, 0.0046, 0.0065, 0.8808, 0.0032, 0.0822],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.2463766485452652
 
[Iteration 3] Process ID: 216417 [Epoch: 141,  2304/ 2309 points] total loss per batch: 0.806
Policy (actual, predicted): 6 6
Policy data: tensor([0.0255, 0.0160, 0.0128, 0.0128, 0.2736, 0.0077, 0.6517],
       device='cuda:0')
Policy pred: tensor([0.0272, 0.0139, 0.0120, 0.0122, 0.3039, 0.0064, 0.6244],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.7761465311050415
 
[Iteration 3] Process ID: 216417 [Epoch: 142,   576/ 2309 points] total loss per batch: 0.750
Policy (actual, predicted): 6 6
Policy data: tensor([0.1674, 0.0225, 0.0569, 0.0041, 0.0041, 0.0128, 0.7321],
       device='cuda:0')
Policy pred: tensor([0.1496, 0.0279, 0.0557, 0.0037, 0.0051, 0.0106, 0.7475],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9398536086082458
 
[Iteration 3] Process ID: 216417 [Epoch: 142,  1152/ 2309 points] total loss per batch: 0.733
Policy (actual, predicted): 0 0
Policy data: tensor([0.6993, 0.0379, 0.2323, 0.0041, 0.0041, 0.0129, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6293, 0.0550, 0.2351, 0.0169, 0.0186, 0.0247, 0.0205],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.0003721117682289332
 
[Iteration 3] Process ID: 216417 [Epoch: 142,  1728/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 9.9998e-01, 0.0000e+00, 2.2252e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([8.6488e-09, 9.9889e-01, 2.8400e-07, 1.1119e-03, 2.5018e-07, 9.3182e-11,
        2.6656e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 142,  2304/ 2309 points] total loss per batch: 0.839
Policy (actual, predicted): 6 6
Policy data: tensor([0.0847, 0.0042, 0.0248, 0.0061, 0.0115, 0.0042, 0.8644],
       device='cuda:0')
Policy pred: tensor([0.0844, 0.0049, 0.0221, 0.0031, 0.0150, 0.0026, 0.8679],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999957084655762
 
[Iteration 3] Process ID: 216417 [Epoch: 143,   576/ 2309 points] total loss per batch: 0.749
Policy (actual, predicted): 4 4
Policy data: tensor([2.8165e-07, 9.5095e-20, 2.4665e-09, 9.5095e-20, 1.0000e+00, 4.0792e-17,
        1.9171e-07], device='cuda:0')
Policy pred: tensor([5.1216e-04, 7.6580e-08, 1.3731e-06, 6.9015e-09, 9.9942e-01, 1.8299e-10,
        6.2718e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 143,  1152/ 2309 points] total loss per batch: 0.810
Policy (actual, predicted): 6 6
Policy data: tensor([0.1430, 0.0000, 0.0698, 0.2599, 0.1666, 0.0385, 0.3222],
       device='cuda:0')
Policy pred: tensor([1.2508e-01, 9.0992e-06, 6.2971e-02, 2.6333e-01, 1.7411e-01, 4.5790e-02,
        3.2870e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 143,  1728/ 2309 points] total loss per batch: 0.790
Policy (actual, predicted): 4 4
Policy data: tensor([2.9462e-16, 1.4779e-16, 1.3896e-11, 1.0300e-15, 1.0000e+00, 1.8242e-15,
        8.2052e-07], device='cuda:0')
Policy pred: tensor([2.6632e-04, 1.3476e-06, 4.8554e-06, 1.9979e-07, 9.9972e-01, 1.5142e-08,
        2.7730e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 143,  2304/ 2309 points] total loss per batch: 0.767
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 6.6225e-19, 0.0000e+00, 1.0952e-26, 2.3091e-09, 8.4689e-01,
        1.5311e-01], device='cuda:0')
Policy pred: tensor([1.1889e-06, 5.7369e-03, 3.8588e-05, 8.4691e-04, 1.7137e-03, 8.1816e-01,
        1.7350e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999985098838806
 
[Iteration 3] Process ID: 216417 [Epoch: 144,   576/ 2309 points] total loss per batch: 0.778
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 1.0000e+00, 9.0438e-08, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.3005e-06, 3.3851e-09, 9.9712e-01, 2.0745e-03, 1.1927e-05, 1.1206e-06,
        7.9228e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 144,  1152/ 2309 points] total loss per batch: 0.806
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 9.8037e-01, 1.9624e-02, 4.0825e-23, 0.0000e+00, 1.9296e-06,
        4.4040e-06], device='cuda:0')
Policy pred: tensor([7.5348e-09, 9.8361e-01, 1.5440e-02, 3.7497e-04, 3.3337e-08, 3.3586e-04,
        2.3905e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999107837677002
 
[Iteration 3] Process ID: 216417 [Epoch: 144,  1728/ 2309 points] total loss per batch: 0.819
Policy (actual, predicted): 5 5
Policy data: tensor([2.5265e-03, 2.8531e-21, 1.2532e-05, 3.0635e-12, 4.9477e-23, 9.9745e-01,
        1.2532e-05], device='cuda:0')
Policy pred: tensor([1.7853e-03, 3.8753e-05, 1.7590e-07, 3.6453e-05, 1.9286e-08, 9.9775e-01,
        3.9398e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 144,  2304/ 2309 points] total loss per batch: 0.701
Policy (actual, predicted): 4 4
Policy data: tensor([0.0836, 0.0094, 0.0128, 0.0654, 0.7603, 0.0059, 0.0626],
       device='cuda:0')
Policy pred: tensor([0.0812, 0.0105, 0.0186, 0.0641, 0.7617, 0.0052, 0.0587],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.09239116311073303
 
[Iteration 3] Process ID: 216417 [Epoch: 145,   576/ 2309 points] total loss per batch: 0.781
Policy (actual, predicted): 0 0
Policy data: tensor([9.7480e-01, 7.2624e-17, 2.0340e-19, 1.5214e-05, 1.2594e-18, 2.5180e-02,
        7.2624e-17], device='cuda:0')
Policy pred: tensor([9.4140e-01, 1.1992e-06, 1.0859e-05, 7.0957e-06, 4.1990e-06, 5.8142e-02,
        4.3357e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9975667595863342
 
[Iteration 3] Process ID: 216417 [Epoch: 145,  1152/ 2309 points] total loss per batch: 0.781
Policy (actual, predicted): 0 0
Policy data: tensor([0.2507, 0.1776, 0.1360, 0.1360, 0.0780, 0.0858, 0.1360],
       device='cuda:0')
Policy pred: tensor([0.2487, 0.1581, 0.1326, 0.1433, 0.0706, 0.0939, 0.1528],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 145,  1728/ 2309 points] total loss per batch: 0.769
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 2.9699e-13, 2.0067e-12, 2.9290e-18, 1.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.7522e-04, 4.1634e-06, 1.6118e-04, 2.4336e-06, 9.9966e-01, 2.9028e-10,
        5.1866e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 145,  2304/ 2309 points] total loss per batch: 0.766
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 1.7654e-16, 0.0000e+00, 1.4302e-17, 9.0128e-11, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.0000e+00, 1.4352e-06, 1.4061e-10, 5.9078e-09, 8.2373e-07, 6.6812e-12,
        3.9595e-11], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 146,   576/ 2309 points] total loss per batch: 0.779
Policy (actual, predicted): 5 6
Policy data: tensor([0.0000, 0.0000, 0.1570, 0.0857, 0.1471, 0.3144, 0.2958],
       device='cuda:0')
Policy pred: tensor([5.2271e-05, 2.3231e-05, 1.3996e-01, 9.1634e-02, 1.7142e-01, 2.8357e-01,
        3.1335e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 146,  1152/ 2309 points] total loss per batch: 0.810
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000, 0.0000, 0.2066, 0.1309, 0.0933, 0.2496, 0.3196],
       device='cuda:0')
Policy pred: tensor([7.0049e-06, 1.3168e-05, 2.1146e-01, 1.2627e-01, 9.8882e-02, 2.6140e-01,
        3.0197e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999993443489075
 
[Iteration 3] Process ID: 216417 [Epoch: 146,  1728/ 2309 points] total loss per batch: 0.743
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 3.1297e-22, 1.1175e-19, 3.2818e-26, 1.1717e-13, 1.8924e-24,
        9.2701e-18], device='cuda:0')
Policy pred: tensor([9.9859e-01, 5.3888e-05, 1.5006e-04, 3.5128e-05, 7.0476e-04, 4.1240e-04,
        5.2964e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 146,  2304/ 2309 points] total loss per batch: 0.781
Policy (actual, predicted): 4 4
Policy data: tensor([1.7223e-17, 4.1175e-18, 1.8937e-15, 2.9168e-22, 1.0000e+00, 8.4369e-21,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.8902e-06, 7.2689e-06, 2.1693e-07, 2.5631e-07, 9.9999e-01, 2.4441e-06,
        1.6695e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999997019767761
 
[Iteration 3] Process ID: 216417 [Epoch: 147,   576/ 2309 points] total loss per batch: 0.803
Policy (actual, predicted): 5 5
Policy data: tensor([0.0483, 0.0394, 0.0527, 0.0060, 0.0242, 0.7856, 0.0439],
       device='cuda:0')
Policy pred: tensor([0.0486, 0.0358, 0.0461, 0.0065, 0.0207, 0.8066, 0.0356],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.2929530739784241
 
[Iteration 3] Process ID: 216417 [Epoch: 147,  1152/ 2309 points] total loss per batch: 0.787
Policy (actual, predicted): 3 3
Policy data: tensor([3.3743e-14, 0.0000e+00, 1.3321e-21, 1.0000e+00, 0.0000e+00, 1.3009e-24,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([8.8091e-05, 1.2084e-10, 1.0739e-07, 9.9991e-01, 8.4147e-09, 9.3319e-08,
        6.0457e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 147,  1728/ 2309 points] total loss per batch: 0.739
Policy (actual, predicted): 0 0
Policy data: tensor([0.5920, 0.0040, 0.1101, 0.0124, 0.1332, 0.0075, 0.1409],
       device='cuda:0')
Policy pred: tensor([0.6182, 0.0066, 0.1164, 0.0103, 0.1340, 0.0086, 0.1059],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9985427260398865
 
[Iteration 3] Process ID: 216417 [Epoch: 147,  2304/ 2309 points] total loss per batch: 0.780
Policy (actual, predicted): 4 4
Policy data: tensor([0.2322, 0.0128, 0.0161, 0.0077, 0.7011, 0.0059, 0.0241],
       device='cuda:0')
Policy pred: tensor([0.1773, 0.0115, 0.0116, 0.0070, 0.7678, 0.0042, 0.0207],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9992241263389587
 
[Iteration 3] Process ID: 216417 [Epoch: 148,   576/ 2309 points] total loss per batch: 0.855
Policy (actual, predicted): 6 6
Policy data: tensor([0.2143, 0.1154, 0.0388, 0.0039, 0.0000, 0.2096, 0.4181],
       device='cuda:0')
Policy pred: tensor([2.0871e-01, 1.0652e-01, 3.4875e-02, 2.4095e-03, 5.9687e-08, 1.8332e-01,
        4.6417e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998211860657
 
[Iteration 3] Process ID: 216417 [Epoch: 148,  1152/ 2309 points] total loss per batch: 0.746
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 1.0195e-01, 8.9805e-01, 1.1188e-08, 0.0000e+00, 9.7229e-08,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.9760e-06, 9.4443e-02, 9.0534e-01, 7.4594e-05, 5.1094e-06, 1.3602e-04,
        2.4491e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 148,  1728/ 2309 points] total loss per batch: 0.709
Policy (actual, predicted): 3 3
Policy data: tensor([0.1043, 0.1954, 0.0787, 0.2321, 0.1253, 0.1143, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1048, 0.1842, 0.0822, 0.2191, 0.1416, 0.1114, 0.1566],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 148,  2304/ 2309 points] total loss per batch: 0.794
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 0.0000e+00, 8.4596e-13, 4.1046e-13, 0.0000e+00, 1.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([8.7434e-08, 2.0217e-09, 9.9678e-05, 8.0891e-04, 2.2744e-05, 9.9898e-01,
        8.8565e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 149,   576/ 2309 points] total loss per batch: 0.814
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000, 0.0000, 0.1196, 0.0000, 0.0000, 0.7558, 0.1246],
       device='cuda:0')
Policy pred: tensor([2.3525e-05, 1.0702e-06, 1.1109e-01, 5.8714e-05, 6.7305e-08, 7.5614e-01,
        1.3269e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 3] Process ID: 216417 [Epoch: 149,  1152/ 2309 points] total loss per batch: 0.791
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 3.7108e-10, 1.7335e-09, 9.9972e-01, 7.6947e-09, 0.0000e+00,
        2.8326e-04], device='cuda:0')
Policy pred: tensor([4.0518e-09, 4.8975e-04, 1.0034e-04, 9.9904e-01, 3.0657e-04, 2.0797e-07,
        5.8634e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999966621398926
 
[Iteration 3] Process ID: 216417 [Epoch: 149,  1728/ 2309 points] total loss per batch: 0.759
Policy (actual, predicted): 0 0
Policy data: tensor([0.6968, 0.0379, 0.2347, 0.0041, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6360, 0.0492, 0.2302, 0.0181, 0.0191, 0.0250, 0.0223],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.007754075340926647
 
[Iteration 3] Process ID: 216417 [Epoch: 149,  2304/ 2309 points] total loss per batch: 0.745
Policy (actual, predicted): 4 0
Policy data: tensor([0.1501, 0.1419, 0.1477, 0.1301, 0.1536, 0.1348, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.6507, 0.0428, 0.2362, 0.0144, 0.0162, 0.0217, 0.0180],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.0015779869863763452
 
[Iteration 3] Process ID: 216417 [Epoch: 150,   576/ 2309 points] total loss per batch: 0.773
Policy (actual, predicted): 6 6
Policy data: tensor([4.8724e-03, 5.6492e-17, 1.1370e-09, 5.2612e-16, 1.1247e-03, 1.8345e-16,
        9.9400e-01], device='cuda:0')
Policy pred: tensor([3.9209e-03, 8.9456e-05, 3.6307e-04, 1.7951e-05, 1.4268e-03, 2.4241e-04,
        9.9394e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 150,  1152/ 2309 points] total loss per batch: 0.731
Policy (actual, predicted): 2 2
Policy data: tensor([3.7056e-07, 2.8524e-08, 9.9160e-01, 6.1285e-15, 0.0000e+00, 1.2218e-14,
        8.4028e-03], device='cuda:0')
Policy pred: tensor([5.3437e-06, 4.3445e-06, 9.9604e-01, 4.4909e-05, 9.2437e-11, 3.3084e-06,
        3.8995e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 216417 [Epoch: 150,  1728/ 2309 points] total loss per batch: 0.761
Policy (actual, predicted): 4 4
Policy data: tensor([0.1075, 0.0252, 0.1491, 0.0058, 0.6659, 0.0093, 0.0372],
       device='cuda:0')
Policy pred: tensor([0.1198, 0.0272, 0.1722, 0.0074, 0.6200, 0.0099, 0.0434],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998013973236084
 
[Iteration 3] Process ID: 216417 [Epoch: 150,  2304/ 2309 points] total loss per batch: 0.842
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5476e-23, 0.0000e+00, 1.5848e-20,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([1.3740e-09, 5.3983e-09, 2.9425e-10, 5.0012e-04, 7.2124e-10, 6.9113e-07,
        9.9950e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
