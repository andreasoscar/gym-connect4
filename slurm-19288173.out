04/07/2022 10:05:04 AM [INFO]: Preparing model for multi-process MCTS...
04/07/2022 10:05:05 AM [INFO]: Loaded cc4_current_net__iter3.pth.tar model.
04/07/2022 10:05:05 AM [INFO]: Spawning 8 processes...
START TIME:  10:04:52
04/07/2022 10:05:08 AM [INFO]: [CPU: 3]: Starting MCTS self-play...
  0%|          | 0/10 [00:00<?, ?it/s]04/07/2022 10:05:08 AM [INFO]: [CPU: 3]: Game 0
04/07/2022 10:05:09 AM [INFO]: [CPU: 1]: Starting MCTS self-play...
  0%|          | 0/10 [00:00<?, ?it/s]04/07/2022 10:05:09 AM [INFO]: [CPU: 1]: Game 0
04/07/2022 10:05:09 AM [INFO]: [CPU: 5]: Starting MCTS self-play...
  0%|          | 0/10 [00:00<?, ?it/s]04/07/2022 10:05:09 AM [INFO]: [CPU: 4]: Starting MCTS self-play...
04/07/2022 10:05:09 AM [INFO]: [CPU: 5]: Game 0
  0%|          | 0/10 [00:00<?, ?it/s]04/07/2022 10:05:09 AM [INFO]: [CPU: 4]: Game 0
04/07/2022 10:05:09 AM [INFO]: [CPU: 7]: Starting MCTS self-play...
04/07/2022 10:05:09 AM [INFO]: [CPU: 0]: Starting MCTS self-play...
  0%|          | 0/10 [00:00<?, ?it/s]04/07/2022 10:05:09 AM [INFO]: [CPU: 7]: Game 0
  0%|          | 0/10 [00:00<?, ?it/s]04/07/2022 10:05:09 AM [INFO]: [CPU: 0]: Game 0
04/07/2022 10:05:09 AM [INFO]: [CPU: 2]: Starting MCTS self-play...
  0%|          | 0/10 [00:00<?, ?it/s]04/07/2022 10:05:09 AM [INFO]: [CPU: 6]: Starting MCTS self-play...
04/07/2022 10:05:09 AM [INFO]: [CPU: 2]: Game 0
  0%|          | 0/10 [00:00<?, ?it/s]04/07/2022 10:05:09 AM [INFO]: [CPU: 6]: Game 0
 10%|█         | 1/10 [00:51<07:41, 51.32s/it]04/07/2022 10:06:00 AM [INFO]: [CPU: 3]: Game 1
 10%|█         | 1/10 [01:29<13:26, 89.61s/it] 10%|█         | 1/10 [01:29<13:26, 89.60s/it]04/07/2022 10:06:38 AM [INFO]: [CPU: 7]: Game 1
04/07/2022 10:06:38 AM [INFO]: [CPU: 2]: Game 1
 10%|█         | 1/10 [02:08<19:14, 128.29s/it]04/07/2022 10:07:17 AM [INFO]: [CPU: 6]: Game 1
 10%|█         | 1/10 [02:08<19:15, 128.34s/it]04/07/2022 10:07:17 AM [INFO]: [CPU: 4]: Game 1
 20%|██        | 2/10 [02:27<10:22, 77.85s/it]04/07/2022 10:07:36 AM [INFO]: [CPU: 3]: Game 2
 10%|█         | 1/10 [02:41<24:17, 161.89s/it]04/07/2022 10:07:50 AM [INFO]: [CPU: 0]: Game 1
 10%|█         | 1/10 [02:56<26:28, 176.46s/it]04/07/2022 10:08:05 AM [INFO]: [CPU: 1]: Game 1
 10%|█         | 1/10 [03:01<27:11, 181.32s/it]04/07/2022 10:08:10 AM [INFO]: [CPU: 5]: Game 1
 20%|██        | 2/10 [03:25<13:59, 104.95s/it]04/07/2022 10:08:34 AM [INFO]: [CPU: 2]: Game 2
 20%|██        | 2/10 [03:25<13:05, 98.21s/it] 04/07/2022 10:08:34 AM [INFO]: [CPU: 4]: Game 2
 20%|██        | 2/10 [03:30<14:22, 107.81s/it]04/07/2022 10:08:39 AM [INFO]: [CPU: 7]: Game 2
 20%|██        | 2/10 [04:13<16:52, 126.56s/it]04/07/2022 10:09:22 AM [INFO]: [CPU: 6]: Game 2
 20%|██        | 2/10 [04:47<18:22, 137.76s/it]04/07/2022 10:09:56 AM [INFO]: [CPU: 1]: Game 2
 30%|███       | 3/10 [04:47<11:01, 94.43s/it] 04/07/2022 10:09:56 AM [INFO]: [CPU: 2]: Game 3
 30%|███       | 3/10 [04:52<10:51, 93.03s/it]04/07/2022 10:10:01 AM [INFO]: [CPU: 4]: Game 3
 30%|███       | 3/10 [04:57<12:53, 110.50s/it]04/07/2022 10:10:06 AM [INFO]: [CPU: 3]: Game 3
 20%|██        | 2/10 [05:11<20:36, 154.51s/it]04/07/2022 10:10:20 AM [INFO]: [CPU: 0]: Game 2
 30%|███       | 3/10 [05:21<11:36, 99.57s/it] 04/07/2022 10:10:30 AM [INFO]: [CPU: 6]: Game 3
 30%|███       | 3/10 [05:54<14:32, 124.62s/it]04/07/2022 10:11:03 AM [INFO]: [CPU: 7]: Game 3
 30%|███       | 3/10 [06:04<12:37, 108.22s/it]04/07/2022 10:11:13 AM [INFO]: [CPU: 0]: Game 3
 20%|██        | 2/10 [06:09<24:41, 185.24s/it]04/07/2022 10:11:18 AM [INFO]: [CPU: 5]: Game 2
 40%|████      | 4/10 [06:28<09:26, 94.38s/it]04/07/2022 10:11:37 AM [INFO]: [CPU: 4]: Game 4
 40%|████      | 4/10 [06:57<10:51, 108.57s/it]04/07/2022 10:12:06 AM [INFO]: [CPU: 2]: Game 4
 40%|████      | 4/10 [07:07<09:01, 90.23s/it] 04/07/2022 10:12:16 AM [INFO]: [CPU: 0]: Game 4
 40%|████      | 4/10 [07:26<10:58, 109.81s/it]04/07/2022 10:12:35 AM [INFO]: [CPU: 6]: Game 4
 40%|████      | 4/10 [08:00<13:55, 139.23s/it]04/07/2022 10:13:09 AM [INFO]: [CPU: 3]: Game 4
 50%|█████     | 5/10 [08:00<07:47, 93.42s/it]04/07/2022 10:13:09 AM [INFO]: [CPU: 4]: Game 5
 30%|███       | 3/10 [08:04<19:16, 165.15s/it]04/07/2022 10:13:13 AM [INFO]: [CPU: 1]: Game 3
 50%|█████     | 5/10 [08:04<07:48, 93.77s/it] 04/07/2022 10:13:14 AM [INFO]: [CPU: 2]: Game 5
 50%|█████     | 5/10 [08:24<07:35, 91.07s/it] 04/07/2022 10:13:33 AM [INFO]: [CPU: 6]: Game 5
 60%|██████    | 6/10 [08:48<05:06, 76.64s/it]04/07/2022 10:13:57 AM [INFO]: [CPU: 2]: Game 6
 40%|████      | 4/10 [08:58<14:46, 147.76s/it]04/07/2022 10:14:07 AM [INFO]: [CPU: 7]: Game 4
 30%|███       | 3/10 [09:17<21:45, 186.51s/it]04/07/2022 10:14:26 AM [INFO]: [CPU: 5]: Game 3
 60%|██████    | 6/10 [09:31<05:32, 83.05s/it]04/07/2022 10:14:40 AM [INFO]: [CPU: 6]: Game 6
 50%|█████     | 5/10 [10:05<10:09, 121.99s/it]04/07/2022 10:15:14 AM [INFO]: [CPU: 0]: Game 5
 40%|████      | 4/10 [10:10<13:22, 133.81s/it]04/07/2022 10:15:19 AM [INFO]: [CPU: 5]: Game 4
 70%|███████   | 7/10 [10:10<03:55, 78.38s/it]04/07/2022 10:15:19 AM [INFO]: [CPU: 2]: Game 7
 50%|█████     | 5/10 [10:29<11:54, 142.90s/it]04/07/2022 10:15:38 AM [INFO]: [CPU: 3]: Game 5
 40%|████      | 4/10 [10:43<16:16, 162.74s/it]04/07/2022 10:15:52 AM [INFO]: [CPU: 1]: Game 4
 50%|█████     | 5/10 [10:48<11:12, 134.48s/it]04/07/2022 10:15:57 AM [INFO]: [CPU: 7]: Game 5
 60%|██████    | 6/10 [10:58<08:09, 122.29s/it]04/07/2022 10:16:07 AM [INFO]: [CPU: 4]: Game 6
 70%|███████   | 7/10 [11:22<04:36, 92.17s/it]04/07/2022 10:16:31 AM [INFO]: [CPU: 6]: Game 7
 50%|█████     | 5/10 [12:20<11:34, 138.81s/it]04/07/2022 10:17:29 AM [INFO]: [CPU: 1]: Game 5
 60%|██████    | 6/10 [12:25<08:32, 128.04s/it]04/07/2022 10:17:34 AM [INFO]: [CPU: 0]: Game 6
 70%|███████   | 7/10 [12:25<05:32, 110.68s/it]04/07/2022 10:17:34 AM [INFO]: [CPU: 4]: Game 7
 50%|█████     | 5/10 [12:30<11:19, 135.97s/it]04/07/2022 10:17:39 AM [INFO]: [CPU: 5]: Game 5
 80%|████████  | 8/10 [12:49<03:00, 90.45s/it]04/07/2022 10:17:58 AM [INFO]: [CPU: 6]: Game 8
 80%|████████  | 8/10 [13:08<03:40, 110.18s/it]04/07/2022 10:18:17 AM [INFO]: [CPU: 2]: Game 8
 60%|██████    | 6/10 [13:32<10:26, 156.56s/it]04/07/2022 10:18:41 AM [INFO]: [CPU: 3]: Game 6
 60%|██████    | 6/10 [13:47<09:57, 149.37s/it]04/07/2022 10:18:56 AM [INFO]: [CPU: 7]: Game 6
 90%|█████████ | 9/10 [14:06<01:33, 93.80s/it] 04/07/2022 10:19:15 AM [INFO]: [CPU: 2]: Game 9
 60%|██████    | 6/10 [14:06<08:10, 122.50s/it]04/07/2022 10:19:15 AM [INFO]: [CPU: 5]: Game 6
 90%|█████████ | 9/10 [14:16<01:29, 89.28s/it]04/07/2022 10:19:25 AM [INFO]: [CPU: 6]: Game 9
 70%|███████   | 7/10 [15:03<06:54, 138.10s/it]04/07/2022 10:20:12 AM [INFO]: [CPU: 0]: Game 7
 80%|████████  | 8/10 [15:04<04:12, 126.01s/it]04/07/2022 10:20:13 AM [INFO]: [CPU: 4]: Game 8
100%|██████████| 10/10 [15:28<00:00, 83.95s/it]100%|██████████| 10/10 [15:28<00:00, 92.84s/it]
 60%|██████    | 6/10 [15:32<10:27, 156.85s/it]04/07/2022 10:20:41 AM [INFO]: [CPU: 1]: Game 6
100%|██████████| 10/10 [15:32<00:00, 91.38s/it]100%|██████████| 10/10 [15:32<00:00, 93.24s/it]
 70%|███████   | 7/10 [15:50<07:02, 140.97s/it]04/07/2022 10:20:59 AM [INFO]: [CPU: 7]: Game 7
 80%|████████  | 8/10 [16:09<03:49, 114.95s/it]04/07/2022 10:21:18 AM [INFO]: [CPU: 0]: Game 8
 90%|█████████ | 9/10 [16:13<01:48, 108.21s/it]04/07/2022 10:21:22 AM [INFO]: [CPU: 4]: Game 9
 70%|███████   | 7/10 [16:24<08:04, 161.43s/it]04/07/2022 10:21:33 AM [INFO]: [CPU: 3]: Game 7
 80%|████████  | 8/10 [16:39<03:42, 111.41s/it]04/07/2022 10:21:48 AM [INFO]: [CPU: 7]: Game 8
 70%|███████   | 7/10 [16:42<06:25, 128.58s/it]04/07/2022 10:21:51 AM [INFO]: [CPU: 1]: Game 7
 70%|███████   | 7/10 [16:53<06:51, 137.15s/it]04/07/2022 10:22:02 AM [INFO]: [CPU: 5]: Game 7
 80%|████████  | 8/10 [17:30<04:22, 131.23s/it]04/07/2022 10:22:39 AM [INFO]: [CPU: 3]: Game 8
 90%|█████████ | 9/10 [17:45<01:49, 109.06s/it]04/07/2022 10:22:54 AM [INFO]: [CPU: 0]: Game 9
100%|██████████| 10/10 [17:53<00:00, 105.66s/it]100%|██████████| 10/10 [17:53<00:00, 107.34s/it]
 90%|█████████ | 9/10 [18:12<01:45, 105.71s/it]04/07/2022 10:23:21 AM [INFO]: [CPU: 7]: Game 9
 80%|████████  | 8/10 [18:27<04:02, 121.18s/it]04/07/2022 10:23:36 AM [INFO]: [CPU: 1]: Game 8
 80%|████████  | 8/10 [18:51<04:21, 130.90s/it]04/07/2022 10:24:00 AM [INFO]: [CPU: 5]: Game 8
100%|██████████| 10/10 [18:57<00:00, 87.00s/it]100%|██████████| 10/10 [18:57<00:00, 113.73s/it]
 90%|█████████ | 9/10 [19:29<02:07, 127.22s/it]04/07/2022 10:24:38 AM [INFO]: [CPU: 3]: Game 9
 90%|█████████ | 9/10 [19:39<01:45, 105.75s/it]04/07/2022 10:24:48 AM [INFO]: [CPU: 1]: Game 9
/home/x_aolss/gym_connect4/gym-connect4/MCTS_c4.py:160: RuntimeWarning: invalid value encountered in true_divide
  return ((root.child_number_visits)**(1/temp))/sum(root.child_number_visits**(1/temp))
 90%|█████████ | 9/10 [19:53<02:12, 132.56s/it]
Process Process-1:
Traceback (most recent call last):
  File "/home/x_aolss/.conda/envs/myownenv/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/x_aolss/.conda/envs/myownenv/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/x_aolss/gym_connect4/gym-connect4/MCTS_c4.py", line 192, in MCTS_self_play
    np.random.choice(np.array([0,1,2,3,4,5,6]), \
  File "mtrand.pyx", line 935, in numpy.random.mtrand.RandomState.choice
ValueError: probabilities contain NaN
 90%|█████████ | 9/10 [20:00<01:51, 111.74s/it]04/07/2022 10:25:09 AM [INFO]: [CPU: 5]: Game 9
100%|██████████| 10/10 [20:34<00:00, 87.60s/it]100%|██████████| 10/10 [20:34<00:00, 123.45s/it]
100%|██████████| 10/10 [20:48<00:00, 94.32s/it]100%|██████████| 10/10 [20:48<00:00, 124.84s/it]
100%|██████████| 10/10 [20:55<00:00, 114.50s/it]100%|██████████| 10/10 [20:55<00:00, 125.53s/it]
04/07/2022 10:26:04 AM [INFO]: Finished multi-process MCTS!
04/07/2022 10:26:04 AM [INFO]: Loading training data...
/home/x_aolss/gym_connect4/gym-connect4/train_c4.py:141: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  datasets = np.array(datasets)
04/07/2022 10:26:05 AM [INFO]: Loaded data from ./datasets/iter_3/.
04/07/2022 10:26:05 AM [INFO]: Loaded checkpoint model cc4_current_net__iter3.pth.tar.
04/07/2022 10:26:05 AM [INFO]: Starting training process...
04/07/2022 10:30:09 AM [INFO]: Finished Training!
FINISHED SELF PLAY:  10:26:04
Update step size: 17
[Iteration 3] Process ID: 217646 [Epoch: 1,   544/ 2265 points] total loss per batch: 2.651
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 1.6711e-15, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([0.0010, 0.5486, 0.0340, 0.1213, 0.0030, 0.0213, 0.2710],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 1,  1088/ 2265 points] total loss per batch: 2.359
Policy (actual, predicted): 6 6
Policy data: tensor([0.3521, 0.0059, 0.0145, 0.0059, 0.0041, 0.0059, 0.6114],
       device='cuda:0')
Policy pred: tensor([0.2827, 0.0257, 0.1285, 0.0139, 0.0670, 0.1552, 0.3269],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.0026066319551318884
 
[Iteration 3] Process ID: 217646 [Epoch: 1,  1632/ 2265 points] total loss per batch: 2.172
Policy (actual, predicted): 1 4
Policy data: tensor([0.4448, 0.4653, 0.0267, 0.0109, 0.0142, 0.0190, 0.0190],
       device='cuda:0')
Policy pred: tensor([0.0916, 0.0837, 0.1182, 0.0107, 0.5244, 0.0716, 0.0997],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.16460327804088593
 
[Iteration 3] Process ID: 217646 [Epoch: 1,  2176/ 2265 points] total loss per batch: 2.060
Policy (actual, predicted): 2 5
Policy data: tensor([0.0000e+00, 0.0000e+00, 7.9821e-01, 2.7838e-08, 0.0000e+00, 1.9566e-02,
        1.8222e-01], device='cuda:0')
Policy pred: tensor([1.1791e-04, 2.5364e-04, 8.0119e-02, 4.2414e-02, 4.1182e-05, 6.2500e-01,
        2.5206e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9991248846054077
 
[Iteration 3] Process ID: 217646 [Epoch: 2,   544/ 2265 points] total loss per batch: 1.658
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 2.5937e-17, 1.4606e-18, 2.4156e-26, 0.0000e+00, 1.3930e-24,
        6.8235e-18], device='cuda:0')
Policy pred: tensor([5.8693e-01, 4.9534e-02, 1.6874e-01, 5.4152e-03, 4.5096e-06, 1.2303e-01,
        6.6352e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9993413686752319
 
[Iteration 3] Process ID: 217646 [Epoch: 2,  1088/ 2265 points] total loss per batch: 1.775
Policy (actual, predicted): 6 0
Policy data: tensor([0.0220, 0.0081, 0.0117, 0.0043, 0.0043, 0.0081, 0.9413],
       device='cuda:0')
Policy pred: tensor([0.6867, 0.0045, 0.0620, 0.0089, 0.0074, 0.0571, 0.1735],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.8742891550064087
 
[Iteration 3] Process ID: 217646 [Epoch: 2,  1632/ 2265 points] total loss per batch: 1.665
Policy (actual, predicted): 4 4
Policy data: tensor([9.4565e-16, 2.6086e-20, 7.7508e-11, 5.5839e-21, 1.0000e+00, 9.6834e-23,
        1.2396e-12], device='cuda:0')
Policy pred: tensor([0.0433, 0.0071, 0.0180, 0.0134, 0.7815, 0.0041, 0.1326],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.8093075156211853
 
[Iteration 3] Process ID: 217646 [Epoch: 2,  2176/ 2265 points] total loss per batch: 1.543
Policy (actual, predicted): 4 4
Policy data: tensor([0.0836, 0.0094, 0.0128, 0.0654, 0.7603, 0.0059, 0.0626],
       device='cuda:0')
Policy pred: tensor([0.0384, 0.0100, 0.0102, 0.0431, 0.8646, 0.0097, 0.0240],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.5239675045013428
 
[Iteration 3] Process ID: 217646 [Epoch: 3,   544/ 2265 points] total loss per batch: 1.352
Policy (actual, predicted): 6 6
Policy data: tensor([4.7825e-14, 5.0148e-08, 7.6806e-13, 5.5139e-16, 4.8973e-11, 2.8918e-16,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([0.1397, 0.0347, 0.0496, 0.0162, 0.1730, 0.1354, 0.4514],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999944806098938
 
[Iteration 3] Process ID: 217646 [Epoch: 3,  1088/ 2265 points] total loss per batch: 1.400
Policy (actual, predicted): 5 3
Policy data: tensor([0.0000e+00, 6.2654e-16, 0.0000e+00, 2.2497e-15, 0.0000e+00, 1.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.8439e-05, 6.0610e-02, 8.6076e-05, 4.9013e-01, 1.8764e-02, 4.2227e-01,
        8.1231e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9996997714042664
 
[Iteration 3] Process ID: 217646 [Epoch: 3,  1632/ 2265 points] total loss per batch: 1.461
Policy (actual, predicted): 4 4
Policy data: tensor([0.0225, 0.0094, 0.0177, 0.0094, 0.6997, 0.0145, 0.2267],
       device='cuda:0')
Policy pred: tensor([0.0346, 0.0073, 0.0255, 0.0082, 0.7141, 0.0165, 0.1938],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.33929529786109924
 
[Iteration 3] Process ID: 217646 [Epoch: 3,  2176/ 2265 points] total loss per batch: 1.385
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0481, 0.0288, 0.0267, 0.0198, 0.0409, 0.0485, 0.7872],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.052840668708086014
 
[Iteration 3] Process ID: 217646 [Epoch: 4,   544/ 2265 points] total loss per batch: 1.180
Policy (actual, predicted): 0 0
Policy data: tensor([0.5216, 0.0022, 0.3725, 0.0022, 0.0531, 0.0040, 0.0445],
       device='cuda:0')
Policy pred: tensor([0.5198, 0.0160, 0.3091, 0.0058, 0.0534, 0.0316, 0.0643],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9743174910545349
 
[Iteration 3] Process ID: 217646 [Epoch: 4,  1088/ 2265 points] total loss per batch: 1.201
Policy (actual, predicted): 1 1
Policy data: tensor([1.8456e-16, 1.0000e+00, 5.1689e-19, 3.0522e-24, 1.0671e-13, 1.4601e-20,
        3.0522e-14], device='cuda:0')
Policy pred: tensor([1.6778e-04, 8.9244e-01, 2.1351e-04, 2.6405e-05, 2.7044e-03, 5.4746e-04,
        1.0390e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9906521439552307
 
[Iteration 3] Process ID: 217646 [Epoch: 4,  1632/ 2265 points] total loss per batch: 1.300
Policy (actual, predicted): 2 2
Policy data: tensor([0.0159, 0.1844, 0.6458, 0.0041, 0.0022, 0.0041, 0.1436],
       device='cuda:0')
Policy pred: tensor([0.1124, 0.2176, 0.4266, 0.0151, 0.0208, 0.0137, 0.1938],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.8633806705474854
 
[Iteration 3] Process ID: 217646 [Epoch: 4,  2176/ 2265 points] total loss per batch: 1.282
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 1.3640e-06, 1.0000e+00, 6.5064e-09, 1.0940e-08, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.0439e-04, 4.8106e-02, 9.4895e-01, 1.4908e-03, 7.3895e-04, 2.4224e-04,
        7.1000e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998276233673096
 
[Iteration 3] Process ID: 217646 [Epoch: 5,   544/ 2265 points] total loss per batch: 1.120
Policy (actual, predicted): 5 5
Policy data: tensor([0.0043, 0.0269, 0.0081, 0.0043, 0.0043, 0.9253, 0.0269],
       device='cuda:0')
Policy pred: tensor([0.0210, 0.0354, 0.0402, 0.0049, 0.0033, 0.8735, 0.0218],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.3189210593700409
 
[Iteration 3] Process ID: 217646 [Epoch: 5,  1088/ 2265 points] total loss per batch: 1.236
Policy (actual, predicted): 4 6
Policy data: tensor([0.0366, 0.0108, 0.0688, 0.0108, 0.4305, 0.0278, 0.4147],
       device='cuda:0')
Policy pred: tensor([0.0183, 0.0063, 0.1062, 0.0044, 0.3211, 0.0385, 0.5053],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.4234698414802551
 
[Iteration 3] Process ID: 217646 [Epoch: 5,  1632/ 2265 points] total loss per batch: 1.083
Policy (actual, predicted): 6 6
Policy data: tensor([0.1107, 0.0478, 0.0658, 0.0307, 0.0589, 0.0576, 0.6286],
       device='cuda:0')
Policy pred: tensor([0.0440, 0.0385, 0.0273, 0.0753, 0.0758, 0.0713, 0.6678],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9627801179885864
 
[Iteration 3] Process ID: 217646 [Epoch: 5,  2176/ 2265 points] total loss per batch: 1.109
Policy (actual, predicted): 0 4
Policy data: tensor([0.2287, 0.1357, 0.1357, 0.0357, 0.2287, 0.0587, 0.1768],
       device='cuda:0')
Policy pred: tensor([0.1556, 0.1059, 0.0827, 0.0746, 0.2995, 0.1174, 0.1643],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9997290968894958
 
[Iteration 3] Process ID: 217646 [Epoch: 6,   544/ 2265 points] total loss per batch: 1.094
Policy (actual, predicted): 5 5
Policy data: tensor([0.0362, 0.0538, 0.0902, 0.0041, 0.0111, 0.7550, 0.0495],
       device='cuda:0')
Policy pred: tensor([0.0528, 0.1419, 0.0976, 0.0090, 0.1776, 0.4837, 0.0374],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.34410324692726135
 
[Iteration 3] Process ID: 217646 [Epoch: 6,  1088/ 2265 points] total loss per batch: 1.043
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0257, 0.0655, 0.2438, 0.0039, 0.0058, 0.0185, 0.6369],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.07271382212638855
 
[Iteration 3] Process ID: 217646 [Epoch: 6,  1632/ 2265 points] total loss per batch: 1.052
Policy (actual, predicted): 6 6
Policy data: tensor([2.9297e-15, 2.8610e-18, 1.0358e-10, 9.9757e-19, 8.8858e-08, 0.0000e+00,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([5.7377e-03, 1.0574e-03, 7.0867e-03, 3.5273e-03, 6.8700e-04, 2.6771e-04,
        9.8164e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9984949827194214
 
[Iteration 3] Process ID: 217646 [Epoch: 6,  2176/ 2265 points] total loss per batch: 1.104
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 9.9997e-01, 2.7189e-05, 3.4341e-10, 0.0000e+00, 1.6367e-10,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([8.0822e-07, 9.9350e-01, 5.5401e-04, 5.3742e-06, 7.6066e-08, 5.9416e-03,
        1.5814e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999998927116394
 
[Iteration 3] Process ID: 217646 [Epoch: 7,   544/ 2265 points] total loss per batch: 0.993
Policy (actual, predicted): 4 4
Policy data: tensor([1.2063e-14, 1.0153e-18, 1.1163e-06, 2.8436e-21, 1.0000e+00, 8.2253e-20,
        4.8569e-15], device='cuda:0')
Policy pred: tensor([2.2642e-03, 3.1801e-05, 9.1093e-04, 1.8076e-04, 8.4344e-01, 8.8920e-03,
        1.4428e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.8636484146118164
 
[Iteration 3] Process ID: 217646 [Epoch: 7,  1088/ 2265 points] total loss per batch: 0.943
Policy (actual, predicted): 2 2
Policy data: tensor([8.5510e-03, 9.5995e-15, 9.9141e-01, 9.8299e-22, 3.6035e-05, 5.8045e-17,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([0.1727, 0.0032, 0.7257, 0.0013, 0.0880, 0.0064, 0.0027],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9980506896972656
 
[Iteration 3] Process ID: 217646 [Epoch: 7,  1632/ 2265 points] total loss per batch: 1.054
Policy (actual, predicted): 4 4
Policy data: tensor([1.9591e-12, 4.2534e-14, 2.6336e-13, 7.3761e-26, 1.0000e+00, 7.3761e-26,
        7.2032e-19], device='cuda:0')
Policy pred: tensor([6.2896e-02, 3.3539e-03, 3.5379e-03, 5.0941e-03, 8.8348e-01, 5.9786e-04,
        4.1043e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.8628077507019043
 
[Iteration 3] Process ID: 217646 [Epoch: 7,  2176/ 2265 points] total loss per batch: 1.076
Policy (actual, predicted): 4 4
Policy data: tensor([0.0211, 0.0274, 0.0320, 0.0411, 0.8049, 0.0162, 0.0573],
       device='cuda:0')
Policy pred: tensor([0.0466, 0.0191, 0.0191, 0.0084, 0.8799, 0.0106, 0.0163],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.7305617332458496
 
[Iteration 3] Process ID: 217646 [Epoch: 8,   544/ 2265 points] total loss per batch: 0.947
Policy (actual, predicted): 6 0
Policy data: tensor([0.1932, 0.1356, 0.0778, 0.1239, 0.1621, 0.0778, 0.2296],
       device='cuda:0')
Policy pred: tensor([0.4886, 0.1487, 0.0302, 0.0204, 0.0646, 0.1062, 0.1414],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999804496765137
 
[Iteration 3] Process ID: 217646 [Epoch: 8,  1088/ 2265 points] total loss per batch: 0.995
Policy (actual, predicted): 2 2
Policy data: tensor([6.6193e-03, 3.2583e-20, 9.9338e-01, 3.4165e-24, 2.0658e-16, 9.4247e-19,
        1.6044e-11], device='cuda:0')
Policy pred: tensor([8.3423e-02, 1.2367e-02, 7.5344e-01, 4.9302e-04, 8.4793e-02, 6.4155e-03,
        5.9070e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9976025819778442
 
[Iteration 3] Process ID: 217646 [Epoch: 8,  1632/ 2265 points] total loss per batch: 0.977
Policy (actual, predicted): 2 2
Policy data: tensor([0.0159, 0.1844, 0.6458, 0.0041, 0.0022, 0.0041, 0.1436],
       device='cuda:0')
Policy pred: tensor([0.0297, 0.1776, 0.5971, 0.0026, 0.0103, 0.0037, 0.1790],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.8009629249572754
 
[Iteration 3] Process ID: 217646 [Epoch: 8,  2176/ 2265 points] total loss per batch: 0.981
Policy (actual, predicted): 2 2
Policy data: tensor([1.7310e-01, 4.2227e-02, 7.8465e-01, 3.7896e-08, 3.8009e-06, 1.7310e-11,
        1.5899e-05], device='cuda:0')
Policy pred: tensor([0.0564, 0.0100, 0.8961, 0.0015, 0.0264, 0.0056, 0.0039],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9994741678237915
 
[Iteration 3] Process ID: 217646 [Epoch: 9,   544/ 2265 points] total loss per batch: 0.868
Policy (actual, predicted): 6 6
Policy data: tensor([0.0062, 0.0184, 0.0098, 0.0116, 0.0409, 0.0080, 0.9050],
       device='cuda:0')
Policy pred: tensor([0.0208, 0.0162, 0.0310, 0.0075, 0.0575, 0.0101, 0.8569],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.14403091371059418
 
[Iteration 3] Process ID: 217646 [Epoch: 9,  1088/ 2265 points] total loss per batch: 0.975
Policy (actual, predicted): 4 4
Policy data: tensor([0.0079, 0.0132, 0.0132, 0.0745, 0.8634, 0.0079, 0.0199],
       device='cuda:0')
Policy pred: tensor([0.0076, 0.0077, 0.0329, 0.0142, 0.9042, 0.0052, 0.0282],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9980642795562744
 
[Iteration 3] Process ID: 217646 [Epoch: 9,  1632/ 2265 points] total loss per batch: 0.976
Policy (actual, predicted): 6 6
Policy data: tensor([5.7172e-11, 3.1441e-15, 3.9948e-08, 2.0413e-08, 2.9407e-05, 0.0000e+00,
        9.9997e-01], device='cuda:0')
Policy pred: tensor([1.2064e-01, 3.5374e-04, 1.3093e-03, 3.7749e-03, 3.3164e-03, 3.1526e-05,
        8.7057e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9987112283706665
 
[Iteration 3] Process ID: 217646 [Epoch: 9,  2176/ 2265 points] total loss per batch: 0.982
Policy (actual, predicted): 4 4
Policy data: tensor([5.2341e-14, 1.3202e-12, 8.5345e-11, 3.2133e-24, 9.9937e-01, 1.9239e-14,
        6.3210e-04], device='cuda:0')
Policy pred: tensor([3.4454e-04, 1.3122e-02, 1.3055e-07, 6.7391e-06, 9.8134e-01, 5.0989e-03,
        8.9096e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.3419674038887024
 
[Iteration 3] Process ID: 217646 [Epoch: 10,   544/ 2265 points] total loss per batch: 0.944
Policy (actual, predicted): 6 3
Policy data: tensor([0.1454, 0.1325, 0.1395, 0.1477, 0.1383, 0.1419, 0.1547],
       device='cuda:0')
Policy pred: tensor([0.1768, 0.1115, 0.0959, 0.2592, 0.1399, 0.0951, 0.1217],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9984267354011536
 
[Iteration 3] Process ID: 217646 [Epoch: 10,  1088/ 2265 points] total loss per batch: 0.926
Policy (actual, predicted): 2 2
Policy data: tensor([2.4519e-01, 9.3662e-06, 7.5234e-01, 3.0415e-05, 8.7229e-05, 2.3067e-03,
        4.0002e-05], device='cuda:0')
Policy pred: tensor([0.1802, 0.0018, 0.6074, 0.0024, 0.0783, 0.0215, 0.1084],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9980955123901367
 
[Iteration 3] Process ID: 217646 [Epoch: 10,  1632/ 2265 points] total loss per batch: 0.882
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 8.4841e-17, 4.2084e-19, 2.6057e-18, 1.4674e-19, 1.0915e-18,
        1.7705e-14], device='cuda:0')
Policy pred: tensor([8.8471e-01, 3.5083e-03, 1.5444e-03, 1.7686e-03, 5.2999e-05, 2.8980e-02,
        7.9431e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9972630143165588
 
[Iteration 3] Process ID: 217646 [Epoch: 10,  2176/ 2265 points] total loss per batch: 0.937
Policy (actual, predicted): 1 1
Policy data: tensor([5.7937e-20, 1.0000e+00, 1.6616e-29, 1.7423e-23, 1.7015e-26, 1.6616e-29,
        1.7423e-23], device='cuda:0')
Policy pred: tensor([2.2436e-05, 9.9088e-01, 1.5701e-06, 4.8653e-05, 4.1300e-05, 8.6335e-04,
        8.1386e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.996995747089386
 
[Iteration 3] Process ID: 217646 [Epoch: 11,   544/ 2265 points] total loss per batch: 0.867
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 5.4908e-04, 9.9945e-01, 1.4811e-24, 1.4246e-09, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.3880e-05, 1.7666e-03, 9.9373e-01, 2.0343e-04, 3.9686e-03, 3.0666e-04,
        1.0601e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999409317970276
 
[Iteration 3] Process ID: 217646 [Epoch: 11,  1088/ 2265 points] total loss per batch: 0.973
Policy (actual, predicted): 4 2
Policy data: tensor([0.0000, 0.1285, 0.2486, 0.0208, 0.4932, 0.0456, 0.0634],
       device='cuda:0')
Policy pred: tensor([3.8438e-05, 1.6506e-01, 3.2900e-01, 2.5724e-02, 3.1711e-01, 1.1155e-01,
        5.1513e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9973421096801758
 
[Iteration 3] Process ID: 217646 [Epoch: 11,  1632/ 2265 points] total loss per batch: 0.910
Policy (actual, predicted): 5 2
Policy data: tensor([9.0075e-08, 2.5833e-17, 4.8503e-14, 2.4636e-23, 0.0000e+00, 6.6368e-01,
        3.3632e-01], device='cuda:0')
Policy pred: tensor([1.2243e-03, 3.3653e-03, 4.8860e-01, 4.4715e-04, 3.6288e-06, 3.6546e-01,
        1.4090e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999529123306274
 
[Iteration 3] Process ID: 217646 [Epoch: 11,  2176/ 2265 points] total loss per batch: 0.936
Policy (actual, predicted): 6 6
Policy data: tensor([6.7012e-06, 1.4689e-23, 2.5473e-25, 2.6710e-19, 1.4689e-23, 8.6736e-19,
        9.9999e-01], device='cuda:0')
Policy pred: tensor([1.8523e-04, 5.7600e-04, 6.0945e-05, 1.1936e-04, 6.9470e-06, 2.2830e-03,
        9.9677e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.8767724633216858
 
[Iteration 3] Process ID: 217646 [Epoch: 12,   544/ 2265 points] total loss per batch: 0.894
Policy (actual, predicted): 4 4
Policy data: tensor([9.3091e-16, 2.5679e-20, 7.6300e-11, 5.4969e-21, 1.0000e+00, 9.5325e-23,
        9.5325e-13], device='cuda:0')
Policy pred: tensor([7.2682e-03, 1.1607e-03, 1.1460e-03, 1.6455e-04, 9.8428e-01, 1.0677e-04,
        5.8703e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9881565570831299
 
[Iteration 3] Process ID: 217646 [Epoch: 12,  1088/ 2265 points] total loss per batch: 0.920
Policy (actual, predicted): 0 0
Policy data: tensor([0.6993, 0.0379, 0.2323, 0.0041, 0.0041, 0.0129, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6248, 0.0775, 0.1716, 0.0257, 0.0309, 0.0381, 0.0313],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.05359780415892601
 
[Iteration 3] Process ID: 217646 [Epoch: 12,  1632/ 2265 points] total loss per batch: 0.943
Policy (actual, predicted): 2 0
Policy data: tensor([0.2831, 0.0090, 0.3576, 0.0303, 0.0073, 0.0389, 0.2738],
       device='cuda:0')
Policy pred: tensor([0.5859, 0.0090, 0.1491, 0.0245, 0.0014, 0.0306, 0.1994],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.867840588092804
 
[Iteration 3] Process ID: 217646 [Epoch: 12,  2176/ 2265 points] total loss per batch: 0.828
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0289, 0.1173, 0.3558, 0.0056, 0.0086, 0.0137, 0.4701],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.01277994830161333
 
[Iteration 3] Process ID: 217646 [Epoch: 13,   544/ 2265 points] total loss per batch: 0.878
Policy (actual, predicted): 6 6
Policy data: tensor([0.2937, 0.0200, 0.0918, 0.0275, 0.0260, 0.0530, 0.4879],
       device='cuda:0')
Policy pred: tensor([0.1178, 0.0270, 0.2448, 0.0186, 0.0307, 0.1033, 0.4579],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9120867252349854
 
[Iteration 3] Process ID: 217646 [Epoch: 13,  1088/ 2265 points] total loss per batch: 0.890
Policy (actual, predicted): 3 3
Policy data: tensor([0.0257, 0.0145, 0.0257, 0.7759, 0.0642, 0.0060, 0.0880],
       device='cuda:0')
Policy pred: tensor([0.0642, 0.0145, 0.0302, 0.7742, 0.0913, 0.0100, 0.0156],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9097220301628113
 
[Iteration 3] Process ID: 217646 [Epoch: 13,  1632/ 2265 points] total loss per batch: 0.935
Policy (actual, predicted): 0 0
Policy data: tensor([0.6993, 0.0379, 0.2323, 0.0041, 0.0041, 0.0129, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.5681, 0.0660, 0.2414, 0.0310, 0.0269, 0.0372, 0.0294],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.02142992429435253
 
[Iteration 3] Process ID: 217646 [Epoch: 13,  2176/ 2265 points] total loss per batch: 0.833
Policy (actual, predicted): 0 1
Policy data: tensor([0.2414, 0.1916, 0.1202, 0.1057, 0.0984, 0.0823, 0.1604],
       device='cuda:0')
Policy pred: tensor([0.2131, 0.2602, 0.1144, 0.1044, 0.0476, 0.1515, 0.1087],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9993844032287598
 
[Iteration 3] Process ID: 217646 [Epoch: 14,   544/ 2265 points] total loss per batch: 0.850
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 1.4159e-26, 0.0000e+00, 8.1649e-25, 1.4159e-26, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9996e-01, 2.4470e-09, 9.2171e-11, 3.8141e-05, 1.8784e-09, 2.6421e-13,
        4.7807e-11], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998211860657
 
[Iteration 3] Process ID: 217646 [Epoch: 14,  1088/ 2265 points] total loss per batch: 0.885
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 1.7758e-29, 1.0995e-18, 0.0000e+00,
        2.4481e-18], device='cuda:0')
Policy pred: tensor([1.5579e-06, 9.9343e-01, 1.0885e-06, 1.2301e-05, 1.2969e-04, 6.7498e-08,
        6.4299e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999692440032959
 
[Iteration 3] Process ID: 217646 [Epoch: 14,  1632/ 2265 points] total loss per batch: 0.911
Policy (actual, predicted): 1 1
Policy data: tensor([1.6724e-02, 8.8238e-01, 4.4557e-03, 6.6212e-03, 4.4557e-03, 3.5145e-05,
        8.5326e-02], device='cuda:0')
Policy pred: tensor([0.0054, 0.9703, 0.0010, 0.0065, 0.0026, 0.0011, 0.0131],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999966621398926
 
[Iteration 3] Process ID: 217646 [Epoch: 14,  2176/ 2265 points] total loss per batch: 0.805
Policy (actual, predicted): 4 0
Policy data: tensor([0.1512, 0.1454, 0.1477, 0.1289, 0.1524, 0.1360, 0.1384],
       device='cuda:0')
Policy pred: tensor([0.5668, 0.0557, 0.2864, 0.0153, 0.0211, 0.0259, 0.0289],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.020662736147642136
 
[Iteration 3] Process ID: 217646 [Epoch: 15,   544/ 2265 points] total loss per batch: 0.869
Policy (actual, predicted): 4 4
Policy data: tensor([5.3195e-05, 1.4550e-20, 2.6457e-16, 9.9682e-05, 5.4617e-01, 1.4550e-20,
        4.5368e-01], device='cuda:0')
Policy pred: tensor([0.0242, 0.0065, 0.0124, 0.0388, 0.5550, 0.0021, 0.3611],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999911785125732
 
[Iteration 3] Process ID: 217646 [Epoch: 15,  1088/ 2265 points] total loss per batch: 0.885
Policy (actual, predicted): 0 6
Policy data: tensor([0.3647, 0.0107, 0.3417, 0.0040, 0.0232, 0.0074, 0.2483],
       device='cuda:0')
Policy pred: tensor([0.2591, 0.0185, 0.1824, 0.0136, 0.0392, 0.0315, 0.4557],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.2179935723543167
 
[Iteration 3] Process ID: 217646 [Epoch: 15,  1632/ 2265 points] total loss per batch: 0.849
Policy (actual, predicted): 0 0
Policy data: tensor([0.7944, 0.0078, 0.0095, 0.0041, 0.0913, 0.0427, 0.0501],
       device='cuda:0')
Policy pred: tensor([9.6010e-01, 9.2622e-04, 2.8353e-03, 7.4513e-04, 1.9846e-02, 9.6723e-03,
        5.8752e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9246076345443726
 
[Iteration 3] Process ID: 217646 [Epoch: 15,  2176/ 2265 points] total loss per batch: 0.867
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 5.4958e-12, 6.4215e-10, 1.0000e+00, 1.0620e-17, 1.0620e-07,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.4900e-07, 2.2160e-04, 3.9980e-04, 9.9709e-01, 2.0059e-06, 2.2849e-03,
        3.1664e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999997019767761
 
[Iteration 3] Process ID: 217646 [Epoch: 16,   544/ 2265 points] total loss per batch: 0.879
Policy (actual, predicted): 3 3
Policy data: tensor([0., 0., 0., 1., 0., 0., 0.], device='cuda:0')
Policy pred: tensor([2.4122e-05, 1.5938e-06, 5.0558e-03, 9.9168e-01, 7.2855e-05, 1.1780e-03,
        1.9897e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999976754188538
 
[Iteration 3] Process ID: 217646 [Epoch: 16,  1088/ 2265 points] total loss per batch: 0.866
Policy (actual, predicted): 0 0
Policy data: tensor([9.5353e-01, 2.0238e-22, 3.5095e-24, 3.5095e-24, 4.6465e-02, 3.5095e-24,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.5011e-01, 4.9375e-04, 3.1708e-02, 1.0604e-04, 1.6622e-02, 9.5880e-04,
        1.0818e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999539852142334
 
[Iteration 3] Process ID: 217646 [Epoch: 16,  1632/ 2265 points] total loss per batch: 0.873
Policy (actual, predicted): 2 2
Policy data: tensor([0.0093, 0.1918, 0.6213, 0.0109, 0.0093, 0.0109, 0.1464],
       device='cuda:0')
Policy pred: tensor([0.0404, 0.1802, 0.5937, 0.0196, 0.0432, 0.0152, 0.1077],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.6546589136123657
 
[Iteration 3] Process ID: 217646 [Epoch: 16,  2176/ 2265 points] total loss per batch: 0.832
Policy (actual, predicted): 0 0
Policy data: tensor([0.3647, 0.0107, 0.3417, 0.0040, 0.0232, 0.0074, 0.2483],
       device='cuda:0')
Policy pred: tensor([0.3601, 0.0296, 0.3437, 0.0195, 0.0419, 0.0252, 0.1801],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.004469562321901321
 
[Iteration 3] Process ID: 217646 [Epoch: 17,   544/ 2265 points] total loss per batch: 0.872
Policy (actual, predicted): 4 4
Policy data: tensor([0.0443, 0.0429, 0.0580, 0.0727, 0.5502, 0.1316, 0.1001],
       device='cuda:0')
Policy pred: tensor([0.0501, 0.0331, 0.0367, 0.0520, 0.4577, 0.2840, 0.0864],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.8698990941047668
 
[Iteration 3] Process ID: 217646 [Epoch: 17,  1088/ 2265 points] total loss per batch: 0.853
Policy (actual, predicted): 0 0
Policy data: tensor([9.4462e-01, 1.7377e-13, 7.0252e-18, 6.8605e-21, 6.5427e-17, 5.5381e-02,
        7.0252e-18], device='cuda:0')
Policy pred: tensor([9.8945e-01, 4.5545e-04, 2.6944e-05, 9.5398e-05, 5.4251e-04, 8.8620e-03,
        5.6656e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999996423721313
 
[Iteration 3] Process ID: 217646 [Epoch: 17,  1632/ 2265 points] total loss per batch: 0.845
Policy (actual, predicted): 2 1
Policy data: tensor([0.0000e+00, 3.2534e-01, 6.7429e-01, 7.2963e-19, 4.5177e-18, 1.0300e-14,
        3.7672e-04], device='cuda:0')
Policy pred: tensor([4.7452e-05, 5.0558e-01, 2.1401e-01, 3.0630e-03, 1.1004e-02, 2.6367e-01,
        2.6293e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999984622001648
 
[Iteration 3] Process ID: 217646 [Epoch: 17,  2176/ 2265 points] total loss per batch: 0.876
Policy (actual, predicted): 3 3
Policy data: tensor([2.0942e-20, 2.0451e-23, 5.5092e-21, 1.0000e+00, 5.5092e-21, 1.9972e-26,
        1.9046e-22], device='cuda:0')
Policy pred: tensor([2.8244e-06, 1.0133e-05, 1.0346e-04, 9.8356e-01, 2.8213e-03, 1.3268e-03,
        1.2176e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9794923067092896
 
[Iteration 3] Process ID: 217646 [Epoch: 18,   544/ 2265 points] total loss per batch: 0.858
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 4.5945e-06, 2.1417e-10, 8.4426e-11, 2.7097e-09, 1.3593e-10,
        6.1424e-10], device='cuda:0')
Policy pred: tensor([9.9733e-01, 3.4685e-04, 8.5939e-04, 7.2643e-08, 1.4530e-03, 7.1325e-06,
        7.0483e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999995827674866
 
[Iteration 3] Process ID: 217646 [Epoch: 18,  1088/ 2265 points] total loss per batch: 0.837
Policy (actual, predicted): 4 0
Policy data: tensor([0.1501, 0.1419, 0.1477, 0.1301, 0.1536, 0.1348, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.6855, 0.0517, 0.2139, 0.0102, 0.0100, 0.0158, 0.0129],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.0178790632635355
 
[Iteration 3] Process ID: 217646 [Epoch: 18,  1632/ 2265 points] total loss per batch: 0.870
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 2.9699e-13, 2.0067e-12, 2.9290e-18, 1.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([6.9707e-05, 6.4698e-03, 2.7198e-03, 7.3010e-05, 9.9067e-01, 1.7212e-07,
        8.8488e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999619126319885
 
[Iteration 3] Process ID: 217646 [Epoch: 18,  2176/ 2265 points] total loss per batch: 0.839
Policy (actual, predicted): 5 5
Policy data: tensor([9.0075e-08, 2.5833e-17, 4.8503e-14, 2.4636e-23, 0.0000e+00, 6.6368e-01,
        3.3632e-01], device='cuda:0')
Policy pred: tensor([7.6671e-04, 6.9394e-04, 7.4745e-03, 1.0132e-03, 2.1570e-06, 9.3280e-01,
        5.7248e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999998152256012
 
[Iteration 3] Process ID: 217646 [Epoch: 19,   544/ 2265 points] total loss per batch: 0.826
Policy (actual, predicted): 0 0
Policy data: tensor([0.6976, 0.0379, 0.2321, 0.0059, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.5924, 0.0736, 0.2053, 0.0306, 0.0291, 0.0367, 0.0323],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.010173800401389599
 
[Iteration 3] Process ID: 217646 [Epoch: 19,  1088/ 2265 points] total loss per batch: 0.847
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 3.8226e-06, 5.2445e-12, 1.8131e-23, 0.0000e+00, 2.9985e-21,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([1.9638e-07, 1.2132e-05, 3.0059e-03, 2.3165e-05, 7.6744e-08, 1.7158e-03,
        9.9524e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9995179176330566
 
[Iteration 3] Process ID: 217646 [Epoch: 19,  1632/ 2265 points] total loss per batch: 0.890
Policy (actual, predicted): 5 5
Policy data: tensor([0.0151, 0.0043, 0.0080, 0.0168, 0.0251, 0.9155, 0.0151],
       device='cuda:0')
Policy pred: tensor([0.0115, 0.0032, 0.0080, 0.0115, 0.0125, 0.9438, 0.0096],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.6280041933059692
 
[Iteration 3] Process ID: 217646 [Epoch: 19,  2176/ 2265 points] total loss per batch: 0.829
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 1.5080e-25, 1.5442e-22, 8.6961e-24, 1.5080e-25, 4.1015e-09,
        4.1600e-10], device='cuda:0')
Policy pred: tensor([9.8733e-01, 1.0616e-05, 8.0252e-05, 1.7945e-06, 4.7582e-04, 1.7613e-05,
        1.2089e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9871773719787598
 
[Iteration 3] Process ID: 217646 [Epoch: 20,   544/ 2265 points] total loss per batch: 0.851
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 9.8391e-01, 7.6580e-09, 1.6089e-02, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.7259e-10, 1.1026e-11, 9.9949e-01, 9.7648e-06, 4.9953e-04, 2.5588e-11,
        3.1394e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 20,  1088/ 2265 points] total loss per batch: 0.797
Policy (actual, predicted): 6 6
Policy data: tensor([5.8236e-11, 0.0000e+00, 6.0546e-26, 1.7103e-17, 0.0000e+00, 6.6571e-14,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([8.4513e-06, 2.8686e-06, 1.4452e-07, 1.5289e-06, 3.5137e-10, 2.0523e-04,
        9.9978e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9996563792228699
 
[Iteration 3] Process ID: 217646 [Epoch: 20,  1632/ 2265 points] total loss per batch: 0.844
Policy (actual, predicted): 6 6
Policy data: tensor([3.5475e-06, 2.6296e-10, 2.4401e-07, 2.2090e-27, 0.0000e+00, 6.5429e-13,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([4.7917e-03, 8.8857e-08, 3.7542e-05, 3.8105e-09, 1.2654e-15, 2.0915e-06,
        9.9517e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999988079071045
 
[Iteration 3] Process ID: 217646 [Epoch: 20,  2176/ 2265 points] total loss per batch: 0.825
Policy (actual, predicted): 5 5
Policy data: tensor([1.0240e-07, 8.0937e-19, 6.5569e-20, 2.3769e-25, 1.9482e-10, 1.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([7.1242e-05, 2.1294e-07, 7.8133e-05, 1.6356e-05, 5.0309e-04, 9.9933e-01,
        8.3814e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999798536300659
 
[Iteration 3] Process ID: 217646 [Epoch: 21,   544/ 2265 points] total loss per batch: 0.843
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 1.0000e+00, 2.4477e-07, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.4710e-04, 3.3065e-06, 9.9484e-01, 4.7822e-03, 1.9265e-08, 1.1932e-04,
        1.1054e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9254049062728882
 
[Iteration 3] Process ID: 217646 [Epoch: 21,  1088/ 2265 points] total loss per batch: 0.803
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 0.0000e+00, 7.6624e-07, 4.1146e-09, 6.3762e-09, 2.6024e-09,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([4.1072e-05, 1.1767e-05, 9.7818e-04, 5.0184e-05, 5.4946e-05, 8.3569e-03,
        9.9051e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999988675117493
 
[Iteration 3] Process ID: 217646 [Epoch: 21,  1632/ 2265 points] total loss per batch: 0.778
Policy (actual, predicted): 3 3
Policy data: tensor([6.0908e-12, 2.6500e-20, 2.6500e-20, 1.0000e+00, 3.0538e-10, 9.8370e-23,
        9.8370e-23], device='cuda:0')
Policy pred: tensor([3.3456e-04, 1.8667e-06, 6.7285e-06, 9.9928e-01, 6.2984e-05, 3.9782e-05,
        2.7703e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999995231628418
 
[Iteration 3] Process ID: 217646 [Epoch: 21,  2176/ 2265 points] total loss per batch: 0.902
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000, 0.0000, 0.9912, 0.0088, 0.0000, 0.0000, 0.0000],
       device='cuda:0')
Policy pred: tensor([2.6744e-09, 1.0495e-08, 9.9610e-01, 3.8955e-03, 1.4260e-12, 1.2420e-07,
        1.7239e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9961093068122864
 
[Iteration 3] Process ID: 217646 [Epoch: 22,   544/ 2265 points] total loss per batch: 0.819
Policy (actual, predicted): 4 4
Policy data: tensor([5.1251e-18, 9.5431e-11, 2.8861e-19, 2.1985e-15, 1.0000e+00, 8.2773e-19,
        9.1010e-17], device='cuda:0')
Policy pred: tensor([1.9033e-04, 3.2511e-02, 5.8840e-04, 1.9235e-04, 9.6454e-01, 2.1022e-04,
        1.7698e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999634027481079
 
[Iteration 3] Process ID: 217646 [Epoch: 22,  1088/ 2265 points] total loss per batch: 0.848
Policy (actual, predicted): 0 0
Policy data: tensor([0.8861, 0.0150, 0.0407, 0.0061, 0.0329, 0.0042, 0.0150],
       device='cuda:0')
Policy pred: tensor([0.8547, 0.0212, 0.0641, 0.0050, 0.0179, 0.0067, 0.0304],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9967040419578552
 
[Iteration 3] Process ID: 217646 [Epoch: 22,  1632/ 2265 points] total loss per batch: 0.830
Policy (actual, predicted): 2 2
Policy data: tensor([0.0831, 0.0379, 0.4136, 0.0217, 0.0057, 0.0335, 0.4045],
       device='cuda:0')
Policy pred: tensor([0.0815, 0.0462, 0.4407, 0.0228, 0.0592, 0.0242, 0.3253],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.8151630163192749
 
[Iteration 3] Process ID: 217646 [Epoch: 22,  2176/ 2265 points] total loss per batch: 0.810
Policy (actual, predicted): 0 0
Policy data: tensor([0.6976, 0.0379, 0.2321, 0.0059, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.5771, 0.0670, 0.2365, 0.0274, 0.0264, 0.0327, 0.0328],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.02264673076570034
 
[Iteration 3] Process ID: 217646 [Epoch: 23,   544/ 2265 points] total loss per batch: 0.848
Policy (actual, predicted): 4 4
Policy data: tensor([0.0405, 0.0149, 0.0166, 0.0023, 0.8761, 0.0280, 0.0216],
       device='cuda:0')
Policy pred: tensor([0.1040, 0.0036, 0.0227, 0.0014, 0.8510, 0.0129, 0.0045],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.993636965751648
 
[Iteration 3] Process ID: 217646 [Epoch: 23,  1088/ 2265 points] total loss per batch: 0.784
Policy (actual, predicted): 0 0
Policy data: tensor([0.3534, 0.1070, 0.0576, 0.0719, 0.0795, 0.1458, 0.1847],
       device='cuda:0')
Policy pred: tensor([0.4469, 0.1204, 0.1273, 0.0492, 0.0533, 0.1064, 0.0964],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9975650906562805
 
[Iteration 3] Process ID: 217646 [Epoch: 23,  1632/ 2265 points] total loss per batch: 0.852
Policy (actual, predicted): 1 1
Policy data: tensor([0.1006, 0.2174, 0.1613, 0.1728, 0.1366, 0.1366, 0.0746],
       device='cuda:0')
Policy pred: tensor([0.0700, 0.2235, 0.1935, 0.1338, 0.2029, 0.0926, 0.0837],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9778720736503601
 
[Iteration 3] Process ID: 217646 [Epoch: 23,  2176/ 2265 points] total loss per batch: 0.815
Policy (actual, predicted): 4 4
Policy data: tensor([0.2260, 0.1036, 0.0947, 0.0365, 0.4309, 0.0365, 0.0718],
       device='cuda:0')
Policy pred: tensor([0.2729, 0.0607, 0.0587, 0.0707, 0.4415, 0.0322, 0.0634],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999982714653015
 
[Iteration 3] Process ID: 217646 [Epoch: 24,   544/ 2265 points] total loss per batch: 0.845
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 7.4638e-12, 0.0000e+00, 1.0000e+00, 9.4026e-16, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([8.9679e-13, 3.4289e-04, 2.0748e-06, 9.9701e-01, 2.5826e-03, 5.4256e-05,
        5.4048e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999991655349731
 
[Iteration 3] Process ID: 217646 [Epoch: 24,  1088/ 2265 points] total loss per batch: 0.790
Policy (actual, predicted): 4 4
Policy data: tensor([0.1512, 0.1442, 0.1407, 0.1301, 0.1547, 0.1277, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1178, 0.1234, 0.1662, 0.0798, 0.2367, 0.0829, 0.1930],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999829530715942
 
[Iteration 3] Process ID: 217646 [Epoch: 24,  1632/ 2265 points] total loss per batch: 0.829
Policy (actual, predicted): 4 0
Policy data: tensor([0.1512, 0.1466, 0.1501, 0.1277, 0.1524, 0.1325, 0.1395],
       device='cuda:0')
Policy pred: tensor([0.5646, 0.0692, 0.2276, 0.0343, 0.0298, 0.0416, 0.0328],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.005053205415606499
 
[Iteration 3] Process ID: 217646 [Epoch: 24,  2176/ 2265 points] total loss per batch: 0.851
Policy (actual, predicted): 4 4
Policy data: tensor([6.5456e-02, 2.1713e-02, 2.4650e-01, 1.6862e-07, 6.2805e-01, 1.6862e-07,
        3.8277e-02], device='cuda:0')
Policy pred: tensor([8.6762e-03, 4.0693e-03, 4.1976e-02, 3.2630e-04, 9.3298e-01, 2.6622e-03,
        9.3101e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9956921339035034
 
[Iteration 3] Process ID: 217646 [Epoch: 25,   544/ 2265 points] total loss per batch: 0.842
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 9.8507e-08, 2.2765e-07, 0.0000e+00, 1.9935e-11,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.8851e-06, 9.9778e-01, 3.0307e-04, 1.4259e-03, 7.5501e-10, 4.7630e-04,
        1.2005e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999155402183533
 
[Iteration 3] Process ID: 217646 [Epoch: 25,  1088/ 2265 points] total loss per batch: 0.815
Policy (actual, predicted): 4 4
Policy data: tensor([2.3423e-07, 1.0567e-21, 3.0566e-20, 1.1080e-25, 1.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.5145e-04, 2.4681e-07, 2.5768e-05, 1.6503e-04, 9.9944e-01, 1.1833e-07,
        2.1959e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9996230602264404
 
[Iteration 3] Process ID: 217646 [Epoch: 25,  1632/ 2265 points] total loss per batch: 0.851
Policy (actual, predicted): 4 4
Policy data: tensor([0.0151, 0.0080, 0.0062, 0.0023, 0.9010, 0.0098, 0.0577],
       device='cuda:0')
Policy pred: tensor([1.3940e-03, 3.1737e-03, 6.0131e-03, 5.8555e-04, 9.3502e-01, 1.9145e-02,
        3.4668e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9878525733947754
 
[Iteration 3] Process ID: 217646 [Epoch: 25,  2176/ 2265 points] total loss per batch: 0.823
Policy (actual, predicted): 1 1
Policy data: tensor([7.2196e-09, 1.0000e+00, 1.6774e-19, 1.6774e-19, 3.8554e-11, 6.2267e-22,
        6.5596e-08], device='cuda:0')
Policy pred: tensor([1.6751e-03, 9.9742e-01, 3.8331e-06, 2.7063e-06, 8.9337e-04, 7.0593e-06,
        1.5619e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999996423721313
 
[Iteration 3] Process ID: 217646 [Epoch: 26,   544/ 2265 points] total loss per batch: 0.769
Policy (actual, predicted): 6 6
Policy data: tensor([0.0240, 0.0160, 0.0128, 0.0128, 0.2739, 0.0059, 0.6546],
       device='cuda:0')
Policy pred: tensor([0.0304, 0.0185, 0.0165, 0.0192, 0.2181, 0.0145, 0.6828],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.8610862493515015
 
[Iteration 3] Process ID: 217646 [Epoch: 26,  1088/ 2265 points] total loss per batch: 0.815
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 9.9997e-01, 1.7341e-12, 2.9079e-05, 0.0000e+00, 4.7430e-18,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.5488e-08, 9.9027e-01, 8.6165e-03, 9.9181e-04, 5.1411e-09, 1.1709e-04,
        2.3806e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998722076416016
 
[Iteration 3] Process ID: 217646 [Epoch: 26,  1632/ 2265 points] total loss per batch: 0.877
Policy (actual, predicted): 3 3
Policy data: tensor([0., 0., 0., 1., 0., 0., 0.], device='cuda:0')
Policy pred: tensor([1.1317e-04, 8.4981e-07, 3.9252e-06, 9.9930e-01, 1.0282e-08, 9.9490e-05,
        4.8675e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999892115592957
 
[Iteration 3] Process ID: 217646 [Epoch: 26,  2176/ 2265 points] total loss per batch: 0.837
Policy (actual, predicted): 1 1
Policy data: tensor([5.0161e-11, 1.0000e+00, 1.8184e-16, 4.9735e-22, 0.0000e+00, 2.9368e-17,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.3755e-04, 9.9968e-01, 7.1540e-06, 5.2032e-09, 4.0165e-09, 1.6966e-04,
        2.9882e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998446702957153
 
[Iteration 3] Process ID: 217646 [Epoch: 27,   544/ 2265 points] total loss per batch: 0.783
Policy (actual, predicted): 4 0
Policy data: tensor([0.1501, 0.1454, 0.1501, 0.1242, 0.1524, 0.1337, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.2227, 0.1370, 0.1799, 0.0739, 0.1151, 0.0947, 0.1766],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.8270468711853027
 
[Iteration 3] Process ID: 217646 [Epoch: 27,  1088/ 2265 points] total loss per batch: 0.892
Policy (actual, predicted): 6 6
Policy data: tensor([0.4120, 0.0126, 0.0221, 0.0058, 0.0205, 0.0386, 0.4885],
       device='cuda:0')
Policy pred: tensor([0.2994, 0.0046, 0.0295, 0.0075, 0.0133, 0.0163, 0.6294],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.12383021414279938
 
[Iteration 3] Process ID: 217646 [Epoch: 27,  1632/ 2265 points] total loss per batch: 0.862
Policy (actual, predicted): 4 4
Policy data: tensor([0.0978, 0.0449, 0.0176, 0.0041, 0.7300, 0.0254, 0.0802],
       device='cuda:0')
Policy pred: tensor([0.0892, 0.0501, 0.0322, 0.0052, 0.7696, 0.0088, 0.0449],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9135382175445557
 
[Iteration 3] Process ID: 217646 [Epoch: 27,  2176/ 2265 points] total loss per batch: 0.813
Policy (actual, predicted): 1 1
Policy data: tensor([1.0240e-17, 1.0000e+00, 1.0240e-07, 4.6716e-20, 0.0000e+00, 5.7665e-19,
        4.8986e-14], device='cuda:0')
Policy pred: tensor([1.2942e-03, 9.7477e-01, 1.5016e-02, 1.5401e-03, 2.1766e-08, 3.2292e-03,
        4.1467e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9982746243476868
 
[Iteration 3] Process ID: 217646 [Epoch: 28,   544/ 2265 points] total loss per batch: 0.769
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4689e-23, 1.4345e-26, 1.4345e-26,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([5.7522e-08, 9.3578e-08, 2.3684e-07, 5.4706e-04, 4.8160e-04, 1.0992e-03,
        9.9787e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9997318983078003
 
[Iteration 3] Process ID: 217646 [Epoch: 28,  1088/ 2265 points] total loss per batch: 0.876
Policy (actual, predicted): 2 2
Policy data: tensor([1.0268e-02, 4.1960e-08, 9.8500e-01, 2.2535e-15, 4.2546e-03, 1.3029e-12,
        4.7209e-04], device='cuda:0')
Policy pred: tensor([3.6866e-04, 1.8697e-04, 9.9241e-01, 9.5710e-05, 3.2768e-04, 9.0984e-04,
        5.6976e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9795711040496826
 
[Iteration 3] Process ID: 217646 [Epoch: 28,  1632/ 2265 points] total loss per batch: 0.855
Policy (actual, predicted): 4 4
Policy data: tensor([0.0060, 0.0275, 0.0442, 0.0060, 0.7810, 0.0060, 0.1294],
       device='cuda:0')
Policy pred: tensor([0.0206, 0.0141, 0.0307, 0.0175, 0.7143, 0.0101, 0.1927],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.1473020315170288
 
[Iteration 3] Process ID: 217646 [Epoch: 28,  2176/ 2265 points] total loss per batch: 0.852
Policy (actual, predicted): 1 1
Policy data: tensor([1.5772e-14, 1.0000e+00, 1.9468e-13, 5.4526e-26, 0.0000e+00, 7.3408e-18,
        5.0782e-15], device='cuda:0')
Policy pred: tensor([1.2019e-02, 9.4168e-01, 2.5324e-03, 9.8769e-03, 7.2030e-05, 2.7001e-02,
        6.8214e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9971436858177185
 
[Iteration 3] Process ID: 217646 [Epoch: 29,   544/ 2265 points] total loss per batch: 0.755
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 1.0116e-05, 1.4199e-05, 2.7073e-15, 6.9553e-19, 9.9998e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.0536e-05, 1.2959e-02, 1.4272e-03, 1.1988e-02, 5.4230e-05, 9.7354e-01,
        3.2389e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9740650057792664
 
[Iteration 3] Process ID: 217646 [Epoch: 29,  1088/ 2265 points] total loss per batch: 0.825
Policy (actual, predicted): 4 4
Policy data: tensor([0.0978, 0.0326, 0.0058, 0.2978, 0.5547, 0.0021, 0.0092],
       device='cuda:0')
Policy pred: tensor([6.2176e-02, 1.5789e-02, 9.2969e-03, 1.1450e-01, 7.9124e-01, 4.6782e-04,
        6.5349e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9926106929779053
 
[Iteration 3] Process ID: 217646 [Epoch: 29,  1632/ 2265 points] total loss per batch: 0.916
Policy (actual, predicted): 2 2
Policy data: tensor([0.0203, 0.0099, 0.9290, 0.0043, 0.0081, 0.0099, 0.0186],
       device='cuda:0')
Policy pred: tensor([1.1339e-02, 1.9223e-03, 9.7495e-01, 3.1263e-04, 1.5608e-03, 4.5707e-03,
        5.3409e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998712539672852
 
[Iteration 3] Process ID: 217646 [Epoch: 29,  2176/ 2265 points] total loss per batch: 0.836
Policy (actual, predicted): 1 4
Policy data: tensor([0.4448, 0.4653, 0.0267, 0.0109, 0.0142, 0.0190, 0.0190],
       device='cuda:0')
Policy pred: tensor([0.0318, 0.0289, 0.0061, 0.0073, 0.7613, 0.0087, 0.1559],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.037952665239572525
 
[Iteration 3] Process ID: 217646 [Epoch: 30,   544/ 2265 points] total loss per batch: 0.852
Policy (actual, predicted): 6 6
Policy data: tensor([2.8772e-10, 2.1522e-12, 2.1347e-01, 2.8576e-09, 2.0728e-20, 8.4297e-03,
        7.7810e-01], device='cuda:0')
Policy pred: tensor([3.7252e-02, 3.3695e-03, 3.0281e-01, 7.0591e-03, 3.6700e-04, 2.0545e-02,
        6.2859e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9963436722755432
 
[Iteration 3] Process ID: 217646 [Epoch: 30,  1088/ 2265 points] total loss per batch: 0.812
Policy (actual, predicted): 5 5
Policy data: tensor([0.0043, 0.0268, 0.0117, 0.0043, 0.0043, 0.9234, 0.0252],
       device='cuda:0')
Policy pred: tensor([0.0153, 0.0347, 0.0174, 0.0090, 0.0032, 0.8698, 0.0506],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.5608208179473877
 
[Iteration 3] Process ID: 217646 [Epoch: 30,  1632/ 2265 points] total loss per batch: 0.768
Policy (actual, predicted): 0 6
Policy data: tensor([0.5684, 0.0190, 0.0312, 0.0076, 0.0093, 0.0357, 0.3288],
       device='cuda:0')
Policy pred: tensor([0.3600, 0.0164, 0.0430, 0.0182, 0.0109, 0.0712, 0.4803],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.8926784992218018
 
[Iteration 3] Process ID: 217646 [Epoch: 30,  2176/ 2265 points] total loss per batch: 0.858
Policy (actual, predicted): 6 6
Policy data: tensor([2.8799e-02, 0.0000e+00, 1.1262e-03, 4.3835e-20, 0.0000e+00, 1.0843e-15,
        9.7008e-01], device='cuda:0')
Policy pred: tensor([1.2345e-02, 1.9122e-06, 5.8172e-05, 5.1315e-05, 5.6400e-05, 1.2794e-03,
        9.8621e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9969136118888855
 
[Iteration 3] Process ID: 217646 [Epoch: 31,   544/ 2265 points] total loss per batch: 0.875
Policy (actual, predicted): 1 2
Policy data: tensor([0.1509, 0.1966, 0.1801, 0.1260, 0.0870, 0.0792, 0.1801],
       device='cuda:0')
Policy pred: tensor([0.1326, 0.1655, 0.2046, 0.1144, 0.0978, 0.0806, 0.2044],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999904036521912
 
[Iteration 3] Process ID: 217646 [Epoch: 31,  1088/ 2265 points] total loss per batch: 0.763
Policy (actual, predicted): 0 0
Policy data: tensor([7.5001e-01, 1.0635e-16, 6.4476e-08, 3.1232e-23, 2.4999e-01, 8.4137e-11,
        1.8442e-18], device='cuda:0')
Policy pred: tensor([6.2311e-01, 6.1431e-04, 6.9761e-05, 9.3128e-07, 3.7610e-01, 4.4932e-05,
        6.3926e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.013885123655200005
 
[Iteration 3] Process ID: 217646 [Epoch: 31,  1632/ 2265 points] total loss per batch: 0.834
Policy (actual, predicted): 1 6
Policy data: tensor([0.1272, 0.2187, 0.1473, 0.1236, 0.0970, 0.0822, 0.2039],
       device='cuda:0')
Policy pred: tensor([0.1587, 0.2042, 0.1032, 0.0695, 0.0676, 0.0708, 0.3260],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999905526638031
 
[Iteration 3] Process ID: 217646 [Epoch: 31,  2176/ 2265 points] total loss per batch: 0.831
Policy (actual, predicted): 0 0
Policy data: tensor([0.6989, 0.0379, 0.2309, 0.0059, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6666, 0.0473, 0.2074, 0.0158, 0.0198, 0.0211, 0.0220],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.007243465632200241
 
[Iteration 3] Process ID: 217646 [Epoch: 32,   544/ 2265 points] total loss per batch: 0.865
Policy (actual, predicted): 1 1
Policy data: tensor([0.0092, 0.5124, 0.3730, 0.0092, 0.0414, 0.0075, 0.0471],
       device='cuda:0')
Policy pred: tensor([0.0112, 0.4941, 0.4114, 0.0085, 0.0357, 0.0033, 0.0358],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.10824975371360779
 
[Iteration 3] Process ID: 217646 [Epoch: 32,  1088/ 2265 points] total loss per batch: 0.821
Policy (actual, predicted): 6 6
Policy data: tensor([0.0098, 0.0098, 0.0249, 0.0115, 0.0542, 0.0080, 0.8819],
       device='cuda:0')
Policy pred: tensor([0.0096, 0.0097, 0.0297, 0.0150, 0.0308, 0.0115, 0.8938],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.31969937682151794
 
[Iteration 3] Process ID: 217646 [Epoch: 32,  1632/ 2265 points] total loss per batch: 0.840
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 1.5527e-12, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([7.4834e-06, 1.0664e-03, 6.2876e-04, 9.9771e-01, 2.0630e-08, 2.3419e-04,
        3.5252e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 32,  2176/ 2265 points] total loss per batch: 0.834
Policy (actual, predicted): 0 0
Policy data: tensor([0.6981, 0.0379, 0.2335, 0.0041, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6246, 0.0507, 0.2253, 0.0221, 0.0224, 0.0293, 0.0256],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.013406838290393353
 
[Iteration 3] Process ID: 217646 [Epoch: 33,   544/ 2265 points] total loss per batch: 0.858
Policy (actual, predicted): 0 0
Policy data: tensor([0.4597, 0.2207, 0.1338, 0.0386, 0.0121, 0.1138, 0.0213],
       device='cuda:0')
Policy pred: tensor([0.3344, 0.3206, 0.1188, 0.0462, 0.0063, 0.1425, 0.0312],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9955310821533203
 
[Iteration 3] Process ID: 217646 [Epoch: 33,  1088/ 2265 points] total loss per batch: 0.852
Policy (actual, predicted): 2 2
Policy data: tensor([0.0062, 0.0116, 0.9116, 0.0043, 0.0283, 0.0080, 0.0300],
       device='cuda:0')
Policy pred: tensor([3.2957e-03, 7.6393e-04, 9.5881e-01, 3.2501e-04, 8.1441e-03, 1.2666e-02,
        1.5993e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.980018675327301
 
[Iteration 3] Process ID: 217646 [Epoch: 33,  1632/ 2265 points] total loss per batch: 0.841
Policy (actual, predicted): 0 0
Policy data: tensor([0.7490, 0.0078, 0.0060, 0.0042, 0.0113, 0.2217, 0.0000],
       device='cuda:0')
Policy pred: tensor([6.4582e-01, 4.6326e-03, 2.2346e-02, 5.2221e-03, 1.7551e-02, 3.0443e-01,
        2.8806e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.997739315032959
 
[Iteration 3] Process ID: 217646 [Epoch: 33,  2176/ 2265 points] total loss per batch: 0.805
Policy (actual, predicted): 0 0
Policy data: tensor([0.8967, 0.0200, 0.0167, 0.0115, 0.0184, 0.0233, 0.0133],
       device='cuda:0')
Policy pred: tensor([0.8602, 0.0187, 0.0239, 0.0080, 0.0310, 0.0179, 0.0404],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9910715222358704
 
[Iteration 3] Process ID: 217646 [Epoch: 34,   544/ 2265 points] total loss per batch: 0.823
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 0.0000e+00, 8.0810e-19, 3.3453e-20, 1.1124e-16, 3.2669e-23,
        4.3982e-15], device='cuda:0')
Policy pred: tensor([9.9931e-01, 3.1831e-08, 7.4453e-05, 1.4897e-07, 3.1111e-05, 5.1009e-06,
        5.7642e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999985098838806
 
[Iteration 3] Process ID: 217646 [Epoch: 34,  1088/ 2265 points] total loss per batch: 0.791
Policy (actual, predicted): 2 2
Policy data: tensor([0.0058, 0.1957, 0.6197, 0.0058, 0.0206, 0.0058, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.0133, 0.1845, 0.6755, 0.0102, 0.0234, 0.0108, 0.0823],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9668576121330261
 
[Iteration 3] Process ID: 217646 [Epoch: 34,  1632/ 2265 points] total loss per batch: 0.853
Policy (actual, predicted): 2 2
Policy data: tensor([4.9126e-07, 4.0880e-19, 1.0000e+00, 1.4472e-27, 1.2064e-08, 0.0000e+00,
        7.7948e-08], device='cuda:0')
Policy pred: tensor([2.3502e-04, 8.9508e-06, 9.9258e-01, 2.2347e-05, 1.1814e-05, 6.5965e-07,
        7.1450e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999960660934448
 
[Iteration 3] Process ID: 217646 [Epoch: 34,  2176/ 2265 points] total loss per batch: 0.847
Policy (actual, predicted): 0 0
Policy data: tensor([0.6989, 0.0379, 0.2309, 0.0059, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6153, 0.0548, 0.2352, 0.0214, 0.0219, 0.0279, 0.0234],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.0053113834001123905
 
[Iteration 3] Process ID: 217646 [Epoch: 35,   544/ 2265 points] total loss per batch: 0.789
Policy (actual, predicted): 1 1
Policy data: tensor([1.8456e-16, 1.0000e+00, 5.1689e-19, 3.0522e-24, 1.0671e-13, 1.4601e-20,
        3.0522e-14], device='cuda:0')
Policy pred: tensor([3.5431e-07, 9.9938e-01, 3.2431e-06, 6.4196e-10, 1.0949e-05, 1.5709e-05,
        5.9459e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998634457588196
 
[Iteration 3] Process ID: 217646 [Epoch: 35,  1088/ 2265 points] total loss per batch: 0.880
Policy (actual, predicted): 5 5
Policy data: tensor([0.0483, 0.0394, 0.0527, 0.0060, 0.0242, 0.7856, 0.0439],
       device='cuda:0')
Policy pred: tensor([0.0524, 0.0373, 0.0477, 0.0039, 0.0207, 0.8002, 0.0377],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.1521928757429123
 
[Iteration 3] Process ID: 217646 [Epoch: 35,  1632/ 2265 points] total loss per batch: 0.752
Policy (actual, predicted): 6 6
Policy data: tensor([0.0437, 0.0639, 0.2217, 0.0678, 0.0691, 0.0923, 0.4414],
       device='cuda:0')
Policy pred: tensor([0.0417, 0.0223, 0.2495, 0.0474, 0.0543, 0.0688, 0.5161],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9938976168632507
 
[Iteration 3] Process ID: 217646 [Epoch: 35,  2176/ 2265 points] total loss per batch: 0.827
Policy (actual, predicted): 2 2
Policy data: tensor([6.3603e-07, 1.6460e-19, 1.0000e+00, 5.9668e-25, 1.6545e-07, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.0508e-02, 7.2101e-04, 9.8627e-01, 3.8788e-04, 2.1072e-03, 3.6345e-06,
        2.2387e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999990463256836
 
[Iteration 3] Process ID: 217646 [Epoch: 36,   544/ 2265 points] total loss per batch: 0.873
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 1.3229e-07, 0.0000e+00, 1.6539e-06, 9.9996e-01, 3.7432e-05,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.9458e-10, 1.3058e-03, 2.8001e-07, 3.1573e-05, 9.9812e-01, 5.4275e-04,
        1.1283e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 36,  1088/ 2265 points] total loss per batch: 0.757
Policy (actual, predicted): 2 2
Policy data: tensor([2.8822e-11, 2.0447e-16, 9.5930e-01, 7.8830e-27, 4.9981e-13, 8.0722e-24,
        4.0702e-02], device='cuda:0')
Policy pred: tensor([0.0076, 0.0041, 0.9623, 0.0020, 0.0062, 0.0014, 0.0165],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9970464110374451
 
[Iteration 3] Process ID: 217646 [Epoch: 36,  1632/ 2265 points] total loss per batch: 0.823
Policy (actual, predicted): 3 3
Policy data: tensor([0.0955, 0.1501, 0.0539, 0.2739, 0.0955, 0.0792, 0.2519],
       device='cuda:0')
Policy pred: tensor([0.0882, 0.0976, 0.0467, 0.3809, 0.0791, 0.0675, 0.2400],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999993443489075
 
[Iteration 3] Process ID: 217646 [Epoch: 36,  2176/ 2265 points] total loss per batch: 0.798
Policy (actual, predicted): 0 0
Policy data: tensor([8.7452e-01, 2.7270e-10, 1.2548e-01, 7.3463e-18, 2.5615e-08, 1.4997e-14,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([8.3179e-01, 1.5985e-03, 1.6106e-01, 2.1266e-04, 2.8566e-03, 2.4146e-03,
        6.7615e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999976754188538
 
[Iteration 3] Process ID: 217646 [Epoch: 37,   544/ 2265 points] total loss per batch: 0.802
Policy (actual, predicted): 6 0
Policy data: tensor([0.4120, 0.0126, 0.0221, 0.0058, 0.0205, 0.0386, 0.4885],
       device='cuda:0')
Policy pred: tensor([0.5046, 0.0091, 0.0362, 0.0074, 0.0138, 0.0330, 0.3960],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.0038853948935866356
 
[Iteration 3] Process ID: 217646 [Epoch: 37,  1088/ 2265 points] total loss per batch: 0.857
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 1.0000e+00, 5.2847e-07, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.6155e-07, 7.6415e-08, 9.9956e-01, 4.2495e-04, 3.5750e-09, 6.8668e-06,
        7.1329e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 37,  1632/ 2265 points] total loss per batch: 0.817
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 2.3201e-13, 0.0000e+00, 4.9603e-13,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.6663e-10, 9.9951e-01, 6.8608e-07, 4.3506e-06, 3.2677e-07, 4.8238e-04,
        3.2050e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 37,  2176/ 2265 points] total loss per batch: 0.766
Policy (actual, predicted): 6 6
Policy data: tensor([3.6210e-09, 8.8827e-13, 1.5404e-14, 2.6087e-19, 4.8800e-04, 1.2779e-12,
        9.9951e-01], device='cuda:0')
Policy pred: tensor([2.5643e-03, 7.3074e-04, 7.1157e-04, 9.0108e-05, 8.3549e-04, 2.8836e-04,
        9.9478e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9274052977561951
 
[Iteration 3] Process ID: 217646 [Epoch: 38,   544/ 2265 points] total loss per batch: 0.858
Policy (actual, predicted): 4 4
Policy data: tensor([0.0078, 0.0274, 0.0442, 0.0060, 0.7794, 0.0060, 0.1293],
       device='cuda:0')
Policy pred: tensor([0.0254, 0.0336, 0.0273, 0.0093, 0.6953, 0.0089, 0.2002],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.09548887610435486
 
[Iteration 3] Process ID: 217646 [Epoch: 38,  1088/ 2265 points] total loss per batch: 0.814
Policy (actual, predicted): 5 5
Policy data: tensor([7.3440e-17, 0.0000e+00, 2.1511e-24, 1.5694e-11, 0.0000e+00, 1.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.3841e-03, 4.9417e-05, 4.2000e-06, 6.3266e-07, 6.5065e-07, 9.9856e-01,
        4.7877e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999194145202637
 
[Iteration 3] Process ID: 217646 [Epoch: 38,  1632/ 2265 points] total loss per batch: 0.763
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 0.0000e+00, 1.1953e-09, 1.5448e-13, 0.0000e+00, 2.6823e-07,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9958e-01, 2.3340e-07, 7.2364e-05, 1.5434e-05, 1.9399e-07, 3.3330e-04,
        4.3704e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 38,  2176/ 2265 points] total loss per batch: 0.810
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0284, 0.1413, 0.3119, 0.0100, 0.0088, 0.0173, 0.4823],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.055447593331336975
 
[Iteration 3] Process ID: 217646 [Epoch: 39,   544/ 2265 points] total loss per batch: 0.784
Policy (actual, predicted): 4 4
Policy data: tensor([6.0353e-19, 1.4070e-21, 3.2078e-18, 1.3740e-24, 1.0000e+00, 1.4070e-21,
        6.5728e-21], device='cuda:0')
Policy pred: tensor([1.1542e-03, 3.8532e-04, 2.8160e-04, 1.2421e-04, 9.9551e-01, 6.5038e-04,
        1.8969e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999892115592957
 
[Iteration 3] Process ID: 217646 [Epoch: 39,  1088/ 2265 points] total loss per batch: 0.818
Policy (actual, predicted): 0 0
Policy data: tensor([0.4577, 0.0234, 0.3952, 0.0125, 0.0108, 0.0771, 0.0234],
       device='cuda:0')
Policy pred: tensor([0.4670, 0.0286, 0.3434, 0.0049, 0.0114, 0.0990, 0.0456],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9752340912818909
 
[Iteration 3] Process ID: 217646 [Epoch: 39,  1632/ 2265 points] total loss per batch: 0.797
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0262, 0.1104, 0.3533, 0.0085, 0.0101, 0.0141, 0.4775],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.03639613091945648
 
[Iteration 3] Process ID: 217646 [Epoch: 39,  2176/ 2265 points] total loss per batch: 0.836
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0582, 0.0192, 0.0184, 0.0162, 0.0439, 0.0517, 0.7924],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.041722629219293594
 
[Iteration 3] Process ID: 217646 [Epoch: 40,   544/ 2265 points] total loss per batch: 0.794
Policy (actual, predicted): 2 2
Policy data: tensor([7.0756e-02, 2.0566e-04, 9.2904e-01, 3.5665e-26, 0.0000e+00, 3.8295e-17,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.1781e-04, 9.3031e-05, 9.9958e-01, 1.7418e-06, 1.6662e-06, 3.2791e-06,
        9.8908e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 217646 [Epoch: 40,  1088/ 2265 points] total loss per batch: 0.853
Policy (actual, predicted): 0 0
Policy data: tensor([9.8951e-01, 9.5272e-03, 9.6631e-04, 6.8965e-10, 7.0620e-07, 9.2155e-10,
        7.2198e-09], device='cuda:0')
Policy pred: tensor([9.5293e-01, 3.1431e-02, 1.2308e-03, 2.8762e-07, 1.4029e-02, 2.3986e-04,
        1.4357e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 217646 [Epoch: 40,  1632/ 2265 points] total loss per batch: 0.822
Policy (actual, predicted): 4 4
Policy data: tensor([1.2361e-08, 1.6112e-06, 1.2151e-03, 6.5192e-10, 9.9877e-01, 9.9028e-12,
        1.3955e-05], device='cuda:0')
Policy pred: tensor([6.2696e-03, 3.6354e-03, 7.9974e-03, 1.1433e-03, 9.7310e-01, 3.1383e-05,
        7.8187e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998593926429749
 
[Iteration 3] Process ID: 217646 [Epoch: 40,  2176/ 2265 points] total loss per batch: 0.771
Policy (actual, predicted): 4 4
Policy data: tensor([6.1499e-04, 1.9922e-17, 5.8507e-24, 5.8507e-24, 9.9937e-01, 5.8507e-24,
        1.5383e-05], device='cuda:0')
Policy pred: tensor([2.8795e-03, 2.1203e-05, 8.2604e-04, 5.0381e-06, 9.9549e-01, 1.2696e-06,
        7.8013e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9963080883026123
 
[Iteration 3] Process ID: 217646 [Epoch: 41,   544/ 2265 points] total loss per batch: 0.742
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 1.5085e-14, 4.1743e-14, 5.3403e-23, 1.4386e-20, 4.1743e-14,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([1.5206e-07, 2.2077e-03, 1.1280e-02, 1.4722e-04, 1.4450e-04, 1.9222e-03,
        9.8430e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999978542327881
 
[Iteration 3] Process ID: 217646 [Epoch: 41,  1088/ 2265 points] total loss per batch: 0.833
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0630, 0.0266, 0.0261, 0.0201, 0.0461, 0.0544, 0.7637],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.06032000109553337
 
[Iteration 3] Process ID: 217646 [Epoch: 41,  1632/ 2265 points] total loss per batch: 0.796
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 5.0235e-15, 1.1437e-20, 1.9368e-25, 0.0000e+00, 1.0000e+00,
        1.4190e-06], device='cuda:0')
Policy pred: tensor([4.9581e-06, 3.5263e-02, 3.2886e-02, 2.8417e-03, 1.2675e-06, 8.2110e-01,
        1.0790e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.8551437854766846
 
[Iteration 3] Process ID: 217646 [Epoch: 41,  2176/ 2265 points] total loss per batch: 0.922
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 0.0000e+00, 4.4273e-05, 1.8085e-07, 0.0000e+00, 7.4354e-03,
        9.9252e-01], device='cuda:0')
Policy pred: tensor([5.1190e-08, 5.8000e-06, 5.9331e-05, 5.8390e-05, 1.0317e-06, 1.0981e-02,
        9.8889e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9992817640304565
 
[Iteration 3] Process ID: 217646 [Epoch: 42,   544/ 2265 points] total loss per batch: 0.823
Policy (actual, predicted): 4 4
Policy data: tensor([0.3281, 0.0060, 0.0060, 0.0022, 0.6514, 0.0022, 0.0041],
       device='cuda:0')
Policy pred: tensor([0.2668, 0.0080, 0.0015, 0.0035, 0.6905, 0.0067, 0.0229],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9875379800796509
 
[Iteration 3] Process ID: 217646 [Epoch: 42,  1088/ 2265 points] total loss per batch: 0.851
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 3.3702e-08, 1.0000e+00, 9.0909e-29, 5.7639e-15, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.3205e-06, 9.9620e-04, 9.9792e-01, 1.8436e-05, 1.0581e-03, 6.3322e-08,
        1.3986e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999054670333862
 
[Iteration 3] Process ID: 217646 [Epoch: 42,  1632/ 2265 points] total loss per batch: 0.864
Policy (actual, predicted): 3 3
Policy data: tensor([0.0924, 0.1543, 0.0094, 0.7010, 0.0176, 0.0076, 0.0176],
       device='cuda:0')
Policy pred: tensor([0.1177, 0.2340, 0.0295, 0.5405, 0.0529, 0.0114, 0.0139],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998869895935059
 
[Iteration 3] Process ID: 217646 [Epoch: 42,  2176/ 2265 points] total loss per batch: 0.803
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 2.5143e-18, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0517e-17,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.6275e-12, 3.8453e-07, 9.4001e-09, 9.9991e-01, 1.3906e-05, 7.1395e-05,
        7.9461e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 43,   544/ 2265 points] total loss per batch: 0.824
Policy (actual, predicted): 0 0
Policy data: tensor([9.9999e-01, 2.5310e-10, 8.3452e-06, 6.2345e-10, 1.6294e-12, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9937e-01, 9.2521e-06, 6.8330e-06, 9.5284e-05, 4.9982e-04, 2.1744e-06,
        1.3612e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999992311000824
 
[Iteration 3] Process ID: 217646 [Epoch: 43,  1088/ 2265 points] total loss per batch: 0.795
Policy (actual, predicted): 6 6
Policy data: tensor([8.0968e-04, 1.3077e-14, 9.5412e-03, 2.7992e-15, 6.2324e-15, 2.7992e-15,
        9.8965e-01], device='cuda:0')
Policy pred: tensor([7.6158e-03, 1.2768e-03, 5.4436e-03, 5.5941e-04, 2.1379e-04, 1.2055e-03,
        9.8369e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9985544681549072
 
[Iteration 3] Process ID: 217646 [Epoch: 43,  1632/ 2265 points] total loss per batch: 0.818
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 3.5279e-16, 1.2789e-21, 2.1658e-26, 1.0000e+00, 2.0655e-22,
        2.0655e-22], device='cuda:0')
Policy pred: tensor([4.4520e-07, 2.0212e-04, 1.2275e-04, 8.3183e-07, 9.9964e-01, 6.3790e-06,
        2.9841e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9200922846794128
 
[Iteration 3] Process ID: 217646 [Epoch: 43,  2176/ 2265 points] total loss per batch: 0.880
Policy (actual, predicted): 1 1
Policy data: tensor([0.0092, 0.5111, 0.3729, 0.0092, 0.0428, 0.0075, 0.0471],
       device='cuda:0')
Policy pred: tensor([0.0225, 0.5086, 0.3282, 0.0154, 0.0401, 0.0180, 0.0670],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.0835244432091713
 
[Iteration 3] Process ID: 217646 [Epoch: 44,   544/ 2265 points] total loss per batch: 0.804
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 9.9999e-01, 1.2840e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.3781e-05, 1.0171e-05, 9.8930e-01, 9.3603e-03, 4.7277e-08, 3.7116e-05,
        1.2574e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999721646308899
 
[Iteration 3] Process ID: 217646 [Epoch: 44,  1088/ 2265 points] total loss per batch: 0.841
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 0.0000e+00, 1.1530e-09, 7.2927e-14, 0.0000e+00, 2.5873e-07,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9779e-01, 2.6479e-07, 2.0650e-04, 3.6188e-05, 1.0075e-07, 1.9592e-03,
        7.4635e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 217646 [Epoch: 44,  1632/ 2265 points] total loss per batch: 0.841
Policy (actual, predicted): 2 2
Policy data: tensor([0.0754, 0.0040, 0.6754, 0.0040, 0.1402, 0.0283, 0.0726],
       device='cuda:0')
Policy pred: tensor([0.0855, 0.0135, 0.5838, 0.0052, 0.1509, 0.0536, 0.1076],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9991344213485718
 
[Iteration 3] Process ID: 217646 [Epoch: 44,  2176/ 2265 points] total loss per batch: 0.825
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 4.2208e-03, 3.0258e-12, 2.0716e-21, 9.9578e-01, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([7.5673e-07, 2.2136e-03, 1.4605e-05, 5.3638e-05, 9.9769e-01, 8.9408e-06,
        1.3568e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999958872795105
 
[Iteration 3] Process ID: 217646 [Epoch: 45,   544/ 2265 points] total loss per batch: 0.766
Policy (actual, predicted): 0 0
Policy data: tensor([0.6968, 0.0379, 0.2347, 0.0041, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6273, 0.0601, 0.2024, 0.0244, 0.0285, 0.0294, 0.0279],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.03989092633128166
 
[Iteration 3] Process ID: 217646 [Epoch: 45,  1088/ 2265 points] total loss per batch: 0.828
Policy (actual, predicted): 6 6
Policy data: tensor([0.0240, 0.0144, 0.0128, 0.0128, 0.2750, 0.0077, 0.6534],
       device='cuda:0')
Policy pred: tensor([0.0313, 0.0140, 0.0146, 0.0200, 0.3057, 0.0075, 0.6070],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.7281663417816162
 
[Iteration 3] Process ID: 217646 [Epoch: 45,  1632/ 2265 points] total loss per batch: 0.827
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 6.1248e-07, 7.5410e-08, 5.4797e-21, 0.0000e+00, 1.0000e+00,
        5.6112e-18], device='cuda:0')
Policy pred: tensor([2.8515e-07, 1.0366e-07, 1.2481e-05, 3.4473e-08, 2.4837e-10, 9.9987e-01,
        1.1384e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999300479888916
 
[Iteration 3] Process ID: 217646 [Epoch: 45,  2176/ 2265 points] total loss per batch: 0.836
Policy (actual, predicted): 5 5
Policy data: tensor([0.0976, 0.0472, 0.0702, 0.0416, 0.0976, 0.5650, 0.0808],
       device='cuda:0')
Policy pred: tensor([0.1478, 0.1079, 0.1074, 0.0617, 0.0881, 0.3384, 0.1486],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999954104423523
 
[Iteration 3] Process ID: 217646 [Epoch: 46,   544/ 2265 points] total loss per batch: 0.783
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 9.9992e-01, 4.8701e-18, 2.2001e-05, 2.9859e-05,
        2.3768e-05], device='cuda:0')
Policy pred: tensor([1.5243e-08, 4.6153e-13, 9.9980e-01, 1.3765e-05, 1.5594e-04, 5.6545e-06,
        2.2909e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999984502792358
 
[Iteration 3] Process ID: 217646 [Epoch: 46,  1088/ 2265 points] total loss per batch: 0.852
Policy (actual, predicted): 0 0
Policy data: tensor([0.2673, 0.0786, 0.1640, 0.1570, 0.0972, 0.1119, 0.1239],
       device='cuda:0')
Policy pred: tensor([0.2108, 0.0866, 0.1742, 0.1451, 0.1136, 0.1498, 0.1200],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9993481636047363
 
[Iteration 3] Process ID: 217646 [Epoch: 46,  1632/ 2265 points] total loss per batch: 0.829
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 0.0000e+00, 5.1463e-20, 8.7152e-25, 1.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.9025e-08, 5.9115e-10, 6.3009e-03, 2.4658e-05, 9.9367e-01, 6.0481e-11,
        6.6333e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9993376731872559
 
[Iteration 3] Process ID: 217646 [Epoch: 46,  2176/ 2265 points] total loss per batch: 0.838
Policy (actual, predicted): 4 4
Policy data: tensor([0.0225, 0.0094, 0.0177, 0.0094, 0.6997, 0.0145, 0.2267],
       device='cuda:0')
Policy pred: tensor([0.0141, 0.0060, 0.0082, 0.0056, 0.7574, 0.0070, 0.2017],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.546771764755249
 
[Iteration 3] Process ID: 217646 [Epoch: 47,   544/ 2265 points] total loss per batch: 0.849
Policy (actual, predicted): 2 2
Policy data: tensor([0.0458, 0.0117, 0.9216, 0.0023, 0.0081, 0.0062, 0.0043],
       device='cuda:0')
Policy pred: tensor([0.0521, 0.0228, 0.8776, 0.0028, 0.0249, 0.0059, 0.0139],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999777615070343
 
[Iteration 3] Process ID: 217646 [Epoch: 47,  1088/ 2265 points] total loss per batch: 0.846
Policy (actual, predicted): 4 4
Policy data: tensor([0.0289, 0.0211, 0.0060, 0.0078, 0.7522, 0.0078, 0.1762],
       device='cuda:0')
Policy pred: tensor([0.0574, 0.0638, 0.0066, 0.0072, 0.7214, 0.0084, 0.1352],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.07130339741706848
 
[Iteration 3] Process ID: 217646 [Epoch: 47,  1632/ 2265 points] total loss per batch: 0.823
Policy (actual, predicted): 0 0
Policy data: tensor([0.8915, 0.0062, 0.0080, 0.0062, 0.0098, 0.0392, 0.0392],
       device='cuda:0')
Policy pred: tensor([0.9120, 0.0021, 0.0058, 0.0048, 0.0052, 0.0334, 0.0367],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.2954024374485016
 
[Iteration 3] Process ID: 217646 [Epoch: 47,  2176/ 2265 points] total loss per batch: 0.797
Policy (actual, predicted): 5 5
Policy data: tensor([0.0183, 0.0115, 0.0115, 0.0359, 0.0359, 0.8807, 0.0061],
       device='cuda:0')
Policy pred: tensor([0.0110, 0.0118, 0.0070, 0.0446, 0.0615, 0.8576, 0.0065],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9322168827056885
 
[Iteration 3] Process ID: 217646 [Epoch: 48,   544/ 2265 points] total loss per batch: 0.842
Policy (actual, predicted): 0 0
Policy data: tensor([0.7931, 0.0130, 0.0113, 0.0042, 0.0983, 0.0113, 0.0690],
       device='cuda:0')
Policy pred: tensor([0.4943, 0.0229, 0.0149, 0.0057, 0.0654, 0.0093, 0.3875],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9832382202148438
 
[Iteration 3] Process ID: 217646 [Epoch: 48,  1088/ 2265 points] total loss per batch: 0.807
Policy (actual, predicted): 4 4
Policy data: tensor([0.1975, 0.0060, 0.0291, 0.0022, 0.7496, 0.0078, 0.0078],
       device='cuda:0')
Policy pred: tensor([0.1411, 0.0071, 0.0440, 0.0065, 0.7802, 0.0051, 0.0161],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9450197815895081
 
[Iteration 3] Process ID: 217646 [Epoch: 48,  1632/ 2265 points] total loss per batch: 0.827
Policy (actual, predicted): 0 0
Policy data: tensor([0.6981, 0.0379, 0.2335, 0.0041, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6468, 0.0483, 0.2095, 0.0166, 0.0222, 0.0316, 0.0249],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.0013224269496276975
 
[Iteration 3] Process ID: 217646 [Epoch: 48,  2176/ 2265 points] total loss per batch: 0.810
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 9.1849e-25, 1.6310e-23, 0.0000e+00, 1.6310e-23,
        1.5190e-22], device='cuda:0')
Policy pred: tensor([7.2811e-12, 9.9948e-01, 3.4065e-06, 2.0676e-06, 1.5803e-11, 4.8527e-04,
        2.7593e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999722242355347
 
[Iteration 3] Process ID: 217646 [Epoch: 49,   544/ 2265 points] total loss per batch: 0.832
Policy (actual, predicted): 4 4
Policy data: tensor([2.8165e-07, 9.5095e-20, 2.4665e-09, 9.5095e-20, 1.0000e+00, 4.0792e-17,
        1.9171e-07], device='cuda:0')
Policy pred: tensor([3.5274e-03, 1.1803e-05, 4.9825e-04, 3.5584e-07, 9.9588e-01, 6.3699e-06,
        7.7295e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999986469745636
 
[Iteration 3] Process ID: 217646 [Epoch: 49,  1088/ 2265 points] total loss per batch: 0.812
Policy (actual, predicted): 4 4
Policy data: tensor([0.0818, 0.0422, 0.0805, 0.0492, 0.6271, 0.0321, 0.0871],
       device='cuda:0')
Policy pred: tensor([0.0616, 0.0662, 0.0816, 0.0412, 0.6218, 0.0396, 0.0881],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.6081935167312622
 
[Iteration 3] Process ID: 217646 [Epoch: 49,  1632/ 2265 points] total loss per batch: 0.814
Policy (actual, predicted): 3 3
Policy data: tensor([0.0729, 0.1156, 0.0729, 0.3226, 0.1056, 0.0368, 0.2738],
       device='cuda:0')
Policy pred: tensor([0.0806, 0.1099, 0.0636, 0.3514, 0.1052, 0.0221, 0.2672],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 217646 [Epoch: 49,  2176/ 2265 points] total loss per batch: 0.829
Policy (actual, predicted): 4 4
Policy data: tensor([0.1241, 0.0327, 0.0965, 0.0453, 0.4092, 0.0256, 0.2666],
       device='cuda:0')
Policy pred: tensor([0.1806, 0.0338, 0.1106, 0.0366, 0.3293, 0.0252, 0.2838],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9456630945205688
 
[Iteration 3] Process ID: 217646 [Epoch: 50,   544/ 2265 points] total loss per batch: 0.823
Policy (actual, predicted): 1 0
Policy data: tensor([0.1501, 0.1512, 0.1466, 0.1277, 0.1454, 0.1372, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1838, 0.1346, 0.1506, 0.1473, 0.1320, 0.1165, 0.1352],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999042809009552
 
[Iteration 3] Process ID: 217646 [Epoch: 50,  1088/ 2265 points] total loss per batch: 0.860
Policy (actual, predicted): 6 6
Policy data: tensor([0.0062, 0.0184, 0.0098, 0.0116, 0.0409, 0.0080, 0.9050],
       device='cuda:0')
Policy pred: tensor([0.0056, 0.0155, 0.0118, 0.0105, 0.0449, 0.0078, 0.9040],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.11980905383825302
 
[Iteration 3] Process ID: 217646 [Epoch: 50,  1632/ 2265 points] total loss per batch: 0.803
Policy (actual, predicted): 4 4
Policy data: tensor([0.0281, 0.0265, 0.0166, 0.0150, 0.8873, 0.0132, 0.0132],
       device='cuda:0')
Policy pred: tensor([0.0346, 0.0175, 0.0077, 0.0068, 0.9075, 0.0153, 0.0106],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9604156017303467
 
[Iteration 3] Process ID: 217646 [Epoch: 50,  2176/ 2265 points] total loss per batch: 0.761
Policy (actual, predicted): 6 6
Policy data: tensor([1.8927e-19, 1.3169e-12, 3.1302e-17, 3.1068e-03, 6.3105e-15, 3.4417e-15,
        9.9689e-01], device='cuda:0')
Policy pred: tensor([0.0017, 0.0016, 0.0010, 0.0016, 0.0055, 0.0015, 0.9871],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999989867210388
 
[Iteration 3] Process ID: 217646 [Epoch: 51,   544/ 2265 points] total loss per batch: 0.776
Policy (actual, predicted): 3 4
Policy data: tensor([0.1430, 0.1465, 0.1407, 0.1500, 0.1430, 0.1336, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1397, 0.1272, 0.1511, 0.1395, 0.1873, 0.1377, 0.1175],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998359084129333
 
[Iteration 3] Process ID: 217646 [Epoch: 51,  1088/ 2265 points] total loss per batch: 0.812
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 1.9368e-25, 1.9368e-25, 1.8914e-28, 1.0201e-06, 1.9368e-25,
        5.6023e-14], device='cuda:0')
Policy pred: tensor([9.8661e-01, 7.2025e-05, 1.0362e-02, 5.7593e-06, 2.2734e-03, 9.4034e-05,
        5.8620e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9989815354347229
 
[Iteration 3] Process ID: 217646 [Epoch: 51,  1632/ 2265 points] total loss per batch: 0.782
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 5.1273e-19, 2.0242e-26, 2.0242e-26, 1.1673e-24, 2.0242e-26,
        5.7180e-18], device='cuda:0')
Policy pred: tensor([1.0000e+00, 5.4925e-10, 9.4992e-10, 1.7390e-10, 3.7863e-06, 2.1510e-10,
        3.4042e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9996805787086487
 
[Iteration 3] Process ID: 217646 [Epoch: 51,  2176/ 2265 points] total loss per batch: 0.848
Policy (actual, predicted): 2 3
Policy data: tensor([0.1419, 0.1477, 0.1489, 0.1442, 0.1336, 0.1372, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1215, 0.1226, 0.1243, 0.1957, 0.1317, 0.1400, 0.1642],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9993798136711121
 
[Iteration 3] Process ID: 217646 [Epoch: 52,   544/ 2265 points] total loss per batch: 0.761
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 5.6639e-12, 2.1892e-10, 2.8095e-24, 9.9840e-01, 1.5999e-03,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([5.5879e-08, 6.3774e-05, 5.8123e-03, 1.4370e-05, 9.9329e-01, 6.9224e-04,
        1.2284e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999985694885254
 
[Iteration 3] Process ID: 217646 [Epoch: 52,  1088/ 2265 points] total loss per batch: 0.792
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 0.0000e+00, 9.9571e-16, 5.1682e-18, 3.8389e-16, 3.5753e-15,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([6.2027e-06, 1.0927e-07, 5.6339e-06, 1.5393e-06, 3.5998e-05, 3.6193e-03,
        9.9633e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 3] Process ID: 217646 [Epoch: 52,  1632/ 2265 points] total loss per batch: 0.811
Policy (actual, predicted): 1 1
Policy data: tensor([2.5143e-18, 1.0000e+00, 5.1519e-21, 1.8238e-29, 1.8238e-29, 1.7811e-22,
        1.8238e-29], device='cuda:0')
Policy pred: tensor([2.2993e-03, 9.9601e-01, 4.3358e-04, 4.0094e-05, 3.6205e-04, 4.6602e-04,
        3.8777e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998211860657
 
[Iteration 3] Process ID: 217646 [Epoch: 52,  2176/ 2265 points] total loss per batch: 0.818
Policy (actual, predicted): 2 1
Policy data: tensor([0.1419, 0.1477, 0.1489, 0.1442, 0.1336, 0.1372, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1068, 0.1816, 0.1455, 0.1246, 0.1737, 0.1155, 0.1523],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9977594017982483
 
[Iteration 3] Process ID: 217646 [Epoch: 53,   544/ 2265 points] total loss per batch: 0.789
Policy (actual, predicted): 0 0
Policy data: tensor([0.6993, 0.0379, 0.2323, 0.0041, 0.0041, 0.0129, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.5973, 0.0626, 0.2505, 0.0176, 0.0208, 0.0274, 0.0238],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.016846003010869026
 
[Iteration 3] Process ID: 217646 [Epoch: 53,  1088/ 2265 points] total loss per batch: 0.771
Policy (actual, predicted): 6 6
Policy data: tensor([1.2833e-14, 4.3714e-13, 3.2459e-16, 2.6296e-17, 5.2423e-17, 3.8246e-14,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([4.7772e-06, 4.1446e-05, 7.8755e-07, 1.8958e-05, 8.6289e-06, 7.4563e-05,
        9.9985e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.996888279914856
 
[Iteration 3] Process ID: 217646 [Epoch: 53,  1632/ 2265 points] total loss per batch: 0.794
Policy (actual, predicted): 1 1
Policy data: tensor([0.0092, 0.5124, 0.3730, 0.0092, 0.0414, 0.0075, 0.0471],
       device='cuda:0')
Policy pred: tensor([0.0057, 0.5380, 0.3845, 0.0084, 0.0216, 0.0054, 0.0364],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.0831681415438652
 
[Iteration 3] Process ID: 217646 [Epoch: 53,  2176/ 2265 points] total loss per batch: 0.811
Policy (actual, predicted): 4 4
Policy data: tensor([0.0457, 0.0415, 0.0580, 0.0727, 0.5502, 0.1316, 0.1001],
       device='cuda:0')
Policy pred: tensor([0.0530, 0.0458, 0.0660, 0.0840, 0.5167, 0.1404, 0.0941],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.7778333425521851
 
[Iteration 3] Process ID: 217646 [Epoch: 54,   544/ 2265 points] total loss per batch: 0.787
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 5.7969e-09, 2.0924e-12, 0.0000e+00, 9.4550e-22,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([6.1752e-09, 9.9888e-01, 8.9845e-04, 7.6983e-05, 1.5640e-08, 1.2060e-04,
        2.2879e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999354481697083
 
[Iteration 3] Process ID: 217646 [Epoch: 54,  1088/ 2265 points] total loss per batch: 0.816
Policy (actual, predicted): 6 6
Policy data: tensor([1.5208e-03, 6.5189e-16, 1.0528e-16, 6.2169e-22, 0.0000e+00, 5.3086e-05,
        9.9843e-01], device='cuda:0')
Policy pred: tensor([7.1662e-04, 5.3220e-06, 6.1714e-04, 2.2142e-06, 7.0063e-05, 8.5918e-04,
        9.9773e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999488353729248
 
[Iteration 3] Process ID: 217646 [Epoch: 54,  1632/ 2265 points] total loss per batch: 0.800
Policy (actual, predicted): 1 1
Policy data: tensor([1.8184e-16, 1.0000e+00, 5.0929e-19, 3.0073e-24, 1.0514e-13, 3.0795e-21,
        3.0073e-14], device='cuda:0')
Policy pred: tensor([2.0525e-06, 9.9962e-01, 1.9263e-06, 7.6788e-09, 1.5661e-05, 2.0590e-04,
        1.5452e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999751627445221
 
[Iteration 3] Process ID: 217646 [Epoch: 54,  2176/ 2265 points] total loss per batch: 0.816
Policy (actual, predicted): 4 4
Policy data: tensor([6.0353e-19, 1.4070e-21, 3.2078e-18, 1.3740e-24, 1.0000e+00, 1.4070e-21,
        6.5728e-21], device='cuda:0')
Policy pred: tensor([2.5968e-03, 8.9829e-04, 6.2428e-04, 2.2898e-04, 9.9016e-01, 2.3771e-03,
        3.1162e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998906850814819
 
[Iteration 3] Process ID: 217646 [Epoch: 55,   544/ 2265 points] total loss per batch: 0.810
Policy (actual, predicted): 4 4
Policy data: tensor([0.0305, 0.0351, 0.0146, 0.0179, 0.8029, 0.0146, 0.0843],
       device='cuda:0')
Policy pred: tensor([0.0319, 0.0330, 0.0257, 0.0122, 0.8342, 0.0125, 0.0505],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9703305959701538
 
[Iteration 3] Process ID: 217646 [Epoch: 55,  1088/ 2265 points] total loss per batch: 0.796
Policy (actual, predicted): 0 0
Policy data: tensor([0.6687, 0.0664, 0.1092, 0.0295, 0.0412, 0.0526, 0.0324],
       device='cuda:0')
Policy pred: tensor([0.7032, 0.0570, 0.0896, 0.0314, 0.0275, 0.0552, 0.0362],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9980324506759644
 
[Iteration 3] Process ID: 217646 [Epoch: 55,  1632/ 2265 points] total loss per batch: 0.747
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000, 0.0564, 0.2144, 0.0632, 0.6660, 0.0000, 0.0000],
       device='cuda:0')
Policy pred: tensor([3.7925e-04, 8.7008e-02, 1.5825e-01, 4.2774e-02, 7.1154e-01, 6.1325e-06,
        3.8599e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 55,  2176/ 2265 points] total loss per batch: 0.814
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000, 0.3818, 0.0441, 0.3392, 0.0833, 0.1516, 0.0000],
       device='cuda:0')
Policy pred: tensor([4.1644e-05, 3.6008e-01, 3.8570e-02, 3.5489e-01, 7.4298e-02, 1.7203e-01,
        1.0393e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999550580978394
 
[Iteration 3] Process ID: 217646 [Epoch: 56,   544/ 2265 points] total loss per batch: 0.774
Policy (actual, predicted): 4 4
Policy data: tensor([0.1477, 0.1407, 0.1501, 0.1289, 0.1605, 0.1266, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1367, 0.1239, 0.1530, 0.1243, 0.2036, 0.1143, 0.1441],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999995827674866
 
[Iteration 3] Process ID: 217646 [Epoch: 56,  1088/ 2265 points] total loss per batch: 0.810
Policy (actual, predicted): 3 3
Policy data: tensor([1.7573e-14, 0.0000e+00, 1.2964e-21, 1.0000e+00, 0.0000e+00, 1.2660e-24,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.3667e-05, 4.8205e-09, 1.9462e-06, 9.9997e-01, 4.0248e-11, 6.1890e-08,
        4.6030e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999935626983643
 
[Iteration 3] Process ID: 217646 [Epoch: 56,  1632/ 2265 points] total loss per batch: 0.857
Policy (actual, predicted): 5 5
Policy data: tensor([5.5850e-08, 1.6543e-03, 1.7949e-09, 4.7137e-03, 1.8072e-10, 9.9363e-01,
        4.5518e-10], device='cuda:0')
Policy pred: tensor([5.4262e-04, 2.6033e-03, 2.9237e-04, 1.7283e-03, 2.4756e-04, 9.9421e-01,
        3.7367e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999982714653015
 
[Iteration 3] Process ID: 217646 [Epoch: 56,  2176/ 2265 points] total loss per batch: 0.742
Policy (actual, predicted): 6 6
Policy data: tensor([7.6505e-11, 3.8265e-07, 4.4117e-09, 2.8150e-12, 2.0665e-02, 3.5741e-09,
        9.7933e-01], device='cuda:0')
Policy pred: tensor([1.6760e-04, 2.6220e-06, 2.3545e-07, 6.7231e-05, 7.3798e-03, 4.0985e-06,
        9.9238e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999991059303284
 
[Iteration 3] Process ID: 217646 [Epoch: 57,   544/ 2265 points] total loss per batch: 0.777
Policy (actual, predicted): 0 0
Policy data: tensor([9.8535e-01, 3.7990e-21, 2.7067e-11, 1.7498e-09, 6.5880e-23, 4.2353e-04,
        1.4223e-02], device='cuda:0')
Policy pred: tensor([9.8421e-01, 1.3049e-05, 2.6688e-08, 8.0649e-06, 1.6176e-07, 4.9253e-03,
        1.0845e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 3] Process ID: 217646 [Epoch: 57,  1088/ 2265 points] total loss per batch: 0.793
Policy (actual, predicted): 5 5
Policy data: tensor([0.0928, 0.0179, 0.0243, 0.0022, 0.0516, 0.7982, 0.0130],
       device='cuda:0')
Policy pred: tensor([1.5074e-02, 2.5597e-03, 3.7747e-03, 1.7685e-04, 1.4016e-02, 9.5894e-01,
        5.4606e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998819231987
 
[Iteration 3] Process ID: 217646 [Epoch: 57,  1632/ 2265 points] total loss per batch: 0.815
Policy (actual, predicted): 4 4
Policy data: tensor([0.0149, 0.0115, 0.0079, 0.0097, 0.8568, 0.0061, 0.0930],
       device='cuda:0')
Policy pred: tensor([0.0146, 0.0142, 0.0045, 0.0100, 0.8659, 0.0049, 0.0859],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.34501442313194275
 
[Iteration 3] Process ID: 217646 [Epoch: 57,  2176/ 2265 points] total loss per batch: 0.809
Policy (actual, predicted): 1 1
Policy data: tensor([0.0022, 0.5259, 0.0077, 0.0022, 0.4538, 0.0060, 0.0022],
       device='cuda:0')
Policy pred: tensor([0.0033, 0.5226, 0.0203, 0.0047, 0.4328, 0.0064, 0.0099],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.998099148273468
 
[Iteration 3] Process ID: 217646 [Epoch: 58,   544/ 2265 points] total loss per batch: 0.714
Policy (actual, predicted): 4 4
Policy data: tensor([1.6879e-12, 7.3307e-14, 1.2537e-20, 1.2537e-20, 9.9856e-01, 1.5258e-05,
        1.4209e-03], device='cuda:0')
Policy pred: tensor([2.1674e-03, 4.1305e-04, 3.7235e-04, 1.9157e-04, 9.9559e-01, 3.1913e-04,
        9.4935e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998155832290649
 
[Iteration 3] Process ID: 217646 [Epoch: 58,  1088/ 2265 points] total loss per batch: 0.895
Policy (actual, predicted): 6 6
Policy data: tensor([5.3287e-09, 4.0652e-22, 6.0154e-09, 7.8158e-16, 3.9699e-25, 1.8642e-12,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([2.9638e-03, 1.9147e-06, 1.4969e-06, 7.9650e-05, 2.8945e-07, 3.6611e-04,
        9.9659e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999316930770874
 
[Iteration 3] Process ID: 217646 [Epoch: 58,  1632/ 2265 points] total loss per batch: 0.793
Policy (actual, predicted): 5 5
Policy data: tensor([8.9969e-09, 7.8944e-09, 2.6538e-11, 3.4687e-19, 7.5287e-15, 1.0000e+00,
        1.2095e-09], device='cuda:0')
Policy pred: tensor([2.6760e-04, 1.6754e-03, 3.2226e-03, 1.0364e-04, 1.0414e-04, 9.9400e-01,
        6.2572e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998606443405151
 
[Iteration 3] Process ID: 217646 [Epoch: 58,  2176/ 2265 points] total loss per batch: 0.779
Policy (actual, predicted): 4 4
Policy data: tensor([0.0225, 0.0094, 0.0177, 0.0094, 0.6997, 0.0145, 0.2267],
       device='cuda:0')
Policy pred: tensor([0.0213, 0.0096, 0.0195, 0.0104, 0.6923, 0.0170, 0.2300],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.5201694965362549
 
[Iteration 3] Process ID: 217646 [Epoch: 59,   544/ 2265 points] total loss per batch: 0.828
Policy (actual, predicted): 1 1
Policy data: tensor([3.1691e-16, 1.0000e+00, 5.1689e-19, 3.0522e-24, 1.0671e-13, 3.1255e-21,
        3.0522e-14], device='cuda:0')
Policy pred: tensor([9.6242e-06, 9.9957e-01, 8.5603e-06, 2.1985e-08, 2.7533e-05, 1.0228e-04,
        2.8550e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998615384101868
 
[Iteration 3] Process ID: 217646 [Epoch: 59,  1088/ 2265 points] total loss per batch: 0.799
Policy (actual, predicted): 1 6
Policy data: tensor([0.2073, 0.2587, 0.0449, 0.0955, 0.0000, 0.1531, 0.2404],
       device='cuda:0')
Policy pred: tensor([1.8623e-01, 2.1704e-01, 4.7135e-02, 9.4823e-02, 2.4610e-04, 1.6481e-01,
        2.8972e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999982118606567
 
[Iteration 3] Process ID: 217646 [Epoch: 59,  1632/ 2265 points] total loss per batch: 0.753
Policy (actual, predicted): 4 4
Policy data: tensor([0.0169, 0.0081, 0.0099, 0.0043, 0.9326, 0.0062, 0.0220],
       device='cuda:0')
Policy pred: tensor([0.0142, 0.0058, 0.0089, 0.0039, 0.9423, 0.0059, 0.0190],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.5502808094024658
 
[Iteration 3] Process ID: 217646 [Epoch: 59,  2176/ 2265 points] total loss per batch: 0.811
Policy (actual, predicted): 6 6
Policy data: tensor([0.0116, 0.0062, 0.0579, 0.0023, 0.0023, 0.0099, 0.9099],
       device='cuda:0')
Policy pred: tensor([0.0154, 0.0135, 0.0431, 0.0012, 0.0018, 0.0077, 0.9173],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9516463875770569
 
[Iteration 3] Process ID: 217646 [Epoch: 60,   544/ 2265 points] total loss per batch: 0.823
Policy (actual, predicted): 1 1
Policy data: tensor([5.7937e-20, 1.0000e+00, 1.6616e-29, 1.7423e-23, 1.7015e-26, 1.6616e-29,
        1.7423e-23], device='cuda:0')
Policy pred: tensor([5.8693e-08, 9.9989e-01, 9.6821e-08, 5.2466e-07, 8.6797e-05, 9.8764e-06,
        1.3450e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999280571937561
 
[Iteration 3] Process ID: 217646 [Epoch: 60,  1088/ 2265 points] total loss per batch: 0.821
Policy (actual, predicted): 6 6
Policy data: tensor([0.0238, 0.0374, 0.0284, 0.0605, 0.0159, 0.1096, 0.7244],
       device='cuda:0')
Policy pred: tensor([0.0404, 0.0502, 0.0440, 0.0642, 0.0336, 0.1070, 0.6605],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.15231092274188995
 
[Iteration 3] Process ID: 217646 [Epoch: 60,  1632/ 2265 points] total loss per batch: 0.766
Policy (actual, predicted): 3 6
Policy data: tensor([0.1176, 0.1539, 0.0501, 0.2581, 0.1287, 0.0738, 0.2179],
       device='cuda:0')
Policy pred: tensor([0.1030, 0.1479, 0.0610, 0.2338, 0.1271, 0.0710, 0.2562],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998841881752014
 
[Iteration 3] Process ID: 217646 [Epoch: 60,  2176/ 2265 points] total loss per batch: 0.797
Policy (actual, predicted): 0 0
Policy data: tensor([0.2993, 0.1154, 0.1382, 0.0364, 0.1154, 0.1154, 0.1800],
       device='cuda:0')
Policy pred: tensor([0.2962, 0.1060, 0.1232, 0.0353, 0.1230, 0.1310, 0.1852],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 217646 [Epoch: 61,   544/ 2265 points] total loss per batch: 0.775
Policy (actual, predicted): 6 6
Policy data: tensor([6.5292e-16, 1.1167e-22, 1.7763e-15, 1.9412e-10, 0.0000e+00, 6.6859e-13,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([4.6917e-07, 5.8690e-06, 1.9347e-05, 2.4115e-07, 7.3408e-12, 6.1897e-05,
        9.9991e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9985879063606262
 
[Iteration 3] Process ID: 217646 [Epoch: 61,  1088/ 2265 points] total loss per batch: 0.727
Policy (actual, predicted): 6 4
Policy data: tensor([0.1419, 0.1489, 0.1395, 0.1419, 0.1383, 0.1383, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1522, 0.1448, 0.1196, 0.1332, 0.1622, 0.1298, 0.1582],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.998627245426178
 
[Iteration 3] Process ID: 217646 [Epoch: 61,  1632/ 2265 points] total loss per batch: 0.859
Policy (actual, predicted): 4 4
Policy data: tensor([0.0100, 0.0100, 0.0082, 0.0043, 0.9531, 0.0082, 0.0063],
       device='cuda:0')
Policy pred: tensor([0.0042, 0.0046, 0.0047, 0.0051, 0.9665, 0.0061, 0.0088],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9876871705055237
 
[Iteration 3] Process ID: 217646 [Epoch: 61,  2176/ 2265 points] total loss per batch: 0.812
Policy (actual, predicted): 5 5
Policy data: tensor([4.6937e-21, 1.7015e-26, 1.6227e-22, 1.7015e-26, 1.6227e-22, 1.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([6.7025e-04, 9.6989e-06, 2.5719e-04, 8.0654e-07, 1.2759e-04, 9.9893e-01,
        2.9868e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 3] Process ID: 217646 [Epoch: 62,   544/ 2265 points] total loss per batch: 0.809
Policy (actual, predicted): 3 3
Policy data: tensor([0.1193, 0.2030, 0.0681, 0.2849, 0.1429, 0.0824, 0.0993],
       device='cuda:0')
Policy pred: tensor([0.1260, 0.2143, 0.0598, 0.2419, 0.1787, 0.0776, 0.1018],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999998927116394
 
[Iteration 3] Process ID: 217646 [Epoch: 62,  1088/ 2265 points] total loss per batch: 0.831
Policy (actual, predicted): 2 2
Policy data: tensor([5.0945e-18, 4.1608e-14, 1.0000e+00, 1.3195e-16, 0.0000e+00, 4.0632e-17,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9629e-07, 8.3575e-06, 9.9997e-01, 2.4027e-08, 2.4346e-10, 2.4778e-05,
        6.3987e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9997914433479309
 
[Iteration 3] Process ID: 217646 [Epoch: 62,  1632/ 2265 points] total loss per batch: 0.764
Policy (actual, predicted): 5 5
Policy data: tensor([0.0044, 0.0044, 0.0044, 0.0118, 0.0063, 0.9644, 0.0044],
       device='cuda:0')
Policy pred: tensor([0.0046, 0.0026, 0.0053, 0.0116, 0.0011, 0.9737, 0.0011],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999932050704956
 
[Iteration 3] Process ID: 217646 [Epoch: 62,  2176/ 2265 points] total loss per batch: 0.796
Policy (actual, predicted): 0 0
Policy data: tensor([9.8535e-01, 3.7990e-21, 2.7067e-11, 1.7498e-09, 6.5880e-23, 4.2353e-04,
        1.4223e-02], device='cuda:0')
Policy pred: tensor([9.5790e-01, 4.1320e-06, 1.3202e-09, 6.1007e-06, 8.8863e-08, 8.6501e-03,
        3.3443e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999983310699463
 
[Iteration 3] Process ID: 217646 [Epoch: 63,   544/ 2265 points] total loss per batch: 0.840
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 1.0000e+00, 8.5814e-22, 8.3803e-25, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.7943e-06, 2.1167e-10, 9.9977e-01, 3.0419e-05, 1.7680e-04, 2.9990e-08,
        2.3773e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999993443489075
 
[Iteration 3] Process ID: 217646 [Epoch: 63,  1088/ 2265 points] total loss per batch: 0.772
Policy (actual, predicted): 2 2
Policy data: tensor([0.0530, 0.0652, 0.5749, 0.0598, 0.0376, 0.0447, 0.1649],
       device='cuda:0')
Policy pred: tensor([0.0733, 0.0750, 0.5170, 0.0681, 0.0469, 0.0480, 0.1718],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9976911544799805
 
[Iteration 3] Process ID: 217646 [Epoch: 63,  1632/ 2265 points] total loss per batch: 0.731
Policy (actual, predicted): 6 6
Policy data: tensor([0.0232, 0.0132, 0.0389, 0.0042, 0.0405, 0.0079, 0.8720],
       device='cuda:0')
Policy pred: tensor([0.0418, 0.0219, 0.0405, 0.0067, 0.0478, 0.0116, 0.8296],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9968701601028442
 
[Iteration 3] Process ID: 217646 [Epoch: 63,  2176/ 2265 points] total loss per batch: 0.827
Policy (actual, predicted): 1 4
Policy data: tensor([0.4448, 0.4653, 0.0267, 0.0109, 0.0142, 0.0190, 0.0190],
       device='cuda:0')
Policy pred: tensor([0.0375, 0.0309, 0.0065, 0.0081, 0.7350, 0.0086, 0.1734],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.04268438369035721
 
[Iteration 3] Process ID: 217646 [Epoch: 64,   544/ 2265 points] total loss per batch: 0.807
Policy (actual, predicted): 4 4
Policy data: tensor([0.0523, 0.0079, 0.0231, 0.0022, 0.8545, 0.0182, 0.0418],
       device='cuda:0')
Policy pred: tensor([0.0557, 0.0141, 0.0289, 0.0055, 0.8153, 0.0238, 0.0567],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.992832362651825
 
[Iteration 3] Process ID: 217646 [Epoch: 64,  1088/ 2265 points] total loss per batch: 0.817
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 5.8745e-07, 5.4710e-17, 1.0000e+00, 0.0000e+00, 7.9572e-14,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.6975e-11, 4.7135e-06, 8.7799e-06, 9.9982e-01, 2.4492e-07, 1.7075e-04,
        5.6148e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999983310699463
 
[Iteration 3] Process ID: 217646 [Epoch: 64,  1632/ 2265 points] total loss per batch: 0.766
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000, 0.1705, 0.2630, 0.0242, 0.4474, 0.0948, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.0094e-04, 1.5585e-01, 3.0252e-01, 1.9426e-02, 4.4685e-01, 7.5222e-02,
        2.7627e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999431371688843
 
[Iteration 3] Process ID: 217646 [Epoch: 64,  2176/ 2265 points] total loss per batch: 0.802
Policy (actual, predicted): 0 0
Policy data: tensor([0.6072, 0.0869, 0.2897, 0.0022, 0.0041, 0.0041, 0.0059],
       device='cuda:0')
Policy pred: tensor([0.6313, 0.0533, 0.2957, 0.0023, 0.0076, 0.0039, 0.0060],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9992372989654541
 
[Iteration 3] Process ID: 217646 [Epoch: 65,   544/ 2265 points] total loss per batch: 0.807
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 5.2097e-12, 0.0000e+00, 1.2450e-09,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([7.1118e-10, 9.9901e-01, 3.2847e-08, 5.9790e-07, 3.3021e-09, 9.8488e-04,
        4.1814e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 65,  1088/ 2265 points] total loss per batch: 0.809
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 3.3702e-08, 1.0000e+00, 9.0909e-29, 5.7639e-15, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([5.3723e-06, 2.2486e-03, 9.9764e-01, 4.3107e-06, 4.0320e-05, 6.7947e-07,
        6.3031e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998106360435486
 
[Iteration 3] Process ID: 217646 [Epoch: 65,  1632/ 2265 points] total loss per batch: 0.832
Policy (actual, predicted): 0 0
Policy data: tensor([7.3424e-01, 0.0000e+00, 2.7464e-21, 2.7464e-21, 0.0000e+00, 2.6563e-01,
        1.3454e-04], device='cuda:0')
Policy pred: tensor([6.8018e-01, 3.7539e-04, 1.3256e-03, 1.1924e-03, 1.8934e-05, 3.1358e-01,
        3.3317e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999881386756897
 
[Iteration 3] Process ID: 217646 [Epoch: 65,  2176/ 2265 points] total loss per batch: 0.756
Policy (actual, predicted): 6 6
Policy data: tensor([0.1630, 0.1369, 0.0392, 0.0201, 0.0091, 0.0722, 0.5596],
       device='cuda:0')
Policy pred: tensor([0.1549, 0.1377, 0.0478, 0.0216, 0.0138, 0.0613, 0.5629],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9986335039138794
 
[Iteration 3] Process ID: 217646 [Epoch: 66,   544/ 2265 points] total loss per batch: 0.779
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 0.0000e+00, 3.9247e-12, 3.2969e-19, 0.0000e+00, 3.2969e-19,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9936e-01, 2.8652e-06, 5.5410e-07, 1.3845e-07, 3.9321e-09, 6.1989e-04,
        1.4938e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 66,  1088/ 2265 points] total loss per batch: 0.850
Policy (actual, predicted): 4 0
Policy data: tensor([0.1454, 0.1501, 0.1489, 0.1301, 0.1524, 0.1336, 0.1395],
       device='cuda:0')
Policy pred: tensor([0.5121, 0.1040, 0.2501, 0.0297, 0.0292, 0.0409, 0.0340],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.015325779095292091
 
[Iteration 3] Process ID: 217646 [Epoch: 66,  1632/ 2265 points] total loss per batch: 0.746
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 2.8008e-13, 2.4708e-12, 3.6929e-15, 1.0000e+00, 3.4393e-24,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.2127e-06, 3.3238e-04, 1.0130e-05, 1.2884e-06, 9.9965e-01, 1.4358e-07,
        1.9326e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 66,  2176/ 2265 points] total loss per batch: 0.813
Policy (actual, predicted): 6 6
Policy data: tensor([0.0240, 0.0144, 0.0128, 0.0128, 0.2738, 0.0077, 0.6546],
       device='cuda:0')
Policy pred: tensor([0.0169, 0.0117, 0.0120, 0.0096, 0.2785, 0.0049, 0.6664],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.6685812473297119
 
[Iteration 3] Process ID: 217646 [Epoch: 67,   544/ 2265 points] total loss per batch: 0.809
Policy (actual, predicted): 4 4
Policy data: tensor([0.0642, 0.0357, 0.0312, 0.0174, 0.6840, 0.0236, 0.1438],
       device='cuda:0')
Policy pred: tensor([0.0691, 0.0276, 0.0270, 0.0099, 0.7229, 0.0135, 0.1301],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9991968274116516
 
[Iteration 3] Process ID: 217646 [Epoch: 67,  1088/ 2265 points] total loss per batch: 0.752
Policy (actual, predicted): 6 6
Policy data: tensor([1.2258e-01, 1.1500e-19, 7.0865e-03, 1.0967e-25, 2.2110e-13, 0.0000e+00,
        8.7033e-01], device='cuda:0')
Policy pred: tensor([1.6375e-01, 1.4847e-03, 7.4271e-03, 9.3841e-05, 4.6399e-04, 1.0707e-03,
        8.2571e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.994864284992218
 
[Iteration 3] Process ID: 217646 [Epoch: 67,  1632/ 2265 points] total loss per batch: 0.786
Policy (actual, predicted): 1 1
Policy data: tensor([2.2528e-05, 9.9997e-01, 4.1396e-16, 1.7731e-22, 1.0721e-14, 8.4821e-19,
        4.8224e-06], device='cuda:0')
Policy pred: tensor([7.9264e-04, 9.9692e-01, 3.9104e-04, 1.1322e-06, 4.6667e-05, 2.0663e-05,
        1.8232e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 3] Process ID: 217646 [Epoch: 67,  2176/ 2265 points] total loss per batch: 0.836
Policy (actual, predicted): 4 4
Policy data: tensor([0.0653, 0.0375, 0.2246, 0.1202, 0.2932, 0.1031, 0.1561],
       device='cuda:0')
Policy pred: tensor([0.0809, 0.0414, 0.2014, 0.1452, 0.3102, 0.0879, 0.1331],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9961423277854919
 
[Iteration 3] Process ID: 217646 [Epoch: 68,   544/ 2265 points] total loss per batch: 0.802
Policy (actual, predicted): 5 5
Policy data: tensor([0.1126, 0.0205, 0.0806, 0.0158, 0.0058, 0.6746, 0.0900],
       device='cuda:0')
Policy pred: tensor([0.0800, 0.0081, 0.0490, 0.0136, 0.0031, 0.7712, 0.0750],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9841060042381287
 
[Iteration 3] Process ID: 217646 [Epoch: 68,  1088/ 2265 points] total loss per batch: 0.783
Policy (actual, predicted): 4 4
Policy data: tensor([0.1075, 0.0252, 0.1491, 0.0058, 0.6659, 0.0093, 0.0372],
       device='cuda:0')
Policy pred: tensor([0.0706, 0.0373, 0.0838, 0.0058, 0.7455, 0.0210, 0.0359],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9677457213401794
 
[Iteration 3] Process ID: 217646 [Epoch: 68,  1632/ 2265 points] total loss per batch: 0.788
Policy (actual, predicted): 4 4
Policy data: tensor([0.1283, 0.0486, 0.0837, 0.0566, 0.3217, 0.2737, 0.0875],
       device='cuda:0')
Policy pred: tensor([0.1172, 0.0445, 0.0984, 0.0596, 0.3001, 0.2751, 0.1052],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9375081062316895
 
[Iteration 3] Process ID: 217646 [Epoch: 68,  2176/ 2265 points] total loss per batch: 0.830
Policy (actual, predicted): 4 0
Policy data: tensor([0.1512, 0.1454, 0.1477, 0.1289, 0.1524, 0.1360, 0.1384],
       device='cuda:0')
Policy pred: tensor([0.5987, 0.0698, 0.2122, 0.0248, 0.0296, 0.0328, 0.0322],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.013725942000746727
 
[Iteration 3] Process ID: 217646 [Epoch: 69,   544/ 2265 points] total loss per batch: 0.764
Policy (actual, predicted): 0 0
Policy data: tensor([0.8625, 0.0555, 0.0540, 0.0061, 0.0097, 0.0042, 0.0079],
       device='cuda:0')
Policy pred: tensor([0.8427, 0.0585, 0.0593, 0.0071, 0.0178, 0.0073, 0.0074],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9930659532546997
 
[Iteration 3] Process ID: 217646 [Epoch: 69,  1088/ 2265 points] total loss per batch: 0.824
Policy (actual, predicted): 4 4
Policy data: tensor([1.9217e-10, 5.4969e-21, 5.2423e-17, 9.0909e-19, 1.0000e+00, 9.7613e-20,
        1.0235e-13], device='cuda:0')
Policy pred: tensor([9.0857e-04, 6.1510e-05, 1.3375e-04, 7.0315e-04, 9.9494e-01, 2.7618e-04,
        2.9772e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999669194221497
 
[Iteration 3] Process ID: 217646 [Epoch: 69,  1632/ 2265 points] total loss per batch: 0.797
Policy (actual, predicted): 1 1
Policy data: tensor([9.8535e-12, 1.0000e+00, 8.4760e-26, 5.0050e-21, 8.0833e-22, 8.0833e-22,
        9.5431e-11], device='cuda:0')
Policy pred: tensor([2.1670e-05, 6.0845e-01, 3.3204e-06, 4.4739e-05, 1.0719e-03, 1.1024e-05,
        3.9040e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9881508946418762
 
[Iteration 3] Process ID: 217646 [Epoch: 69,  2176/ 2265 points] total loss per batch: 0.824
Policy (actual, predicted): 2 2
Policy data: tensor([0.0175, 0.1843, 0.6444, 0.0041, 0.0022, 0.0041, 0.1435],
       device='cuda:0')
Policy pred: tensor([0.0288, 0.2164, 0.5763, 0.0054, 0.0062, 0.0055, 0.1614],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.6033356189727783
 
[Iteration 3] Process ID: 217646 [Epoch: 70,   544/ 2265 points] total loss per batch: 0.850
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 1.2661e-16, 0.0000e+00, 6.4311e-26, 1.3241e-11, 1.0000e+00,
        1.0727e-12], device='cuda:0')
Policy pred: tensor([1.1363e-06, 2.3231e-03, 1.3839e-05, 1.9599e-05, 3.7934e-04, 9.9312e-01,
        4.1447e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9985200762748718
 
[Iteration 3] Process ID: 217646 [Epoch: 70,  1088/ 2265 points] total loss per batch: 0.780
Policy (actual, predicted): 5 5
Policy data: tensor([0.0483, 0.0394, 0.0527, 0.0060, 0.0242, 0.7856, 0.0439],
       device='cuda:0')
Policy pred: tensor([0.0450, 0.0381, 0.0484, 0.0065, 0.0293, 0.7879, 0.0448],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.14338447153568268
 
[Iteration 3] Process ID: 217646 [Epoch: 70,  1632/ 2265 points] total loss per batch: 0.800
Policy (actual, predicted): 5 5
Policy data: tensor([9.8066e-03, 4.4396e-03, 1.5249e-15, 1.1853e-13, 3.4717e-21, 9.8575e-01,
        6.3129e-17], device='cuda:0')
Policy pred: tensor([0.0163, 0.0088, 0.0022, 0.0042, 0.0018, 0.9524, 0.0143],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998977184295654
 
[Iteration 3] Process ID: 217646 [Epoch: 70,  2176/ 2265 points] total loss per batch: 0.797
Policy (actual, predicted): 2 2
Policy data: tensor([0.0175, 0.1843, 0.6444, 0.0041, 0.0022, 0.0041, 0.1435],
       device='cuda:0')
Policy pred: tensor([0.0172, 0.2097, 0.6074, 0.0055, 0.0038, 0.0030, 0.1534],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.7005557417869568
 
[Iteration 3] Process ID: 217646 [Epoch: 71,   544/ 2265 points] total loss per batch: 0.778
Policy (actual, predicted): 1 1
Policy data: tensor([1.0455e-03, 9.9757e-01, 1.3512e-07, 9.5134e-08, 1.3306e-08, 1.3306e-08,
        1.3803e-03], device='cuda:0')
Policy pred: tensor([6.7149e-04, 9.9871e-01, 1.4794e-04, 1.3662e-05, 8.2086e-06, 5.1530e-05,
        3.9299e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999997615814209
 
[Iteration 3] Process ID: 217646 [Epoch: 71,  1088/ 2265 points] total loss per batch: 0.775
Policy (actual, predicted): 5 5
Policy data: tensor([2.6180e-07, 0.0000e+00, 4.0636e-11, 1.6599e-13, 0.0000e+00, 1.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.6905e-04, 4.7834e-06, 2.0320e-05, 1.8470e-07, 3.8600e-07, 9.9900e-01,
        7.4401e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999986886978149
 
[Iteration 3] Process ID: 217646 [Epoch: 71,  1632/ 2265 points] total loss per batch: 0.881
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 7.3946e-15, 8.0060e-10, 6.8868e-24, 4.3664e-10, 5.2405e-03,
        9.9476e-01], device='cuda:0')
Policy pred: tensor([9.1524e-07, 6.5463e-04, 1.1985e-02, 2.1962e-05, 4.4515e-04, 1.6842e-03,
        9.8521e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999909400939941
 
[Iteration 3] Process ID: 217646 [Epoch: 71,  2176/ 2265 points] total loss per batch: 0.906
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0149, 0.0891, 0.3844, 0.0056, 0.0046, 0.0069, 0.4945],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.06655365228652954
 
[Iteration 3] Process ID: 217646 [Epoch: 72,   544/ 2265 points] total loss per batch: 0.901
Policy (actual, predicted): 4 0
Policy data: tensor([0.1512, 0.1466, 0.1501, 0.1277, 0.1524, 0.1325, 0.1395],
       device='cuda:0')
Policy pred: tensor([0.5741, 0.0673, 0.2326, 0.0304, 0.0325, 0.0327, 0.0304],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.010870342142879963
 
[Iteration 3] Process ID: 217646 [Epoch: 72,  1088/ 2265 points] total loss per batch: 0.786
Policy (actual, predicted): 2 2
Policy data: tensor([0.0732, 0.1104, 0.6080, 0.0204, 0.0058, 0.0058, 0.1765],
       device='cuda:0')
Policy pred: tensor([0.0631, 0.0682, 0.6494, 0.0142, 0.0051, 0.0077, 0.1923],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.07831010222434998
 
[Iteration 3] Process ID: 217646 [Epoch: 72,  1632/ 2265 points] total loss per batch: 0.840
Policy (actual, predicted): 2 2
Policy data: tensor([0.0809, 0.0116, 0.8847, 0.0043, 0.0062, 0.0062, 0.0062],
       device='cuda:0')
Policy pred: tensor([0.1162, 0.0192, 0.8333, 0.0060, 0.0072, 0.0110, 0.0071],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9355052709579468
 
[Iteration 3] Process ID: 217646 [Epoch: 72,  2176/ 2265 points] total loss per batch: 0.933
Policy (actual, predicted): 3 3
Policy data: tensor([6.9636e-17, 1.1517e-24, 1.9972e-26, 1.0000e+00, 0.0000e+00, 1.9972e-26,
        2.0942e-20], device='cuda:0')
Policy pred: tensor([1.7147e-02, 1.7021e-05, 9.4367e-04, 9.7846e-01, 7.5323e-07, 2.5248e-03,
        9.0189e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9969432353973389
 
[Iteration 3] Process ID: 217646 [Epoch: 73,   544/ 2265 points] total loss per batch: 0.941
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 9.6702e-17, 0.0000e+00, 2.2047e-13, 1.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.8095e-05, 2.4549e-03, 2.3978e-10, 3.5063e-03, 9.9401e-01, 1.6184e-08,
        1.1580e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999926686286926
 
[Iteration 3] Process ID: 217646 [Epoch: 73,  1088/ 2265 points] total loss per batch: 0.787
Policy (actual, predicted): 5 5
Policy data: tensor([0.0794, 0.0322, 0.0409, 0.0741, 0.0263, 0.6335, 0.1136],
       device='cuda:0')
Policy pred: tensor([0.0404, 0.0249, 0.0477, 0.0408, 0.0082, 0.8146, 0.0235],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.8408671021461487
 
[Iteration 3] Process ID: 217646 [Epoch: 73,  1632/ 2265 points] total loss per batch: 0.829
Policy (actual, predicted): 5 5
Policy data: tensor([0.1367, 0.1015, 0.0728, 0.0991, 0.1497, 0.3363, 0.1040],
       device='cuda:0')
Policy pred: tensor([0.1857, 0.0737, 0.0421, 0.0592, 0.2313, 0.3488, 0.0592],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9040232300758362
 
[Iteration 3] Process ID: 217646 [Epoch: 73,  2176/ 2265 points] total loss per batch: 0.836
Policy (actual, predicted): 0 0
Policy data: tensor([0.9136, 0.0235, 0.0134, 0.0080, 0.0080, 0.0202, 0.0134],
       device='cuda:0')
Policy pred: tensor([0.8777, 0.0346, 0.0239, 0.0150, 0.0084, 0.0198, 0.0207],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9826118350028992
 
[Iteration 3] Process ID: 217646 [Epoch: 74,   544/ 2265 points] total loss per batch: 0.846
Policy (actual, predicted): 4 4
Policy data: tensor([0.0184, 0.0133, 0.0116, 0.0062, 0.9007, 0.0201, 0.0298],
       device='cuda:0')
Policy pred: tensor([0.0135, 0.0396, 0.0292, 0.0131, 0.7633, 0.0412, 0.1000],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9892853498458862
 
[Iteration 3] Process ID: 217646 [Epoch: 74,  1088/ 2265 points] total loss per batch: 0.911
Policy (actual, predicted): 6 4
Policy data: tensor([0.0340, 0.0250, 0.0189, 0.0141, 0.4043, 0.0220, 0.4817],
       device='cuda:0')
Policy pred: tensor([0.0263, 0.0202, 0.0163, 0.0115, 0.4925, 0.0116, 0.4217],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.7152075171470642
 
[Iteration 3] Process ID: 217646 [Epoch: 74,  1632/ 2265 points] total loss per batch: 0.777
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000, 0.0000, 0.9912, 0.0088, 0.0000, 0.0000, 0.0000],
       device='cuda:0')
Policy pred: tensor([2.3327e-07, 4.6064e-04, 9.8379e-01, 1.5651e-02, 5.7699e-10, 2.4810e-07,
        9.3544e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 74,  2176/ 2265 points] total loss per batch: 0.786
Policy (actual, predicted): 5 5
Policy data: tensor([3.0816e-02, 1.6413e-15, 5.2145e-06, 1.6028e-18, 1.6028e-18, 9.6918e-01,
        1.5653e-11], device='cuda:0')
Policy pred: tensor([1.6123e-02, 2.2351e-04, 5.2448e-04, 1.4055e-04, 4.0759e-04, 9.7441e-01,
        8.1714e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9992630481719971
 
[Iteration 3] Process ID: 217646 [Epoch: 75,   544/ 2265 points] total loss per batch: 0.800
Policy (actual, predicted): 0 0
Policy data: tensor([0.6883, 0.0144, 0.0208, 0.0059, 0.1977, 0.0094, 0.0635],
       device='cuda:0')
Policy pred: tensor([0.4240, 0.0081, 0.0177, 0.0103, 0.4143, 0.0093, 0.1162],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9802946448326111
 
[Iteration 3] Process ID: 217646 [Epoch: 75,  1088/ 2265 points] total loss per batch: 0.830
Policy (actual, predicted): 2 2
Policy data: tensor([0.0153, 0.0063, 0.9515, 0.0063, 0.0063, 0.0081, 0.0063],
       device='cuda:0')
Policy pred: tensor([0.0060, 0.0050, 0.9567, 0.0031, 0.0058, 0.0062, 0.0173],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999942183494568
 
[Iteration 3] Process ID: 217646 [Epoch: 75,  1632/ 2265 points] total loss per batch: 0.852
Policy (actual, predicted): 6 6
Policy data: tensor([0.0340, 0.0250, 0.0189, 0.0141, 0.4045, 0.0204, 0.4830],
       device='cuda:0')
Policy pred: tensor([0.0234, 0.0268, 0.0256, 0.0266, 0.4300, 0.0243, 0.4432],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.7049636840820312
 
[Iteration 3] Process ID: 217646 [Epoch: 75,  2176/ 2265 points] total loss per batch: 0.790
Policy (actual, predicted): 4 4
Policy data: tensor([0.1800, 0.1388, 0.2132, 0.0414, 0.3487, 0.0276, 0.0503],
       device='cuda:0')
Policy pred: tensor([0.1992, 0.1253, 0.2562, 0.0298, 0.3131, 0.0249, 0.0515],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999030232429504
 
[Iteration 3] Process ID: 217646 [Epoch: 76,   544/ 2265 points] total loss per batch: 0.796
Policy (actual, predicted): 4 4
Policy data: tensor([0.0169, 0.0081, 0.0099, 0.0043, 0.9326, 0.0062, 0.0220],
       device='cuda:0')
Policy pred: tensor([0.0207, 0.0076, 0.0106, 0.0031, 0.9264, 0.0061, 0.0255],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.49677443504333496
 
[Iteration 3] Process ID: 217646 [Epoch: 76,  1088/ 2265 points] total loss per batch: 0.798
Policy (actual, predicted): 5 5
Policy data: tensor([9.8066e-03, 4.4396e-03, 1.5249e-15, 1.1853e-13, 3.4717e-21, 9.8575e-01,
        6.3129e-17], device='cuda:0')
Policy pred: tensor([1.1758e-03, 1.3565e-03, 2.9656e-04, 6.3682e-04, 1.0684e-03, 9.9445e-01,
        1.0204e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9997135996818542
 
[Iteration 3] Process ID: 217646 [Epoch: 76,  1632/ 2265 points] total loss per batch: 0.846
Policy (actual, predicted): 3 3
Policy data: tensor([0., 0., 0., 1., 0., 0., 0.], device='cuda:0')
Policy pred: tensor([4.5634e-06, 7.8667e-09, 1.2268e-06, 9.9999e-01, 1.3663e-07, 1.2732e-06,
        1.5259e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 76,  2176/ 2265 points] total loss per batch: 0.767
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 4.5945e-06, 2.1417e-10, 8.4426e-11, 2.7097e-09, 1.3593e-10,
        6.1424e-10], device='cuda:0')
Policy pred: tensor([9.9718e-01, 1.1833e-04, 2.5995e-03, 1.7525e-07, 8.9567e-05, 1.4727e-05,
        1.0371e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 217646 [Epoch: 77,   544/ 2265 points] total loss per batch: 0.783
Policy (actual, predicted): 0 0
Policy data: tensor([9.9950e-01, 3.1690e-15, 4.9993e-04, 9.5047e-20, 2.6849e-11, 1.5719e-27,
        4.4403e-19], device='cuda:0')
Policy pred: tensor([9.9205e-01, 2.5195e-05, 6.8111e-03, 2.0653e-05, 2.7513e-04, 5.3683e-04,
        2.8167e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.993471622467041
 
[Iteration 3] Process ID: 217646 [Epoch: 77,  1088/ 2265 points] total loss per batch: 0.880
Policy (actual, predicted): 0 0
Policy data: tensor([0.2094, 0.1496, 0.1425, 0.1235, 0.0734, 0.1103, 0.1912],
       device='cuda:0')
Policy pred: tensor([0.2006, 0.1883, 0.1706, 0.1111, 0.0669, 0.0950, 0.1676],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9867436289787292
 
[Iteration 3] Process ID: 217646 [Epoch: 77,  1632/ 2265 points] total loss per batch: 0.784
Policy (actual, predicted): 4 4
Policy data: tensor([6.5490e-06, 4.6719e-14, 4.4996e-22, 7.6201e-27, 9.9815e-01, 7.8030e-24,
        1.8473e-03], device='cuda:0')
Policy pred: tensor([6.4841e-03, 2.2223e-06, 9.4614e-05, 5.1508e-06, 9.9245e-01, 9.4352e-05,
        8.7138e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998977184295654
 
[Iteration 3] Process ID: 217646 [Epoch: 77,  2176/ 2265 points] total loss per batch: 0.794
Policy (actual, predicted): 4 0
Policy data: tensor([0.1454, 0.1489, 0.1477, 0.1301, 0.1559, 0.1325, 0.1395],
       device='cuda:0')
Policy pred: tensor([0.6244, 0.0536, 0.2286, 0.0207, 0.0230, 0.0268, 0.0228],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.0027861541602760553
 
[Iteration 3] Process ID: 217646 [Epoch: 78,   544/ 2265 points] total loss per batch: 0.827
Policy (actual, predicted): 0 4
Policy data: tensor([0.6883, 0.0144, 0.0208, 0.0059, 0.1977, 0.0094, 0.0635],
       device='cuda:0')
Policy pred: tensor([0.3704, 0.0217, 0.0304, 0.0104, 0.3863, 0.0193, 0.1615],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9938296675682068
 
[Iteration 3] Process ID: 217646 [Epoch: 78,  1088/ 2265 points] total loss per batch: 0.814
Policy (actual, predicted): 0 0
Policy data: tensor([0.6993, 0.0379, 0.2323, 0.0041, 0.0041, 0.0129, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6527, 0.0505, 0.2009, 0.0203, 0.0229, 0.0267, 0.0260],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.0045626163482666016
 
[Iteration 3] Process ID: 217646 [Epoch: 78,  1632/ 2265 points] total loss per batch: 0.821
Policy (actual, predicted): 2 2
Policy data: tensor([0.4272, 0.0286, 0.5207, 0.0041, 0.0041, 0.0077, 0.0077],
       device='cuda:0')
Policy pred: tensor([0.4163, 0.0344, 0.5146, 0.0036, 0.0052, 0.0084, 0.0175],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.7492871284484863
 
[Iteration 3] Process ID: 217646 [Epoch: 78,  2176/ 2265 points] total loss per batch: 0.759
Policy (actual, predicted): 2 2
Policy data: tensor([1.7310e-01, 4.2227e-02, 7.8465e-01, 3.7896e-08, 3.8009e-06, 1.7310e-11,
        1.5899e-05], device='cuda:0')
Policy pred: tensor([1.2408e-01, 1.8212e-02, 8.4808e-01, 4.1310e-04, 7.4730e-03, 1.0591e-03,
        6.7891e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9991127848625183
 
[Iteration 3] Process ID: 217646 [Epoch: 79,   544/ 2265 points] total loss per batch: 0.796
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 5.6367e-06, 7.1860e-04, 7.0524e-12, 1.9847e-07, 1.4598e-13,
        9.9928e-01], device='cuda:0')
Policy pred: tensor([1.5838e-09, 2.2763e-04, 1.5448e-04, 2.7277e-08, 2.1236e-06, 3.4572e-04,
        9.9927e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 79,  1088/ 2265 points] total loss per batch: 0.750
Policy (actual, predicted): 2 2
Policy data: tensor([2.0474e-01, 5.9969e-09, 7.9526e-01, 1.3380e-12, 0.0000e+00, 7.8164e-07,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.4958e-01, 1.2029e-03, 8.4717e-01, 3.0046e-06, 3.6285e-07, 2.0450e-03,
        3.4290e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999960660934448
 
[Iteration 3] Process ID: 217646 [Epoch: 79,  1632/ 2265 points] total loss per batch: 0.871
Policy (actual, predicted): 1 1
Policy data: tensor([0.0093, 0.5138, 0.3744, 0.0093, 0.0385, 0.0076, 0.0472],
       device='cuda:0')
Policy pred: tensor([0.0111, 0.5098, 0.3876, 0.0099, 0.0288, 0.0069, 0.0460],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.05938583239912987
 
[Iteration 3] Process ID: 217646 [Epoch: 79,  2176/ 2265 points] total loss per batch: 0.760
Policy (actual, predicted): 6 6
Policy data: tensor([0.0062, 0.0184, 0.0098, 0.0116, 0.0409, 0.0080, 0.9050],
       device='cuda:0')
Policy pred: tensor([0.0078, 0.0223, 0.0142, 0.0134, 0.0442, 0.0084, 0.8896],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.1094495877623558
 
[Iteration 3] Process ID: 217646 [Epoch: 80,   544/ 2265 points] total loss per batch: 0.825
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0270, 0.1105, 0.3479, 0.0121, 0.0110, 0.0175, 0.4738],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.06952673196792603
 
[Iteration 3] Process ID: 217646 [Epoch: 80,  1088/ 2265 points] total loss per batch: 0.826
Policy (actual, predicted): 6 6
Policy data: tensor([0.1561, 0.1427, 0.1304, 0.1427, 0.1427, 0.0989, 0.1864],
       device='cuda:0')
Policy pred: tensor([0.1652, 0.1534, 0.1198, 0.1375, 0.1235, 0.1082, 0.1924],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9994651675224304
 
[Iteration 3] Process ID: 217646 [Epoch: 80,  1632/ 2265 points] total loss per batch: 0.750
Policy (actual, predicted): 0 0
Policy data: tensor([0.7386, 0.0077, 0.0145, 0.0095, 0.0349, 0.0288, 0.1661],
       device='cuda:0')
Policy pred: tensor([0.7296, 0.0143, 0.0087, 0.0038, 0.0275, 0.0217, 0.1944],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9892962574958801
 
[Iteration 3] Process ID: 217646 [Epoch: 80,  2176/ 2265 points] total loss per batch: 0.782
Policy (actual, predicted): 5 5
Policy data: tensor([5.0749e-16, 4.8877e-14, 5.0749e-16, 1.6687e-16, 9.1010e-17, 1.0000e+00,
        9.3194e-14], device='cuda:0')
Policy pred: tensor([1.0697e-03, 1.1719e-03, 1.6041e-03, 1.4408e-03, 1.6469e-04, 9.9249e-01,
        2.0561e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998102784156799
 
[Iteration 3] Process ID: 217646 [Epoch: 81,   544/ 2265 points] total loss per batch: 0.811
Policy (actual, predicted): 4 6
Policy data: tensor([0.1430, 0.1454, 0.1442, 0.1348, 0.1512, 0.1383, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1351, 0.1474, 0.1322, 0.1208, 0.1586, 0.1457, 0.1602],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9994626045227051
 
[Iteration 3] Process ID: 217646 [Epoch: 81,  1088/ 2265 points] total loss per batch: 0.765
Policy (actual, predicted): 6 6
Policy data: tensor([0.0146, 0.0228, 0.0427, 0.0195, 0.0321, 0.0531, 0.8151],
       device='cuda:0')
Policy pred: tensor([0.0259, 0.0356, 0.0548, 0.0313, 0.0606, 0.0593, 0.7326],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9862795472145081
 
[Iteration 3] Process ID: 217646 [Epoch: 81,  1632/ 2265 points] total loss per batch: 0.819
Policy (actual, predicted): 2 2
Policy data: tensor([1.0737e-21, 1.2379e-13, 1.0000e+00, 1.0995e-28, 1.3403e-08, 6.4925e-24,
        1.1806e-19], device='cuda:0')
Policy pred: tensor([2.5570e-07, 7.1059e-04, 9.9908e-01, 1.2615e-06, 1.7914e-04, 2.0561e-05,
        6.3706e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9993401765823364
 
[Iteration 3] Process ID: 217646 [Epoch: 81,  2176/ 2265 points] total loss per batch: 0.800
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 7.7902e-14, 1.0000e+00, 2.8918e-26, 1.1699e-15, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.2264e-04, 8.9749e-04, 9.9601e-01, 1.0741e-03, 1.4536e-03, 4.4108e-04,
        5.2002e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 82,   544/ 2265 points] total loss per batch: 0.748
Policy (actual, predicted): 4 4
Policy data: tensor([0.0598, 0.0114, 0.0403, 0.0079, 0.8565, 0.0042, 0.0198],
       device='cuda:0')
Policy pred: tensor([0.0567, 0.0115, 0.0397, 0.0081, 0.8593, 0.0104, 0.0143],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9915081858634949
 
[Iteration 3] Process ID: 217646 [Epoch: 82,  1088/ 2265 points] total loss per batch: 0.793
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0734, 0.0179, 0.0175, 0.0162, 0.0448, 0.0488, 0.7815],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.03323246166110039
 
[Iteration 3] Process ID: 217646 [Epoch: 82,  1632/ 2265 points] total loss per batch: 0.834
Policy (actual, predicted): 1 1
Policy data: tensor([1.4326e-05, 9.9596e-01, 1.4326e-05, 2.3199e-05, 5.7030e-05, 6.1980e-08,
        3.9279e-03], device='cuda:0')
Policy pred: tensor([2.2704e-04, 9.9767e-01, 3.8104e-04, 1.6677e-04, 4.7896e-04, 3.7019e-05,
        1.0375e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9985988736152649
 
[Iteration 3] Process ID: 217646 [Epoch: 82,  2176/ 2265 points] total loss per batch: 0.819
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 9.9620e-01, 2.9259e-03, 0.0000e+00, 8.7467e-04,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.6378e-08, 1.3299e-05, 9.9796e-01, 1.7565e-03, 8.0385e-09, 2.6754e-04,
        3.6298e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999954700469971
 
[Iteration 3] Process ID: 217646 [Epoch: 83,   544/ 2265 points] total loss per batch: 0.765
Policy (actual, predicted): 0 0
Policy data: tensor([7.8443e-01, 3.3426e-03, 1.1305e-03, 7.5954e-25, 2.1109e-01, 7.7777e-22,
        3.1465e-11], device='cuda:0')
Policy pred: tensor([7.8427e-01, 9.5870e-03, 5.2619e-03, 3.4507e-05, 1.9909e-01, 9.1717e-05,
        1.6654e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 83,  1088/ 2265 points] total loss per batch: 0.812
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0687, 0.0180, 0.0184, 0.0192, 0.0458, 0.0562, 0.7737],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.012706071138381958
 
[Iteration 3] Process ID: 217646 [Epoch: 83,  1632/ 2265 points] total loss per batch: 0.778
Policy (actual, predicted): 1 1
Policy data: tensor([2.4756e-11, 9.2375e-01, 7.6236e-02, 1.3221e-13, 2.0537e-09, 9.8245e-06,
        4.0942e-09], device='cuda:0')
Policy pred: tensor([2.2900e-04, 9.7674e-01, 1.5509e-02, 7.3909e-05, 8.1107e-04, 5.6100e-03,
        1.0236e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999940395355225
 
[Iteration 3] Process ID: 217646 [Epoch: 83,  2176/ 2265 points] total loss per batch: 0.822
Policy (actual, predicted): 0 0
Policy data: tensor([0.6968, 0.0379, 0.2347, 0.0041, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6642, 0.0442, 0.2201, 0.0145, 0.0162, 0.0206, 0.0202],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.006372717674821615
 
[Iteration 3] Process ID: 217646 [Epoch: 84,   544/ 2265 points] total loss per batch: 0.845
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 8.5827e-13, 2.4933e-13, 2.3450e-24, 0.0000e+00, 0.0000e+00,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([1.0365e-06, 4.1395e-05, 8.5714e-07, 3.0980e-06, 1.0401e-08, 2.9005e-05,
        9.9992e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999988317489624
 
[Iteration 3] Process ID: 217646 [Epoch: 84,  1088/ 2265 points] total loss per batch: 0.827
Policy (actual, predicted): 1 1
Policy data: tensor([3.1691e-16, 1.0000e+00, 5.1689e-19, 3.0522e-24, 1.0671e-13, 3.1255e-21,
        3.0522e-14], device='cuda:0')
Policy pred: tensor([3.8758e-06, 9.9966e-01, 8.7991e-06, 7.1869e-08, 3.3199e-05, 4.7446e-05,
        2.4965e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998134970664978
 
[Iteration 3] Process ID: 217646 [Epoch: 84,  1632/ 2265 points] total loss per batch: 0.756
Policy (actual, predicted): 1 1
Policy data: tensor([5.7180e-18, 1.0000e+00, 1.9768e-29, 2.0728e-23, 1.9305e-22, 2.0242e-26,
        2.1226e-20], device='cuda:0')
Policy pred: tensor([1.6560e-07, 9.9924e-01, 4.4174e-09, 6.4176e-07, 7.4833e-04, 7.4908e-07,
        5.9932e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9994739890098572
 
[Iteration 3] Process ID: 217646 [Epoch: 84,  2176/ 2265 points] total loss per batch: 0.749
Policy (actual, predicted): 0 0
Policy data: tensor([9.9889e-01, 7.2458e-12, 6.6883e-04, 1.2271e-16, 1.2271e-16, 4.3812e-04,
        2.8081e-09], device='cuda:0')
Policy pred: tensor([9.9790e-01, 2.3201e-05, 2.6956e-04, 2.8348e-06, 3.8237e-04, 1.1438e-03,
        2.7969e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 85,   544/ 2265 points] total loss per batch: 0.816
Policy (actual, predicted): 0 0
Policy data: tensor([0.8539, 0.0061, 0.0132, 0.0042, 0.0873, 0.0042, 0.0311],
       device='cuda:0')
Policy pred: tensor([0.8743, 0.0043, 0.0131, 0.0043, 0.0692, 0.0062, 0.0287],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.041111476719379425
 
[Iteration 3] Process ID: 217646 [Epoch: 85,  1088/ 2265 points] total loss per batch: 0.819
Policy (actual, predicted): 0 0
Policy data: tensor([0.8132, 0.0181, 0.0131, 0.0061, 0.1375, 0.0042, 0.0079],
       device='cuda:0')
Policy pred: tensor([0.8173, 0.0130, 0.0123, 0.0042, 0.1433, 0.0018, 0.0081],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9498264193534851
 
[Iteration 3] Process ID: 217646 [Epoch: 85,  1632/ 2265 points] total loss per batch: 0.797
Policy (actual, predicted): 0 0
Policy data: tensor([0.6968, 0.0379, 0.2347, 0.0041, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.5659, 0.0696, 0.2131, 0.0328, 0.0355, 0.0420, 0.0411],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.014761623926460743
 
[Iteration 3] Process ID: 217646 [Epoch: 85,  2176/ 2265 points] total loss per batch: 0.741
Policy (actual, predicted): 6 6
Policy data: tensor([4.0919e-08, 3.1124e-13, 2.9682e-09, 2.9682e-19, 3.1871e-20, 8.6862e-02,
        9.1314e-01], device='cuda:0')
Policy pred: tensor([0.0032, 0.0022, 0.0019, 0.0009, 0.0013, 0.1152, 0.8753],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998946785926819
 
[Iteration 3] Process ID: 217646 [Epoch: 86,   544/ 2265 points] total loss per batch: 0.793
Policy (actual, predicted): 6 6
Policy data: tensor([3.0476e-03, 2.6844e-14, 2.4415e-16, 1.4417e-21, 8.8390e-09, 1.7834e-05,
        9.9693e-01], device='cuda:0')
Policy pred: tensor([8.8485e-04, 8.7415e-06, 1.9174e-03, 2.7219e-04, 3.9949e-03, 2.6506e-03,
        9.9027e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9975141286849976
 
[Iteration 3] Process ID: 217646 [Epoch: 86,  1088/ 2265 points] total loss per batch: 0.778
Policy (actual, predicted): 0 0
Policy data: tensor([7.5001e-01, 1.0635e-16, 6.4476e-08, 3.1232e-23, 2.4999e-01, 8.4137e-11,
        1.8442e-18], device='cuda:0')
Policy pred: tensor([7.7501e-01, 1.1356e-03, 2.2373e-04, 9.6990e-06, 2.2334e-01, 1.9012e-04,
        9.2649e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.06444598734378815
 
[Iteration 3] Process ID: 217646 [Epoch: 86,  1632/ 2265 points] total loss per batch: 0.822
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0761, 0.0243, 0.0276, 0.0227, 0.0568, 0.0615, 0.7310],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.030199084430933
 
[Iteration 3] Process ID: 217646 [Epoch: 86,  2176/ 2265 points] total loss per batch: 0.809
Policy (actual, predicted): 1 1
Policy data: tensor([3.7928e-16, 1.0000e+00, 6.1861e-29, 1.6045e-18, 6.6423e-20, 3.6529e-24,
        2.3160e-10], device='cuda:0')
Policy pred: tensor([1.0648e-10, 1.0000e+00, 2.7356e-10, 4.5937e-11, 4.9415e-09, 2.9721e-09,
        3.9742e-11], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999944567680359
 
[Iteration 3] Process ID: 217646 [Epoch: 87,   544/ 2265 points] total loss per batch: 0.798
Policy (actual, predicted): 4 4
Policy data: tensor([1.7112e-22, 4.9497e-21, 1.7523e-29, 1.7112e-22, 1.0000e+00, 1.7523e-29,
        1.0595e-21], device='cuda:0')
Policy pred: tensor([6.6652e-05, 1.9651e-04, 1.4522e-04, 3.7916e-04, 9.9859e-01, 1.1418e-04,
        5.0964e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9802371859550476
 
[Iteration 3] Process ID: 217646 [Epoch: 87,  1088/ 2265 points] total loss per batch: 0.807
Policy (actual, predicted): 4 4
Policy data: tensor([0.0169, 0.0081, 0.0099, 0.0043, 0.9342, 0.0062, 0.0203],
       device='cuda:0')
Policy pred: tensor([0.0181, 0.0093, 0.0117, 0.0041, 0.9260, 0.0089, 0.0219],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.5200935006141663
 
[Iteration 3] Process ID: 217646 [Epoch: 87,  1632/ 2265 points] total loss per batch: 0.819
Policy (actual, predicted): 4 4
Policy data: tensor([0.0305, 0.0211, 0.0060, 0.0078, 0.7496, 0.0078, 0.1774],
       device='cuda:0')
Policy pred: tensor([0.0498, 0.0394, 0.0064, 0.0066, 0.7165, 0.0088, 0.1726],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.07131032645702362
 
[Iteration 3] Process ID: 217646 [Epoch: 87,  2176/ 2265 points] total loss per batch: 0.743
Policy (actual, predicted): 6 6
Policy data: tensor([0.1419, 0.1477, 0.1360, 0.1430, 0.1430, 0.1383, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1556, 0.1442, 0.1243, 0.1423, 0.1487, 0.1265, 0.1583],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9692062735557556
 
[Iteration 3] Process ID: 217646 [Epoch: 88,   544/ 2265 points] total loss per batch: 0.760
Policy (actual, predicted): 4 4
Policy data: tensor([0.0360, 0.0217, 0.0115, 0.0080, 0.8911, 0.0167, 0.0150],
       device='cuda:0')
Policy pred: tensor([0.0149, 0.0132, 0.0073, 0.0057, 0.9342, 0.0095, 0.0153],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9808525443077087
 
[Iteration 3] Process ID: 217646 [Epoch: 88,  1088/ 2265 points] total loss per batch: 0.817
Policy (actual, predicted): 4 4
Policy data: tensor([2.5318e-06, 2.1814e-15, 1.9375e-20, 2.0316e-24, 9.9999e-01, 6.6133e-06,
        5.7388e-16], device='cuda:0')
Policy pred: tensor([1.9996e-04, 3.7864e-06, 2.3969e-05, 2.7171e-05, 9.9876e-01, 1.9042e-04,
        7.8992e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9665248394012451
 
[Iteration 3] Process ID: 217646 [Epoch: 88,  1632/ 2265 points] total loss per batch: 0.761
Policy (actual, predicted): 1 2
Policy data: tensor([0.1501, 0.1536, 0.1419, 0.1301, 0.1501, 0.1325, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1382, 0.1421, 0.1560, 0.1413, 0.1525, 0.1303, 0.1396],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999935626983643
 
[Iteration 3] Process ID: 217646 [Epoch: 88,  2176/ 2265 points] total loss per batch: 0.839
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0211, 0.0935, 0.3696, 0.0097, 0.0086, 0.0147, 0.4829],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.07881054282188416
 
[Iteration 3] Process ID: 217646 [Epoch: 89,   544/ 2265 points] total loss per batch: 0.826
Policy (actual, predicted): 1 1
Policy data: tensor([9.4909e-14, 1.0000e+00, 2.0316e-24, 3.5231e-26, 0.0000e+00, 8.9239e-19,
        1.4253e-15], device='cuda:0')
Policy pred: tensor([4.2778e-06, 9.9996e-01, 7.8671e-08, 6.6234e-07, 1.1734e-08, 9.9717e-06,
        2.1437e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9996904134750366
 
[Iteration 3] Process ID: 217646 [Epoch: 89,  1088/ 2265 points] total loss per batch: 0.803
Policy (actual, predicted): 5 5
Policy data: tensor([3.9849e-10, 2.1401e-17, 1.0238e-13, 6.2850e-24, 7.4620e-08, 9.9946e-01,
        5.4034e-04], device='cuda:0')
Policy pred: tensor([1.8589e-04, 1.8138e-04, 4.1658e-05, 2.7387e-05, 3.4336e-04, 9.9883e-01,
        3.9410e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9995330572128296
 
[Iteration 3] Process ID: 217646 [Epoch: 89,  1632/ 2265 points] total loss per batch: 0.789
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0679, 0.0172, 0.0205, 0.0186, 0.0433, 0.0479, 0.7847],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.03236883878707886
 
[Iteration 3] Process ID: 217646 [Epoch: 89,  2176/ 2265 points] total loss per batch: 0.759
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0650e-25, 1.0000e+00, 1.5720e-26,
        1.5352e-19], device='cuda:0')
Policy pred: tensor([1.2069e-13, 8.4554e-16, 5.9798e-11, 7.3923e-06, 9.9999e-01, 9.3489e-09,
        6.7920e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 90,   544/ 2265 points] total loss per batch: 0.789
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000, 0.0000, 0.1215, 0.0000, 0.0000, 0.2830, 0.5955],
       device='cuda:0')
Policy pred: tensor([8.1141e-05, 8.5939e-06, 1.3539e-01, 3.2092e-04, 1.9815e-05, 3.4078e-01,
        5.2341e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999890327453613
 
[Iteration 3] Process ID: 217646 [Epoch: 90,  1088/ 2265 points] total loss per batch: 0.785
Policy (actual, predicted): 6 6
Policy data: tensor([0.1395, 0.1465, 0.1348, 0.1489, 0.1407, 0.1383, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1330, 0.1425, 0.1505, 0.1358, 0.1278, 0.1470, 0.1633],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9842697978019714
 
[Iteration 3] Process ID: 217646 [Epoch: 90,  1632/ 2265 points] total loss per batch: 0.783
Policy (actual, predicted): 4 4
Policy data: tensor([0.0100, 0.0118, 0.0023, 0.0043, 0.9556, 0.0023, 0.0136],
       device='cuda:0')
Policy pred: tensor([0.0037, 0.0038, 0.0028, 0.0012, 0.9722, 0.0014, 0.0149],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.8880425691604614
 
[Iteration 3] Process ID: 217646 [Epoch: 90,  2176/ 2265 points] total loss per batch: 0.839
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 0.0000e+00, 5.5108e-03, 7.4619e-07, 0.0000e+00, 9.9449e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([8.4384e-08, 6.3231e-06, 1.2859e-02, 1.7586e-04, 2.9282e-08, 9.8694e-01,
        1.5256e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 3] Process ID: 217646 [Epoch: 91,   544/ 2265 points] total loss per batch: 0.819
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 5.2784e-17, 0.0000e+00, 6.7770e-15, 9.8842e-15, 1.4219e-14,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([9.1386e-08, 7.3866e-04, 1.1580e-04, 2.4149e-04, 2.8918e-03, 4.1178e-03,
        9.9189e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999304413795471
 
[Iteration 3] Process ID: 217646 [Epoch: 91,  1088/ 2265 points] total loss per batch: 0.794
Policy (actual, predicted): 0 0
Policy data: tensor([0.3016, 0.1273, 0.1978, 0.0495, 0.1163, 0.0803, 0.1273],
       device='cuda:0')
Policy pred: tensor([0.2649, 0.1363, 0.1854, 0.0489, 0.1356, 0.0817, 0.1471],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999992847442627
 
[Iteration 3] Process ID: 217646 [Epoch: 91,  1632/ 2265 points] total loss per batch: 0.834
Policy (actual, predicted): 1 1
Policy data: tensor([3.1691e-16, 1.0000e+00, 5.1689e-19, 3.0522e-24, 1.0671e-13, 3.1255e-21,
        3.0522e-14], device='cuda:0')
Policy pred: tensor([3.3964e-08, 9.9999e-01, 2.6104e-07, 6.6393e-11, 9.8243e-07, 1.2884e-06,
        6.9466e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999620914459229
 
[Iteration 3] Process ID: 217646 [Epoch: 91,  2176/ 2265 points] total loss per batch: 0.749
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 1.1331e-12, 2.8008e-23, 0.0000e+00, 1.6151e-21,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.7400e-09, 9.9998e-01, 1.2905e-05, 2.0953e-07, 6.8511e-13, 2.3105e-06,
        3.5538e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999931454658508
 
[Iteration 3] Process ID: 217646 [Epoch: 92,   544/ 2265 points] total loss per batch: 0.816
Policy (actual, predicted): 4 4
Policy data: tensor([0.0832, 0.0094, 0.0271, 0.0651, 0.7470, 0.0059, 0.0623],
       device='cuda:0')
Policy pred: tensor([0.1022, 0.0142, 0.0225, 0.0822, 0.6877, 0.0091, 0.0820],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.10541337728500366
 
[Iteration 3] Process ID: 217646 [Epoch: 92,  1088/ 2265 points] total loss per batch: 0.817
Policy (actual, predicted): 1 1
Policy data: tensor([0.1272, 0.2187, 0.1473, 0.1236, 0.0970, 0.0822, 0.2039],
       device='cuda:0')
Policy pred: tensor([0.1255, 0.2468, 0.1534, 0.1252, 0.0958, 0.0874, 0.1659],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9850451350212097
 
[Iteration 3] Process ID: 217646 [Epoch: 92,  1632/ 2265 points] total loss per batch: 0.767
Policy (actual, predicted): 5 5
Policy data: tensor([0.0098, 0.0098, 0.0235, 0.0151, 0.0134, 0.9150, 0.0134],
       device='cuda:0')
Policy pred: tensor([0.0020, 0.0047, 0.0050, 0.0043, 0.0032, 0.9778, 0.0031],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999901533126831
 
[Iteration 3] Process ID: 217646 [Epoch: 92,  2176/ 2265 points] total loss per batch: 0.779
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 2.4090e-09, 1.2471e-16, 6.4866e-23, 6.3346e-26, 1.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.1526e-08, 1.5090e-04, 6.5020e-06, 1.4493e-05, 1.5061e-09, 9.9983e-01,
        2.2931e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999938011169434
 
[Iteration 3] Process ID: 217646 [Epoch: 93,   544/ 2265 points] total loss per batch: 0.873
Policy (actual, predicted): 4 4
Policy data: tensor([0.0127, 0.0448, 0.0433, 0.0922, 0.7350, 0.0360, 0.0360],
       device='cuda:0')
Policy pred: tensor([0.0107, 0.0449, 0.0508, 0.0939, 0.7338, 0.0267, 0.0392],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9993507266044617
 
[Iteration 3] Process ID: 217646 [Epoch: 93,  1088/ 2265 points] total loss per batch: 0.762
Policy (actual, predicted): 2 2
Policy data: tensor([2.0435e-04, 1.2973e-13, 9.9875e-01, 3.0604e-15, 3.6647e-05, 5.6738e-10,
        1.0072e-03], device='cuda:0')
Policy pred: tensor([1.4406e-04, 1.4884e-06, 9.9784e-01, 1.7783e-05, 3.8759e-04, 1.0717e-04,
        1.4985e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999113082885742
 
[Iteration 3] Process ID: 217646 [Epoch: 93,  1632/ 2265 points] total loss per batch: 0.745
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 9.1966e-09, 4.2293e-08, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.4857e-06, 9.9989e-01, 1.5907e-05, 3.9799e-05, 4.8854e-05, 7.3142e-08,
        2.9565e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999990463256836
 
[Iteration 3] Process ID: 217646 [Epoch: 93,  2176/ 2265 points] total loss per batch: 0.788
Policy (actual, predicted): 1 1
Policy data: tensor([1.3483e-14, 1.0000e+00, 1.9378e-21, 1.9378e-21, 0.0000e+00, 1.9378e-21,
        8.5120e-16], device='cuda:0')
Policy pred: tensor([1.3176e-06, 9.9994e-01, 5.3182e-07, 3.3577e-11, 7.6156e-09, 7.4274e-07,
        5.9913e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 3] Process ID: 217646 [Epoch: 94,   544/ 2265 points] total loss per batch: 0.806
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 9.9930e-01, 7.0127e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.4124e-09, 2.3835e-10, 9.9939e-01, 6.0677e-04, 7.1480e-09, 1.6876e-08,
        9.8632e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 94,  1088/ 2265 points] total loss per batch: 0.765
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 5.7665e-19, 1.8184e-16, 9.7656e-24, 3.3253e-07, 2.2799e-17,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9822e-01, 1.5301e-05, 2.0440e-05, 3.1748e-06, 5.7353e-04, 1.1654e-03,
        6.1159e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9993399977684021
 
[Iteration 3] Process ID: 217646 [Epoch: 94,  1632/ 2265 points] total loss per batch: 0.776
Policy (actual, predicted): 2 0
Policy data: tensor([0.4272, 0.0286, 0.5207, 0.0041, 0.0041, 0.0077, 0.0077],
       device='cuda:0')
Policy pred: tensor([0.5191, 0.0233, 0.4398, 0.0020, 0.0036, 0.0050, 0.0072],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.697264552116394
 
[Iteration 3] Process ID: 217646 [Epoch: 94,  2176/ 2265 points] total loss per batch: 0.820
Policy (actual, predicted): 5 5
Policy data: tensor([0.0326, 0.0131, 0.0568, 0.0079, 0.0061, 0.8557, 0.0279],
       device='cuda:0')
Policy pred: tensor([0.0077, 0.0061, 0.0257, 0.0038, 0.0021, 0.9448, 0.0098],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999943971633911
 
[Iteration 3] Process ID: 217646 [Epoch: 95,   544/ 2265 points] total loss per batch: 0.778
Policy (actual, predicted): 5 5
Policy data: tensor([0.0763, 0.0577, 0.0229, 0.0042, 0.0042, 0.8152, 0.0196],
       device='cuda:0')
Policy pred: tensor([0.1318, 0.0863, 0.0312, 0.0062, 0.0096, 0.7020, 0.0329],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9656121730804443
 
[Iteration 3] Process ID: 217646 [Epoch: 95,  1088/ 2265 points] total loss per batch: 0.768
Policy (actual, predicted): 6 6
Policy data: tensor([0.0676, 0.0798, 0.0367, 0.0731, 0.0425, 0.0353, 0.6649],
       device='cuda:0')
Policy pred: tensor([0.0641, 0.0742, 0.0335, 0.0697, 0.0432, 0.0333, 0.6819],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.670738697052002
 
[Iteration 3] Process ID: 217646 [Epoch: 95,  1632/ 2265 points] total loss per batch: 0.863
Policy (actual, predicted): 4 6
Policy data: tensor([0.1419, 0.1384, 0.1454, 0.1277, 0.1547, 0.1430, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1361, 0.1313, 0.1438, 0.1492, 0.1534, 0.1327, 0.1535],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999889731407166
 
[Iteration 3] Process ID: 217646 [Epoch: 95,  2176/ 2265 points] total loss per batch: 0.770
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0687, 0.0175, 0.0177, 0.0182, 0.0408, 0.0517, 0.7855],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.012453063391149044
 
[Iteration 3] Process ID: 217646 [Epoch: 96,   544/ 2265 points] total loss per batch: 0.819
Policy (actual, predicted): 0 5
Policy data: tensor([0.7490, 0.0078, 0.0060, 0.0042, 0.0113, 0.2217, 0.0000],
       device='cuda:0')
Policy pred: tensor([4.5629e-01, 3.2189e-03, 6.7648e-03, 2.4228e-03, 7.2447e-03, 5.2403e-01,
        2.4475e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9996489882469177
 
[Iteration 3] Process ID: 217646 [Epoch: 96,  1088/ 2265 points] total loss per batch: 0.756
Policy (actual, predicted): 5 5
Policy data: tensor([1.0642e-02, 2.7929e-17, 9.8873e-16, 1.0125e-22, 6.8113e-02, 9.2124e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.1009e-02, 1.1126e-04, 1.0924e-04, 1.3388e-04, 2.3917e-02, 9.6472e-01,
        7.2327e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999985933303833
 
[Iteration 3] Process ID: 217646 [Epoch: 96,  1632/ 2265 points] total loss per batch: 0.834
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 1.0378e-17, 1.8428e-26, 0.0000e+00, 1.8428e-26,
        1.9323e-20], device='cuda:0')
Policy pred: tensor([1.9646e-11, 9.9896e-01, 4.4660e-04, 1.3509e-05, 4.2898e-10, 5.8027e-04,
        2.1504e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999933242797852
 
[Iteration 3] Process ID: 217646 [Epoch: 96,  2176/ 2265 points] total loss per batch: 0.780
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 5.8745e-07, 5.4710e-17, 1.0000e+00, 0.0000e+00, 7.9572e-14,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.5567e-10, 5.7607e-06, 1.5806e-05, 9.9975e-01, 4.3719e-08, 2.3055e-04,
        3.0255e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999972581863403
 
[Iteration 3] Process ID: 217646 [Epoch: 97,   544/ 2265 points] total loss per batch: 0.801
Policy (actual, predicted): 0 0
Policy data: tensor([0.6964, 0.0379, 0.2333, 0.0059, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6491, 0.0513, 0.2038, 0.0204, 0.0219, 0.0267, 0.0269],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.005670060403645039
 
[Iteration 3] Process ID: 217646 [Epoch: 97,  1088/ 2265 points] total loss per batch: 0.789
Policy (actual, predicted): 4 4
Policy data: tensor([8.5339e-06, 6.5758e-04, 7.0607e-05, 2.0355e-02, 9.7864e-01, 1.4615e-06,
        2.6839e-04], device='cuda:0')
Policy pred: tensor([7.6384e-06, 1.5076e-04, 4.3192e-04, 1.1019e-02, 9.8504e-01, 3.9177e-05,
        3.3163e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9997457265853882
 
[Iteration 3] Process ID: 217646 [Epoch: 97,  1632/ 2265 points] total loss per batch: 0.766
Policy (actual, predicted): 3 3
Policy data: tensor([0., 0., 0., 1., 0., 0., 0.], device='cuda:0')
Policy pred: tensor([3.3586e-06, 2.5525e-06, 2.6366e-05, 9.9933e-01, 6.0600e-05, 3.7140e-04,
        2.0370e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999980330467224
 
[Iteration 3] Process ID: 217646 [Epoch: 97,  2176/ 2265 points] total loss per batch: 0.809
Policy (actual, predicted): 4 4
Policy data: tensor([0.0710, 0.0131, 0.0042, 0.0810, 0.8225, 0.0022, 0.0061],
       device='cuda:0')
Policy pred: tensor([0.0613, 0.0152, 0.0040, 0.0859, 0.8201, 0.0037, 0.0097],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.4806765913963318
 
[Iteration 3] Process ID: 217646 [Epoch: 98,   544/ 2265 points] total loss per batch: 0.765
Policy (actual, predicted): 0 0
Policy data: tensor([0.2507, 0.1776, 0.1360, 0.1360, 0.0780, 0.0858, 0.1360],
       device='cuda:0')
Policy pred: tensor([0.2422, 0.1741, 0.1406, 0.1387, 0.0667, 0.0855, 0.1520],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 3] Process ID: 217646 [Epoch: 98,  1088/ 2265 points] total loss per batch: 0.768
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 9.9934e-01, 6.6131e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.7555e-06, 5.0130e-08, 9.9063e-01, 9.3503e-03, 6.4769e-06, 2.8223e-06,
        4.0032e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999959468841553
 
[Iteration 3] Process ID: 217646 [Epoch: 98,  1632/ 2265 points] total loss per batch: 0.796
Policy (actual, predicted): 4 4
Policy data: tensor([5.1329e-11, 4.1544e-19, 2.4531e-14, 6.8706e-17, 1.0000e+00, 6.2670e-12,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.4264e-05, 1.8333e-05, 5.8629e-06, 1.4318e-05, 9.9989e-01, 4.6619e-05,
        1.2771e-12], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998515248298645
 
[Iteration 3] Process ID: 217646 [Epoch: 98,  2176/ 2265 points] total loss per batch: 0.860
Policy (actual, predicted): 6 6
Policy data: tensor([0.0526, 0.0199, 0.2237, 0.0674, 0.0229, 0.1229, 0.4906],
       device='cuda:0')
Policy pred: tensor([0.0370, 0.0187, 0.1786, 0.0511, 0.0271, 0.0909, 0.5966],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9810681939125061
 
[Iteration 3] Process ID: 217646 [Epoch: 99,   544/ 2265 points] total loss per batch: 0.836
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 3.2985e-20, 3.1457e-26, 3.1457e-26, 1.4772e-13, 6.1931e-17,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9973e-01, 1.7478e-08, 2.2634e-06, 2.4791e-10, 2.6510e-04, 4.0616e-06,
        4.8962e-16], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9996537566184998
 
[Iteration 3] Process ID: 217646 [Epoch: 99,  1088/ 2265 points] total loss per batch: 0.814
Policy (actual, predicted): 4 4
Policy data: tensor([0.0978, 0.0449, 0.0176, 0.0041, 0.7300, 0.0254, 0.0802],
       device='cuda:0')
Policy pred: tensor([0.1369, 0.0554, 0.0311, 0.0090, 0.6485, 0.0289, 0.0902],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9879006147384644
 
[Iteration 3] Process ID: 217646 [Epoch: 99,  1632/ 2265 points] total loss per batch: 0.726
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 0.0000e+00, 6.0290e-20, 1.7706e-26, 1.0210e-24, 1.0210e-24,
        4.8843e-21], device='cuda:0')
Policy pred: tensor([9.9994e-01, 4.3537e-12, 1.5042e-05, 1.1248e-08, 5.6999e-07, 1.1561e-06,
        3.8336e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999334216117859
 
[Iteration 3] Process ID: 217646 [Epoch: 99,  2176/ 2265 points] total loss per batch: 0.783
Policy (actual, predicted): 5 5
Policy data: tensor([0.0147, 0.0079, 0.0131, 0.0060, 0.0308, 0.8202, 0.1073],
       device='cuda:0')
Policy pred: tensor([0.0161, 0.0092, 0.0139, 0.0076, 0.0326, 0.8319, 0.0888],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.4138467609882355
 
[Iteration 3] Process ID: 217646 [Epoch: 100,   544/ 2265 points] total loss per batch: 0.821
Policy (actual, predicted): 2 2
Policy data: tensor([1.5156e-05, 1.5863e-11, 7.1788e-01, 1.5533e-13, 2.8211e-01, 7.3477e-12,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.0779e-03, 7.9325e-04, 7.8474e-01, 8.1329e-04, 2.1059e-01, 9.3766e-04,
        4.4498e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.4412139058113098
 
[Iteration 3] Process ID: 217646 [Epoch: 100,  1088/ 2265 points] total loss per batch: 0.811
Policy (actual, predicted): 6 6
Policy data: tensor([2.1453e-07, 2.0364e-11, 4.9192e-10, 1.9421e-17, 1.2193e-11, 1.9128e-09,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([1.6392e-05, 9.6462e-05, 1.5506e-06, 3.4246e-04, 1.6495e-05, 8.7240e-04,
        9.9865e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999793171882629
 
[Iteration 3] Process ID: 217646 [Epoch: 100,  1632/ 2265 points] total loss per batch: 0.753
Policy (actual, predicted): 4 4
Policy data: tensor([2.4962e-14, 3.3005e-07, 1.7682e-28, 1.9442e-16, 1.0000e+00, 1.0441e-23,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([5.6626e-08, 1.5615e-06, 3.6847e-08, 1.4189e-08, 1.0000e+00, 3.0347e-08,
        1.3283e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999570906162262
 
[Iteration 3] Process ID: 217646 [Epoch: 100,  2176/ 2265 points] total loss per batch: 0.790
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000, 0.0000, 0.0000, 0.9975, 0.0000, 0.0025, 0.0000],
       device='cuda:0')
Policy pred: tensor([7.9056e-08, 2.1715e-08, 3.0632e-06, 9.9834e-01, 4.9034e-06, 1.6482e-03,
        7.1474e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999996423721313
 
[Iteration 3] Process ID: 217646 [Epoch: 101,   544/ 2265 points] total loss per batch: 0.752
Policy (actual, predicted): 4 4
Policy data: tensor([0.0169, 0.0081, 0.0099, 0.0043, 0.9326, 0.0062, 0.0220],
       device='cuda:0')
Policy pred: tensor([0.0120, 0.0064, 0.0086, 0.0031, 0.9488, 0.0052, 0.0159],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.5204518437385559
 
[Iteration 3] Process ID: 217646 [Epoch: 101,  1088/ 2265 points] total loss per batch: 0.825
Policy (actual, predicted): 4 4
Policy data: tensor([1.2746e-18, 1.1870e-17, 2.1079e-26, 2.1079e-26, 1.0000e+00, 2.0585e-29,
        2.0103e-22], device='cuda:0')
Policy pred: tensor([7.5831e-06, 2.5705e-04, 3.4859e-05, 5.3815e-04, 9.9817e-01, 1.3703e-05,
        9.8101e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9991635680198669
 
[Iteration 3] Process ID: 217646 [Epoch: 101,  1632/ 2265 points] total loss per batch: 0.821
Policy (actual, predicted): 2 6
Policy data: tensor([0.1419, 0.1477, 0.1489, 0.1442, 0.1336, 0.1372, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1218, 0.1312, 0.1479, 0.1501, 0.1385, 0.1504, 0.1601],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9931633472442627
 
[Iteration 3] Process ID: 217646 [Epoch: 101,  2176/ 2265 points] total loss per batch: 0.791
Policy (actual, predicted): 4 4
Policy data: tensor([2.6439e-18, 4.1700e-22, 2.2460e-12, 2.4623e-17, 1.0000e+00, 4.2700e-19,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([6.6205e-07, 2.3505e-11, 1.3399e-06, 1.2750e-09, 1.0000e+00, 1.6552e-06,
        1.1806e-11], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999987483024597
 
[Iteration 3] Process ID: 217646 [Epoch: 102,   544/ 2265 points] total loss per batch: 0.806
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 5.9327e-17, 1.0000e+00, 9.8117e-25, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.7776e-13, 2.6538e-05, 9.9997e-01, 3.7727e-06, 1.5700e-09, 2.1803e-11,
        1.8952e-12], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 102,  1088/ 2265 points] total loss per batch: 0.781
Policy (actual, predicted): 2 2
Policy data: tensor([0.1033, 0.1106, 0.2405, 0.1733, 0.1929, 0.0723, 0.1070],
       device='cuda:0')
Policy pred: tensor([0.1076, 0.1209, 0.2537, 0.1608, 0.1873, 0.0724, 0.0973],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9988353848457336
 
[Iteration 3] Process ID: 217646 [Epoch: 102,  1632/ 2265 points] total loss per batch: 0.806
Policy (actual, predicted): 0 0
Policy data: tensor([0.8539, 0.0061, 0.0132, 0.0042, 0.0873, 0.0042, 0.0311],
       device='cuda:0')
Policy pred: tensor([0.8510, 0.0050, 0.0141, 0.0052, 0.0892, 0.0057, 0.0298],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.019096221774816513
 
[Iteration 3] Process ID: 217646 [Epoch: 102,  2176/ 2265 points] total loss per batch: 0.789
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 8.2013e-08, 1.6742e-14, 2.9034e-16, 1.0525e-11, 5.1303e-10,
        2.1692e-11], device='cuda:0')
Policy pred: tensor([9.9989e-01, 1.9255e-07, 5.7973e-05, 8.5823e-07, 9.4296e-06, 3.6952e-05,
        7.4502e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999973714351654
 
[Iteration 3] Process ID: 217646 [Epoch: 103,   544/ 2265 points] total loss per batch: 0.755
Policy (actual, predicted): 2 0
Policy data: tensor([0.1454, 0.1442, 0.1524, 0.1313, 0.1512, 0.1348, 0.1407],
       device='cuda:0')
Policy pred: tensor([0.6160, 0.0552, 0.2187, 0.0244, 0.0269, 0.0298, 0.0291],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.0017701759934425354
 
[Iteration 3] Process ID: 217646 [Epoch: 103,  1088/ 2265 points] total loss per batch: 0.775
Policy (actual, predicted): 0 0
Policy data: tensor([0.6989, 0.0379, 0.2309, 0.0059, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6542, 0.0506, 0.1999, 0.0206, 0.0244, 0.0265, 0.0238],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.007984930649399757
 
[Iteration 3] Process ID: 217646 [Epoch: 103,  1632/ 2265 points] total loss per batch: 0.903
Policy (actual, predicted): 5 5
Policy data: tensor([0.0164, 0.0131, 0.0148, 0.0096, 0.0401, 0.8379, 0.0681],
       device='cuda:0')
Policy pred: tensor([0.0212, 0.0193, 0.0210, 0.0122, 0.0485, 0.7892, 0.0884],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.45673975348472595
 
[Iteration 3] Process ID: 217646 [Epoch: 103,  2176/ 2265 points] total loss per batch: 0.749
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 6.4373e-15, 0.0000e+00, 4.3070e-12, 6.5273e-10, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9999e-01, 7.3149e-07, 6.4100e-08, 3.5424e-06, 5.1964e-06, 1.6069e-07,
        6.3573e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9984903931617737
 
[Iteration 3] Process ID: 217646 [Epoch: 104,   544/ 2265 points] total loss per batch: 0.782
Policy (actual, predicted): 6 6
Policy data: tensor([4.4256e-19, 1.7892e-23, 1.0075e-24, 1.7472e-26, 0.0000e+00, 1.0075e-24,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([1.4039e-04, 1.5024e-07, 7.0645e-08, 2.9663e-09, 2.3942e-11, 1.2786e-06,
        9.9986e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999931275844574
 
[Iteration 3] Process ID: 217646 [Epoch: 104,  1088/ 2265 points] total loss per batch: 0.783
Policy (actual, predicted): 2 2
Policy data: tensor([7.1640e-08, 5.2736e-05, 9.9995e-01, 1.7100e-09, 2.5362e-16, 1.3164e-08,
        2.5970e-13], device='cuda:0')
Policy pred: tensor([1.3929e-04, 4.8829e-05, 9.9688e-01, 3.5790e-05, 5.9349e-06, 2.7059e-03,
        1.8221e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999859929084778
 
[Iteration 3] Process ID: 217646 [Epoch: 104,  1632/ 2265 points] total loss per batch: 0.769
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 9.9869e-01, 4.4993e-14, 1.3130e-03, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.9845e-07, 2.7752e-09, 9.9809e-01, 4.8529e-05, 1.8178e-03, 1.6227e-05,
        2.6346e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999985694885254
 
[Iteration 3] Process ID: 217646 [Epoch: 104,  2176/ 2265 points] total loss per batch: 0.849
Policy (actual, predicted): 3 3
Policy data: tensor([0.0729, 0.1156, 0.0729, 0.3226, 0.1056, 0.0368, 0.2738],
       device='cuda:0')
Policy pred: tensor([0.0688, 0.1116, 0.0850, 0.2996, 0.1171, 0.0335, 0.2845],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999994039535522
 
[Iteration 3] Process ID: 217646 [Epoch: 105,   544/ 2265 points] total loss per batch: 0.800
Policy (actual, predicted): 2 2
Policy data: tensor([0.0159, 0.1844, 0.6458, 0.0041, 0.0022, 0.0041, 0.1436],
       device='cuda:0')
Policy pred: tensor([0.0173, 0.1710, 0.6682, 0.0032, 0.0028, 0.0047, 0.1328],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.5050254464149475
 
[Iteration 3] Process ID: 217646 [Epoch: 105,  1088/ 2265 points] total loss per batch: 0.767
Policy (actual, predicted): 0 0
Policy data: tensor([0.5920, 0.0040, 0.1101, 0.0124, 0.1332, 0.0075, 0.1409],
       device='cuda:0')
Policy pred: tensor([0.5852, 0.0060, 0.0997, 0.0133, 0.1201, 0.0128, 0.1629],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9952802658081055
 
[Iteration 3] Process ID: 217646 [Epoch: 105,  1632/ 2265 points] total loss per batch: 0.826
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 1.5813e-07, 1.0000e+00, 1.4487e-28, 0.0000e+00, 5.0511e-19,
        1.1874e-13], device='cuda:0')
Policy pred: tensor([8.9079e-11, 2.7829e-04, 9.9946e-01, 2.2463e-05, 4.3339e-07, 1.9705e-04,
        4.2548e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999940395355225
 
[Iteration 3] Process ID: 217646 [Epoch: 105,  2176/ 2265 points] total loss per batch: 0.773
Policy (actual, predicted): 4 4
Policy data: tensor([4.5025e-17, 2.2870e-26, 0.0000e+00, 4.5025e-17, 1.0000e+00, 6.3087e-21,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.0443e-05, 2.0973e-08, 5.3017e-10, 4.8686e-06, 9.9997e-01, 1.4652e-07,
        1.9539e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 106,   544/ 2265 points] total loss per batch: 0.780
Policy (actual, predicted): 4 4
Policy data: tensor([0.0169, 0.0081, 0.0099, 0.0043, 0.9326, 0.0062, 0.0220],
       device='cuda:0')
Policy pred: tensor([0.0133, 0.0065, 0.0085, 0.0028, 0.9459, 0.0045, 0.0185],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.4783872365951538
 
[Iteration 3] Process ID: 217646 [Epoch: 106,  1088/ 2265 points] total loss per batch: 0.776
Policy (actual, predicted): 5 5
Policy data: tensor([4.1409e-14, 4.8162e-08, 1.0003e-12, 1.8891e-16, 0.0000e+00, 1.0000e+00,
        1.2858e-08], device='cuda:0')
Policy pred: tensor([2.3172e-04, 2.5492e-05, 3.0262e-07, 2.1738e-07, 4.9272e-11, 9.9834e-01,
        1.4048e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999994039535522
 
[Iteration 3] Process ID: 217646 [Epoch: 106,  1632/ 2265 points] total loss per batch: 0.822
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 1.9291e-18, 6.4147e-15, 3.4256e-17, 1.9291e-18, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9997e-01, 1.0586e-09, 2.1217e-05, 1.0428e-07, 5.4705e-06, 2.7769e-10,
        1.4934e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 106,  2176/ 2265 points] total loss per batch: 0.799
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 5.7638e-09, 9.0865e-02, 3.2957e-26, 9.0913e-01, 3.3748e-23,
        1.4316e-06], device='cuda:0')
Policy pred: tensor([2.8049e-07, 4.1871e-03, 9.4650e-02, 3.2875e-04, 8.9858e-01, 1.2988e-05,
        2.2406e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999597668647766
 
[Iteration 3] Process ID: 217646 [Epoch: 107,   544/ 2265 points] total loss per batch: 0.728
Policy (actual, predicted): 5 5
Policy data: tensor([8.1228e-13, 5.5612e-22, 4.6691e-05, 5.3036e-28, 3.1317e-23, 9.9995e-01,
        5.5612e-22], device='cuda:0')
Policy pred: tensor([7.2965e-04, 6.2095e-05, 1.5212e-05, 7.9450e-07, 6.1272e-05, 9.9912e-01,
        1.1629e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9997067451477051
 
[Iteration 3] Process ID: 217646 [Epoch: 107,  1088/ 2265 points] total loss per batch: 0.798
Policy (actual, predicted): 4 4
Policy data: tensor([2.5815e-14, 3.9584e-07, 1.8287e-28, 2.0106e-16, 1.0000e+00, 1.0798e-23,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.0772e-05, 1.4811e-05, 1.1303e-05, 1.1286e-05, 9.9992e-01, 9.7978e-06,
        4.1469e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9990729689598083
 
[Iteration 3] Process ID: 217646 [Epoch: 107,  1632/ 2265 points] total loss per batch: 0.799
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9807e-09, 0.0000e+00, 1.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.7625e-13, 1.0293e-12, 3.3901e-13, 1.2601e-06, 1.0004e-13, 1.0000e+00,
        1.4832e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 217646 [Epoch: 107,  2176/ 2265 points] total loss per batch: 0.819
Policy (actual, predicted): 4 4
Policy data: tensor([0.0289, 0.0211, 0.0060, 0.0078, 0.7522, 0.0078, 0.1762],
       device='cuda:0')
Policy pred: tensor([0.0784, 0.0652, 0.0100, 0.0108, 0.6315, 0.0123, 0.1918],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.0347655788064003
 
[Iteration 3] Process ID: 217646 [Epoch: 108,   544/ 2265 points] total loss per batch: 0.740
Policy (actual, predicted): 5 5
Policy data: tensor([1.1881e-14, 8.3647e-15, 2.8918e-26, 2.8240e-29, 0.0000e+00, 1.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.6303e-04, 7.5053e-05, 1.4765e-04, 3.0580e-07, 8.7188e-09, 9.9961e-01,
        2.4410e-11], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999961256980896
 
[Iteration 3] Process ID: 217646 [Epoch: 108,  1088/ 2265 points] total loss per batch: 0.811
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 1.4229e-18, 6.0319e-17, 3.2394e-24, 3.3171e-21, 1.0000e+00,
        1.5496e-10], device='cuda:0')
Policy pred: tensor([3.8399e-12, 2.1240e-04, 8.8474e-05, 3.5704e-08, 9.2584e-12, 9.9967e-01,
        2.5866e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999942183494568
 
[Iteration 3] Process ID: 217646 [Epoch: 108,  1632/ 2265 points] total loss per batch: 0.822
Policy (actual, predicted): 2 2
Policy data: tensor([0.1372, 0.1419, 0.1500, 0.1419, 0.1430, 0.1407, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1365, 0.1487, 0.1554, 0.1432, 0.1246, 0.1467, 0.1449],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9676121473312378
 
[Iteration 3] Process ID: 217646 [Epoch: 108,  2176/ 2265 points] total loss per batch: 0.794
Policy (actual, predicted): 6 6
Policy data: tensor([0.0694, 0.0000, 0.2733, 0.2135, 0.0000, 0.0523, 0.3915],
       device='cuda:0')
Policy pred: tensor([7.7645e-02, 2.4478e-07, 2.6929e-01, 2.2495e-01, 4.8920e-05, 5.2364e-02,
        3.7570e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999992847442627
 
[Iteration 3] Process ID: 217646 [Epoch: 109,   544/ 2265 points] total loss per batch: 0.851
Policy (actual, predicted): 4 4
Policy data: tensor([6.3865e-13, 1.5612e-09, 1.2062e-16, 4.0722e-21, 1.0000e+00, 2.5819e-17,
        2.0182e-08], device='cuda:0')
Policy pred: tensor([5.6180e-05, 5.9768e-05, 3.3994e-06, 5.9045e-08, 9.9986e-01, 4.7768e-07,
        1.6797e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9989483952522278
 
[Iteration 3] Process ID: 217646 [Epoch: 109,  1088/ 2265 points] total loss per batch: 0.762
Policy (actual, predicted): 0 0
Policy data: tensor([0.2507, 0.1776, 0.1360, 0.1360, 0.0780, 0.0858, 0.1360],
       device='cuda:0')
Policy pred: tensor([0.2184, 0.1807, 0.1448, 0.1368, 0.0667, 0.1100, 0.1426],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 3] Process ID: 217646 [Epoch: 109,  1632/ 2265 points] total loss per batch: 0.731
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 2.5143e-18, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0517e-17,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.1198e-12, 5.5720e-05, 7.4352e-09, 9.9951e-01, 4.9301e-07, 4.2751e-04,
        5.7616e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 3] Process ID: 217646 [Epoch: 109,  2176/ 2265 points] total loss per batch: 0.814
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 2.1646e-15, 3.9188e-13, 8.9607e-17, 1.6430e-16, 0.0000e+00,
        8.5456e-13], device='cuda:0')
Policy pred: tensor([9.9993e-01, 4.8363e-06, 1.9487e-05, 1.8090e-06, 8.5213e-06, 2.2363e-07,
        3.5127e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999650716781616
 
[Iteration 3] Process ID: 217646 [Epoch: 110,   544/ 2265 points] total loss per batch: 0.776
Policy (actual, predicted): 6 6
Policy data: tensor([8.2883e-02, 1.6709e-12, 7.6983e-17, 2.7907e-22, 1.6573e-01, 2.9263e-16,
        7.5139e-01], device='cuda:0')
Policy pred: tensor([6.9622e-02, 1.3406e-05, 1.8394e-03, 1.3494e-04, 1.1336e-01, 4.2315e-04,
        8.1461e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9996561408042908
 
[Iteration 3] Process ID: 217646 [Epoch: 110,  1088/ 2265 points] total loss per batch: 0.769
Policy (actual, predicted): 0 0
Policy data: tensor([9.9245e-01, 3.5568e-15, 2.1507e-07, 1.7841e-05, 5.8823e-23, 4.6762e-10,
        7.5298e-03], device='cuda:0')
Policy pred: tensor([9.9789e-01, 8.8007e-05, 4.5117e-06, 1.4695e-05, 6.7119e-07, 1.6306e-03,
        3.6793e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999818205833435
 
[Iteration 3] Process ID: 217646 [Epoch: 110,  1632/ 2265 points] total loss per batch: 0.792
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0675, 0.0178, 0.0166, 0.0156, 0.0425, 0.0494, 0.7905],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.00917759258300066
 
[Iteration 3] Process ID: 217646 [Epoch: 110,  2176/ 2265 points] total loss per batch: 0.841
Policy (actual, predicted): 4 4
Policy data: tensor([0.0710, 0.0131, 0.0042, 0.0810, 0.8225, 0.0022, 0.0061],
       device='cuda:0')
Policy pred: tensor([0.0755, 0.0132, 0.0034, 0.0588, 0.8409, 0.0015, 0.0065],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.5141164660453796
 
[Iteration 3] Process ID: 217646 [Epoch: 111,   544/ 2265 points] total loss per batch: 0.771
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 1.2661e-16, 0.0000e+00, 6.4311e-26, 1.3241e-11, 1.0000e+00,
        1.0727e-12], device='cuda:0')
Policy pred: tensor([5.7429e-09, 2.0022e-04, 4.4170e-07, 3.0449e-06, 1.5961e-05, 9.9929e-01,
        4.9155e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999148845672607
 
[Iteration 3] Process ID: 217646 [Epoch: 111,  1088/ 2265 points] total loss per batch: 0.813
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 2.3503e-16, 2.4067e-23, 0.0000e+00, 3.8284e-16,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([5.5653e-12, 1.0000e+00, 4.9646e-10, 3.9304e-10, 5.6306e-13, 3.6253e-07,
        5.5064e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999496936798096
 
[Iteration 3] Process ID: 217646 [Epoch: 111,  1632/ 2265 points] total loss per batch: 0.767
Policy (actual, predicted): 5 5
Policy data: tensor([0.0542, 0.0080, 0.0023, 0.0023, 0.0023, 0.8622, 0.0689],
       device='cuda:0')
Policy pred: tensor([0.0356, 0.0061, 0.0011, 0.0013, 0.0014, 0.9264, 0.0281],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999147057533264
 
[Iteration 3] Process ID: 217646 [Epoch: 111,  2176/ 2265 points] total loss per batch: 0.791
Policy (actual, predicted): 4 4
Policy data: tensor([0.0891, 0.0786, 0.0200, 0.0260, 0.4807, 0.0170, 0.2887],
       device='cuda:0')
Policy pred: tensor([0.0581, 0.0676, 0.0241, 0.0189, 0.5753, 0.0149, 0.2411],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9993934035301208
 
[Iteration 3] Process ID: 217646 [Epoch: 112,   544/ 2265 points] total loss per batch: 0.746
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 6.9976e-23, 6.8335e-26, 6.6734e-29, 1.8949e-08, 6.6734e-29,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([9.7365e-08, 4.4566e-05, 1.4026e-03, 8.8757e-05, 6.9855e-04, 4.0210e-04,
        9.9736e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.994678258895874
 
[Iteration 3] Process ID: 217646 [Epoch: 112,  1088/ 2265 points] total loss per batch: 0.811
Policy (actual, predicted): 4 4
Policy data: tensor([0.1714, 0.1108, 0.0925, 0.0357, 0.4551, 0.0237, 0.1108],
       device='cuda:0')
Policy pred: tensor([0.1682, 0.1034, 0.1052, 0.0345, 0.4702, 0.0241, 0.0943],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 112,  1632/ 2265 points] total loss per batch: 0.802
Policy (actual, predicted): 4 4
Policy data: tensor([5.1329e-11, 4.1544e-19, 2.4531e-14, 6.8706e-17, 1.0000e+00, 6.2670e-12,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.4571e-05, 1.6626e-05, 5.1572e-06, 2.8945e-05, 9.9985e-01, 8.1709e-05,
        2.0679e-12], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999975323677063
 
[Iteration 3] Process ID: 217646 [Epoch: 112,  2176/ 2265 points] total loss per batch: 0.806
Policy (actual, predicted): 6 6
Policy data: tensor([1.0984e-09, 1.8166e-17, 3.7975e-21, 6.4311e-26, 3.7975e-21, 3.7085e-24,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([7.3550e-04, 5.1258e-04, 3.8572e-05, 2.4943e-06, 1.5800e-03, 2.6638e-04,
        9.9686e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999675154685974
 
[Iteration 3] Process ID: 217646 [Epoch: 113,   544/ 2265 points] total loss per batch: 0.797
Policy (actual, predicted): 1 4
Policy data: tensor([0.1489, 0.1536, 0.1466, 0.1254, 0.1489, 0.1325, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1556, 0.1529, 0.1510, 0.1073, 0.1560, 0.1245, 0.1528],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9997299909591675
 
[Iteration 3] Process ID: 217646 [Epoch: 113,  1088/ 2265 points] total loss per batch: 0.791
Policy (actual, predicted): 0 0
Policy data: tensor([0.6981, 0.0379, 0.2335, 0.0041, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6396, 0.0511, 0.2119, 0.0215, 0.0244, 0.0269, 0.0247],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.0018771603936329484
 
[Iteration 3] Process ID: 217646 [Epoch: 113,  1632/ 2265 points] total loss per batch: 0.774
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 1.5813e-07, 1.0000e+00, 1.4487e-28, 0.0000e+00, 5.0511e-19,
        1.1874e-13], device='cuda:0')
Policy pred: tensor([1.0979e-11, 1.1004e-04, 9.9975e-01, 2.8939e-05, 3.7466e-08, 7.4611e-05,
        3.6268e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999958872795105
 
[Iteration 3] Process ID: 217646 [Epoch: 113,  2176/ 2265 points] total loss per batch: 0.792
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 4.8621e-12, 8.1791e-13, 2.5243e-15, 1.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.0961e-05, 4.6345e-06, 2.8908e-05, 7.2766e-06, 9.9993e-01, 3.6352e-09,
        2.2703e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999978542327881
 
[Iteration 3] Process ID: 217646 [Epoch: 114,   544/ 2265 points] total loss per batch: 0.831
Policy (actual, predicted): 1 1
Policy data: tensor([0.0093, 0.5251, 0.3807, 0.0093, 0.0206, 0.0076, 0.0474],
       device='cuda:0')
Policy pred: tensor([0.0084, 0.4873, 0.3977, 0.0092, 0.0355, 0.0058, 0.0562],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.08789408951997757
 
[Iteration 3] Process ID: 217646 [Epoch: 114,  1088/ 2265 points] total loss per batch: 0.776
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 0.0000e+00, 1.1199e-05, 1.7671e-05, 0.0000e+00, 9.9997e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.2073e-05, 5.0747e-05, 1.3348e-02, 4.8293e-04, 3.5382e-05, 9.8593e-01,
        1.4337e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999487996101379
 
[Iteration 3] Process ID: 217646 [Epoch: 114,  1632/ 2265 points] total loss per batch: 0.808
Policy (actual, predicted): 0 0
Policy data: tensor([0.3016, 0.1273, 0.1978, 0.0495, 0.1163, 0.0803, 0.1273],
       device='cuda:0')
Policy pred: tensor([0.2769, 0.1092, 0.2162, 0.0714, 0.1137, 0.0928, 0.1199],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999985098838806
 
[Iteration 3] Process ID: 217646 [Epoch: 114,  2176/ 2265 points] total loss per batch: 0.789
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 1.0414e-19, 0.0000e+00, 7.5653e-12, 0.0000e+00, 1.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([6.0373e-17, 6.7646e-11, 8.3049e-15, 5.8722e-06, 1.6506e-12, 9.9999e-01,
        8.7758e-12], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 115,   544/ 2265 points] total loss per batch: 0.792
Policy (actual, predicted): 0 0
Policy data: tensor([0.9586, 0.0063, 0.0063, 0.0043, 0.0082, 0.0063, 0.0100],
       device='cuda:0')
Policy pred: tensor([0.9657, 0.0053, 0.0060, 0.0027, 0.0092, 0.0031, 0.0080],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9742920398712158
 
[Iteration 3] Process ID: 217646 [Epoch: 115,  1088/ 2265 points] total loss per batch: 0.792
Policy (actual, predicted): 1 1
Policy data: tensor([0.0750, 0.2409, 0.0561, 0.1862, 0.1862, 0.0994, 0.1562],
       device='cuda:0')
Policy pred: tensor([0.0752, 0.2484, 0.0555, 0.2266, 0.1588, 0.0832, 0.1523],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999996423721313
 
[Iteration 3] Process ID: 217646 [Epoch: 115,  1632/ 2265 points] total loss per batch: 0.774
Policy (actual, predicted): 5 5
Policy data: tensor([0.0130, 0.0078, 0.0042, 0.0042, 0.0113, 0.7688, 0.1907],
       device='cuda:0')
Policy pred: tensor([0.0144, 0.0047, 0.0053, 0.0030, 0.0100, 0.7092, 0.2535],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9993194341659546
 
[Iteration 3] Process ID: 217646 [Epoch: 115,  2176/ 2265 points] total loss per batch: 0.827
Policy (actual, predicted): 4 4
Policy data: tensor([0.0289, 0.0211, 0.0060, 0.0078, 0.7522, 0.0078, 0.1762],
       device='cuda:0')
Policy pred: tensor([0.0596, 0.0471, 0.0092, 0.0088, 0.6997, 0.0088, 0.1667],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.06866160780191422
 
[Iteration 3] Process ID: 217646 [Epoch: 116,   544/ 2265 points] total loss per batch: 0.761
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 7.9865e-13, 1.0689e-17, 0.0000e+00, 9.8152e-16,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.7531e-12, 1.0000e+00, 4.5115e-10, 5.8432e-09, 9.3869e-15, 6.9887e-07,
        1.3337e-11], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999994039535522
 
[Iteration 3] Process ID: 217646 [Epoch: 116,  1088/ 2265 points] total loss per batch: 0.792
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 4.3166e-13, 0.0000e+00, 6.6084e-11, 9.9585e-01, 4.1535e-03,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.6973e-09, 1.3164e-04, 5.6109e-08, 5.0663e-04, 9.9398e-01, 5.3784e-03,
        7.7956e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999982714653015
 
[Iteration 3] Process ID: 217646 [Epoch: 116,  1632/ 2265 points] total loss per batch: 0.806
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000, 0.0000, 0.0000, 0.1270, 0.0000, 0.1077, 0.7653],
       device='cuda:0')
Policy pred: tensor([4.0508e-05, 2.8359e-05, 3.6622e-05, 1.3034e-01, 1.6042e-04, 1.0984e-01,
        7.5955e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 116,  2176/ 2265 points] total loss per batch: 0.821
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 8.0038e-12, 1.8659e-24, 3.0858e-22, 1.0000e+00, 3.0858e-22,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.3785e-08, 4.9920e-04, 8.1199e-05, 2.5192e-05, 9.9938e-01, 1.0371e-05,
        4.4688e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 117,   544/ 2265 points] total loss per batch: 0.830
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 1.1431e-13, 1.0000e+00, 1.4677e-11, 3.5401e-19, 0.0000e+00,
        1.7756e-11], device='cuda:0')
Policy pred: tensor([1.6786e-07, 2.2363e-05, 9.9979e-01, 1.6683e-06, 1.5324e-05, 9.4230e-06,
        1.6011e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999542832374573
 
[Iteration 3] Process ID: 217646 [Epoch: 117,  1088/ 2265 points] total loss per batch: 0.753
Policy (actual, predicted): 0 0
Policy data: tensor([0.3384, 0.0408, 0.2471, 0.0088, 0.1606, 0.0740, 0.1304],
       device='cuda:0')
Policy pred: tensor([0.3580, 0.0513, 0.2026, 0.0094, 0.1670, 0.0743, 0.1374],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9982283711433411
 
[Iteration 3] Process ID: 217646 [Epoch: 117,  1632/ 2265 points] total loss per batch: 0.819
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 2.5143e-18, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0517e-17,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([7.4104e-12, 2.2347e-05, 8.9969e-09, 9.9868e-01, 5.5991e-06, 1.2638e-03,
        2.7991e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 117,  2176/ 2265 points] total loss per batch: 0.777
Policy (actual, predicted): 6 6
Policy data: tensor([0.3521, 0.0059, 0.0145, 0.0059, 0.0041, 0.0059, 0.6114],
       device='cuda:0')
Policy pred: tensor([0.3291, 0.0084, 0.0173, 0.0081, 0.0063, 0.0078, 0.6231],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.12305060774087906
 
[Iteration 3] Process ID: 217646 [Epoch: 118,   544/ 2265 points] total loss per batch: 0.823
Policy (actual, predicted): 4 4
Policy data: tensor([0.0289, 0.0211, 0.0060, 0.0078, 0.7494, 0.0095, 0.1774],
       device='cuda:0')
Policy pred: tensor([0.0715, 0.0615, 0.0104, 0.0089, 0.6522, 0.0108, 0.1847],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.03626573085784912
 
[Iteration 3] Process ID: 217646 [Epoch: 118,  1088/ 2265 points] total loss per batch: 0.815
Policy (actual, predicted): 6 6
Policy data: tensor([0.0935, 0.1762, 0.1476, 0.1350, 0.1613, 0.0579, 0.2285],
       device='cuda:0')
Policy pred: tensor([0.0950, 0.1841, 0.1437, 0.1348, 0.1521, 0.0606, 0.2297],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 118,  1632/ 2265 points] total loss per batch: 0.797
Policy (actual, predicted): 2 2
Policy data: tensor([0.2095, 0.1991, 0.3056, 0.0973, 0.0860, 0.0164, 0.0860],
       device='cuda:0')
Policy pred: tensor([0.1968, 0.2064, 0.2312, 0.1154, 0.1219, 0.0237, 0.1045],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999342679977417
 
[Iteration 3] Process ID: 217646 [Epoch: 118,  2176/ 2265 points] total loss per batch: 0.747
Policy (actual, predicted): 2 2
Policy data: tensor([0.0203, 0.0099, 0.9290, 0.0043, 0.0081, 0.0099, 0.0186],
       device='cuda:0')
Policy pred: tensor([0.0223, 0.0084, 0.9477, 0.0021, 0.0058, 0.0059, 0.0078],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9987455606460571
 
[Iteration 3] Process ID: 217646 [Epoch: 119,   544/ 2265 points] total loss per batch: 0.748
Policy (actual, predicted): 3 3
Policy data: tensor([0.1339, 0.0000, 0.1733, 0.3619, 0.0000, 0.0283, 0.3026],
       device='cuda:0')
Policy pred: tensor([1.5447e-01, 1.6498e-07, 1.7044e-01, 3.6603e-01, 5.0249e-05, 3.4607e-02,
        2.7440e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999629855155945
 
[Iteration 3] Process ID: 217646 [Epoch: 119,  1088/ 2265 points] total loss per batch: 0.804
Policy (actual, predicted): 5 5
Policy data: tensor([2.8123e-16, 3.7861e-18, 2.8123e-26, 2.8123e-26, 5.5366e-17, 1.0000e+00,
        2.8798e-23], device='cuda:0')
Policy pred: tensor([5.6113e-04, 2.8427e-04, 1.3275e-05, 1.7691e-05, 1.2911e-03, 9.9774e-01,
        9.4293e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9932807087898254
 
[Iteration 3] Process ID: 217646 [Epoch: 119,  1632/ 2265 points] total loss per batch: 0.761
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 9.9090e-01, 0.0000e+00, 3.3593e-08, 9.0964e-03, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.5635e-07, 9.7284e-01, 4.9020e-07, 1.1836e-04, 2.7031e-02, 5.0479e-06,
        4.3439e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999983310699463
 
[Iteration 3] Process ID: 217646 [Epoch: 119,  2176/ 2265 points] total loss per batch: 0.868
Policy (actual, predicted): 2 2
Policy data: tensor([0.0581, 0.0728, 0.5311, 0.0288, 0.1711, 0.0316, 0.1065],
       device='cuda:0')
Policy pred: tensor([0.0724, 0.0816, 0.4839, 0.0253, 0.1831, 0.0428, 0.1110],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999974250793457
 
[Iteration 3] Process ID: 217646 [Epoch: 120,   544/ 2265 points] total loss per batch: 0.764
Policy (actual, predicted): 4 4
Policy data: tensor([0.2003, 0.1342, 0.1483, 0.0895, 0.2037, 0.0993, 0.1247],
       device='cuda:0')
Policy pred: tensor([0.1704, 0.1474, 0.1235, 0.0896, 0.2344, 0.1181, 0.1166],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9987502694129944
 
[Iteration 3] Process ID: 217646 [Epoch: 120,  1088/ 2265 points] total loss per batch: 0.809
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 2.8484e-15, 6.1495e-15, 1.8493e-18, 1.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.2129e-06, 9.4702e-04, 3.7710e-05, 8.4734e-05, 9.9892e-01, 2.6330e-07,
        5.9866e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999633431434631
 
[Iteration 3] Process ID: 217646 [Epoch: 120,  1632/ 2265 points] total loss per batch: 0.822
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 0.0000e+00, 8.2529e-22, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.3400e-10, 9.9994e-01, 8.3036e-08, 5.6873e-05, 5.1484e-09, 2.3504e-07,
        2.5006e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999979734420776
 
[Iteration 3] Process ID: 217646 [Epoch: 120,  2176/ 2265 points] total loss per batch: 0.784
Policy (actual, predicted): 5 5
Policy data: tensor([6.6312e-11, 4.6654e-24, 8.0905e-26, 7.9009e-29, 2.2854e-17, 1.0000e+00,
        5.1296e-12], device='cuda:0')
Policy pred: tensor([3.0896e-03, 1.4899e-04, 3.3404e-04, 2.5610e-05, 4.3627e-05, 9.9420e-01,
        2.1601e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999949932098389
 
[Iteration 3] Process ID: 217646 [Epoch: 121,   544/ 2265 points] total loss per batch: 0.878
Policy (actual, predicted): 4 4
Policy data: tensor([8.0726e-09, 1.1317e-16, 1.1317e-26, 1.1317e-26, 8.9787e-01, 1.1317e-26,
        1.0213e-01], device='cuda:0')
Policy pred: tensor([1.8927e-03, 4.7279e-05, 3.9170e-04, 5.4641e-04, 8.7557e-01, 2.4840e-05,
        1.2153e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9876748323440552
 
[Iteration 3] Process ID: 217646 [Epoch: 121,  1088/ 2265 points] total loss per batch: 0.769
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 0.0000e+00, 9.9999e-01, 5.8720e-06, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.8883e-06, 3.6009e-08, 9.9990e-01, 9.5019e-05, 5.4355e-09, 6.9760e-07,
        2.0054e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999415874481201
 
[Iteration 3] Process ID: 217646 [Epoch: 121,  1632/ 2265 points] total loss per batch: 0.762
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 1.3913e-03, 6.8640e-01, 1.5627e-06, 8.7999e-08, 3.1220e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.6254e-05, 8.5691e-03, 5.3232e-01, 2.0614e-03, 4.7534e-04, 4.5646e-01,
        2.2276e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999997019767761
 
[Iteration 3] Process ID: 217646 [Epoch: 121,  2176/ 2265 points] total loss per batch: 0.756
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 1.3345e-09, 9.9953e-01, 8.1934e-18, 2.1555e-18, 1.8065e-06,
        4.6784e-04], device='cuda:0')
Policy pred: tensor([5.5570e-10, 2.4157e-05, 9.9551e-01, 7.0810e-05, 1.0007e-06, 8.0939e-04,
        3.5867e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999352097511292
 
[Iteration 3] Process ID: 217646 [Epoch: 122,   544/ 2265 points] total loss per batch: 0.796
Policy (actual, predicted): 6 2
Policy data: tensor([0.1524, 0.1431, 0.1477, 0.1313, 0.1442, 0.1266, 0.1547],
       device='cuda:0')
Policy pred: tensor([0.1467, 0.1404, 0.1537, 0.1487, 0.1422, 0.1207, 0.1475],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9993676543235779
 
[Iteration 3] Process ID: 217646 [Epoch: 122,  1088/ 2265 points] total loss per batch: 0.837
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000, 0.0000, 0.3735, 0.1669, 0.2440, 0.0486, 0.1669],
       device='cuda:0')
Policy pred: tensor([5.3087e-06, 4.6707e-06, 3.4806e-01, 1.5242e-01, 2.6097e-01, 5.1054e-02,
        1.8748e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 122,  1632/ 2265 points] total loss per batch: 0.800
Policy (actual, predicted): 4 4
Policy data: tensor([0.0982, 0.0041, 0.0259, 0.0041, 0.7900, 0.0130, 0.0646],
       device='cuda:0')
Policy pred: tensor([0.1104, 0.0045, 0.0217, 0.0052, 0.7843, 0.0149, 0.0590],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.2574756443500519
 
[Iteration 3] Process ID: 217646 [Epoch: 122,  2176/ 2265 points] total loss per batch: 0.738
Policy (actual, predicted): 5 5
Policy data: tensor([0.0147, 0.0079, 0.0131, 0.0060, 0.0308, 0.8202, 0.1073],
       device='cuda:0')
Policy pred: tensor([0.0104, 0.0060, 0.0106, 0.0059, 0.0223, 0.8699, 0.0748],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.4033803343772888
 
[Iteration 3] Process ID: 217646 [Epoch: 123,   544/ 2265 points] total loss per batch: 0.706
Policy (actual, predicted): 4 4
Policy data: tensor([1.7112e-22, 4.9497e-21, 1.7523e-29, 1.7112e-22, 1.0000e+00, 1.7523e-29,
        1.0595e-21], device='cuda:0')
Policy pred: tensor([1.3183e-05, 3.2959e-05, 1.3347e-05, 7.2286e-05, 9.9979e-01, 1.4630e-05,
        6.3083e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9913541674613953
 
[Iteration 3] Process ID: 217646 [Epoch: 123,  1088/ 2265 points] total loss per batch: 0.812
Policy (actual, predicted): 5 5
Policy data: tensor([1.2854e-16, 6.2267e-22, 1.6538e-18, 3.3538e-12, 3.8554e-21, 1.0000e+00,
        3.7651e-14], device='cuda:0')
Policy pred: tensor([3.2352e-05, 7.3196e-05, 1.8926e-05, 2.1694e-04, 7.6144e-05, 9.9839e-01,
        1.1946e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 3] Process ID: 217646 [Epoch: 123,  1632/ 2265 points] total loss per batch: 0.816
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 1.2137e-09, 9.5495e-01, 4.5053e-02, 0.0000e+00, 2.7726e-08,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([7.9737e-08, 1.5742e-03, 9.3937e-01, 5.5899e-02, 1.7670e-03, 1.2510e-03,
        1.3741e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999982714653015
 
[Iteration 3] Process ID: 217646 [Epoch: 123,  2176/ 2265 points] total loss per batch: 0.853
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000, 0.0099, 0.0203, 0.0043, 0.0318, 0.0043, 0.9294],
       device='cuda:0')
Policy pred: tensor([1.4900e-06, 4.3477e-03, 1.6673e-02, 2.3963e-03, 1.3203e-02, 4.9498e-03,
        9.5843e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998672008514404
 
[Iteration 3] Process ID: 217646 [Epoch: 124,   544/ 2265 points] total loss per batch: 0.739
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 8.0649e-11, 3.3760e-26, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.5594e-07, 9.9966e-01, 3.4151e-04, 2.8568e-06, 3.2945e-08, 7.5447e-09,
        6.6086e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 124,  1088/ 2265 points] total loss per batch: 0.794
Policy (actual, predicted): 1 1
Policy data: tensor([1.8966e-10, 1.0000e+00, 1.0215e-10, 1.0215e-10, 1.0215e-10, 5.2820e-11,
        7.2710e-09], device='cuda:0')
Policy pred: tensor([1.5472e-04, 9.9944e-01, 2.5548e-06, 1.2609e-08, 1.3152e-06, 5.2593e-08,
        3.9916e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999982118606567
 
[Iteration 3] Process ID: 217646 [Epoch: 124,  1632/ 2265 points] total loss per batch: 0.807
Policy (actual, predicted): 6 6
Policy data: tensor([4.0343e-04, 3.2719e-17, 3.2799e-03, 1.0376e-09, 0.0000e+00, 1.7993e-21,
        9.9632e-01], device='cuda:0')
Policy pred: tensor([7.4820e-04, 1.4515e-07, 7.9401e-04, 1.5239e-05, 3.4654e-08, 6.6380e-06,
        9.9844e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999325275421143
 
[Iteration 3] Process ID: 217646 [Epoch: 124,  2176/ 2265 points] total loss per batch: 0.838
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 7.9033e-01, 0.0000e+00, 3.5082e-05, 2.0964e-01, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.3702e-05, 8.0865e-01, 1.0802e-05, 1.9022e-03, 1.8929e-01, 5.7479e-05,
        5.3051e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999999463558197
 
[Iteration 3] Process ID: 217646 [Epoch: 125,   544/ 2265 points] total loss per batch: 0.769
Policy (actual, predicted): 5 5
Policy data: tensor([6.2725e-15, 2.4764e-22, 1.7718e-06, 2.3616e-28, 1.4623e-17, 1.0000e+00,
        2.4764e-22], device='cuda:0')
Policy pred: tensor([2.1272e-04, 4.7352e-06, 5.8056e-04, 1.0303e-05, 1.5407e-06, 9.9919e-01,
        6.0392e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9984415769577026
 
[Iteration 3] Process ID: 217646 [Epoch: 125,  1088/ 2265 points] total loss per batch: 0.832
Policy (actual, predicted): 6 6
Policy data: tensor([2.8772e-10, 2.1522e-12, 2.1347e-01, 2.8576e-09, 2.0728e-20, 8.4297e-03,
        7.7810e-01], device='cuda:0')
Policy pred: tensor([5.1090e-03, 8.7477e-04, 4.3795e-01, 1.6470e-03, 1.0161e-04, 7.0328e-03,
        5.4729e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9991714954376221
 
[Iteration 3] Process ID: 217646 [Epoch: 125,  1632/ 2265 points] total loss per batch: 0.735
Policy (actual, predicted): 0 0
Policy data: tensor([0.6964, 0.0379, 0.2333, 0.0059, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6426, 0.0605, 0.2026, 0.0180, 0.0219, 0.0271, 0.0273],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.0039056993555277586
 
[Iteration 3] Process ID: 217646 [Epoch: 125,  2176/ 2265 points] total loss per batch: 0.815
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 1.2137e-09, 9.5495e-01, 4.5053e-02, 0.0000e+00, 2.7726e-08,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.1144e-08, 7.5990e-04, 9.7755e-01, 2.0435e-02, 1.2041e-04, 1.0756e-03,
        5.4096e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999916553497314
 
[Iteration 3] Process ID: 217646 [Epoch: 126,   544/ 2265 points] total loss per batch: 0.826
Policy (actual, predicted): 5 5
Policy data: tensor([0.1363, 0.0880, 0.0489, 0.1983, 0.0556, 0.4095, 0.0635],
       device='cuda:0')
Policy pred: tensor([0.1395, 0.1120, 0.0636, 0.1882, 0.0380, 0.3870, 0.0717],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999987006187439
 
[Iteration 3] Process ID: 217646 [Epoch: 126,  1088/ 2265 points] total loss per batch: 0.822
Policy (actual, predicted): 4 4
Policy data: tensor([0.0151, 0.0080, 0.0062, 0.0023, 0.9010, 0.0098, 0.0577],
       device='cuda:0')
Policy pred: tensor([6.2728e-03, 4.0048e-03, 4.0381e-03, 5.1944e-04, 9.2964e-01, 5.6783e-03,
        4.9842e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.99094557762146
 
[Iteration 3] Process ID: 217646 [Epoch: 126,  1632/ 2265 points] total loss per batch: 0.760
Policy (actual, predicted): 0 0
Policy data: tensor([0.3016, 0.1273, 0.1978, 0.0495, 0.1163, 0.0803, 0.1273],
       device='cuda:0')
Policy pred: tensor([0.2840, 0.1173, 0.1874, 0.0392, 0.1244, 0.0870, 0.1606],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999908208847046
 
[Iteration 3] Process ID: 217646 [Epoch: 126,  2176/ 2265 points] total loss per batch: 0.827
Policy (actual, predicted): 0 0
Policy data: tensor([0.6968, 0.0379, 0.2347, 0.0041, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6397, 0.0506, 0.2305, 0.0171, 0.0191, 0.0220, 0.0209],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.009884689003229141
 
[Iteration 3] Process ID: 217646 [Epoch: 127,   544/ 2265 points] total loss per batch: 0.855
Policy (actual, predicted): 5 5
Policy data: tensor([0.0044, 0.0044, 0.0044, 0.0044, 0.0118, 0.9663, 0.0044],
       device='cuda:0')
Policy pred: tensor([0.0280, 0.0079, 0.0116, 0.0098, 0.0681, 0.8628, 0.0117],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999480843544006
 
[Iteration 3] Process ID: 217646 [Epoch: 127,  1088/ 2265 points] total loss per batch: 0.804
Policy (actual, predicted): 1 1
Policy data: tensor([3.1691e-16, 1.0000e+00, 5.1689e-19, 3.0522e-24, 1.0671e-13, 3.1255e-21,
        3.0522e-14], device='cuda:0')
Policy pred: tensor([3.5793e-03, 9.6520e-01, 2.4383e-03, 5.9695e-05, 9.1734e-03, 3.0730e-03,
        1.6477e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9527235627174377
 
[Iteration 3] Process ID: 217646 [Epoch: 127,  1632/ 2265 points] total loss per batch: 0.850
Policy (actual, predicted): 6 6
Policy data: tensor([1.0693e-14, 1.7418e-14, 6.1661e-23, 1.0693e-24, 0.0000e+00, 4.5177e-04,
        9.9955e-01], device='cuda:0')
Policy pred: tensor([9.4707e-04, 9.3884e-02, 1.5794e-05, 1.2184e-06, 9.7485e-06, 1.7153e-03,
        9.0343e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 127,  2176/ 2265 points] total loss per batch: 0.977
Policy (actual, predicted): 4 4
Policy data: tensor([0.0642, 0.0357, 0.0312, 0.0174, 0.6840, 0.0236, 0.1438],
       device='cuda:0')
Policy pred: tensor([0.1067, 0.0825, 0.0378, 0.0288, 0.6148, 0.0379, 0.0916],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9850788116455078
 
[Iteration 3] Process ID: 217646 [Epoch: 128,   544/ 2265 points] total loss per batch: 0.884
Policy (actual, predicted): 4 4
Policy data: tensor([0.0245, 0.0261, 0.0245, 0.0245, 0.8390, 0.0261, 0.0354],
       device='cuda:0')
Policy pred: tensor([0.0025, 0.0068, 0.0178, 0.0042, 0.9321, 0.0049, 0.0317],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9478150606155396
 
[Iteration 3] Process ID: 217646 [Epoch: 128,  1088/ 2265 points] total loss per batch: 0.867
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 3.0169e-10, 0.0000e+00, 3.2086e-15, 1.6035e-09, 1.9698e-15,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([5.5538e-12, 4.3853e-03, 2.7817e-08, 1.7036e-06, 1.9136e-05, 3.2861e-06,
        9.9559e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998635649681091
 
[Iteration 3] Process ID: 217646 [Epoch: 128,  1632/ 2265 points] total loss per batch: 0.916
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0344, 0.1115, 0.2869, 0.0088, 0.0086, 0.0219, 0.5280],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.0862874910235405
 
[Iteration 3] Process ID: 217646 [Epoch: 128,  2176/ 2265 points] total loss per batch: 0.797
Policy (actual, predicted): 6 6
Policy data: tensor([0.0515, 0.2798, 0.0515, 0.0993, 0.1190, 0.0423, 0.3567],
       device='cuda:0')
Policy pred: tensor([0.0417, 0.3009, 0.0490, 0.0595, 0.1908, 0.0229, 0.3353],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999997079372406
 
[Iteration 3] Process ID: 217646 [Epoch: 129,   544/ 2265 points] total loss per batch: 0.854
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 1.0087e-12, 4.7569e-03, 1.4701e-14, 9.9524e-01, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.1514e-09, 2.9738e-06, 2.9294e-05, 2.2622e-06, 9.9997e-01, 4.4575e-08,
        2.3749e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999998152256012
 
[Iteration 3] Process ID: 217646 [Epoch: 129,  1088/ 2265 points] total loss per batch: 0.849
Policy (actual, predicted): 6 6
Policy data: tensor([0.0240, 0.0144, 0.0128, 0.0128, 0.2738, 0.0077, 0.6546],
       device='cuda:0')
Policy pred: tensor([0.0192, 0.0196, 0.0210, 0.0083, 0.2766, 0.0073, 0.6480],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.7383631467819214
 
[Iteration 3] Process ID: 217646 [Epoch: 129,  1632/ 2265 points] total loss per batch: 0.800
Policy (actual, predicted): 4 4
Policy data: tensor([5.1329e-11, 4.1544e-19, 2.4531e-14, 6.8706e-17, 1.0000e+00, 6.2670e-12,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.7420e-04, 2.4713e-04, 2.1790e-04, 2.5244e-03, 9.9646e-01, 1.7941e-04,
        2.0295e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999192953109741
 
[Iteration 3] Process ID: 217646 [Epoch: 129,  2176/ 2265 points] total loss per batch: 0.831
Policy (actual, predicted): 6 6
Policy data: tensor([0.0223, 0.0374, 0.0284, 0.0605, 0.0159, 0.1096, 0.7258],
       device='cuda:0')
Policy pred: tensor([0.0354, 0.0503, 0.0366, 0.0632, 0.0350, 0.0987, 0.6809],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.15953290462493896
 
[Iteration 3] Process ID: 217646 [Epoch: 130,   544/ 2265 points] total loss per batch: 0.817
Policy (actual, predicted): 0 0
Policy data: tensor([0.6968, 0.0379, 0.2347, 0.0041, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6330, 0.0566, 0.2251, 0.0192, 0.0207, 0.0241, 0.0214],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.009636364877223969
 
[Iteration 3] Process ID: 217646 [Epoch: 130,  1088/ 2265 points] total loss per batch: 0.789
Policy (actual, predicted): 1 1
Policy data: tensor([7.7063e-12, 1.0000e+00, 6.6290e-26, 3.9143e-21, 6.3219e-22, 6.3219e-22,
        4.2030e-12], device='cuda:0')
Policy pred: tensor([4.8103e-09, 1.0000e+00, 4.1369e-09, 3.9961e-07, 1.4822e-06, 2.4170e-07,
        1.3497e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9903796315193176
 
[Iteration 3] Process ID: 217646 [Epoch: 130,  1632/ 2265 points] total loss per batch: 0.825
Policy (actual, predicted): 4 4
Policy data: tensor([0.1501, 0.1501, 0.1442, 0.1266, 0.1571, 0.1230, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1462, 0.1155, 0.1558, 0.1314, 0.1742, 0.1286, 0.1483],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9984801411628723
 
[Iteration 3] Process ID: 217646 [Epoch: 130,  2176/ 2265 points] total loss per batch: 0.772
Policy (actual, predicted): 6 6
Policy data: tensor([1.2771e-13, 4.0164e-12, 1.7474e-20, 6.4866e-23, 1.2471e-16, 6.4866e-23,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([5.6052e-07, 1.8087e-04, 3.1093e-09, 1.3973e-10, 1.2924e-04, 9.4665e-08,
        9.9969e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 3] Process ID: 217646 [Epoch: 131,   544/ 2265 points] total loss per batch: 0.841
Policy (actual, predicted): 4 4
Policy data: tensor([3.6611e-22, 3.7489e-19, 3.6611e-22, 3.8389e-26, 1.0000e+00, 9.9571e-16,
        1.3707e-13], device='cuda:0')
Policy pred: tensor([3.8369e-05, 1.9206e-08, 6.2543e-06, 4.5514e-05, 9.9710e-01, 7.0620e-04,
        2.1002e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999973773956299
 
[Iteration 3] Process ID: 217646 [Epoch: 131,  1088/ 2265 points] total loss per batch: 0.772
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 2.5180e-15, 1.0000e+00, 4.0667e-26, 4.0667e-16, 4.0667e-16,
        1.4180e-16], device='cuda:0')
Policy pred: tensor([2.5905e-06, 7.2459e-04, 9.9387e-01, 7.5220e-07, 2.9411e-04, 4.6903e-03,
        4.2219e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 131,  1632/ 2265 points] total loss per batch: 0.843
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0821, 0.0246, 0.0250, 0.0245, 0.0568, 0.0647, 0.7222],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.01281910203397274
 
[Iteration 3] Process ID: 217646 [Epoch: 131,  2176/ 2265 points] total loss per batch: 0.750
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 9.6702e-17, 0.0000e+00, 2.2047e-13, 1.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.0372e-05, 1.4375e-03, 1.0292e-07, 3.3085e-06, 9.9855e-01, 3.5319e-09,
        1.0922e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999595284461975
 
[Iteration 3] Process ID: 217646 [Epoch: 132,   544/ 2265 points] total loss per batch: 0.759
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000e+00, 1.0000e+00, 1.5088e-07, 9.6383e-10, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.4122e-05, 9.9615e-01, 1.2667e-03, 2.5564e-03, 1.5551e-06, 9.3262e-06,
        4.4085e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 132,  1088/ 2265 points] total loss per batch: 0.823
Policy (actual, predicted): 1 1
Policy data: tensor([0.1407, 0.1512, 0.1454, 0.1430, 0.1372, 0.1360, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1289, 0.1503, 0.1375, 0.1501, 0.1488, 0.1382, 0.1461],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999603629112244
 
[Iteration 3] Process ID: 217646 [Epoch: 132,  1632/ 2265 points] total loss per batch: 0.812
Policy (actual, predicted): 0 0
Policy data: tensor([1.0000e+00, 1.7811e-22, 1.0517e-17, 1.8676e-26, 0.0000e+00, 1.1028e-21,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.9990e-01, 3.5174e-05, 1.1149e-05, 7.9355e-06, 4.8190e-09, 1.0946e-05,
        3.0598e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999988853931427
 
[Iteration 3] Process ID: 217646 [Epoch: 132,  2176/ 2265 points] total loss per batch: 0.756
Policy (actual, predicted): 4 4
Policy data: tensor([0.1477, 0.1419, 0.1501, 0.1313, 0.1524, 0.1336, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1192, 0.1299, 0.1348, 0.1336, 0.1834, 0.1380, 0.1611],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998577833175659
 
[Iteration 3] Process ID: 217646 [Epoch: 133,   544/ 2265 points] total loss per batch: 0.763
Policy (actual, predicted): 4 4
Policy data: tensor([3.7141e-22, 3.8032e-19, 3.7141e-22, 2.2458e-24, 1.0000e+00, 1.0101e-15,
        1.3905e-13], device='cuda:0')
Policy pred: tensor([6.7703e-05, 2.6495e-08, 5.7667e-06, 3.4833e-05, 9.9747e-01, 5.9827e-04,
        1.8237e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999990463256836
 
[Iteration 3] Process ID: 217646 [Epoch: 133,  1088/ 2265 points] total loss per batch: 0.788
Policy (actual, predicted): 4 4
Policy data: tensor([1.7112e-22, 4.9497e-21, 1.7523e-29, 1.7112e-22, 1.0000e+00, 1.7523e-29,
        1.0595e-21], device='cuda:0')
Policy pred: tensor([3.2591e-05, 1.3697e-04, 2.3046e-05, 3.5372e-05, 9.9962e-01, 7.3008e-05,
        7.7029e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.969831109046936
 
[Iteration 3] Process ID: 217646 [Epoch: 133,  1632/ 2265 points] total loss per batch: 0.801
Policy (actual, predicted): 5 5
Policy data: tensor([0.0116, 0.0098, 0.0043, 0.0201, 0.0485, 0.8978, 0.0080],
       device='cuda:0')
Policy pred: tensor([0.0113, 0.0083, 0.0045, 0.0173, 0.0417, 0.9085, 0.0083],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.07816231995820999
 
[Iteration 3] Process ID: 217646 [Epoch: 133,  2176/ 2265 points] total loss per batch: 0.819
Policy (actual, predicted): 1 1
Policy data: tensor([0.0093, 0.5166, 0.3760, 0.0093, 0.0341, 0.0076, 0.0472],
       device='cuda:0')
Policy pred: tensor([0.0095, 0.5650, 0.3300, 0.0092, 0.0323, 0.0082, 0.0458],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.08659333735704422
 
[Iteration 3] Process ID: 217646 [Epoch: 134,   544/ 2265 points] total loss per batch: 0.761
Policy (actual, predicted): 5 5
Policy data: tensor([0.0976, 0.0472, 0.0702, 0.0416, 0.0976, 0.5650, 0.0808],
       device='cuda:0')
Policy pred: tensor([0.0855, 0.0386, 0.0566, 0.0428, 0.0826, 0.6217, 0.0722],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999988675117493
 
[Iteration 3] Process ID: 217646 [Epoch: 134,  1088/ 2265 points] total loss per batch: 0.817
Policy (actual, predicted): 4 4
Policy data: tensor([2.5180e-15, 3.6045e-10, 4.4713e-14, 9.7221e-17, 1.0000e+00, 7.0522e-18,
        1.2214e-06], device='cuda:0')
Policy pred: tensor([3.2034e-05, 1.9529e-08, 1.1077e-09, 2.2364e-08, 9.9978e-01, 2.1671e-06,
        1.8730e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 3] Process ID: 217646 [Epoch: 134,  1632/ 2265 points] total loss per batch: 0.791
Policy (actual, predicted): 6 6
Policy data: tensor([3.6770e-02, 2.6125e-14, 9.8069e-05, 1.2497e-10, 0.0000e+00, 2.6752e-21,
        9.6313e-01], device='cuda:0')
Policy pred: tensor([2.5299e-02, 1.1762e-06, 1.3224e-03, 1.9119e-05, 1.1898e-07, 6.3290e-06,
        9.7335e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999996423721313
 
[Iteration 3] Process ID: 217646 [Epoch: 134,  2176/ 2265 points] total loss per batch: 0.785
Policy (actual, predicted): 0 0
Policy data: tensor([0.3022, 0.0105, 0.2609, 0.0089, 0.0105, 0.2527, 0.1542],
       device='cuda:0')
Policy pred: tensor([0.3154, 0.0132, 0.2811, 0.0096, 0.0072, 0.2038, 0.1696],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.994062066078186
 
[Iteration 3] Process ID: 217646 [Epoch: 135,   544/ 2265 points] total loss per batch: 0.787
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000, 0.0000, 0.0000, 0.9989, 0.0000, 0.0011, 0.0000],
       device='cuda:0')
Policy pred: tensor([2.8611e-07, 1.7014e-06, 4.2587e-07, 9.9799e-01, 1.4083e-04, 1.8482e-03,
        1.6119e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 135,  1088/ 2265 points] total loss per batch: 0.760
Policy (actual, predicted): 5 5
Policy data: tensor([0.1363, 0.0880, 0.0489, 0.1983, 0.0556, 0.4095, 0.0635],
       device='cuda:0')
Policy pred: tensor([0.1791, 0.0822, 0.0443, 0.1970, 0.0520, 0.3836, 0.0618],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999896287918091
 
[Iteration 3] Process ID: 217646 [Epoch: 135,  1632/ 2265 points] total loss per batch: 0.779
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 1.6688e-11, 2.8261e-16, 1.0000e+00, 3.1023e-09, 8.6799e-18,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([6.1942e-08, 2.6241e-05, 2.5471e-04, 9.9925e-01, 3.4687e-04, 1.2619e-04,
        5.3560e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 135,  2176/ 2265 points] total loss per batch: 0.854
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 5.8535e-10, 1.0000e+00, 1.7982e-28, 1.2827e-10, 2.9993e-15,
        3.7023e-14], device='cuda:0')
Policy pred: tensor([3.4186e-10, 6.1877e-05, 9.9972e-01, 5.7104e-09, 2.4677e-05, 1.8274e-04,
        1.0027e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999950110912323
 
[Iteration 3] Process ID: 217646 [Epoch: 136,   544/ 2265 points] total loss per batch: 0.757
Policy (actual, predicted): 6 6
Policy data: tensor([0.0714, 0.0146, 0.0146, 0.0146, 0.0440, 0.0528, 0.7882],
       device='cuda:0')
Policy pred: tensor([0.0618, 0.0175, 0.0170, 0.0181, 0.0444, 0.0510, 0.7900],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.020380178466439247
 
[Iteration 3] Process ID: 217646 [Epoch: 136,  1088/ 2265 points] total loss per batch: 0.856
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 5.4908e-04, 9.9945e-01, 1.4811e-24, 1.4246e-09, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.1562e-07, 1.6773e-03, 9.9329e-01, 5.9558e-04, 4.4326e-03, 2.5655e-06,
        5.6591e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 136,  1632/ 2265 points] total loss per batch: 0.779
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 0.0000e+00, 1.5125e-05, 8.3180e-10, 0.0000e+00, 9.9998e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.3166e-08, 3.6205e-08, 1.9235e-04, 8.4815e-05, 2.2139e-07, 9.9972e-01,
        3.8653e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998704195022583
 
[Iteration 3] Process ID: 217646 [Epoch: 136,  2176/ 2265 points] total loss per batch: 0.774
Policy (actual, predicted): 2 2
Policy data: tensor([1.1126e-14, 2.6497e-02, 9.7350e-01, 1.0865e-17, 0.0000e+00, 2.3257e-08,
        6.8881e-06], device='cuda:0')
Policy pred: tensor([1.7678e-05, 1.4153e-02, 9.8578e-01, 2.2021e-05, 6.7373e-09, 3.9360e-06,
        2.0530e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999984502792358
 
[Iteration 3] Process ID: 217646 [Epoch: 137,   544/ 2265 points] total loss per batch: 0.790
Policy (actual, predicted): 4 4
Policy data: tensor([0.0167, 0.0080, 0.0133, 0.0080, 0.8862, 0.0513, 0.0167],
       device='cuda:0')
Policy pred: tensor([0.0748, 0.0735, 0.0720, 0.0619, 0.5609, 0.0853, 0.0716],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.052973177284002304
 
[Iteration 3] Process ID: 217646 [Epoch: 137,  1088/ 2265 points] total loss per batch: 0.791
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 1.7858e-13, 1.0000e+00, 6.4736e-29, 2.7235e-14, 1.8286e-20,
        2.2043e-12], device='cuda:0')
Policy pred: tensor([1.0056e-07, 6.4992e-04, 9.9687e-01, 9.0146e-05, 1.1334e-03, 8.3018e-05,
        1.1712e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9996738433837891
 
[Iteration 3] Process ID: 217646 [Epoch: 137,  1632/ 2265 points] total loss per batch: 0.855
Policy (actual, predicted): 0 0
Policy data: tensor([9.6982e-01, 1.5738e-17, 3.0178e-02, 9.0755e-16, 1.4657e-16, 9.2933e-13,
        4.1404e-08], device='cuda:0')
Policy pred: tensor([9.7226e-01, 1.4231e-03, 1.9316e-02, 1.4229e-03, 2.2111e-03, 2.0905e-04,
        3.1569e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9970832467079163
 
[Iteration 3] Process ID: 217646 [Epoch: 137,  2176/ 2265 points] total loss per batch: 0.760
Policy (actual, predicted): 4 1
Policy data: tensor([0.1489, 0.1466, 0.1477, 0.1336, 0.1536, 0.1301, 0.1395],
       device='cuda:0')
Policy pred: tensor([0.1327, 0.1844, 0.1427, 0.1525, 0.1641, 0.1150, 0.1086],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.040057241916656494
 
[Iteration 3] Process ID: 217646 [Epoch: 138,   544/ 2265 points] total loss per batch: 0.747
Policy (actual, predicted): 1 1
Policy data: tensor([4.8699e-11, 1.0000e+00, 1.7654e-16, 2.9897e-21, 0.0000e+00, 3.0614e-18,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.4465e-05, 9.9989e-01, 1.4534e-06, 8.5899e-11, 4.2688e-08, 7.2304e-05,
        2.4223e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999999463558197
 
[Iteration 3] Process ID: 217646 [Epoch: 138,  1088/ 2265 points] total loss per batch: 0.790
Policy (actual, predicted): 5 5
Policy data: tensor([4.2726e-06, 4.4817e-01, 1.4043e-08, 1.4178e-04, 1.6572e-05, 5.4795e-01,
        3.7186e-03], device='cuda:0')
Policy pred: tensor([4.9728e-04, 4.7401e-01, 3.2753e-03, 4.3506e-03, 1.3381e-03, 5.1395e-01,
        2.5766e-03], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999962449073792
 
[Iteration 3] Process ID: 217646 [Epoch: 138,  1632/ 2265 points] total loss per batch: 0.838
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 4.2208e-03, 3.0258e-12, 2.0716e-21, 9.9578e-01, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.1291e-09, 7.0162e-04, 3.6321e-05, 6.4633e-07, 9.9926e-01, 3.1280e-07,
        1.0310e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 138,  2176/ 2265 points] total loss per batch: 0.804
Policy (actual, predicted): 0 0
Policy data: tensor([0.8574, 0.0097, 0.0641, 0.0132, 0.0097, 0.0165, 0.0295],
       device='cuda:0')
Policy pred: tensor([0.8642, 0.0105, 0.0588, 0.0133, 0.0093, 0.0183, 0.0255],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9841251969337463
 
[Iteration 3] Process ID: 217646 [Epoch: 139,   544/ 2265 points] total loss per batch: 0.784
Policy (actual, predicted): 2 2
Policy data: tensor([2.1408e-01, 5.3253e-09, 7.8592e-01, 9.0957e-13, 0.0000e+00, 1.7004e-06,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.0410e-01, 1.9330e-03, 7.9109e-01, 4.6597e-06, 1.0152e-06, 2.8639e-03,
        2.7736e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999898672103882
 
[Iteration 3] Process ID: 217646 [Epoch: 139,  1088/ 2265 points] total loss per batch: 0.808
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 3.7643e-05, 0.0000e+00, 7.4641e-03, 9.9250e-01, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.3212e-05, 1.2453e-03, 1.4494e-06, 3.0887e-04, 9.9842e-01, 3.4543e-07,
        1.9130e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999999463558197
 
[Iteration 3] Process ID: 217646 [Epoch: 139,  1632/ 2265 points] total loss per batch: 0.796
Policy (actual, predicted): 2 2
Policy data: tensor([8.3299e-03, 9.3513e-15, 9.9164e-01, 1.6606e-23, 3.5103e-05, 5.6544e-17,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([3.2727e-03, 1.4865e-06, 9.9622e-01, 7.5600e-07, 4.6670e-04, 3.7995e-05,
        1.9514e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9987024068832397
 
[Iteration 3] Process ID: 217646 [Epoch: 139,  2176/ 2265 points] total loss per batch: 0.797
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0238, 0.0935, 0.3462, 0.0085, 0.0064, 0.0113, 0.5103],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.08597047626972198
 
[Iteration 3] Process ID: 217646 [Epoch: 140,   544/ 2265 points] total loss per batch: 0.743
Policy (actual, predicted): 3 3
Policy data: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0304e-09, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.3198e-05, 4.6043e-08, 2.5316e-05, 9.9203e-01, 7.8516e-03, 4.4614e-05,
        7.5292e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 140,  1088/ 2265 points] total loss per batch: 0.785
Policy (actual, predicted): 4 4
Policy data: tensor([0.0169, 0.0081, 0.0099, 0.0043, 0.9326, 0.0062, 0.0220],
       device='cuda:0')
Policy pred: tensor([0.0205, 0.0093, 0.0128, 0.0046, 0.9144, 0.0099, 0.0286],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.502196192741394
 
[Iteration 3] Process ID: 217646 [Epoch: 140,  1632/ 2265 points] total loss per batch: 0.806
Policy (actual, predicted): 3 3
Policy data: tensor([0.1360, 0.1466, 0.1348, 0.1535, 0.1395, 0.1395, 0.1501],
       device='cuda:0')
Policy pred: tensor([0.1338, 0.1466, 0.1327, 0.1606, 0.1361, 0.1439, 0.1463],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9976828694343567
 
[Iteration 3] Process ID: 217646 [Epoch: 140,  2176/ 2265 points] total loss per batch: 0.806
Policy (actual, predicted): 4 4
Policy data: tensor([0.0078, 0.0274, 0.0442, 0.0060, 0.7794, 0.0060, 0.1293],
       device='cuda:0')
Policy pred: tensor([0.0099, 0.0281, 0.0423, 0.0064, 0.7687, 0.0060, 0.1385],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.25765299797058105
 
[Iteration 3] Process ID: 217646 [Epoch: 141,   544/ 2265 points] total loss per batch: 0.771
Policy (actual, predicted): 3 3
Policy data: tensor([1.8852e-15, 0.0000e+00, 1.1953e-21, 1.0000e+00, 0.0000e+00, 1.1673e-24,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([4.3990e-06, 6.5503e-10, 8.4392e-06, 9.9998e-01, 9.7885e-08, 8.0451e-06,
        3.9048e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999695420265198
 
[Iteration 3] Process ID: 217646 [Epoch: 141,  1088/ 2265 points] total loss per batch: 0.844
Policy (actual, predicted): 0 0
Policy data: tensor([9.7847e-01, 1.9785e-08, 2.1533e-02, 4.6043e-10, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.8638e-01, 1.9675e-04, 1.3327e-02, 9.7554e-05, 7.5460e-08, 1.8423e-06,
        1.6732e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999865889549255
 
[Iteration 3] Process ID: 217646 [Epoch: 141,  1632/ 2265 points] total loss per batch: 0.733
Policy (actual, predicted): 6 6
Policy data: tensor([0.0437, 0.0639, 0.2217, 0.0678, 0.0691, 0.0923, 0.4414],
       device='cuda:0')
Policy pred: tensor([0.0341, 0.0654, 0.2085, 0.0647, 0.0523, 0.0830, 0.4920],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.99932461977005
 
[Iteration 3] Process ID: 217646 [Epoch: 141,  2176/ 2265 points] total loss per batch: 0.800
Policy (actual, predicted): 5 5
Policy data: tensor([0.0151, 0.0043, 0.0080, 0.0168, 0.0251, 0.9155, 0.0151],
       device='cuda:0')
Policy pred: tensor([0.0120, 0.0036, 0.0076, 0.0146, 0.0242, 0.9239, 0.0142],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.2690127491950989
 
[Iteration 3] Process ID: 217646 [Epoch: 142,   544/ 2265 points] total loss per batch: 0.806
Policy (actual, predicted): 6 6
Policy data: tensor([0.0509, 0.0337, 0.0537, 0.0203, 0.0495, 0.1670, 0.6250],
       device='cuda:0')
Policy pred: tensor([0.0558, 0.0323, 0.0516, 0.0194, 0.0466, 0.1660, 0.6283],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.03760073706507683
 
[Iteration 3] Process ID: 217646 [Epoch: 142,  1088/ 2265 points] total loss per batch: 0.789
Policy (actual, predicted): 0 0
Policy data: tensor([6.4702e-01, 5.2274e-05, 1.8073e-14, 3.2094e-13, 1.0178e-15, 3.5288e-01,
        4.7547e-05], device='cuda:0')
Policy pred: tensor([0.7131, 0.0033, 0.0026, 0.0008, 0.0009, 0.2765, 0.0028],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999834299087524
 
[Iteration 3] Process ID: 217646 [Epoch: 142,  1632/ 2265 points] total loss per batch: 0.782
Policy (actual, predicted): 6 6
Policy data: tensor([0.0699, 0.0145, 0.0162, 0.0145, 0.0440, 0.0528, 0.7881],
       device='cuda:0')
Policy pred: tensor([0.0673, 0.0218, 0.0243, 0.0219, 0.0513, 0.0546, 0.7588],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.02114882878959179
 
[Iteration 3] Process ID: 217646 [Epoch: 142,  2176/ 2265 points] total loss per batch: 0.806
Policy (actual, predicted): 1 1
Policy data: tensor([5.5746e-05, 8.3478e-01, 5.3362e-07, 1.6614e-04, 1.5155e-01, 7.9611e-07,
        1.3446e-02], device='cuda:0')
Policy pred: tensor([1.5039e-03, 8.2670e-01, 1.4389e-03, 2.2541e-03, 1.5175e-01, 4.0118e-04,
        1.5946e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999525547027588
 
[Iteration 3] Process ID: 217646 [Epoch: 143,   544/ 2265 points] total loss per batch: 0.812
Policy (actual, predicted): 1 1
Policy data: tensor([1.1982e-03, 9.9880e-01, 4.5206e-21, 4.5206e-21, 1.5032e-17, 4.5206e-21,
        4.7623e-07], device='cuda:0')
Policy pred: tensor([5.2854e-04, 9.9910e-01, 1.5830e-06, 8.1907e-08, 1.8461e-04, 2.2646e-07,
        1.8923e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999945759773254
 
[Iteration 3] Process ID: 217646 [Epoch: 143,  1088/ 2265 points] total loss per batch: 0.758
Policy (actual, predicted): 0 0
Policy data: tensor([0.2673, 0.0786, 0.1640, 0.1570, 0.0972, 0.1119, 0.1239],
       device='cuda:0')
Policy pred: tensor([0.2991, 0.0781, 0.1452, 0.1490, 0.0948, 0.1077, 0.1261],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999911367893219
 
[Iteration 3] Process ID: 217646 [Epoch: 143,  1632/ 2265 points] total loss per batch: 0.781
Policy (actual, predicted): 3 3
Policy data: tensor([0., 0., 0., 1., 0., 0., 0.], device='cuda:0')
Policy pred: tensor([6.0323e-05, 2.5679e-06, 2.1149e-05, 9.9986e-01, 5.6724e-07, 6.8010e-06,
        5.2500e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999085664749146
 
[Iteration 3] Process ID: 217646 [Epoch: 143,  2176/ 2265 points] total loss per batch: 0.791
Policy (actual, predicted): 5 5
Policy data: tensor([0.0147, 0.0079, 0.0131, 0.0060, 0.0308, 0.8202, 0.1073],
       device='cuda:0')
Policy pred: tensor([0.0156, 0.0071, 0.0113, 0.0060, 0.0266, 0.8343, 0.0991],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.39091289043426514
 
[Iteration 3] Process ID: 217646 [Epoch: 144,   544/ 2265 points] total loss per batch: 0.750
Policy (actual, predicted): 0 0
Policy data: tensor([0.6968, 0.0379, 0.2347, 0.0041, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.6279, 0.0578, 0.2239, 0.0189, 0.0208, 0.0266, 0.0242],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.0015838058898225427
 
[Iteration 3] Process ID: 217646 [Epoch: 144,  1088/ 2265 points] total loss per batch: 0.847
Policy (actual, predicted): 5 5
Policy data: tensor([0.0151, 0.0043, 0.0080, 0.0168, 0.0251, 0.9155, 0.0151],
       device='cuda:0')
Policy pred: tensor([0.0139, 0.0036, 0.0073, 0.0175, 0.0248, 0.9194, 0.0135],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.2721935212612152
 
[Iteration 3] Process ID: 217646 [Epoch: 144,  1632/ 2265 points] total loss per batch: 0.791
Policy (actual, predicted): 5 5
Policy data: tensor([1.5216e-15, 3.8486e-17, 2.2725e-12, 1.1038e-16, 1.1851e-17, 8.7573e-01,
        1.2427e-01], device='cuda:0')
Policy pred: tensor([8.4801e-04, 2.3516e-03, 9.8479e-04, 2.7161e-04, 1.4843e-04, 9.2784e-01,
        6.7557e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999950528144836
 
[Iteration 3] Process ID: 217646 [Epoch: 144,  2176/ 2265 points] total loss per batch: 0.763
Policy (actual, predicted): 2 2
Policy data: tensor([0.0000e+00, 8.0956e-15, 1.0000e+00, 1.1363e-24, 0.0000e+00, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([6.6142e-07, 1.1168e-04, 9.9986e-01, 2.3834e-05, 5.5365e-07, 2.6191e-07,
        1.2790e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 145,   544/ 2265 points] total loss per batch: 0.835
Policy (actual, predicted): 0 0
Policy data: tensor([0.1512, 0.1454, 0.1466, 0.1360, 0.1512, 0.1277, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1644, 0.1449, 0.1543, 0.1321, 0.1530, 0.1228, 0.1285],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999141097068787
 
[Iteration 3] Process ID: 217646 [Epoch: 145,  1088/ 2265 points] total loss per batch: 0.783
Policy (actual, predicted): 4 2
Policy data: tensor([0.1419, 0.1384, 0.1454, 0.1277, 0.1547, 0.1430, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1391, 0.1399, 0.1582, 0.1266, 0.1502, 0.1482, 0.1378],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999332427978516
 
[Iteration 3] Process ID: 217646 [Epoch: 145,  1632/ 2265 points] total loss per batch: 0.744
Policy (actual, predicted): 6 6
Policy data: tensor([0.1032, 0.1277, 0.1505, 0.0040, 0.0057, 0.0263, 0.5825],
       device='cuda:0')
Policy pred: tensor([0.0807, 0.1279, 0.1595, 0.0031, 0.0083, 0.0300, 0.5904],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9775758981704712
 
[Iteration 3] Process ID: 217646 [Epoch: 145,  2176/ 2265 points] total loss per batch: 0.802
Policy (actual, predicted): 4 4
Policy data: tensor([7.0672e-06, 2.2139e-16, 9.7102e-20, 9.2604e-16, 9.9999e-01, 1.6059e-27,
        7.7193e-07], device='cuda:0')
Policy pred: tensor([4.0745e-04, 4.5996e-06, 4.4536e-07, 5.5769e-06, 9.9953e-01, 5.5461e-06,
        4.4144e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 146,   544/ 2265 points] total loss per batch: 0.770
Policy (actual, predicted): 5 5
Policy data: tensor([0.0313, 0.0133, 0.0233, 0.0061, 0.0200, 0.8943, 0.0115],
       device='cuda:0')
Policy pred: tensor([0.0316, 0.0115, 0.0232, 0.0062, 0.0157, 0.8968, 0.0149],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9995613098144531
 
[Iteration 3] Process ID: 217646 [Epoch: 146,  1088/ 2265 points] total loss per batch: 0.813
Policy (actual, predicted): 6 6
Policy data: tensor([3.8783e-12, 0.0000e+00, 0.0000e+00, 1.1218e-20, 0.0000e+00, 8.1767e-15,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([1.1203e-05, 1.1083e-09, 6.3959e-11, 7.1432e-07, 1.8392e-05, 2.2527e-04,
        9.9974e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999997019767761
 
[Iteration 3] Process ID: 217646 [Epoch: 146,  1632/ 2265 points] total loss per batch: 0.756
Policy (actual, predicted): 6 6
Policy data: tensor([0.0332, 0.0062, 0.0043, 0.0134, 0.0062, 0.0202, 0.9165],
       device='cuda:0')
Policy pred: tensor([0.0280, 0.0048, 0.0041, 0.0104, 0.0064, 0.0159, 0.9304],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.8011991381645203
 
[Iteration 3] Process ID: 217646 [Epoch: 146,  2176/ 2265 points] total loss per batch: 0.846
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7860e-06, 9.9999e-01, 0.0000e+00,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([9.5138e-07, 1.6024e-11, 1.0988e-07, 1.7719e-04, 9.9982e-01, 3.6443e-07,
        9.1044e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 147,   544/ 2265 points] total loss per batch: 0.801
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 7.7026e-04, 5.0560e-09, 6.7591e-07, 2.4424e-09, 9.9923e-01,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([1.0797e-09, 4.3691e-05, 7.4980e-05, 8.4447e-07, 1.4838e-04, 9.9973e-01,
        2.5939e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 147,  1088/ 2265 points] total loss per batch: 0.763
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000, 0.0000, 0.1698, 0.0400, 0.1593, 0.2055, 0.4254],
       device='cuda:0')
Policy pred: tensor([1.4660e-06, 4.5979e-06, 1.8108e-01, 4.0359e-02, 1.4726e-01, 2.0246e-01,
        4.2884e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999998152256012
 
[Iteration 3] Process ID: 217646 [Epoch: 147,  1632/ 2265 points] total loss per batch: 0.771
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000e+00, 1.0798e-15, 3.3088e-11, 4.1045e-15, 1.8286e-20, 3.9143e-21,
        1.0000e+00], device='cuda:0')
Policy pred: tensor([2.3589e-08, 1.6252e-03, 2.6223e-03, 3.4252e-05, 1.8014e-03, 5.2231e-04,
        9.9339e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999995231628418
 
[Iteration 3] Process ID: 217646 [Epoch: 147,  2176/ 2265 points] total loss per batch: 0.834
Policy (actual, predicted): 4 4
Policy data: tensor([0.0224, 0.0346, 0.1495, 0.0176, 0.7247, 0.0077, 0.0435],
       device='cuda:0')
Policy pred: tensor([0.0235, 0.0497, 0.2226, 0.0120, 0.6473, 0.0083, 0.0367],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999992251396179
 
[Iteration 3] Process ID: 217646 [Epoch: 148,   544/ 2265 points] total loss per batch: 0.753
Policy (actual, predicted): 6 6
Policy data: tensor([2.0119e-10, 2.3128e-19, 0.0000e+00, 4.2055e-15, 6.0559e-03, 2.3128e-19,
        9.9394e-01], device='cuda:0')
Policy pred: tensor([1.1161e-04, 2.5923e-06, 7.2208e-10, 7.8717e-06, 4.2280e-03, 6.9822e-05,
        9.9558e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 3] Process ID: 217646 [Epoch: 148,  1088/ 2265 points] total loss per batch: 0.799
Policy (actual, predicted): 0 0
Policy data: tensor([9.7838e-01, 3.5255e-15, 2.1615e-02, 8.8249e-09, 2.8733e-07, 8.2188e-08,
        6.6929e-07], device='cuda:0')
Policy pred: tensor([9.7205e-01, 1.2122e-05, 2.7399e-02, 1.1759e-05, 1.5518e-05, 3.2694e-04,
        1.8471e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999327659606934
 
[Iteration 3] Process ID: 217646 [Epoch: 148,  1632/ 2265 points] total loss per batch: 0.843
Policy (actual, predicted): 0 0
Policy data: tensor([0.6968, 0.0379, 0.2347, 0.0041, 0.0041, 0.0128, 0.0095],
       device='cuda:0')
Policy pred: tensor([0.5832, 0.0644, 0.2206, 0.0293, 0.0295, 0.0384, 0.0345],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.0011558174155652523
 
[Iteration 3] Process ID: 217646 [Epoch: 148,  2176/ 2265 points] total loss per batch: 0.789
Policy (actual, predicted): 0 0
Policy data: tensor([0.9118, 0.0099, 0.0503, 0.0023, 0.0081, 0.0043, 0.0134],
       device='cuda:0')
Policy pred: tensor([0.9339, 0.0055, 0.0402, 0.0014, 0.0081, 0.0016, 0.0093],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999976396560669
 
[Iteration 3] Process ID: 217646 [Epoch: 149,   544/ 2265 points] total loss per batch: 0.767
Policy (actual, predicted): 0 0
Policy data: tensor([0.7931, 0.0130, 0.0113, 0.0042, 0.0983, 0.0113, 0.0690],
       device='cuda:0')
Policy pred: tensor([0.7261, 0.0153, 0.0189, 0.0068, 0.1224, 0.0161, 0.0945],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9891098737716675
 
[Iteration 3] Process ID: 217646 [Epoch: 149,  1088/ 2265 points] total loss per batch: 0.811
Policy (actual, predicted): 6 6
Policy data: tensor([0.0205, 0.1017, 0.3574, 0.0058, 0.0040, 0.0092, 0.5015],
       device='cuda:0')
Policy pred: tensor([0.0226, 0.0966, 0.3236, 0.0078, 0.0060, 0.0103, 0.5331],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.09164204448461533
 
[Iteration 3] Process ID: 217646 [Epoch: 149,  1632/ 2265 points] total loss per batch: 0.719
Policy (actual, predicted): 2 2
Policy data: tensor([2.2110e-05, 1.2451e-06, 9.9998e-01, 3.3586e-27, 2.0308e-19, 2.0796e-16,
        1.7666e-10], device='cuda:0')
Policy pred: tensor([1.5519e-03, 6.2493e-04, 9.9772e-01, 3.2016e-06, 8.0205e-05, 1.9203e-06,
        2.0907e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999986290931702
 
[Iteration 3] Process ID: 217646 [Epoch: 149,  2176/ 2265 points] total loss per batch: 0.839
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000e+00, 5.0235e-15, 1.1437e-20, 1.9368e-25, 0.0000e+00, 1.0000e+00,
        1.4190e-06], device='cuda:0')
Policy pred: tensor([2.4627e-12, 3.0374e-05, 5.7234e-05, 3.0670e-06, 1.1626e-10, 9.9988e-01,
        3.1809e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999703764915466
 
[Iteration 3] Process ID: 217646 [Epoch: 150,   544/ 2265 points] total loss per batch: 0.817
Policy (actual, predicted): 2 2
Policy data: tensor([2.0474e-01, 5.9969e-09, 7.9526e-01, 1.3380e-12, 0.0000e+00, 7.8164e-07,
        0.0000e+00], device='cuda:0')
Policy pred: tensor([2.1819e-01, 9.2868e-04, 7.7826e-01, 8.0456e-06, 2.4493e-06, 2.6060e-03,
        2.6486e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999377727508545
 
[Iteration 3] Process ID: 217646 [Epoch: 150,  1088/ 2265 points] total loss per batch: 0.774
Policy (actual, predicted): 4 0
Policy data: tensor([0.1466, 0.1466, 0.1489, 0.1336, 0.1524, 0.1325, 0.1395],
       device='cuda:0')
Policy pred: tensor([0.6582, 0.0521, 0.2068, 0.0168, 0.0212, 0.0243, 0.0206],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.008081470616161823
 
[Iteration 3] Process ID: 217646 [Epoch: 150,  1632/ 2265 points] total loss per batch: 0.762
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0745, 0.0212, 0.0213, 0.0226, 0.0511, 0.0618, 0.7475],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.01799049787223339
 
[Iteration 3] Process ID: 217646 [Epoch: 150,  2176/ 2265 points] total loss per batch: 0.804
Policy (actual, predicted): 6 6
Policy data: tensor([0.0713, 0.0145, 0.0162, 0.0145, 0.0439, 0.0527, 0.7867],
       device='cuda:0')
Policy pred: tensor([0.0642, 0.0190, 0.0180, 0.0193, 0.0452, 0.0513, 0.7830],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.020948363468050957
 
