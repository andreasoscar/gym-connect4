04/07/2022 02:59:30 PM [INFO]: Preparing model for multi-process MCTS...
04/07/2022 02:59:30 PM [INFO]: Loaded cc4_current_net__iter5.pth.tar model.
04/07/2022 02:59:30 PM [INFO]: Spawning 12 processes...
START TIME:  14:59:17
04/07/2022 02:59:35 PM [INFO]: [CPU: 7]: Starting MCTS self-play...
04/07/2022 02:59:35 PM [INFO]: [CPU: 4]: Starting MCTS self-play...
04/07/2022 02:59:35 PM [INFO]: [CPU: 3]: Starting MCTS self-play...
04/07/2022 02:59:35 PM [INFO]: [CPU: 0]: Starting MCTS self-play...
04/07/2022 02:59:35 PM [INFO]: [CPU: 5]: Starting MCTS self-play...
04/07/2022 02:59:35 PM [INFO]: [CPU: 2]: Starting MCTS self-play...
04/07/2022 02:59:35 PM [INFO]: [CPU: 8]: Starting MCTS self-play...
04/07/2022 02:59:35 PM [INFO]: [CPU: 10]: Starting MCTS self-play...
04/07/2022 02:59:35 PM [INFO]: [CPU: 1]: Starting MCTS self-play...
04/07/2022 02:59:35 PM [INFO]: [CPU: 9]: Starting MCTS self-play...
04/07/2022 02:59:35 PM [INFO]: [CPU: 6]: Starting MCTS self-play...
04/07/2022 02:59:35 PM [INFO]: [CPU: 11]: Starting MCTS self-play...
  0%|          | 0/120 [00:00<?, ?it/s]  0%|          | 0/120 [00:00<?, ?it/s]04/07/2022 02:59:35 PM [INFO]: [CPU: 1]: Game 0
04/07/2022 02:59:35 PM [INFO]: [CPU: 0]: Game 0
  0%|          | 0/120 [00:00<?, ?it/s]04/07/2022 02:59:35 PM [INFO]: [CPU: 5]: Game 0
  0%|          | 0/120 [00:00<?, ?it/s]04/07/2022 02:59:35 PM [INFO]: [CPU: 10]: Game 0
  0%|          | 0/120 [00:00<?, ?it/s]04/07/2022 02:59:35 PM [INFO]: [CPU: 3]: Game 0
  0%|          | 0/120 [00:00<?, ?it/s]  0%|          | 0/120 [00:00<?, ?it/s]  0%|          | 0/120 [00:00<?, ?it/s]  0%|          | 0/120 [00:00<?, ?it/s]04/07/2022 02:59:35 PM [INFO]: [CPU: 8]: Game 0
  0%|          | 0/120 [00:00<?, ?it/s]04/07/2022 02:59:35 PM [INFO]: [CPU: 6]: Game 0
04/07/2022 02:59:35 PM [INFO]: [CPU: 9]: Game 0
  0%|          | 0/120 [00:00<?, ?it/s]  0%|          | 0/120 [00:00<?, ?it/s]04/07/2022 02:59:35 PM [INFO]: [CPU: 11]: Game 0
04/07/2022 02:59:35 PM [INFO]: [CPU: 2]: Game 0
04/07/2022 02:59:35 PM [INFO]: [CPU: 7]: Game 0
04/07/2022 02:59:35 PM [INFO]: [CPU: 4]: Game 0
  1%|          | 1/120 [01:47<3:33:59, 107.90s/it]  1%|          | 1/120 [01:47<3:34:06, 107.95s/it]04/07/2022 03:01:23 PM [INFO]: [CPU: 0]: Game 1
04/07/2022 03:01:23 PM [INFO]: [CPU: 11]: Game 1
  1%|          | 1/120 [02:01<4:01:36, 121.82s/it]04/07/2022 03:01:37 PM [INFO]: [CPU: 9]: Game 1
  1%|          | 1/120 [02:08<4:15:24, 128.77s/it]04/07/2022 03:01:44 PM [INFO]: [CPU: 4]: Game 1
  1%|          | 1/120 [02:08<4:15:48, 128.98s/it]04/07/2022 03:01:44 PM [INFO]: [CPU: 6]: Game 1
  1%|          | 1/120 [02:22<4:42:49, 142.60s/it]04/07/2022 03:01:58 PM [INFO]: [CPU: 2]: Game 1
  1%|          | 1/120 [02:22<4:42:58, 142.68s/it]04/07/2022 03:01:58 PM [INFO]: [CPU: 1]: Game 1
  1%|          | 1/120 [02:43<5:24:06, 163.42s/it]04/07/2022 03:02:18 PM [INFO]: [CPU: 8]: Game 1
  1%|          | 1/120 [02:43<5:24:14, 163.48s/it]04/07/2022 03:02:18 PM [INFO]: [CPU: 5]: Game 1
  1%|          | 1/120 [02:57<5:51:28, 177.22s/it]04/07/2022 03:02:32 PM [INFO]: [CPU: 3]: Game 1
  1%|          | 1/120 [02:57<5:51:41, 177.32s/it]04/07/2022 03:02:32 PM [INFO]: [CPU: 7]: Game 1
  2%|▏         | 2/120 [03:25<3:14:56, 99.13s/it] 04/07/2022 03:03:00 PM [INFO]: [CPU: 9]: Game 2
  2%|▏         | 2/120 [03:39<3:36:00, 109.83s/it]04/07/2022 03:03:14 PM [INFO]: [CPU: 11]: Game 2
  1%|          | 1/120 [04:07<8:10:06, 247.12s/it]04/07/2022 03:03:42 PM [INFO]: [CPU: 10]: Game 1
  2%|▎         | 3/120 [04:13<2:28:16, 76.04s/it]04/07/2022 03:03:49 PM [INFO]: [CPU: 9]: Game 3
  2%|▏         | 2/120 [04:20<4:24:02, 134.26s/it]04/07/2022 03:03:56 PM [INFO]: [CPU: 0]: Game 2
  2%|▏         | 2/120 [04:27<4:12:41, 128.49s/it]04/07/2022 03:04:02 PM [INFO]: [CPU: 8]: Game 2
  2%|▏         | 2/120 [04:27<4:12:45, 128.52s/it]04/07/2022 03:04:03 PM [INFO]: [CPU: 5]: Game 2
  2%|▏         | 2/120 [04:41<4:23:54, 134.19s/it]04/07/2022 03:04:16 PM [INFO]: [CPU: 7]: Game 2
  2%|▏         | 2/120 [04:41<4:36:02, 140.36s/it]04/07/2022 03:04:16 PM [INFO]: [CPU: 1]: Game 2
  2%|▏         | 2/120 [05:02<5:04:54, 155.04s/it]04/07/2022 03:04:37 PM [INFO]: [CPU: 4]: Game 2
  2%|▏         | 2/120 [05:16<5:21:07, 163.28s/it]04/07/2022 03:04:51 PM [INFO]: [CPU: 6]: Game 2
  3%|▎         | 4/120 [06:04<2:53:48, 89.90s/it]04/07/2022 03:05:40 PM [INFO]: [CPU: 9]: Game 4
  2%|▏         | 2/120 [06:11<6:08:22, 187.31s/it]04/07/2022 03:05:47 PM [INFO]: [CPU: 3]: Game 2
  2%|▎         | 3/120 [06:11<4:01:14, 123.72s/it]04/07/2022 03:05:47 PM [INFO]: [CPU: 0]: Game 3
  2%|▎         | 3/120 [06:32<4:07:32, 126.95s/it]04/07/2022 03:06:08 PM [INFO]: [CPU: 8]: Game 3
  2%|▏         | 2/120 [06:46<7:00:36, 213.87s/it]04/07/2022 03:06:21 PM [INFO]: [CPU: 2]: Game 2
  2%|▎         | 3/120 [06:53<4:19:54, 133.29s/it]04/07/2022 03:06:29 PM [INFO]: [CPU: 7]: Game 3
  2%|▏         | 2/120 [07:01<6:41:19, 204.06s/it]04/07/2022 03:06:36 PM [INFO]: [CPU: 10]: Game 2
  2%|▎         | 3/120 [07:21<4:51:10, 149.32s/it]04/07/2022 03:06:56 PM [INFO]: [CPU: 1]: Game 3
  2%|▎         | 3/120 [07:28<4:54:22, 150.97s/it]04/07/2022 03:07:03 PM [INFO]: [CPU: 4]: Game 3
  2%|▎         | 3/120 [07:42<5:09:33, 158.75s/it]04/07/2022 03:07:17 PM [INFO]: [CPU: 5]: Game 3
  2%|▎         | 3/120 [07:49<5:39:08, 173.92s/it]04/07/2022 03:07:24 PM [INFO]: [CPU: 11]: Game 3
  2%|▎         | 3/120 [07:49<5:09:42, 158.83s/it]04/07/2022 03:07:25 PM [INFO]: [CPU: 6]: Game 3
  2%|▎         | 3/120 [07:49<4:19:39, 133.16s/it]04/07/2022 03:07:25 PM [INFO]: [CPU: 10]: Game 3
  4%|▍         | 5/120 [08:03<3:11:58, 100.16s/it]04/07/2022 03:07:38 PM [INFO]: [CPU: 9]: Game 5
  3%|▎         | 4/120 [08:10<3:34:24, 110.90s/it]04/07/2022 03:07:45 PM [INFO]: [CPU: 7]: Game 4
  2%|▎         | 3/120 [08:23<5:13:25, 160.73s/it]04/07/2022 03:07:59 PM [INFO]: [CPU: 2]: Game 3
  2%|▎         | 3/120 [08:30<5:22:31, 165.40s/it]04/07/2022 03:08:06 PM [INFO]: [CPU: 3]: Game 3
  3%|▎         | 4/120 [08:51<4:00:23, 124.34s/it]04/07/2022 03:08:27 PM [INFO]: [CPU: 4]: Game 4
  3%|▎         | 4/120 [08:51<4:14:51, 131.82s/it]04/07/2022 03:08:27 PM [INFO]: [CPU: 8]: Game 4
  3%|▎         | 4/120 [09:05<4:09:30, 129.05s/it]04/07/2022 03:08:41 PM [INFO]: [CPU: 5]: Game 4
  3%|▎         | 4/120 [09:05<4:37:37, 143.60s/it]04/07/2022 03:08:41 PM [INFO]: [CPU: 0]: Game 4
  5%|▌         | 6/120 [09:19<2:55:04, 92.15s/it] 04/07/2022 03:08:55 PM [INFO]: [CPU: 9]: Game 6
  3%|▎         | 4/120 [09:19<4:25:03, 137.10s/it]04/07/2022 03:08:55 PM [INFO]: [CPU: 1]: Game 4
  3%|▎         | 4/120 [09:47<4:11:48, 130.24s/it]04/07/2022 03:09:22 PM [INFO]: [CPU: 2]: Game 4
  4%|▍         | 5/120 [09:54<3:15:41, 102.10s/it]04/07/2022 03:09:30 PM [INFO]: [CPU: 4]: Game 5
  3%|▎         | 4/120 [10:02<4:47:01, 148.47s/it]04/07/2022 03:09:37 PM [INFO]: [CPU: 6]: Game 4
  4%|▍         | 5/120 [10:29<3:52:07, 121.11s/it]04/07/2022 03:10:04 PM [INFO]: [CPU: 7]: Game 5
  3%|▎         | 4/120 [10:29<5:25:48, 168.52s/it]04/07/2022 03:10:05 PM [INFO]: [CPU: 11]: Game 4
  3%|▎         | 4/120 [10:36<4:43:19, 146.55s/it]04/07/2022 03:10:12 PM [INFO]: [CPU: 10]: Game 4
  4%|▍         | 5/120 [10:50<4:03:20, 126.96s/it]04/07/2022 03:10:25 PM [INFO]: [CPU: 8]: Game 5
  4%|▍         | 5/120 [11:04<4:00:08, 125.29s/it]04/07/2022 03:10:39 PM [INFO]: [CPU: 1]: Game 5
  3%|▎         | 4/120 [11:10<5:15:39, 163.27s/it]04/07/2022 03:10:46 PM [INFO]: [CPU: 3]: Game 4
  4%|▍         | 5/120 [11:25<4:14:24, 132.74s/it]04/07/2022 03:11:00 PM [INFO]: [CPU: 5]: Game 5
  4%|▍         | 5/120 [11:31<3:51:47, 120.94s/it]04/07/2022 03:11:07 PM [INFO]: [CPU: 2]: Game 5
  4%|▍         | 5/120 [11:59<3:53:48, 121.98s/it]04/07/2022 03:11:35 PM [INFO]: [CPU: 3]: Game 5
  4%|▍         | 5/120 [12:07<4:28:34, 140.13s/it]04/07/2022 03:11:43 PM [INFO]: [CPU: 6]: Game 5
  4%|▍         | 5/120 [12:42<4:58:12, 155.59s/it]04/07/2022 03:12:17 PM [INFO]: [CPU: 11]: Game 5
  6%|▌         | 7/120 [12:48<4:05:21, 130.28s/it]04/07/2022 03:12:24 PM [INFO]: [CPU: 9]: Game 7
  4%|▍         | 5/120 [12:55<5:34:39, 174.60s/it]04/07/2022 03:12:30 PM [INFO]: [CPU: 0]: Game 5
  5%|▌         | 6/120 [13:16<4:13:35, 133.47s/it]04/07/2022 03:12:51 PM [INFO]: [CPU: 8]: Game 6
  5%|▌         | 6/120 [13:30<3:48:05, 120.05s/it]04/07/2022 03:13:05 PM [INFO]: [CPU: 2]: Game 6
  5%|▌         | 6/120 [13:30<4:11:32, 132.39s/it]04/07/2022 03:13:05 PM [INFO]: [CPU: 1]: Game 6
  5%|▌         | 6/120 [13:37<4:33:15, 143.82s/it]04/07/2022 03:13:12 PM [INFO]: [CPU: 7]: Game 6
  4%|▍         | 5/120 [13:44<5:09:27, 161.46s/it]04/07/2022 03:13:20 PM [INFO]: [CPU: 10]: Game 5
  5%|▌         | 6/120 [13:58<4:25:19, 139.64s/it]04/07/2022 03:13:33 PM [INFO]: [CPU: 5]: Game 6
  5%|▌         | 6/120 [14:19<4:58:53, 157.31s/it]04/07/2022 03:13:54 PM [INFO]: [CPU: 4]: Game 6
  6%|▌         | 7/120 [14:46<3:19:17, 105.82s/it]04/07/2022 03:14:22 PM [INFO]: [CPU: 2]: Game 7
  5%|▌         | 6/120 [14:47<4:39:05, 146.89s/it]04/07/2022 03:14:23 PM [INFO]: [CPU: 6]: Game 6
  6%|▌         | 7/120 [15:00<3:53:42, 124.10s/it]04/07/2022 03:14:36 PM [INFO]: [CPU: 7]: Game 7
  7%|▋         | 8/120 [15:07<4:08:27, 133.10s/it]04/07/2022 03:14:43 PM [INFO]: [CPU: 9]: Game 8
  6%|▌         | 7/120 [15:07<3:49:22, 121.79s/it]04/07/2022 03:14:43 PM [INFO]: [CPU: 4]: Game 7
  5%|▌         | 6/120 [15:35<4:52:15, 153.82s/it]04/07/2022 03:15:10 PM [INFO]: [CPU: 3]: Game 6
  5%|▌         | 6/120 [15:49<5:31:19, 174.38s/it]04/07/2022 03:15:24 PM [INFO]: [CPU: 0]: Game 6
  5%|▌         | 6/120 [15:57<4:47:52, 151.52s/it]04/07/2022 03:15:32 PM [INFO]: [CPU: 10]: Game 6
  6%|▌         | 7/120 [16:03<4:22:04, 139.15s/it]04/07/2022 03:15:38 PM [INFO]: [CPU: 1]: Game 7
  7%|▋         | 8/120 [16:03<3:15:10, 104.56s/it]04/07/2022 03:15:38 PM [INFO]: [CPU: 7]: Game 8
  8%|▊         | 9/120 [16:10<3:25:29, 111.07s/it]04/07/2022 03:15:45 PM [INFO]: [CPU: 9]: Game 9
  6%|▌         | 7/120 [16:17<4:40:42, 149.05s/it]04/07/2022 03:15:52 PM [INFO]: [CPU: 8]: Game 7
  5%|▌         | 6/120 [16:17<5:34:26, 176.02s/it]04/07/2022 03:15:53 PM [INFO]: [CPU: 11]: Game 6
  6%|▌         | 7/120 [16:45<4:40:03, 148.71s/it]04/07/2022 03:16:20 PM [INFO]: [CPU: 5]: Game 7
  6%|▌         | 7/120 [16:46<4:19:03, 137.55s/it]04/07/2022 03:16:21 PM [INFO]: [CPU: 6]: Game 7
  7%|▋         | 8/120 [16:52<3:29:10, 112.05s/it]04/07/2022 03:16:27 PM [INFO]: [CPU: 2]: Game 8
  6%|▌         | 7/120 [17:06<4:13:09, 134.42s/it]04/07/2022 03:16:42 PM [INFO]: [CPU: 11]: Game 7
  7%|▋         | 8/120 [17:33<4:01:52, 129.57s/it]04/07/2022 03:17:09 PM [INFO]: [CPU: 4]: Game 8
  6%|▌         | 7/120 [17:40<4:49:42, 153.83s/it]04/07/2022 03:17:16 PM [INFO]: [CPU: 0]: Game 7
  6%|▌         | 7/120 [17:47<4:36:24, 146.77s/it]04/07/2022 03:17:23 PM [INFO]: [CPU: 3]: Game 7
  7%|▋         | 8/120 [18:01<4:11:44, 134.86s/it]04/07/2022 03:17:37 PM [INFO]: [CPU: 8]: Game 8
  6%|▌         | 7/120 [18:23<4:42:01, 149.75s/it]04/07/2022 03:17:58 PM [INFO]: [CPU: 10]: Game 7
  7%|▋         | 8/120 [18:29<4:23:57, 141.40s/it]04/07/2022 03:18:05 PM [INFO]: [CPU: 1]: Game 8
  7%|▋         | 8/120 [18:43<3:39:50, 117.78s/it]04/07/2022 03:18:18 PM [INFO]: [CPU: 3]: Game 8
  8%|▊         | 9/120 [18:43<3:26:54, 111.84s/it]04/07/2022 03:18:18 PM [INFO]: [CPU: 2]: Game 9
  7%|▋         | 8/120 [18:57<4:27:55, 143.53s/it]04/07/2022 03:18:33 PM [INFO]: [CPU: 5]: Game 8
  8%|▊         | 10/120 [19:11<4:03:12, 132.66s/it]04/07/2022 03:18:46 PM [INFO]: [CPU: 9]: Game 10
  7%|▋         | 8/120 [19:18<4:09:37, 133.73s/it]04/07/2022 03:18:54 PM [INFO]: [CPU: 11]: Game 8
  7%|▋         | 8/120 [19:19<4:26:04, 142.54s/it]04/07/2022 03:18:54 PM [INFO]: [CPU: 6]: Game 8
  8%|▊         | 9/120 [19:25<4:09:41, 134.97s/it]04/07/2022 03:19:00 PM [INFO]: [CPU: 7]: Game 9
  8%|▊         | 9/120 [19:32<2:57:59, 96.21s/it] 04/07/2022 03:19:07 PM [INFO]: [CPU: 3]: Game 9
  8%|▊         | 9/120 [19:53<3:34:50, 116.13s/it]04/07/2022 03:19:29 PM [INFO]: [CPU: 5]: Game 9
  8%|▊         | 9/120 [20:00<3:59:55, 129.69s/it]04/07/2022 03:19:35 PM [INFO]: [CPU: 8]: Game 9
  7%|▋         | 8/120 [20:21<4:50:54, 155.85s/it]04/07/2022 03:19:56 PM [INFO]: [CPU: 0]: Game 8
  8%|▊         | 9/120 [21:03<4:01:37, 130.61s/it]04/07/2022 03:20:39 PM [INFO]: [CPU: 6]: Game 9
  8%|▊         | 10/120 [21:09<3:44:31, 122.47s/it]04/07/2022 03:20:45 PM [INFO]: [CPU: 2]: Game 10
  8%|▊         | 10/120 [21:17<3:14:37, 106.16s/it]04/07/2022 03:20:53 PM [INFO]: [CPU: 5]: Game 10
  7%|▋         | 8/120 [21:31<5:02:15, 161.93s/it]04/07/2022 03:21:06 PM [INFO]: [CPU: 10]: Game 8
  9%|▉         | 11/120 [21:37<4:08:30, 136.80s/it]04/07/2022 03:21:12 PM [INFO]: [CPU: 9]: Game 11
  8%|▊         | 9/120 [21:44<5:09:40, 167.39s/it]04/07/2022 03:21:19 PM [INFO]: [CPU: 4]: Game 9
  8%|▊         | 9/120 [21:51<4:56:33, 160.30s/it]04/07/2022 03:21:26 PM [INFO]: [CPU: 1]: Game 9
  8%|▊         | 10/120 [22:05<4:21:38, 142.72s/it]04/07/2022 03:21:40 PM [INFO]: [CPU: 7]: Game 10
  8%|▊         | 10/120 [22:47<3:52:16, 126.70s/it]04/07/2022 03:22:22 PM [INFO]: [CPU: 3]: Game 10
  8%|▊         | 9/120 [22:47<4:42:44, 152.83s/it]04/07/2022 03:22:22 PM [INFO]: [CPU: 0]: Game 9
  9%|▉         | 11/120 [22:54<3:27:02, 113.96s/it]04/07/2022 03:22:29 PM [INFO]: [CPU: 7]: Game 11
  9%|▉         | 11/120 [23:02<3:12:02, 105.71s/it]04/07/2022 03:22:37 PM [INFO]: [CPU: 5]: Game 11
  8%|▊         | 10/120 [23:08<4:30:48, 147.71s/it]04/07/2022 03:22:43 PM [INFO]: [CPU: 8]: Game 10
  9%|▉         | 11/120 [23:22<3:47:58, 125.49s/it]04/07/2022 03:22:57 PM [INFO]: [CPU: 2]: Game 11
  8%|▊         | 9/120 [23:29<5:14:59, 170.27s/it]04/07/2022 03:23:04 PM [INFO]: [CPU: 11]: Game 9
  8%|▊         | 10/120 [23:56<4:47:01, 156.56s/it]04/07/2022 03:23:32 PM [INFO]: [CPU: 4]: Game 10
  8%|▊         | 10/120 [23:56<3:53:06, 127.15s/it]04/07/2022 03:23:32 PM [INFO]: [CPU: 0]: Game 10
  8%|▊         | 10/120 [24:04<4:27:59, 146.18s/it]04/07/2022 03:23:40 PM [INFO]: [CPU: 6]: Game 10
 10%|█         | 12/120 [24:24<4:22:49, 146.02s/it]04/07/2022 03:24:00 PM [INFO]: [CPU: 9]: Game 12
 10%|█         | 12/120 [24:24<3:11:27, 106.36s/it]04/07/2022 03:24:00 PM [INFO]: [CPU: 2]: Game 12
 10%|█         | 12/120 [24:47<3:09:43, 105.40s/it]04/07/2022 03:24:22 PM [INFO]: [CPU: 5]: Game 12
  9%|▉         | 11/120 [24:52<4:04:16, 134.46s/it]04/07/2022 03:24:28 PM [INFO]: [CPU: 8]: Game 11
  9%|▉         | 11/120 [24:59<3:53:14, 128.39s/it]04/07/2022 03:24:34 PM [INFO]: [CPU: 3]: Game 11
  9%|▉         | 11/120 [25:20<4:03:49, 134.21s/it]04/07/2022 03:24:55 PM [INFO]: [CPU: 4]: Game 11
  8%|▊         | 9/120 [25:27<5:42:48, 185.30s/it]04/07/2022 03:25:03 PM [INFO]: [CPU: 10]: Game 9
  8%|▊         | 10/120 [25:41<5:33:06, 181.69s/it]04/07/2022 03:25:16 PM [INFO]: [CPU: 1]: Game 10
  8%|▊         | 10/120 [25:41<4:50:34, 158.50s/it]04/07/2022 03:25:17 PM [INFO]: [CPU: 11]: Game 10
 11%|█         | 13/120 [26:08<3:57:51, 133.38s/it]04/07/2022 03:25:44 PM [INFO]: [CPU: 9]: Game 13
 11%|█         | 13/120 [26:23<3:16:09, 110.00s/it]04/07/2022 03:25:58 PM [INFO]: [CPU: 2]: Game 13
 10%|█         | 12/120 [26:36<3:29:59, 116.67s/it]04/07/2022 03:26:12 PM [INFO]: [CPU: 4]: Game 12
  9%|▉         | 11/120 [26:36<4:09:16, 137.21s/it]04/07/2022 03:26:12 PM [INFO]: [CPU: 0]: Game 11
 10%|█         | 12/120 [26:57<3:56:58, 131.65s/it]04/07/2022 03:26:33 PM [INFO]: [CPU: 8]: Game 12
 10%|█         | 12/120 [27:18<4:47:28, 159.71s/it]04/07/2022 03:26:53 PM [INFO]: [CPU: 7]: Game 12
 10%|█         | 12/120 [27:39<3:26:12, 114.56s/it]04/07/2022 03:27:15 PM [INFO]: [CPU: 0]: Game 12
  9%|▉         | 11/120 [27:39<4:25:36, 146.20s/it]04/07/2022 03:27:15 PM [INFO]: [CPU: 11]: Game 11
 12%|█▏        | 14/120 [27:53<3:03:55, 104.11s/it]04/07/2022 03:27:29 PM [INFO]: [CPU: 2]: Game 14
  8%|▊         | 10/120 [28:00<5:21:24, 175.32s/it]04/07/2022 03:27:36 PM [INFO]: [CPU: 10]: Game 10
 10%|█         | 12/120 [28:13<4:27:25, 148.57s/it]04/07/2022 03:27:49 PM [INFO]: [CPU: 3]: Game 12
 11%|█         | 13/120 [28:14<3:17:39, 110.83s/it]04/07/2022 03:27:49 PM [INFO]: [CPU: 4]: Game 13
  9%|▉         | 11/120 [28:21<5:18:01, 175.06s/it]04/07/2022 03:27:56 PM [INFO]: [CPU: 1]: Game 11
 11%|█         | 13/120 [28:36<4:15:12, 143.11s/it]04/07/2022 03:28:12 PM [INFO]: [CPU: 5]: Game 13
  8%|▊         | 10/120 [29:03<5:19:40, 174.37s/it]
Process Process-7:
Traceback (most recent call last):
  File "/home/x_aolss/.conda/envs/myownenv/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/x_aolss/.conda/envs/myownenv/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/x_aolss/gym_connect4/gym-connect4/MCTS_c4.py", line 192, in MCTS_self_play
    np.random.choice(np.array([0,1,2,3,4,5,6]), \
  File "mtrand.pyx", line 935, in numpy.random.mtrand.RandomState.choice
ValueError: probabilities contain NaN
 11%|█         | 13/120 [29:16<3:14:36, 109.13s/it]04/07/2022 03:28:51 PM [INFO]: [CPU: 0]: Game 13
 12%|█▎        | 15/120 [29:35<3:00:59, 103.42s/it]04/07/2022 03:29:10 PM [INFO]: [CPU: 2]: Game 15
 12%|█▏        | 14/120 [30:00<4:48:16, 163.18s/it]04/07/2022 03:29:36 PM [INFO]: [CPU: 9]: Game 14
 10%|█         | 12/120 [30:13<4:41:00, 156.12s/it]04/07/2022 03:29:49 PM [INFO]: [CPU: 1]: Game 12
 10%|█         | 12/120 [30:33<4:38:15, 154.59s/it]04/07/2022 03:30:09 PM [INFO]: [CPU: 11]: Game 12
  9%|▉         | 11/120 [30:33<5:06:04, 168.48s/it]04/07/2022 03:30:09 PM [INFO]: [CPU: 10]: Game 11
 11%|█         | 13/120 [30:52<5:14:08, 176.16s/it]04/07/2022 03:30:27 PM [INFO]: [CPU: 7]: Game 13
 12%|█▏        | 14/120 [30:59<3:44:36, 127.13s/it]04/07/2022 03:30:34 PM [INFO]: [CPU: 4]: Game 14
 13%|█▎        | 16/120 [31:05<2:52:26, 99.49s/it] 04/07/2022 03:30:41 PM [INFO]: [CPU: 2]: Game 16
 11%|█         | 13/120 [31:11<4:40:43, 157.42s/it]04/07/2022 03:30:47 PM [INFO]: [CPU: 3]: Game 13
 11%|█         | 13/120 [31:31<5:11:22, 174.60s/it]04/07/2022 03:31:06 PM [INFO]: [CPU: 8]: Game 13
 12%|█▏        | 14/120 [31:33<4:30:26, 153.08s/it]04/07/2022 03:31:08 PM [INFO]: [CPU: 5]: Game 14
 10%|█         | 12/120 [32:16<4:27:26, 148.58s/it]04/07/2022 03:31:52 PM [INFO]: [CPU: 10]: Game 12
 12%|█▏        | 14/120 [32:35<4:32:15, 154.11s/it]04/07/2022 03:32:11 PM [INFO]: [CPU: 7]: Game 14
 12%|█▎        | 15/120 [32:35<4:41:05, 160.63s/it]04/07/2022 03:32:11 PM [INFO]: [CPU: 9]: Game 15
 12%|█▏        | 14/120 [32:42<4:04:36, 138.46s/it]04/07/2022 03:32:18 PM [INFO]: [CPU: 0]: Game 14
 12%|█▎        | 15/120 [33:07<3:43:24, 127.66s/it]04/07/2022 03:32:43 PM [INFO]: [CPU: 4]: Game 15
 11%|█         | 13/120 [33:27<4:46:09, 160.46s/it]04/07/2022 03:33:03 PM [INFO]: [CPU: 11]: Game 13
 14%|█▍        | 17/120 [33:33<3:15:53, 114.11s/it]04/07/2022 03:33:09 PM [INFO]: [CPU: 2]: Game 17
 11%|█         | 13/120 [33:59<5:15:52, 177.12s/it]04/07/2022 03:33:34 PM [INFO]: [CPU: 1]: Game 13
 12%|█▎        | 15/120 [34:01<4:25:19, 151.61s/it]04/07/2022 03:33:36 PM [INFO]: [CPU: 5]: Game 15
 12%|█▏        | 14/120 [34:12<4:50:20, 164.34s/it]04/07/2022 03:33:47 PM [INFO]: [CPU: 3]: Game 14
 12%|█▏        | 14/120 [34:12<5:01:13, 170.50s/it]04/07/2022 03:33:47 PM [INFO]: [CPU: 8]: Game 14
 11%|█         | 13/120 [34:25<4:14:19, 142.61s/it]04/07/2022 03:34:01 PM [INFO]: [CPU: 10]: Game 13
 13%|█▎        | 16/120 [35:10<4:35:15, 158.80s/it]04/07/2022 03:34:45 PM [INFO]: [CPU: 9]: Game 16
 12%|█▎        | 15/120 [35:10<4:29:57, 154.27s/it]04/07/2022 03:34:45 PM [INFO]: [CPU: 7]: Game 15
 12%|█▎        | 15/120 [35:10<4:07:23, 141.37s/it]04/07/2022 03:34:46 PM [INFO]: [CPU: 0]: Game 15
 12%|█▎        | 15/120 [35:23<4:05:50, 140.48s/it]04/07/2022 03:34:58 PM [INFO]: [CPU: 8]: Game 15
 15%|█▌        | 18/120 [35:36<3:18:15, 116.63s/it]04/07/2022 03:35:11 PM [INFO]: [CPU: 2]: Game 18
 12%|█▏        | 14/120 [35:42<4:33:24, 154.75s/it]04/07/2022 03:35:17 PM [INFO]: [CPU: 1]: Game 14
 13%|█▎        | 16/120 [35:57<4:04:10, 140.87s/it]04/07/2022 03:35:32 PM [INFO]: [CPU: 5]: Game 16
 13%|█▎        | 16/120 [36:01<4:05:27, 141.61s/it]04/07/2022 03:35:37 PM [INFO]: [CPU: 4]: Game 16
 12%|█▎        | 15/120 [36:27<4:32:18, 155.60s/it]04/07/2022 03:36:02 PM [INFO]: [CPU: 3]: Game 15
 13%|█▎        | 16/120 [36:27<3:47:13, 131.09s/it]04/07/2022 03:36:03 PM [INFO]: [CPU: 7]: Game 16
 12%|█▏        | 14/120 [36:34<4:57:32, 168.42s/it]04/07/2022 03:36:10 PM [INFO]: [CPU: 11]: Game 14
 13%|█▎        | 16/120 [36:53<3:37:17, 125.36s/it]04/07/2022 03:36:29 PM [INFO]: [CPU: 8]: Game 16
 12%|█▏        | 14/120 [36:53<4:14:53, 144.28s/it]04/07/2022 03:36:29 PM [INFO]: [CPU: 10]: Game 14
 14%|█▍        | 17/120 [37:01<3:22:23, 117.90s/it]04/07/2022 03:36:37 PM [INFO]: [CPU: 5]: Game 17
 14%|█▍        | 17/120 [37:31<4:23:50, 153.69s/it]04/07/2022 03:37:07 PM [INFO]: [CPU: 9]: Game 17
 12%|█▎        | 15/120 [37:45<4:03:20, 139.05s/it]04/07/2022 03:37:21 PM [INFO]: [CPU: 11]: Game 15
 14%|█▍        | 17/120 [38:17<3:59:52, 139.73s/it]04/07/2022 03:37:52 PM [INFO]: [CPU: 4]: Game 17
 12%|█▎        | 15/120 [38:23<4:34:09, 156.66s/it]04/07/2022 03:37:58 PM [INFO]: [CPU: 1]: Game 15
 13%|█▎        | 16/120 [38:30<4:35:30, 158.94s/it]04/07/2022 03:38:05 PM [INFO]: [CPU: 0]: Game 16
 14%|█▍        | 17/120 [38:43<3:27:04, 120.63s/it]04/07/2022 03:38:18 PM [INFO]: [CPU: 8]: Game 17
 13%|█▎        | 16/120 [38:49<4:22:31, 151.46s/it]04/07/2022 03:38:24 PM [INFO]: [CPU: 3]: Game 16
 16%|█▌        | 19/120 [39:28<4:14:36, 151.25s/it]04/07/2022 03:39:03 PM [INFO]: [CPU: 2]: Game 19
 15%|█▌        | 18/120 [39:42<3:42:29, 130.88s/it]04/07/2022 03:39:18 PM [INFO]: [CPU: 5]: Game 18
 15%|█▌        | 18/120 [39:53<4:15:08, 150.08s/it]04/07/2022 03:39:29 PM [INFO]: [CPU: 9]: Game 18
 12%|█▎        | 15/120 [39:54<4:31:31, 155.15s/it]04/07/2022 03:39:29 PM [INFO]: [CPU: 10]: Game 15
 13%|█▎        | 16/120 [39:54<3:55:40, 135.97s/it]04/07/2022 03:39:29 PM [INFO]: [CPU: 11]: Game 16
 14%|█▍        | 17/120 [40:00<4:27:05, 155.59s/it]04/07/2022 03:39:35 PM [INFO]: [CPU: 7]: Game 17
 13%|█▎        | 16/120 [40:06<4:03:34, 140.52s/it]04/07/2022 03:39:41 PM [INFO]: [CPU: 1]: Game 16
 15%|█▌        | 18/120 [40:32<3:55:11, 138.34s/it]04/07/2022 03:40:07 PM [INFO]: [CPU: 4]: Game 18
 14%|█▍        | 17/120 [40:45<4:01:37, 140.75s/it]04/07/2022 03:40:20 PM [INFO]: [CPU: 3]: Game 17
 14%|█▍        | 17/120 [40:58<3:16:24, 114.42s/it]04/07/2022 03:40:34 PM [INFO]: [CPU: 11]: Game 17
 15%|█▌        | 18/120 [41:04<3:35:42, 126.88s/it]04/07/2022 03:40:40 PM [INFO]: [CPU: 8]: Game 18
 17%|█▋        | 20/120 [41:11<3:47:59, 136.79s/it]04/07/2022 03:40:46 PM [INFO]: [CPU: 2]: Game 20
 16%|█▌        | 19/120 [41:43<3:18:40, 118.02s/it]04/07/2022 03:41:18 PM [INFO]: [CPU: 4]: Game 19
 14%|█▍        | 17/120 [41:56<4:57:00, 173.01s/it]04/07/2022 03:41:31 PM [INFO]: [CPU: 0]: Game 17
 15%|█▌        | 18/120 [42:15<4:13:59, 149.41s/it]04/07/2022 03:41:50 PM [INFO]: [CPU: 7]: Game 18
 13%|█▎        | 16/120 [42:15<4:21:46, 151.02s/it]04/07/2022 03:41:51 PM [INFO]: [CPU: 10]: Game 16
 16%|█▌        | 19/120 [42:23<3:55:25, 139.86s/it]04/07/2022 03:41:59 PM [INFO]: [CPU: 5]: Game 19
 15%|█▌        | 18/120 [42:34<3:43:08, 131.26s/it]04/07/2022 03:42:09 PM [INFO]: [CPU: 3]: Game 18
 16%|█▌        | 19/120 [42:47<3:21:26, 119.67s/it]04/07/2022 03:42:23 PM [INFO]: [CPU: 8]: Game 19
 14%|█▍        | 17/120 [42:53<4:14:57, 148.52s/it]04/07/2022 03:42:29 PM [INFO]: [CPU: 1]: Game 17
 17%|█▋        | 20/120 [43:00<2:56:16, 105.76s/it]04/07/2022 03:42:35 PM [INFO]: [CPU: 4]: Game 20
 15%|█▌        | 18/120 [43:20<3:28:18, 122.54s/it]04/07/2022 03:42:55 PM [INFO]: [CPU: 11]: Game 18
 18%|█▊        | 21/120 [43:45<3:54:18, 142.00s/it]04/07/2022 03:43:20 PM [INFO]: [CPU: 2]: Game 21
 16%|█▌        | 19/120 [44:04<5:03:27, 180.28s/it]04/07/2022 03:43:39 PM [INFO]: [CPU: 9]: Game 19
 16%|█▌        | 19/120 [44:17<3:26:35, 122.73s/it]04/07/2022 03:43:52 PM [INFO]: [CPU: 3]: Game 19
 15%|█▌        | 18/120 [44:36<4:47:49, 169.31s/it]04/07/2022 03:44:12 PM [INFO]: [CPU: 0]: Game 18
 16%|█▌        | 19/120 [44:49<4:13:56, 150.85s/it]04/07/2022 03:44:24 PM [INFO]: [CPU: 7]: Game 19
 17%|█▋        | 20/120 [45:04<4:03:31, 146.11s/it]04/07/2022 03:44:39 PM [INFO]: [CPU: 5]: Game 20
 14%|█▍        | 17/120 [45:09<4:30:52, 157.79s/it]04/07/2022 03:44:44 PM [INFO]: [CPU: 10]: Game 17
 17%|█▋        | 20/120 [45:15<3:33:33, 128.14s/it]04/07/2022 03:44:50 PM [INFO]: [CPU: 8]: Game 20
 16%|█▌        | 19/120 [45:22<3:26:02, 122.41s/it]04/07/2022 03:44:57 PM [INFO]: [CPU: 11]: Game 19
 18%|█▊        | 22/120 [45:47<3:42:09, 136.02s/it]04/07/2022 03:45:23 PM [INFO]: [CPU: 2]: Game 22
 15%|█▌        | 18/120 [45:53<4:28:28, 157.93s/it]04/07/2022 03:45:28 PM [INFO]: [CPU: 1]: Game 18
 17%|█▋        | 20/120 [46:06<3:17:44, 118.64s/it]04/07/2022 03:45:41 PM [INFO]: [CPU: 3]: Game 20
 17%|█▋        | 20/120 [46:13<2:48:24, 101.04s/it]04/07/2022 03:45:48 PM [INFO]: [CPU: 11]: Game 20
 18%|█▊        | 21/120 [46:19<3:40:41, 133.75s/it]04/07/2022 03:45:54 PM [INFO]: [CPU: 4]: Game 21
 15%|█▌        | 18/120 [46:26<3:46:55, 133.49s/it]04/07/2022 03:46:01 PM [INFO]: [CPU: 10]: Game 18
 18%|█▊        | 21/120 [46:34<3:33:12, 129.22s/it]04/07/2022 03:46:09 PM [INFO]: [CPU: 5]: Game 21
 17%|█▋        | 20/120 [46:51<3:56:59, 142.20s/it]04/07/2022 03:46:26 PM [INFO]: [CPU: 7]: Game 20
 16%|█▌        | 19/120 [47:04<3:41:46, 131.75s/it]04/07/2022 03:46:39 PM [INFO]: [CPU: 1]: Game 19
 17%|█▋        | 20/120 [47:16<5:06:37, 183.97s/it]04/07/2022 03:46:52 PM [INFO]: [CPU: 9]: Game 20
 16%|█▌        | 19/120 [47:36<4:50:17, 172.45s/it]04/07/2022 03:47:12 PM [INFO]: [CPU: 0]: Game 19
 19%|█▉        | 23/120 [48:02<3:39:18, 135.66s/it]04/07/2022 03:47:37 PM [INFO]: [CPU: 2]: Game 23
 18%|█▊        | 22/120 [48:10<3:14:55, 119.34s/it]04/07/2022 03:47:45 PM [INFO]: [CPU: 5]: Game 22
 18%|█▊        | 21/120 [48:15<3:56:59, 143.64s/it]04/07/2022 03:47:50 PM [INFO]: [CPU: 8]: Game 21
 18%|█▊        | 21/120 [48:21<3:23:48, 123.52s/it]04/07/2022 03:47:56 PM [INFO]: [CPU: 3]: Game 21
 17%|█▋        | 20/120 [48:34<3:18:40, 119.21s/it]04/07/2022 03:48:09 PM [INFO]: [CPU: 1]: Game 20
 18%|█▊        | 21/120 [48:41<3:09:52, 115.08s/it]04/07/2022 03:48:16 PM [INFO]: [CPU: 11]: Game 21
 18%|█▊        | 22/120 [49:06<3:54:46, 143.74s/it]04/07/2022 03:48:41 PM [INFO]: [CPU: 4]: Game 22
 17%|█▋        | 20/120 [49:13<4:09:24, 149.64s/it]04/07/2022 03:48:48 PM [INFO]: [CPU: 0]: Game 20
 18%|█▊        | 21/120 [49:44<4:45:42, 173.16s/it]04/07/2022 03:49:20 PM [INFO]: [CPU: 9]: Game 21
 18%|█▊        | 22/120 [49:44<3:02:13, 111.57s/it]04/07/2022 03:49:20 PM [INFO]: [CPU: 3]: Game 22
 18%|█▊        | 22/120 [49:51<3:31:30, 129.49s/it]04/07/2022 03:49:27 PM [INFO]: [CPU: 8]: Game 22
 16%|█▌        | 19/120 [49:58<4:24:29, 157.13s/it]04/07/2022 03:49:33 PM [INFO]: [CPU: 10]: Game 19
 20%|██        | 24/120 [50:23<3:39:50, 137.40s/it]04/07/2022 03:49:59 PM [INFO]: [CPU: 2]: Game 24
 18%|█▊        | 21/120 [50:43<3:37:25, 131.77s/it]04/07/2022 03:50:18 PM [INFO]: [CPU: 0]: Game 21
 18%|█▊        | 22/120 [50:43<3:11:29, 117.24s/it]04/07/2022 03:50:18 PM [INFO]: [CPU: 11]: Game 22
 19%|█▉        | 23/120 [50:49<2:37:27, 97.40s/it] 04/07/2022 03:50:24 PM [INFO]: [CPU: 3]: Game 23
 18%|█▊        | 21/120 [50:55<4:45:09, 172.82s/it]04/07/2022 03:50:31 PM [INFO]: [CPU: 7]: Game 21
 18%|█▊        | 21/120 [51:02<3:30:57, 127.85s/it]04/07/2022 03:50:37 PM [INFO]: [CPU: 1]: Game 21
 19%|█▉        | 23/120 [51:16<3:45:34, 139.53s/it]04/07/2022 03:50:52 PM [INFO]: [CPU: 5]: Game 23
 19%|█▉        | 23/120 [51:53<4:03:47, 150.80s/it]04/07/2022 03:51:29 PM [INFO]: [CPU: 4]: Game 23
 18%|█▊        | 22/120 [51:53<2:51:22, 104.93s/it]04/07/2022 03:51:29 PM [INFO]: [CPU: 1]: Game 22
 21%|██        | 25/120 [52:00<3:18:07, 125.13s/it]04/07/2022 03:51:35 PM [INFO]: [CPU: 2]: Game 25
 17%|█▋        | 20/120 [52:06<4:07:38, 148.58s/it]04/07/2022 03:51:42 PM [INFO]: [CPU: 10]: Game 20
 19%|█▉        | 23/120 [52:19<2:59:29, 111.02s/it]04/07/2022 03:51:55 PM [INFO]: [CPU: 11]: Game 23
 18%|█▊        | 22/120 [52:38<4:43:05, 173.33s/it]04/07/2022 03:52:14 PM [INFO]: [CPU: 9]: Game 22
 18%|█▊        | 22/120 [52:45<3:30:31, 128.89s/it]04/07/2022 03:52:20 PM [INFO]: [CPU: 0]: Game 22
 20%|██        | 24/120 [52:51<2:47:44, 104.84s/it]04/07/2022 03:52:26 PM [INFO]: [CPU: 3]: Game 24
 20%|██        | 24/120 [52:53<3:22:36, 126.63s/it]04/07/2022 03:52:28 PM [INFO]: [CPU: 5]: Game 24
 18%|█▊        | 22/120 [53:10<4:23:45, 161.48s/it]04/07/2022 03:52:46 PM [INFO]: [CPU: 7]: Game 22
 19%|█▉        | 23/120 [53:17<4:06:20, 152.38s/it]04/07/2022 03:52:52 PM [INFO]: [CPU: 8]: Game 23
 21%|██        | 25/120 [53:49<2:23:39, 90.73s/it] 04/07/2022 03:53:24 PM [INFO]: [CPU: 3]: Game 25
 22%|██▏       | 26/120 [53:49<3:08:35, 120.38s/it]04/07/2022 03:53:25 PM [INFO]: [CPU: 2]: Game 26
 20%|██        | 24/120 [53:55<3:47:30, 142.20s/it]04/07/2022 03:53:31 PM [INFO]: [CPU: 4]: Game 24
 18%|█▊        | 21/120 [54:28<4:01:36, 146.43s/it]04/07/2022 03:54:03 PM [INFO]: [CPU: 10]: Game 21
 21%|██        | 25/120 [54:42<3:12:12, 121.39s/it]04/07/2022 03:54:18 PM [INFO]: [CPU: 5]: Game 25
 21%|██        | 25/120 [55:06<3:11:09, 120.73s/it]04/07/2022 03:54:41 PM [INFO]: [CPU: 4]: Game 25
 19%|█▉        | 23/120 [55:06<3:32:13, 131.27s/it]04/07/2022 03:54:41 PM [INFO]: [CPU: 1]: Game 23
 19%|█▉        | 23/120 [55:12<4:01:55, 149.65s/it]04/07/2022 03:54:48 PM [INFO]: [CPU: 7]: Game 23
 22%|██▏       | 26/120 [55:31<2:27:48, 94.34s/it]04/07/2022 03:55:07 PM [INFO]: [CPU: 3]: Game 26
 20%|██        | 24/120 [55:32<3:55:22, 147.11s/it]04/07/2022 03:55:07 PM [INFO]: [CPU: 8]: Game 24
 20%|██        | 24/120 [55:32<3:36:52, 135.55s/it]04/07/2022 03:55:08 PM [INFO]: [CPU: 11]: Game 24
 19%|█▉        | 23/120 [55:44<4:46:29, 177.22s/it]04/07/2022 03:55:20 PM [INFO]: [CPU: 9]: Game 23
 19%|█▉        | 23/120 [56:17<4:08:38, 153.80s/it]04/07/2022 03:55:52 PM [INFO]: [CPU: 0]: Game 23
 22%|██▏       | 26/120 [56:29<2:51:42, 109.60s/it]04/07/2022 03:56:05 PM [INFO]: [CPU: 4]: Game 26
 22%|██▏       | 26/120 [56:44<3:10:30, 121.60s/it]04/07/2022 03:56:20 PM [INFO]: [CPU: 5]: Game 26
 22%|██▎       | 27/120 [56:55<3:37:14, 140.16s/it]04/07/2022 03:56:31 PM [INFO]: [CPU: 2]: Game 27
 21%|██        | 25/120 [57:02<3:25:49, 130.00s/it]04/07/2022 03:56:37 PM [INFO]: [CPU: 8]: Game 25
 22%|██▎       | 27/120 [57:14<2:30:13, 96.92s/it]04/07/2022 03:56:50 PM [INFO]: [CPU: 3]: Game 27
 20%|██        | 24/120 [57:15<3:20:01, 125.02s/it]04/07/2022 03:56:50 PM [INFO]: [CPU: 0]: Game 24
 18%|█▊        | 22/120 [57:15<4:09:18, 152.64s/it]04/07/2022 03:56:50 PM [INFO]: [CPU: 10]: Game 22
 20%|██        | 24/120 [57:34<4:10:57, 156.85s/it]04/07/2022 03:57:09 PM [INFO]: [CPU: 9]: Game 24
 22%|██▎       | 27/120 [57:53<2:37:52, 101.85s/it]04/07/2022 03:57:29 PM [INFO]: [CPU: 4]: Game 27
 21%|██        | 25/120 [57:54<3:37:26, 137.34s/it]04/07/2022 03:57:29 PM [INFO]: [CPU: 11]: Game 25
 20%|██        | 24/120 [58:25<4:02:41, 151.68s/it]04/07/2022 03:58:01 PM [INFO]: [CPU: 1]: Game 24
 22%|██▎       | 27/120 [58:34<3:02:49, 117.95s/it]04/07/2022 03:58:09 PM [INFO]: [CPU: 5]: Game 27
 23%|██▎       | 28/120 [58:45<3:20:43, 130.91s/it]04/07/2022 03:58:20 PM [INFO]: [CPU: 2]: Game 28
 23%|██▎       | 28/120 [58:45<2:12:59, 86.74s/it] 04/07/2022 03:58:20 PM [INFO]: [CPU: 4]: Game 28
 22%|██▏       | 26/120 [59:04<3:19:59, 127.65s/it]04/07/2022 03:58:39 PM [INFO]: [CPU: 8]: Game 26
 20%|██        | 24/120 [59:23<4:48:00, 180.00s/it]04/07/2022 03:58:58 PM [INFO]: [CPU: 7]: Game 24
 21%|██        | 25/120 [59:30<3:22:44, 128.05s/it]04/07/2022 03:59:05 PM [INFO]: [CPU: 0]: Game 25
 22%|██▏       | 26/120 [59:30<3:15:58, 125.09s/it]04/07/2022 03:59:06 PM [INFO]: [CPU: 11]: Game 26
 23%|██▎       | 28/120 [59:36<2:49:07, 110.30s/it]04/07/2022 03:59:11 PM [INFO]: [CPU: 3]: Game 28
 19%|█▉        | 23/120 [59:43<4:04:25, 151.19s/it]04/07/2022 03:59:18 PM [INFO]: [CPU: 10]: Game 23
 21%|██        | 25/120 [59:55<4:01:01, 152.22s/it]04/07/2022 03:59:31 PM [INFO]: [CPU: 9]: Game 25
 22%|██▏       | 26/120 [1:00:34<2:50:39, 108.93s/it]04/07/2022 04:00:10 PM [INFO]: [CPU: 0]: Game 26
 21%|██        | 25/120 [1:01:12<4:11:21, 158.76s/it]04/07/2022 04:00:48 PM [INFO]: [CPU: 7]: Game 25
 23%|██▎       | 28/120 [1:01:21<3:23:30, 132.72s/it]04/07/2022 04:00:56 PM [INFO]: [CPU: 5]: Game 28
 21%|██        | 25/120 [1:01:25<4:13:35, 160.16s/it]04/07/2022 04:01:01 PM [INFO]: [CPU: 1]: Game 25
 22%|██▏       | 26/120 [1:01:32<3:32:16, 135.49s/it]04/07/2022 04:01:07 PM [INFO]: [CPU: 9]: Game 26
 22%|██▎       | 27/120 [1:01:38<3:30:14, 135.64s/it]04/07/2022 04:01:14 PM [INFO]: [CPU: 8]: Game 27
 24%|██▍       | 29/120 [1:01:45<3:40:52, 145.63s/it]04/07/2022 04:01:20 PM [INFO]: [CPU: 2]: Game 29
 24%|██▍       | 29/120 [1:01:51<2:58:29, 117.69s/it]04/07/2022 04:01:26 PM [INFO]: [CPU: 3]: Game 29
 22%|██▎       | 27/120 [1:02:29<2:53:55, 112.21s/it]04/07/2022 04:02:05 PM [INFO]: [CPU: 9]: Game 27
 22%|██▎       | 27/120 [1:02:30<3:39:24, 141.55s/it]04/07/2022 04:02:06 PM [INFO]: [CPU: 11]: Game 27
 24%|██▍       | 29/120 [1:02:43<3:20:16, 132.05s/it]04/07/2022 04:02:18 PM [INFO]: [CPU: 4]: Game 29
 25%|██▌       | 30/120 [1:03:15<3:13:27, 128.97s/it]04/07/2022 04:02:50 PM [INFO]: [CPU: 2]: Game 30
 24%|██▍       | 29/120 [1:03:23<3:16:28, 129.54s/it]04/07/2022 04:02:59 PM [INFO]: [CPU: 5]: Game 29
 20%|██        | 24/120 [1:03:28<4:37:19, 173.33s/it]04/07/2022 04:03:03 PM [INFO]: [CPU: 10]: Game 24
 25%|██▌       | 30/120 [1:03:40<2:52:47, 115.19s/it]04/07/2022 04:03:16 PM [INFO]: [CPU: 3]: Game 30
 22%|██▏       | 26/120 [1:03:40<3:59:10, 152.66s/it]04/07/2022 04:03:16 PM [INFO]: [CPU: 1]: Game 26
 23%|██▎       | 28/120 [1:04:00<3:30:40, 137.39s/it]04/07/2022 04:03:35 PM [INFO]: [CPU: 8]: Game 28
 21%|██        | 25/120 [1:04:19<3:36:32, 136.77s/it]04/07/2022 04:03:55 PM [INFO]: [CPU: 10]: Game 25
 22%|██▎       | 27/120 [1:04:19<3:42:52, 143.79s/it]04/07/2022 04:03:55 PM [INFO]: [CPU: 0]: Game 27
 22%|██▏       | 26/120 [1:04:32<4:27:49, 170.95s/it]04/07/2022 04:04:07 PM [INFO]: [CPU: 7]: Game 26
 25%|██▌       | 30/120 [1:04:45<3:13:38, 129.10s/it]04/07/2022 04:04:20 PM [INFO]: [CPU: 4]: Game 30
 25%|██▌       | 30/120 [1:04:47<2:53:39, 115.78s/it]04/07/2022 04:04:22 PM [INFO]: [CPU: 5]: Game 30
 23%|██▎       | 28/120 [1:04:52<3:37:03, 141.56s/it]04/07/2022 04:04:27 PM [INFO]: [CPU: 11]: Game 28
 23%|██▎       | 28/120 [1:04:57<3:08:30, 122.94s/it]04/07/2022 04:04:33 PM [INFO]: [CPU: 9]: Game 28
 24%|██▍       | 29/120 [1:05:10<2:58:02, 117.39s/it]04/07/2022 04:04:46 PM [INFO]: [CPU: 8]: Game 29
 22%|██▎       | 27/120 [1:05:30<3:36:26, 139.64s/it]04/07/2022 04:05:05 PM [INFO]: [CPU: 1]: Game 27
 26%|██▌       | 31/120 [1:05:36<2:51:07, 115.36s/it]04/07/2022 04:05:12 PM [INFO]: [CPU: 3]: Game 31
 26%|██▌       | 31/120 [1:05:38<2:23:06, 96.48s/it] 04/07/2022 04:05:14 PM [INFO]: [CPU: 5]: Game 31
 23%|██▎       | 28/120 [1:05:49<3:15:46, 127.68s/it]04/07/2022 04:05:25 PM [INFO]: [CPU: 0]: Game 28
 22%|██▏       | 26/120 [1:05:56<3:15:20, 124.68s/it]04/07/2022 04:05:31 PM [INFO]: [CPU: 10]: Game 26
 26%|██▌       | 31/120 [1:06:08<3:31:08, 142.35s/it]04/07/2022 04:05:44 PM [INFO]: [CPU: 2]: Game 31
 24%|██▍       | 29/120 [1:06:15<3:08:21, 124.19s/it]04/07/2022 04:05:51 PM [INFO]: [CPU: 11]: Game 29
 25%|██▌       | 30/120 [1:07:06<2:55:18, 116.88s/it]04/07/2022 04:06:42 PM [INFO]: [CPU: 8]: Game 30
 26%|██▌       | 31/120 [1:07:19<3:22:42, 136.66s/it]04/07/2022 04:06:55 PM [INFO]: [CPU: 4]: Game 31
 27%|██▋       | 32/120 [1:07:25<2:46:29, 113.52s/it]04/07/2022 04:07:01 PM [INFO]: [CPU: 3]: Game 32
 22%|██▎       | 27/120 [1:07:26<2:57:06, 114.27s/it]04/07/2022 04:07:01 PM [INFO]: [CPU: 10]: Game 27
 23%|██▎       | 28/120 [1:07:32<3:26:01, 134.36s/it]04/07/2022 04:07:07 PM [INFO]: [CPU: 1]: Game 28
 24%|██▍       | 29/120 [1:07:32<3:20:39, 132.30s/it]04/07/2022 04:07:07 PM [INFO]: [CPU: 9]: Game 29
 24%|██▍       | 29/120 [1:07:45<3:08:09, 124.06s/it]04/07/2022 04:07:20 PM [INFO]: [CPU: 0]: Game 29
 22%|██▎       | 27/120 [1:07:57<4:41:08, 181.38s/it]04/07/2022 04:07:33 PM [INFO]: [CPU: 7]: Game 27
 27%|██▋       | 32/120 [1:07:59<2:41:13, 109.93s/it]04/07/2022 04:07:35 PM [INFO]: [CPU: 5]: Game 32
 26%|██▌       | 31/120 [1:08:04<2:27:05, 99.17s/it] 04/07/2022 04:07:39 PM [INFO]: [CPU: 8]: Game 31
 25%|██▌       | 30/120 [1:08:05<2:59:30, 119.67s/it]04/07/2022 04:07:40 PM [INFO]: [CPU: 11]: Game 30
 28%|██▊       | 33/120 [1:09:02<2:37:08, 108.37s/it]04/07/2022 04:08:37 PM [INFO]: [CPU: 3]: Game 33
 27%|██▋       | 32/120 [1:09:21<3:14:02, 132.30s/it]04/07/2022 04:08:57 PM [INFO]: [CPU: 4]: Game 32
 26%|██▌       | 31/120 [1:09:28<2:41:26, 108.84s/it]04/07/2022 04:09:04 PM [INFO]: [CPU: 11]: Game 31
 23%|██▎       | 28/120 [1:09:46<4:04:54, 159.72s/it]04/07/2022 04:09:22 PM [INFO]: [CPU: 7]: Game 28
 27%|██▋       | 32/120 [1:10:00<2:32:41, 104.10s/it]04/07/2022 04:09:35 PM [INFO]: [CPU: 8]: Game 32
 27%|██▋       | 32/120 [1:10:12<4:13:29, 172.84s/it]04/07/2022 04:09:48 PM [INFO]: [CPU: 2]: Game 32
 23%|██▎       | 28/120 [1:10:19<3:22:25, 132.01s/it]04/07/2022 04:09:55 PM [INFO]: [CPU: 10]: Game 28
 24%|██▍       | 29/120 [1:10:25<3:41:36, 146.12s/it]04/07/2022 04:10:01 PM [INFO]: [CPU: 1]: Game 29
 25%|██▌       | 30/120 [1:10:39<3:28:22, 138.91s/it]04/07/2022 04:10:14 PM [INFO]: [CPU: 0]: Game 30
 28%|██▊       | 33/120 [1:10:40<3:01:31, 125.19s/it]04/07/2022 04:10:16 PM [INFO]: [CPU: 5]: Game 33
 25%|██▌       | 30/120 [1:11:04<3:54:23, 156.27s/it]04/07/2022 04:10:39 PM [INFO]: [CPU: 9]: Game 30
 28%|██▊       | 33/120 [1:11:10<2:16:29, 94.13s/it] 04/07/2022 04:10:46 PM [INFO]: [CPU: 8]: Game 33
 27%|██▋       | 32/120 [1:11:18<2:39:51, 108.99s/it]04/07/2022 04:10:53 PM [INFO]: [CPU: 11]: Game 32
 28%|██▊       | 33/120 [1:11:36<3:13:01, 133.12s/it]04/07/2022 04:11:12 PM [INFO]: [CPU: 4]: Game 33
 28%|██▊       | 34/120 [1:11:42<2:57:52, 124.10s/it]04/07/2022 04:11:18 PM [INFO]: [CPU: 3]: Game 34
 28%|██▊       | 34/120 [1:11:51<2:36:03, 108.88s/it]04/07/2022 04:11:27 PM [INFO]: [CPU: 5]: Game 34
 24%|██▍       | 29/120 [1:12:02<3:51:03, 152.35s/it]04/07/2022 04:11:37 PM [INFO]: [CPU: 7]: Game 29
 28%|██▊       | 33/120 [1:12:02<3:43:02, 153.82s/it]04/07/2022 04:11:37 PM [INFO]: [CPU: 2]: Game 33
 24%|██▍       | 29/120 [1:12:47<3:27:35, 136.87s/it]04/07/2022 04:12:23 PM [INFO]: [CPU: 10]: Game 29
 29%|██▉       | 35/120 [1:13:15<2:23:33, 101.33s/it]04/07/2022 04:12:50 PM [INFO]: [CPU: 5]: Game 35
 26%|██▌       | 31/120 [1:13:20<3:35:53, 145.54s/it]04/07/2022 04:12:55 PM [INFO]: [CPU: 0]: Game 31
 29%|██▉       | 35/120 [1:13:32<2:49:36, 119.72s/it]04/07/2022 04:13:07 PM [INFO]: [CPU: 3]: Game 35
 26%|██▌       | 31/120 [1:13:45<3:53:50, 157.65s/it]04/07/2022 04:13:20 PM [INFO]: [CPU: 9]: Game 31
 28%|██▊       | 33/120 [1:13:58<3:00:36, 124.55s/it]04/07/2022 04:13:34 PM [INFO]: [CPU: 11]: Game 33
 25%|██▌       | 30/120 [1:14:11<3:01:20, 120.90s/it]04/07/2022 04:13:46 PM [INFO]: [CPU: 10]: Game 30
 25%|██▌       | 30/120 [1:14:43<4:29:16, 179.52s/it]04/07/2022 04:14:18 PM [INFO]: [CPU: 1]: Game 30
 28%|██▊       | 34/120 [1:14:49<3:36:34, 151.10s/it]04/07/2022 04:14:25 PM [INFO]: [CPU: 4]: Game 34
 28%|██▊       | 34/120 [1:14:56<3:11:19, 133.48s/it]04/07/2022 04:14:31 PM [INFO]: [CPU: 8]: Game 34
 30%|███       | 36/120 [1:15:08<2:37:53, 112.78s/it]04/07/2022 04:14:44 PM [INFO]: [CPU: 3]: Game 36
 27%|██▋       | 32/120 [1:15:35<3:28:55, 142.45s/it]04/07/2022 04:15:10 PM [INFO]: [CPU: 0]: Game 32
 30%|███       | 36/120 [1:15:36<2:38:48, 113.43s/it]04/07/2022 04:15:12 PM [INFO]: [CPU: 5]: Game 36
 25%|██▌       | 30/120 [1:15:47<4:21:19, 174.21s/it]04/07/2022 04:15:22 PM [INFO]: [CPU: 7]: Game 30
 29%|██▉       | 35/120 [1:15:47<2:54:27, 123.15s/it]04/07/2022 04:15:23 PM [INFO]: [CPU: 4]: Game 35
 28%|██▊       | 34/120 [1:16:00<4:16:41, 179.09s/it]04/07/2022 04:15:35 PM [INFO]: [CPU: 2]: Game 34
 26%|██▌       | 31/120 [1:16:06<3:43:37, 150.76s/it]04/07/2022 04:15:42 PM [INFO]: [CPU: 1]: Game 31
 28%|██▊       | 34/120 [1:16:20<3:05:52, 129.68s/it]04/07/2022 04:15:56 PM [INFO]: [CPU: 11]: Game 34
 27%|██▋       | 32/120 [1:16:32<3:55:29, 160.56s/it]04/07/2022 04:16:08 PM [INFO]: [CPU: 9]: Game 32
 31%|███       | 37/120 [1:16:39<2:26:36, 105.99s/it]04/07/2022 04:16:14 PM [INFO]: [CPU: 3]: Game 37
 26%|██▌       | 31/120 [1:16:45<3:14:16, 130.98s/it]04/07/2022 04:16:21 PM [INFO]: [CPU: 10]: Game 31
 27%|██▋       | 32/120 [1:17:23<3:08:46, 128.71s/it]04/07/2022 04:16:59 PM [INFO]: [CPU: 1]: Game 32
 28%|██▊       | 33/120 [1:17:24<3:12:10, 132.53s/it]04/07/2022 04:17:00 PM [INFO]: [CPU: 0]: Game 33
 30%|███       | 36/120 [1:17:30<2:43:59, 117.14s/it]04/07/2022 04:17:06 PM [INFO]: [CPU: 4]: Game 36
 26%|██▌       | 31/120 [1:18:02<4:01:03, 162.51s/it]04/07/2022 04:17:38 PM [INFO]: [CPU: 7]: Game 31
 29%|██▉       | 35/120 [1:18:02<3:31:41, 149.43s/it]04/07/2022 04:17:38 PM [INFO]: [CPU: 8]: Game 35
 31%|███       | 37/120 [1:18:37<3:04:36, 133.46s/it]04/07/2022 04:18:12 PM [INFO]: [CPU: 5]: Game 37
 27%|██▋       | 32/120 [1:18:41<3:05:25, 126.43s/it]04/07/2022 04:18:17 PM [INFO]: [CPU: 10]: Game 32
 29%|██▉       | 35/120 [1:18:54<3:14:14, 137.11s/it]04/07/2022 04:18:30 PM [INFO]: [CPU: 11]: Game 35
 29%|██▉       | 35/120 [1:19:00<4:14:09, 179.40s/it]04/07/2022 04:18:35 PM [INFO]: [CPU: 2]: Game 35
 28%|██▊       | 33/120 [1:19:00<2:52:36, 119.04s/it]04/07/2022 04:18:36 PM [INFO]: [CPU: 1]: Game 33
 32%|███▏      | 38/120 [1:19:13<2:44:40, 120.50s/it]04/07/2022 04:18:48 PM [INFO]: [CPU: 3]: Game 38
 28%|██▊       | 33/120 [1:19:51<4:09:40, 172.19s/it]04/07/2022 04:19:27 PM [INFO]: [CPU: 9]: Game 33
 30%|███       | 36/120 [1:19:58<3:20:08, 142.96s/it]04/07/2022 04:19:33 PM [INFO]: [CPU: 2]: Game 36
 28%|██▊       | 34/120 [1:20:05<3:22:04, 140.98s/it]04/07/2022 04:19:40 PM [INFO]: [CPU: 0]: Game 34
 28%|██▊       | 34/120 [1:20:49<2:46:26, 116.12s/it]04/07/2022 04:20:25 PM [INFO]: [CPU: 1]: Game 34
 32%|███▎      | 39/120 [1:20:49<2:32:55, 113.27s/it]04/07/2022 04:20:25 PM [INFO]: [CPU: 3]: Game 39
 32%|███▏      | 38/120 [1:20:51<3:02:56, 133.86s/it]04/07/2022 04:20:27 PM [INFO]: [CPU: 5]: Game 38
 31%|███       | 37/120 [1:21:02<3:21:27, 145.63s/it]04/07/2022 04:20:38 PM [INFO]: [CPU: 4]: Game 37
 27%|██▋       | 32/120 [1:21:16<4:12:15, 171.99s/it]04/07/2022 04:20:52 PM [INFO]: [CPU: 7]: Game 32
 28%|██▊       | 34/120 [1:21:28<3:34:10, 149.42s/it]04/07/2022 04:21:03 PM [INFO]: [CPU: 9]: Game 34
 30%|███       | 36/120 [1:21:28<3:19:02, 142.17s/it]04/07/2022 04:21:04 PM [INFO]: [CPU: 11]: Game 36
 30%|███       | 36/120 [1:22:00<4:06:12, 175.87s/it]04/07/2022 04:21:35 PM [INFO]: [CPU: 8]: Game 36
 28%|██▊       | 33/120 [1:22:00<3:34:51, 148.18s/it]04/07/2022 04:21:36 PM [INFO]: [CPU: 10]: Game 33
 32%|███▏      | 38/120 [1:22:32<2:56:06, 128.86s/it]04/07/2022 04:22:08 PM [INFO]: [CPU: 4]: Game 38
 31%|███       | 37/120 [1:23:04<3:35:37, 155.88s/it]04/07/2022 04:22:39 PM [INFO]: [CPU: 2]: Game 37
 29%|██▉       | 35/120 [1:23:05<3:36:11, 152.61s/it]04/07/2022 04:22:40 PM [INFO]: [CPU: 0]: Game 35
 31%|███       | 37/120 [1:23:11<3:19:36, 144.30s/it]04/07/2022 04:22:46 PM [INFO]: [CPU: 8]: Game 37
 32%|███▎      | 39/120 [1:23:58<3:21:53, 149.55s/it]04/07/2022 04:23:33 PM [INFO]: [CPU: 5]: Game 39
 29%|██▉       | 35/120 [1:24:02<3:16:59, 139.05s/it]04/07/2022 04:23:37 PM [INFO]: [CPU: 1]: Game 35
 31%|███       | 37/120 [1:24:03<3:21:38, 145.77s/it]04/07/2022 04:23:38 PM [INFO]: [CPU: 11]: Game 37
 28%|██▊       | 33/120 [1:24:16<4:12:47, 174.34s/it]04/07/2022 04:23:51 PM [INFO]: [CPU: 7]: Game 33
 29%|██▉       | 35/120 [1:24:21<3:41:52, 156.62s/it]04/07/2022 04:23:57 PM [INFO]: [CPU: 9]: Game 35
 30%|███       | 36/120 [1:24:28<3:04:38, 131.89s/it]04/07/2022 04:24:04 PM [INFO]: [CPU: 0]: Game 36
 33%|███▎      | 40/120 [1:24:41<3:18:11, 148.64s/it]04/07/2022 04:24:16 PM [INFO]: [CPU: 3]: Game 40
 32%|███▏      | 38/120 [1:24:41<2:54:55, 127.99s/it]04/07/2022 04:24:16 PM [INFO]: [CPU: 8]: Game 38
 32%|███▎      | 39/120 [1:25:13<3:06:48, 138.38s/it]04/07/2022 04:24:48 PM [INFO]: [CPU: 4]: Game 39
 33%|███▎      | 40/120 [1:25:21<2:52:57, 129.72s/it]04/07/2022 04:24:57 PM [INFO]: [CPU: 5]: Game 40
 32%|███▏      | 38/120 [1:25:32<3:29:41, 153.43s/it]04/07/2022 04:25:07 PM [INFO]: [CPU: 2]: Game 38
 28%|██▊       | 34/120 [1:25:32<3:59:49, 167.32s/it]04/07/2022 04:25:08 PM [INFO]: [CPU: 10]: Game 34
 30%|███       | 36/120 [1:25:57<3:13:57, 138.54s/it]04/07/2022 04:25:33 PM [INFO]: [CPU: 9]: Game 36
 28%|██▊       | 34/120 [1:26:05<3:41:51, 154.78s/it]04/07/2022 04:25:41 PM [INFO]: [CPU: 7]: Game 34
 31%|███       | 37/120 [1:26:49<3:06:17, 134.67s/it]04/07/2022 04:26:25 PM [INFO]: [CPU: 0]: Game 37
 34%|███▍      | 41/120 [1:27:04<2:40:07, 121.62s/it]04/07/2022 04:26:39 PM [INFO]: [CPU: 5]: Game 41
 31%|███       | 37/120 [1:27:21<2:48:46, 122.00s/it]04/07/2022 04:26:56 PM [INFO]: [CPU: 9]: Game 37
 32%|███▏      | 38/120 [1:27:22<3:41:03, 161.75s/it]04/07/2022 04:26:57 PM [INFO]: [CPU: 11]: Game 38
 33%|███▎      | 40/120 [1:27:27<3:03:03, 137.30s/it]04/07/2022 04:27:03 PM [INFO]: [CPU: 4]: Game 40
 30%|███       | 36/120 [1:27:34<3:45:13, 160.88s/it]04/07/2022 04:27:09 PM [INFO]: [CPU: 1]: Game 36
 32%|███▎      | 39/120 [1:27:40<3:16:58, 145.90s/it]04/07/2022 04:27:15 PM [INFO]: [CPU: 2]: Game 39
 32%|███▎      | 39/120 [1:28:00<3:21:32, 149.29s/it]04/07/2022 04:27:35 PM [INFO]: [CPU: 8]: Game 39
 32%|███▏      | 38/120 [1:28:12<2:17:46, 100.81s/it]04/07/2022 04:27:48 PM [INFO]: [CPU: 9]: Game 38
 34%|███▍      | 41/120 [1:28:12<2:24:18, 109.60s/it]04/07/2022 04:27:48 PM [INFO]: [CPU: 4]: Game 41
 34%|███▍      | 41/120 [1:28:25<3:45:42, 171.43s/it]04/07/2022 04:28:01 PM [INFO]: [CPU: 3]: Game 41
 29%|██▉       | 35/120 [1:28:33<3:36:15, 152.66s/it]04/07/2022 04:28:08 PM [INFO]: [CPU: 7]: Game 35
 31%|███       | 37/120 [1:28:44<3:05:07, 133.83s/it]04/07/2022 04:28:20 PM [INFO]: [CPU: 1]: Game 37
 29%|██▉       | 35/120 [1:28:45<4:07:47, 174.92s/it]04/07/2022 04:28:20 PM [INFO]: [CPU: 10]: Game 35
 32%|███▏      | 38/120 [1:28:51<2:58:51, 130.88s/it]04/07/2022 04:28:27 PM [INFO]: [CPU: 0]: Game 38
 35%|███▌      | 42/120 [1:28:53<2:33:14, 117.88s/it]04/07/2022 04:28:28 PM [INFO]: [CPU: 5]: Game 42
 32%|███▎      | 39/120 [1:29:16<2:01:17, 89.85s/it] 04/07/2022 04:28:52 PM [INFO]: [CPU: 9]: Game 39
 33%|███▎      | 40/120 [1:30:02<3:08:11, 141.15s/it]04/07/2022 04:29:37 PM [INFO]: [CPU: 8]: Game 40
 30%|███       | 36/120 [1:30:29<3:18:14, 141.61s/it]04/07/2022 04:30:04 PM [INFO]: [CPU: 7]: Game 36
 30%|███       | 36/120 [1:30:34<3:37:20, 155.24s/it]04/07/2022 04:30:10 PM [INFO]: [CPU: 10]: Game 36
 32%|███▎      | 39/120 [1:30:35<3:50:59, 171.10s/it]04/07/2022 04:30:10 PM [INFO]: [CPU: 11]: Game 39
 33%|███▎      | 40/120 [1:30:40<3:28:12, 156.15s/it]04/07/2022 04:30:16 PM [INFO]: [CPU: 2]: Game 40
 32%|███▎      | 39/120 [1:30:47<2:50:36, 126.37s/it]04/07/2022 04:30:23 PM [INFO]: [CPU: 0]: Game 39
 35%|███▌      | 42/120 [1:31:06<2:47:28, 128.83s/it]04/07/2022 04:30:42 PM [INFO]: [CPU: 4]: Game 42
 32%|███▏      | 38/120 [1:31:12<3:08:41, 138.07s/it]04/07/2022 04:30:48 PM [INFO]: [CPU: 1]: Game 38
 33%|███▎      | 40/120 [1:31:25<2:15:19, 101.50s/it]04/07/2022 04:31:01 PM [INFO]: [CPU: 9]: Game 40
 35%|███▌      | 42/120 [1:31:25<3:46:14, 174.04s/it]04/07/2022 04:31:01 PM [INFO]: [CPU: 3]: Game 42
 36%|███▌      | 43/120 [1:32:04<2:17:59, 107.52s/it]04/07/2022 04:31:39 PM [INFO]: [CPU: 4]: Game 43
 31%|███       | 37/120 [1:32:05<2:57:06, 128.04s/it]04/07/2022 04:31:41 PM [INFO]: [CPU: 7]: Game 37
 34%|███▍      | 41/120 [1:32:17<3:03:28, 139.35s/it]04/07/2022 04:31:52 PM [INFO]: [CPU: 8]: Game 41
 36%|███▌      | 43/120 [1:32:19<3:05:07, 144.26s/it]04/07/2022 04:31:54 PM [INFO]: [CPU: 5]: Game 43
 31%|███       | 37/120 [1:32:30<3:18:22, 143.40s/it]04/07/2022 04:32:05 PM [INFO]: [CPU: 10]: Game 37
 32%|███▎      | 39/120 [1:32:49<2:49:31, 125.58s/it]04/07/2022 04:32:24 PM [INFO]: [CPU: 1]: Game 39
 34%|███▍      | 41/120 [1:32:55<3:17:15, 149.82s/it]04/07/2022 04:32:31 PM [INFO]: [CPU: 2]: Game 41
 36%|███▌      | 43/120 [1:33:08<3:15:56, 152.69s/it]04/07/2022 04:32:44 PM [INFO]: [CPU: 3]: Game 43
 33%|███▎      | 40/120 [1:33:28<3:49:07, 171.84s/it]04/07/2022 04:33:04 PM [INFO]: [CPU: 11]: Game 40
 35%|███▌      | 42/120 [1:33:40<2:39:22, 122.60s/it]04/07/2022 04:33:16 PM [INFO]: [CPU: 8]: Game 42
 32%|███▏      | 38/120 [1:34:06<2:56:42, 129.30s/it]04/07/2022 04:33:42 PM [INFO]: [CPU: 10]: Game 38
 33%|███▎      | 40/120 [1:34:26<3:25:23, 154.04s/it]04/07/2022 04:34:01 PM [INFO]: [CPU: 0]: Game 40
 37%|███▋      | 44/120 [1:34:27<2:56:47, 139.58s/it]04/07/2022 04:34:03 PM [INFO]: [CPU: 5]: Game 44
 34%|███▍      | 41/120 [1:34:31<2:47:09, 126.96s/it]04/07/2022 04:34:07 PM [INFO]: [CPU: 9]: Game 41
 32%|███▏      | 38/120 [1:34:33<3:03:08, 134.00s/it]04/07/2022 04:34:08 PM [INFO]: [CPU: 7]: Game 38
 37%|███▋      | 44/120 [1:34:58<2:41:17, 127.34s/it]04/07/2022 04:34:33 PM [INFO]: [CPU: 4]: Game 44
 37%|███▋      | 44/120 [1:35:04<2:59:21, 141.60s/it]04/07/2022 04:34:39 PM [INFO]: [CPU: 3]: Game 44
 33%|███▎      | 40/120 [1:35:10<2:53:44, 130.31s/it]04/07/2022 04:34:46 PM [INFO]: [CPU: 1]: Game 40
 34%|███▍      | 41/120 [1:35:36<2:49:52, 129.02s/it]04/07/2022 04:35:12 PM [INFO]: [CPU: 0]: Game 41
 35%|███▌      | 42/120 [1:35:42<3:21:28, 154.98s/it]04/07/2022 04:35:18 PM [INFO]: [CPU: 2]: Game 42
 32%|███▎      | 39/120 [1:35:50<2:37:49, 116.91s/it]04/07/2022 04:35:25 PM [INFO]: [CPU: 7]: Game 39
 32%|███▎      | 39/120 [1:36:08<2:51:37, 127.13s/it]04/07/2022 04:35:44 PM [INFO]: [CPU: 10]: Game 39
 38%|███▊      | 45/120 [1:36:29<2:47:53, 134.31s/it]04/07/2022 04:36:05 PM [INFO]: [CPU: 5]: Game 45
 34%|███▍      | 41/120 [1:36:34<3:51:57, 176.17s/it]04/07/2022 04:36:10 PM [INFO]: [CPU: 11]: Game 41
 34%|███▍      | 41/120 [1:36:53<2:40:42, 122.05s/it]04/07/2022 04:36:28 PM [INFO]: [CPU: 1]: Game 41
 38%|███▊      | 45/120 [1:37:12<2:52:03, 137.64s/it]04/07/2022 04:36:48 PM [INFO]: [CPU: 3]: Game 45
 33%|███▎      | 40/120 [1:37:19<2:26:56, 110.20s/it]04/07/2022 04:36:55 PM [INFO]: [CPU: 10]: Game 40
 35%|███▌      | 42/120 [1:37:38<3:08:09, 144.74s/it]04/07/2022 04:37:13 PM [INFO]: [CPU: 9]: Game 42
 38%|███▊      | 45/120 [1:37:45<2:54:02, 139.24s/it]04/07/2022 04:37:20 PM [INFO]: [CPU: 4]: Game 45
 36%|███▌      | 43/120 [1:37:57<3:11:10, 148.96s/it]04/07/2022 04:37:33 PM [INFO]: [CPU: 2]: Game 43
 36%|███▌      | 43/120 [1:37:57<3:29:00, 162.87s/it]04/07/2022 04:37:33 PM [INFO]: [CPU: 8]: Game 43
 34%|███▍      | 41/120 [1:38:36<2:12:01, 100.27s/it]04/07/2022 04:38:12 PM [INFO]: [CPU: 10]: Game 41
 38%|███▊      | 46/120 [1:38:42<2:21:36, 114.82s/it]04/07/2022 04:38:18 PM [INFO]: [CPU: 4]: Game 46
 36%|███▌      | 43/120 [1:38:48<2:37:14, 122.53s/it]04/07/2022 04:38:24 PM [INFO]: [CPU: 9]: Game 43
 35%|███▌      | 42/120 [1:38:49<3:12:35, 148.15s/it]04/07/2022 04:38:25 PM [INFO]: [CPU: 0]: Game 42
 33%|███▎      | 40/120 [1:38:50<3:01:03, 135.80s/it]04/07/2022 04:38:25 PM [INFO]: [CPU: 7]: Game 40
 35%|███▌      | 42/120 [1:38:55<2:38:40, 122.06s/it]04/07/2022 04:38:30 PM [INFO]: [CPU: 1]: Game 42
 37%|███▋      | 44/120 [1:39:08<2:51:16, 135.21s/it]04/07/2022 04:38:43 PM [INFO]: [CPU: 8]: Game 44
 38%|███▊      | 46/120 [1:39:34<2:51:11, 138.80s/it]04/07/2022 04:39:09 PM [INFO]: [CPU: 3]: Game 46
 37%|███▋      | 44/120 [1:39:46<2:53:37, 137.08s/it]04/07/2022 04:39:22 PM [INFO]: [CPU: 2]: Game 44
 38%|███▊      | 45/120 [1:39:53<2:15:12, 108.17s/it]04/07/2022 04:39:28 PM [INFO]: [CPU: 8]: Game 45
 35%|███▌      | 42/120 [1:39:54<3:58:05, 183.15s/it]04/07/2022 04:39:29 PM [INFO]: [CPU: 11]: Game 42
 38%|███▊      | 46/120 [1:40:08<3:16:48, 159.58s/it]04/07/2022 04:39:43 PM [INFO]: [CPU: 5]: Game 46
 39%|███▉      | 47/120 [1:40:25<2:15:23, 111.28s/it]04/07/2022 04:40:01 PM [INFO]: [CPU: 4]: Game 47
 36%|███▌      | 43/120 [1:40:32<2:52:40, 134.55s/it]04/07/2022 04:40:08 PM [INFO]: [CPU: 0]: Game 43
 35%|███▌      | 42/120 [1:40:38<2:18:54, 106.85s/it]04/07/2022 04:40:14 PM [INFO]: [CPU: 10]: Game 42
 37%|███▋      | 44/120 [1:41:10<2:42:25, 128.23s/it]04/07/2022 04:40:45 PM [INFO]: [CPU: 9]: Game 44
 36%|███▌      | 43/120 [1:41:37<3:24:06, 159.05s/it]04/07/2022 04:41:12 PM [INFO]: [CPU: 11]: Game 43
 36%|███▌      | 43/120 [1:42:01<3:01:26, 141.38s/it]04/07/2022 04:41:37 PM [INFO]: [CPU: 1]: Game 43
 39%|███▉      | 47/120 [1:42:02<2:52:10, 141.51s/it]04/07/2022 04:41:37 PM [INFO]: [CPU: 3]: Game 47
 34%|███▍      | 41/120 [1:42:09<3:23:55, 154.88s/it]04/07/2022 04:41:45 PM [INFO]: [CPU: 7]: Game 41
 39%|███▉      | 47/120 [1:42:10<3:00:31, 148.38s/it]04/07/2022 04:41:46 PM [INFO]: [CPU: 5]: Game 47
 38%|███▊      | 45/120 [1:42:27<2:21:08, 112.92s/it]04/07/2022 04:42:03 PM [INFO]: [CPU: 9]: Game 45
 37%|███▋      | 44/120 [1:42:28<2:40:35, 126.78s/it]04/07/2022 04:42:04 PM [INFO]: [CPU: 11]: Game 44
 36%|███▌      | 43/120 [1:42:34<2:20:33, 109.52s/it]04/07/2022 04:42:10 PM [INFO]: [CPU: 10]: Game 43
 37%|███▋      | 44/120 [1:42:34<2:45:49, 130.91s/it]04/07/2022 04:42:10 PM [INFO]: [CPU: 0]: Game 44
 40%|████      | 48/120 [1:42:47<2:24:26, 120.37s/it]04/07/2022 04:42:22 PM [INFO]: [CPU: 4]: Game 48
 38%|███▊      | 46/120 [1:42:53<2:40:01, 129.75s/it]04/07/2022 04:42:29 PM [INFO]: [CPU: 8]: Game 46
 38%|███▊      | 45/120 [1:43:12<3:17:09, 157.73s/it]04/07/2022 04:42:48 PM [INFO]: [CPU: 2]: Game 45
 40%|████      | 48/120 [1:43:38<2:33:38, 128.04s/it]04/07/2022 04:43:14 PM [INFO]: [CPU: 3]: Game 48
 35%|███▌      | 42/120 [1:43:46<2:58:36, 137.39s/it]04/07/2022 04:43:21 PM [INFO]: [CPU: 7]: Game 42
 38%|███▊      | 45/120 [1:43:52<2:22:19, 113.86s/it]04/07/2022 04:43:27 PM [INFO]: [CPU: 11]: Game 45
 37%|███▋      | 44/120 [1:44:11<2:13:47, 105.62s/it]04/07/2022 04:43:46 PM [INFO]: [CPU: 10]: Game 44
 37%|███▋      | 44/120 [1:44:49<3:08:53, 149.13s/it]04/07/2022 04:44:24 PM [INFO]: [CPU: 1]: Game 44
 38%|███▊      | 46/120 [1:45:08<2:58:57, 145.10s/it]04/07/2022 04:44:43 PM [INFO]: [CPU: 2]: Game 46
 41%|████      | 49/120 [1:45:08<2:29:53, 126.66s/it]04/07/2022 04:44:44 PM [INFO]: [CPU: 4]: Game 49
 36%|███▌      | 43/120 [1:45:35<2:45:25, 128.90s/it]04/07/2022 04:45:10 PM [INFO]: [CPU: 7]: Game 43
 38%|███▊      | 45/120 [1:45:41<3:04:26, 147.56s/it]04/07/2022 04:45:16 PM [INFO]: [CPU: 0]: Game 45
 40%|████      | 48/120 [1:45:42<3:21:01, 167.52s/it]04/07/2022 04:45:18 PM [INFO]: [CPU: 5]: Game 48
 38%|███▊      | 45/120 [1:45:53<2:10:58, 104.78s/it]04/07/2022 04:45:29 PM [INFO]: [CPU: 10]: Game 45
 38%|███▊      | 46/120 [1:45:59<2:55:59, 142.69s/it]04/07/2022 04:45:35 PM [INFO]: [CPU: 9]: Game 46
 38%|███▊      | 45/120 [1:45:59<2:37:00, 125.61s/it]04/07/2022 04:45:35 PM [INFO]: [CPU: 1]: Game 45
 39%|███▉      | 47/120 [1:46:06<3:00:54, 148.69s/it]04/07/2022 04:45:41 PM [INFO]: [CPU: 8]: Game 47
 41%|████      | 49/120 [1:46:19<2:43:05, 137.82s/it]04/07/2022 04:45:54 PM [INFO]: [CPU: 3]: Game 49
 41%|████      | 49/120 [1:46:47<2:41:35, 136.56s/it]04/07/2022 04:46:22 PM [INFO]: [CPU: 5]: Game 49
 38%|███▊      | 46/120 [1:46:58<2:47:15, 135.61s/it]04/07/2022 04:46:34 PM [INFO]: [CPU: 11]: Game 46
 37%|███▋      | 44/120 [1:47:24<2:35:49, 123.03s/it]04/07/2022 04:47:00 PM [INFO]: [CPU: 7]: Game 44
 38%|███▊      | 46/120 [1:47:37<2:50:13, 138.02s/it]04/07/2022 04:47:12 PM [INFO]: [CPU: 0]: Game 46
 38%|███▊      | 46/120 [1:47:43<2:10:54, 106.15s/it]04/07/2022 04:47:18 PM [INFO]: [CPU: 10]: Game 46
 40%|████      | 48/120 [1:47:55<2:44:15, 136.88s/it]04/07/2022 04:47:31 PM [INFO]: [CPU: 8]: Game 48
 38%|███▊      | 46/120 [1:48:08<2:36:02, 126.52s/it]04/07/2022 04:47:44 PM [INFO]: [CPU: 1]: Game 46
 39%|███▉      | 47/120 [1:48:27<3:16:18, 161.35s/it]04/07/2022 04:48:03 PM [INFO]: [CPU: 2]: Game 47
 42%|████▏     | 50/120 [1:48:53<2:46:33, 142.76s/it]04/07/2022 04:48:29 PM [INFO]: [CPU: 3]: Game 50
 39%|███▉      | 47/120 [1:49:00<1:58:33, 97.45s/it] 04/07/2022 04:48:35 PM [INFO]: [CPU: 10]: Game 47
 39%|███▉      | 47/120 [1:49:07<2:30:25, 123.64s/it]04/07/2022 04:48:42 PM [INFO]: [CPU: 0]: Game 47
 42%|████▏     | 50/120 [1:49:13<3:08:55, 161.94s/it]04/07/2022 04:48:48 PM [INFO]: [CPU: 4]: Game 50
 39%|███▉      | 47/120 [1:49:38<3:21:18, 165.46s/it]04/07/2022 04:49:13 PM [INFO]: [CPU: 9]: Game 47
 42%|████▏     | 50/120 [1:49:40<2:52:17, 147.68s/it]04/07/2022 04:49:16 PM [INFO]: [CPU: 5]: Game 50
 41%|████      | 49/120 [1:49:45<2:32:12, 128.63s/it]04/07/2022 04:49:20 PM [INFO]: [CPU: 8]: Game 49
 39%|███▉      | 47/120 [1:49:45<2:56:32, 145.10s/it]04/07/2022 04:49:21 PM [INFO]: [CPU: 11]: Game 47
 39%|███▉      | 47/120 [1:50:04<2:30:01, 123.31s/it]04/07/2022 04:49:39 PM [INFO]: [CPU: 1]: Game 47
 38%|███▊      | 45/120 [1:50:57<3:07:15, 149.81s/it]04/07/2022 04:50:32 PM [INFO]: [CPU: 7]: Game 45
 40%|████      | 48/120 [1:51:02<2:05:51, 104.88s/it]04/07/2022 04:50:38 PM [INFO]: [CPU: 10]: Game 48
 42%|████▎     | 51/120 [1:51:04<2:27:42, 128.45s/it]04/07/2022 04:50:39 PM [INFO]: [CPU: 5]: Game 51
 40%|████      | 48/120 [1:51:09<2:31:57, 126.64s/it]04/07/2022 04:50:45 PM [INFO]: [CPU: 11]: Game 48
 42%|████▎     | 51/120 [1:51:21<2:45:57, 144.31s/it]04/07/2022 04:50:57 PM [INFO]: [CPU: 3]: Game 51
 40%|████      | 48/120 [1:51:28<2:34:46, 128.98s/it]04/07/2022 04:51:04 PM [INFO]: [CPU: 0]: Game 48
 42%|████▏     | 50/120 [1:52:00<2:32:17, 130.54s/it]04/07/2022 04:51:35 PM [INFO]: [CPU: 8]: Game 50
 40%|████      | 48/120 [1:52:06<2:27:34, 122.97s/it]04/07/2022 04:51:42 PM [INFO]: [CPU: 1]: Game 48
 40%|████      | 48/120 [1:52:12<3:36:33, 180.47s/it]04/07/2022 04:51:48 PM [INFO]: [CPU: 2]: Game 48
 40%|████      | 48/120 [1:52:19<3:16:52, 164.06s/it]04/07/2022 04:51:54 PM [INFO]: [CPU: 9]: Game 48
 43%|████▎     | 52/120 [1:52:58<2:27:17, 129.97s/it]04/07/2022 04:52:33 PM [INFO]: [CPU: 3]: Game 52
 41%|████      | 49/120 [1:53:10<2:04:41, 105.38s/it]04/07/2022 04:52:46 PM [INFO]: [CPU: 1]: Game 49
 43%|████▎     | 52/120 [1:53:13<2:25:39, 128.52s/it]04/07/2022 04:52:48 PM [INFO]: [CPU: 5]: Game 52
 42%|████▎     | 51/120 [1:53:17<3:34:37, 186.64s/it]04/07/2022 04:52:52 PM [INFO]: [CPU: 4]: Game 51
 41%|████      | 49/120 [1:53:17<2:14:50, 113.95s/it]04/07/2022 04:52:53 PM [INFO]: [CPU: 10]: Game 49
 38%|███▊      | 46/120 [1:53:31<3:06:27, 151.18s/it]04/07/2022 04:53:06 PM [INFO]: [CPU: 7]: Game 46
 41%|████      | 49/120 [1:53:56<2:44:15, 138.81s/it]04/07/2022 04:53:32 PM [INFO]: [CPU: 11]: Game 49
 41%|████      | 49/120 [1:54:08<3:10:34, 161.05s/it]04/07/2022 04:53:44 PM [INFO]: [CPU: 2]: Game 49
 44%|████▍     | 53/120 [1:54:15<2:07:25, 114.11s/it]04/07/2022 04:53:50 PM [INFO]: [CPU: 3]: Game 53
 41%|████      | 49/120 [1:54:40<3:06:06, 157.27s/it]04/07/2022 04:54:16 PM [INFO]: [CPU: 9]: Game 49
 42%|████▎     | 51/120 [1:54:40<2:40:33, 139.62s/it]04/07/2022 04:54:16 PM [INFO]: [CPU: 8]: Game 51
 43%|████▎     | 52/120 [1:54:40<2:56:29, 155.73s/it]04/07/2022 04:54:16 PM [INFO]: [CPU: 4]: Game 52
 41%|████      | 49/120 [1:54:41<2:55:19, 148.16s/it]04/07/2022 04:54:17 PM [INFO]: [CPU: 0]: Game 49
 42%|████▏     | 50/120 [1:54:53<2:02:04, 104.63s/it]04/07/2022 04:54:29 PM [INFO]: [CPU: 1]: Game 50
 39%|███▉      | 47/120 [1:55:20<2:48:39, 138.62s/it]04/07/2022 04:54:56 PM [INFO]: [CPU: 7]: Game 47
 44%|████▍     | 53/120 [1:55:47<2:32:10, 136.28s/it]04/07/2022 04:55:22 PM [INFO]: [CPU: 5]: Game 53
 45%|████▌     | 54/120 [1:55:51<1:59:41, 108.81s/it]04/07/2022 04:55:27 PM [INFO]: [CPU: 3]: Game 54
 42%|████▏     | 50/120 [1:55:57<2:49:46, 145.52s/it]04/07/2022 04:55:33 PM [INFO]: [CPU: 2]: Game 50
 42%|████▏     | 50/120 [1:56:04<2:37:42, 135.17s/it]04/07/2022 04:55:39 PM [INFO]: [CPU: 9]: Game 50
 42%|████▏     | 50/120 [1:56:49<2:47:17, 143.39s/it]04/07/2022 04:56:25 PM [INFO]: [CPU: 10]: Game 50
 44%|████▍     | 53/120 [1:57:02<2:49:05, 151.42s/it]04/07/2022 04:56:37 PM [INFO]: [CPU: 4]: Game 53
 42%|████▏     | 50/120 [1:57:09<2:52:45, 148.08s/it]04/07/2022 04:56:44 PM [INFO]: [CPU: 0]: Game 50
 42%|████▏     | 50/120 [1:57:09<3:00:51, 155.02s/it]04/07/2022 04:56:45 PM [INFO]: [CPU: 11]: Game 50
 43%|████▎     | 52/120 [1:57:15<2:43:13, 144.02s/it]04/07/2022 04:56:50 PM [INFO]: [CPU: 8]: Game 52
 46%|████▌     | 55/120 [1:57:28<1:53:50, 105.09s/it]04/07/2022 04:57:03 PM [INFO]: [CPU: 3]: Game 55
 40%|████      | 48/120 [1:57:42<2:47:20, 139.45s/it]04/07/2022 04:57:17 PM [INFO]: [CPU: 7]: Game 48
 42%|████▎     | 51/120 [1:57:47<2:24:06, 125.31s/it]04/07/2022 04:57:22 PM [INFO]: [CPU: 1]: Game 51
 45%|████▌     | 54/120 [1:57:49<2:25:14, 132.04s/it]04/07/2022 04:57:25 PM [INFO]: [CPU: 5]: Game 54
 45%|████▌     | 54/120 [1:58:13<2:19:55, 127.21s/it]04/07/2022 04:57:48 PM [INFO]: [CPU: 4]: Game 54
 42%|████▎     | 51/120 [1:58:51<2:46:27, 144.75s/it]04/07/2022 04:58:26 PM [INFO]: [CPU: 9]: Game 51
 42%|████▎     | 51/120 [1:58:51<2:57:02, 153.95s/it]04/07/2022 04:58:26 PM [INFO]: [CPU: 2]: Game 51
 47%|████▋     | 56/120 [1:58:51<1:45:14, 98.66s/it] 04/07/2022 04:58:27 PM [INFO]: [CPU: 3]: Game 56
 42%|████▎     | 51/120 [1:58:51<2:37:34, 137.02s/it]04/07/2022 04:58:27 PM [INFO]: [CPU: 10]: Game 51
 46%|████▌     | 55/120 [1:59:04<1:53:11, 104.49s/it]04/07/2022 04:58:40 PM [INFO]: [CPU: 4]: Game 55
 44%|████▍     | 53/120 [1:59:30<2:37:47, 141.30s/it]04/07/2022 04:59:05 PM [INFO]: [CPU: 8]: Game 53
 42%|████▎     | 51/120 [1:59:37<2:50:14, 148.04s/it]04/07/2022 04:59:12 PM [INFO]: [CPU: 0]: Game 51
 41%|████      | 49/120 [1:59:44<2:38:52, 134.26s/it]04/07/2022 04:59:19 PM [INFO]: [CPU: 7]: Game 49
 42%|████▎     | 51/120 [1:59:56<3:02:27, 158.67s/it]04/07/2022 04:59:32 PM [INFO]: [CPU: 11]: Game 51
 47%|████▋     | 56/120 [2:00:21<1:42:44, 96.32s/it] 04/07/2022 04:59:57 PM [INFO]: [CPU: 4]: Game 56
 43%|████▎     | 52/120 [2:00:28<2:21:34, 124.92s/it]04/07/2022 05:00:04 PM [INFO]: [CPU: 10]: Game 52
 46%|████▌     | 55/120 [2:00:30<2:32:22, 140.66s/it]04/07/2022 05:00:05 PM [INFO]: [CPU: 5]: Game 55
 43%|████▎     | 52/120 [2:00:34<2:36:12, 137.84s/it]04/07/2022 05:00:09 PM [INFO]: [CPU: 1]: Game 52
 43%|████▎     | 52/120 [2:00:41<2:21:10, 124.57s/it]04/07/2022 05:00:17 PM [INFO]: [CPU: 11]: Game 52
 45%|████▌     | 54/120 [2:00:53<2:16:23, 123.99s/it]04/07/2022 05:00:29 PM [INFO]: [CPU: 8]: Game 54
 48%|████▊     | 57/120 [2:00:53<1:50:59, 105.71s/it]04/07/2022 05:00:29 PM [INFO]: [CPU: 3]: Game 57
 43%|████▎     | 52/120 [2:01:13<2:30:13, 132.56s/it]04/07/2022 05:00:49 PM [INFO]: [CPU: 0]: Game 52
 43%|████▎     | 52/120 [2:01:19<2:45:08, 145.72s/it]04/07/2022 05:00:54 PM [INFO]: [CPU: 9]: Game 52
 43%|████▎     | 52/120 [2:01:25<2:54:35, 154.05s/it]04/07/2022 05:01:01 PM [INFO]: [CPU: 2]: Game 52
 47%|████▋     | 56/120 [2:01:41<2:07:39, 119.69s/it]04/07/2022 05:01:16 PM [INFO]: [CPU: 5]: Game 56
 48%|████▊     | 57/120 [2:02:11<1:45:15, 100.24s/it]04/07/2022 05:01:46 PM [INFO]: [CPU: 4]: Game 57
 42%|████▏     | 50/120 [2:02:12<2:41:27, 138.39s/it]04/07/2022 05:01:47 PM [INFO]: [CPU: 7]: Game 50
 48%|████▊     | 57/120 [2:02:26<1:42:10, 97.30s/it] 04/07/2022 05:02:01 PM [INFO]: [CPU: 5]: Game 57
 48%|████▊     | 58/120 [2:02:30<1:46:23, 102.96s/it]04/07/2022 05:02:05 PM [INFO]: [CPU: 3]: Game 58
 44%|████▍     | 53/120 [2:02:36<2:19:45, 125.15s/it]04/07/2022 05:02:11 PM [INFO]: [CPU: 9]: Game 53
 44%|████▍     | 53/120 [2:02:43<2:13:48, 119.83s/it]04/07/2022 05:02:19 PM [INFO]: [CPU: 0]: Game 53
 44%|████▍     | 53/120 [2:02:50<2:20:29, 125.81s/it]04/07/2022 05:02:25 PM [INFO]: [CPU: 11]: Game 53
 42%|████▎     | 51/120 [2:02:57<2:06:56, 110.39s/it]04/07/2022 05:02:32 PM [INFO]: [CPU: 7]: Game 51
 44%|████▍     | 53/120 [2:03:27<2:41:22, 144.52s/it]04/07/2022 05:03:03 PM [INFO]: [CPU: 2]: Game 53
 46%|████▌     | 55/120 [2:03:28<2:24:14, 133.14s/it]04/07/2022 05:03:03 PM [INFO]: [CPU: 8]: Game 55
 44%|████▍     | 53/120 [2:03:41<2:50:16, 152.48s/it]04/07/2022 05:03:16 PM [INFO]: [CPU: 1]: Game 53
 48%|████▊     | 58/120 [2:03:56<1:38:18, 95.14s/it]04/07/2022 05:03:31 PM [INFO]: [CPU: 5]: Game 58
 45%|████▌     | 54/120 [2:04:01<1:57:45, 107.06s/it]04/07/2022 05:03:36 PM [INFO]: [CPU: 0]: Game 54
 48%|████▊     | 58/120 [2:04:32<1:56:23, 112.64s/it]04/07/2022 05:04:08 PM [INFO]: [CPU: 4]: Game 58
 44%|████▍     | 53/120 [2:04:33<2:59:33, 160.80s/it]04/07/2022 05:04:08 PM [INFO]: [CPU: 10]: Game 53
 45%|████▌     | 54/120 [2:04:33<2:10:50, 118.95s/it]04/07/2022 05:04:08 PM [INFO]: [CPU: 11]: Game 54
 45%|████▌     | 54/120 [2:04:45<2:18:50, 126.21s/it]04/07/2022 05:04:20 PM [INFO]: [CPU: 9]: Game 54
 43%|████▎     | 52/120 [2:04:46<2:04:46, 110.10s/it]04/07/2022 05:04:22 PM [INFO]: [CPU: 7]: Game 52
 45%|████▌     | 54/120 [2:05:11<2:27:08, 133.77s/it]04/07/2022 05:04:46 PM [INFO]: [CPU: 1]: Game 54
 49%|████▉     | 59/120 [2:05:17<2:04:18, 122.27s/it]04/07/2022 05:04:53 PM [INFO]: [CPU: 3]: Game 59
 49%|████▉     | 59/120 [2:05:26<1:35:10, 93.62s/it]04/07/2022 05:05:01 PM [INFO]: [CPU: 5]: Game 59
 46%|████▌     | 55/120 [2:06:09<2:01:33, 112.21s/it]04/07/2022 05:05:45 PM [INFO]: [CPU: 11]: Game 55
 45%|████▌     | 54/120 [2:06:15<2:46:27, 151.33s/it]04/07/2022 05:05:50 PM [INFO]: [CPU: 2]: Game 54
 47%|████▋     | 56/120 [2:06:15<2:32:55, 143.36s/it]04/07/2022 05:05:50 PM [INFO]: [CPU: 8]: Game 56
 44%|████▍     | 53/120 [2:06:36<2:02:41, 109.87s/it]04/07/2022 05:06:11 PM [INFO]: [CPU: 7]: Game 53
 45%|████▌     | 54/120 [2:06:41<2:46:16, 151.16s/it]04/07/2022 05:06:17 PM [INFO]: [CPU: 10]: Game 54
 46%|████▌     | 55/120 [2:07:19<2:23:14, 132.22s/it]04/07/2022 05:06:55 PM [INFO]: [CPU: 1]: Game 55
 46%|████▌     | 55/120 [2:07:38<2:32:09, 140.45s/it]04/07/2022 05:07:14 PM [INFO]: [CPU: 9]: Game 55
 50%|█████     | 60/120 [2:07:39<2:08:01, 128.02s/it]04/07/2022 05:07:14 PM [INFO]: [CPU: 3]: Game 60
 49%|████▉     | 59/120 [2:07:39<2:17:03, 134.81s/it]04/07/2022 05:07:14 PM [INFO]: [CPU: 4]: Game 59
 46%|████▌     | 55/120 [2:07:52<2:36:26, 144.40s/it]04/07/2022 05:07:28 PM [INFO]: [CPU: 0]: Game 55
 50%|█████     | 60/120 [2:08:00<1:51:50, 111.84s/it]04/07/2022 05:07:36 PM [INFO]: [CPU: 5]: Game 60
 46%|████▌     | 55/120 [2:08:31<2:30:10, 138.62s/it]04/07/2022 05:08:06 PM [INFO]: [CPU: 10]: Game 55
 46%|████▌     | 55/120 [2:08:36<2:40:45, 148.39s/it]04/07/2022 05:08:12 PM [INFO]: [CPU: 2]: Game 55
 47%|████▋     | 56/120 [2:09:09<2:12:29, 124.22s/it]04/07/2022 05:08:45 PM [INFO]: [CPU: 0]: Game 56
 50%|█████     | 60/120 [2:09:28<2:07:10, 127.17s/it]04/07/2022 05:09:04 PM [INFO]: [CPU: 4]: Game 60
 47%|████▋     | 56/120 [2:09:34<2:09:19, 121.24s/it]04/07/2022 05:09:10 PM [INFO]: [CPU: 2]: Game 56
 47%|████▋     | 56/120 [2:09:42<2:31:40, 142.20s/it]04/07/2022 05:09:17 PM [INFO]: [CPU: 11]: Game 56
 45%|████▌     | 54/120 [2:09:42<2:26:08, 132.86s/it]04/07/2022 05:09:18 PM [INFO]: [CPU: 7]: Game 54
 47%|████▋     | 56/120 [2:09:47<2:26:04, 136.94s/it]04/07/2022 05:09:23 PM [INFO]: [CPU: 1]: Game 56
 48%|████▊     | 57/120 [2:09:54<2:54:13, 165.92s/it]04/07/2022 05:09:29 PM [INFO]: [CPU: 8]: Game 57
 51%|█████     | 61/120 [2:10:09<1:54:55, 116.87s/it]04/07/2022 05:09:44 PM [INFO]: [CPU: 5]: Game 61
 48%|████▊     | 57/120 [2:10:33<1:57:38, 112.04s/it]04/07/2022 05:10:09 PM [INFO]: [CPU: 0]: Game 57
 48%|████▊     | 58/120 [2:10:39<2:13:58, 129.66s/it]04/07/2022 05:10:14 PM [INFO]: [CPU: 8]: Game 58
 51%|█████     | 61/120 [2:10:52<2:25:01, 147.48s/it]04/07/2022 05:10:27 PM [INFO]: [CPU: 3]: Game 61
 47%|████▋     | 56/120 [2:10:52<2:28:45, 139.47s/it]04/07/2022 05:10:28 PM [INFO]: [CPU: 10]: Game 56
 46%|████▌     | 55/120 [2:11:12<2:09:59, 119.99s/it]04/07/2022 05:10:48 PM [INFO]: [CPU: 7]: Game 55
 47%|████▋     | 56/120 [2:11:23<2:56:53, 165.83s/it]04/07/2022 05:10:59 PM [INFO]: [CPU: 9]: Game 56
 49%|████▉     | 59/120 [2:11:43<1:51:52, 110.05s/it]04/07/2022 05:11:18 PM [INFO]: [CPU: 8]: Game 59
 51%|█████     | 61/120 [2:11:43<2:07:21, 129.52s/it]04/07/2022 05:11:19 PM [INFO]: [CPU: 4]: Game 61
 52%|█████▏    | 62/120 [2:12:05<1:52:39, 116.54s/it]04/07/2022 05:11:40 PM [INFO]: [CPU: 5]: Game 62
 48%|████▊     | 57/120 [2:12:09<2:25:11, 138.28s/it]04/07/2022 05:11:44 PM [INFO]: [CPU: 1]: Game 57
 48%|████▊     | 57/120 [2:12:29<2:12:53, 126.57s/it]04/07/2022 05:12:04 PM [INFO]: [CPU: 10]: Game 57
 48%|████▊     | 57/120 [2:12:35<2:39:14, 151.65s/it]04/07/2022 05:12:11 PM [INFO]: [CPU: 11]: Game 57
 48%|████▊     | 58/120 [2:13:07<2:08:53, 124.73s/it]04/07/2022 05:12:43 PM [INFO]: [CPU: 0]: Game 58
 52%|█████▎    | 63/120 [2:13:09<1:35:48, 100.86s/it]04/07/2022 05:12:44 PM [INFO]: [CPU: 5]: Game 63
 52%|█████▏    | 62/120 [2:13:26<2:24:33, 149.54s/it]04/07/2022 05:13:01 PM [INFO]: [CPU: 3]: Game 62
 48%|████▊     | 58/120 [2:13:52<2:11:55, 127.68s/it]04/07/2022 05:13:27 PM [INFO]: [CPU: 1]: Game 58
 48%|████▊     | 58/120 [2:13:52<2:13:36, 129.31s/it]04/07/2022 05:13:28 PM [INFO]: [CPU: 11]: Game 58
 48%|████▊     | 57/120 [2:13:58<2:50:30, 162.39s/it]04/07/2022 05:13:33 PM [INFO]: [CPU: 9]: Game 57
 48%|████▊     | 57/120 [2:14:04<2:54:10, 165.88s/it]04/07/2022 05:13:40 PM [INFO]: [CPU: 2]: Game 57
 50%|█████     | 60/120 [2:14:04<1:59:29, 119.50s/it]04/07/2022 05:13:40 PM [INFO]: [CPU: 8]: Game 60
 52%|█████▏    | 62/120 [2:14:05<2:08:40, 133.11s/it]04/07/2022 05:13:40 PM [INFO]: [CPU: 4]: Game 62
 47%|████▋     | 56/120 [2:14:06<2:25:09, 136.09s/it]04/07/2022 05:13:41 PM [INFO]: [CPU: 7]: Game 56
 48%|████▊     | 58/120 [2:14:50<2:15:26, 131.07s/it]04/07/2022 05:14:26 PM [INFO]: [CPU: 10]: Game 58
 49%|████▉     | 59/120 [2:14:57<2:02:07, 120.13s/it]04/07/2022 05:14:32 PM [INFO]: [CPU: 0]: Game 59
 52%|█████▎    | 63/120 [2:15:28<2:14:16, 141.33s/it]04/07/2022 05:15:04 PM [INFO]: [CPU: 3]: Game 63
 48%|████▊     | 57/120 [2:15:29<2:06:22, 120.35s/it]04/07/2022 05:15:05 PM [INFO]: [CPU: 7]: Game 57
 49%|████▉     | 59/120 [2:15:41<2:04:12, 122.17s/it]04/07/2022 05:15:16 PM [INFO]: [CPU: 1]: Game 59
 52%|█████▎    | 63/120 [2:15:41<1:56:00, 122.11s/it]04/07/2022 05:15:17 PM [INFO]: [CPU: 4]: Game 63
 48%|████▊     | 58/120 [2:15:53<2:33:20, 148.39s/it]04/07/2022 05:15:29 PM [INFO]: [CPU: 9]: Game 58
 51%|█████     | 61/120 [2:16:07<1:58:16, 120.28s/it]04/07/2022 05:15:42 PM [INFO]: [CPU: 8]: Game 61
 49%|████▉     | 59/120 [2:16:14<1:58:44, 116.80s/it]04/07/2022 05:15:49 PM [INFO]: [CPU: 10]: Game 59
 53%|█████▎    | 64/120 [2:16:15<1:58:07, 126.57s/it]04/07/2022 05:15:51 PM [INFO]: [CPU: 5]: Game 64
 49%|████▉     | 59/120 [2:16:33<2:21:02, 138.73s/it]04/07/2022 05:16:09 PM [INFO]: [CPU: 11]: Game 59
 48%|████▊     | 58/120 [2:16:51<2:51:47, 166.25s/it]04/07/2022 05:16:27 PM [INFO]: [CPU: 2]: Game 58
 54%|█████▍    | 65/120 [2:17:00<1:33:33, 102.07s/it]04/07/2022 05:16:36 PM [INFO]: [CPU: 5]: Game 65
 53%|█████▎    | 64/120 [2:17:05<1:43:11, 110.56s/it]04/07/2022 05:16:40 PM [INFO]: [CPU: 4]: Game 64
 50%|█████     | 60/120 [2:17:05<2:02:38, 122.64s/it]04/07/2022 05:16:41 PM [INFO]: [CPU: 0]: Game 60
 49%|████▉     | 59/120 [2:17:23<2:13:01, 130.85s/it]04/07/2022 05:16:59 PM [INFO]: [CPU: 9]: Game 59
 53%|█████▎    | 64/120 [2:17:24<2:04:43, 133.63s/it]04/07/2022 05:16:59 PM [INFO]: [CPU: 3]: Game 64
 48%|████▊     | 58/120 [2:17:44<2:08:52, 124.72s/it]04/07/2022 05:17:20 PM [INFO]: [CPU: 7]: Game 58
 50%|█████     | 60/120 [2:18:09<2:09:50, 129.85s/it]04/07/2022 05:17:44 PM [INFO]: [CPU: 1]: Game 60
 52%|█████▏    | 62/120 [2:18:09<1:56:48, 120.83s/it]04/07/2022 05:17:44 PM [INFO]: [CPU: 8]: Game 62
 55%|█████▌    | 66/120 [2:18:24<1:26:53, 96.54s/it] 04/07/2022 05:17:59 PM [INFO]: [CPU: 5]: Game 66
 50%|█████     | 60/120 [2:18:35<2:13:44, 133.75s/it]04/07/2022 05:18:11 PM [INFO]: [CPU: 11]: Game 60
 50%|█████     | 60/120 [2:19:00<2:00:31, 120.52s/it]04/07/2022 05:18:35 PM [INFO]: [CPU: 9]: Game 60
 50%|█████     | 60/120 [2:19:01<2:11:53, 131.90s/it]04/07/2022 05:18:36 PM [INFO]: [CPU: 10]: Game 60
 54%|█████▍    | 65/120 [2:19:26<1:49:49, 119.81s/it]04/07/2022 05:19:02 PM [INFO]: [CPU: 4]: Game 65
 49%|████▉     | 59/120 [2:19:32<2:47:18, 164.56s/it]04/07/2022 05:19:07 PM [INFO]: [CPU: 2]: Game 59
 54%|█████▍    | 65/120 [2:19:39<2:02:51, 134.03s/it]04/07/2022 05:19:14 PM [INFO]: [CPU: 3]: Game 65
 51%|█████     | 61/120 [2:19:39<2:09:54, 132.12s/it]04/07/2022 05:19:15 PM [INFO]: [CPU: 0]: Game 61
 52%|█████▎    | 63/120 [2:20:36<2:02:29, 128.94s/it]04/07/2022 05:20:12 PM [INFO]: [CPU: 8]: Game 63
 56%|█████▌    | 67/120 [2:20:45<1:37:10, 110.01s/it]04/07/2022 05:20:21 PM [INFO]: [CPU: 5]: Game 67
 52%|█████▏    | 62/120 [2:20:50<1:49:56, 113.73s/it]04/07/2022 05:20:26 PM [INFO]: [CPU: 0]: Game 62
 51%|█████     | 61/120 [2:21:10<2:17:35, 139.93s/it]04/07/2022 05:20:45 PM [INFO]: [CPU: 11]: Game 61
 49%|████▉     | 59/120 [2:21:10<2:31:31, 149.04s/it]04/07/2022 05:20:46 PM [INFO]: [CPU: 7]: Game 59
 50%|█████     | 60/120 [2:21:21<2:27:59, 148.00s/it]04/07/2022 05:20:57 PM [INFO]: [CPU: 2]: Game 60
 51%|█████     | 61/120 [2:21:22<2:26:18, 148.78s/it]04/07/2022 05:20:57 PM [INFO]: [CPU: 1]: Game 61
 55%|█████▌    | 66/120 [2:21:28<1:53:58, 126.64s/it]04/07/2022 05:21:04 PM [INFO]: [CPU: 3]: Game 66
 53%|█████▎    | 64/120 [2:21:47<1:44:03, 111.49s/it]04/07/2022 05:21:23 PM [INFO]: [CPU: 8]: Game 64
 55%|█████▌    | 66/120 [2:21:47<1:53:39, 126.29s/it]04/07/2022 05:21:23 PM [INFO]: [CPU: 4]: Game 66
 52%|█████▎    | 63/120 [2:21:48<1:32:07, 96.97s/it] 04/07/2022 05:21:24 PM [INFO]: [CPU: 0]: Game 63
 51%|█████     | 61/120 [2:22:00<2:16:04, 138.38s/it]04/07/2022 05:21:35 PM [INFO]: [CPU: 9]: Game 61
 56%|█████▌    | 67/120 [2:22:19<1:31:55, 104.07s/it]04/07/2022 05:21:55 PM [INFO]: [CPU: 3]: Game 67
 51%|█████     | 61/120 [2:22:20<2:29:34, 152.12s/it]04/07/2022 05:21:56 PM [INFO]: [CPU: 10]: Game 61
 57%|█████▋    | 68/120 [2:22:22<1:31:49, 105.95s/it]04/07/2022 05:21:57 PM [INFO]: [CPU: 5]: Game 68
 52%|█████▏    | 62/120 [2:22:40<2:00:46, 124.94s/it]04/07/2022 05:22:15 PM [INFO]: [CPU: 11]: Game 62
 52%|█████▏    | 62/120 [2:22:45<2:04:53, 129.20s/it]04/07/2022 05:22:21 PM [INFO]: [CPU: 1]: Game 62
 51%|█████     | 61/120 [2:23:17<2:16:00, 138.31s/it]04/07/2022 05:22:52 PM [INFO]: [CPU: 2]: Game 61
 54%|█████▍    | 65/120 [2:23:24<1:38:02, 106.95s/it]04/07/2022 05:22:59 PM [INFO]: [CPU: 8]: Game 65
 53%|█████▎    | 64/120 [2:23:44<1:35:45, 102.60s/it]04/07/2022 05:23:19 PM [INFO]: [CPU: 0]: Game 64
 56%|█████▌    | 67/120 [2:23:56<1:52:09, 126.97s/it]04/07/2022 05:23:32 PM [INFO]: [CPU: 4]: Game 67
 50%|█████     | 60/120 [2:23:57<2:34:28, 154.47s/it]04/07/2022 05:23:33 PM [INFO]: [CPU: 7]: Game 60
 52%|█████▏    | 62/120 [2:24:28<2:16:29, 141.20s/it]04/07/2022 05:24:03 PM [INFO]: [CPU: 9]: Game 62
 52%|█████▏    | 62/120 [2:24:42<2:23:56, 148.90s/it]04/07/2022 05:24:17 PM [INFO]: [CPU: 10]: Game 62
 57%|█████▊    | 69/120 [2:24:43<1:39:06, 116.61s/it]04/07/2022 05:24:19 PM [INFO]: [CPU: 5]: Game 69
 57%|█████▋    | 68/120 [2:25:00<1:33:45, 108.19s/it]04/07/2022 05:24:36 PM [INFO]: [CPU: 4]: Game 68
 52%|█████▎    | 63/120 [2:25:08<2:05:14, 131.83s/it]04/07/2022 05:24:43 PM [INFO]: [CPU: 11]: Game 63
 54%|█████▍    | 65/120 [2:25:20<1:32:20, 100.73s/it]04/07/2022 05:24:56 PM [INFO]: [CPU: 0]: Game 65
 55%|█████▌    | 66/120 [2:25:26<1:40:21, 111.51s/it]04/07/2022 05:25:01 PM [INFO]: [CPU: 8]: Game 66
 57%|█████▋    | 68/120 [2:25:39<1:54:56, 132.63s/it]04/07/2022 05:25:14 PM [INFO]: [CPU: 3]: Game 68
 58%|█████▊    | 70/120 [2:25:41<1:22:29, 98.98s/it] 04/07/2022 05:25:17 PM [INFO]: [CPU: 5]: Game 70
 52%|█████▎    | 63/120 [2:25:46<1:57:20, 123.51s/it]04/07/2022 05:25:21 PM [INFO]: [CPU: 10]: Game 63
 52%|█████▎    | 63/120 [2:25:52<2:19:03, 146.38s/it]04/07/2022 05:25:27 PM [INFO]: [CPU: 1]: Game 63
 52%|█████▎    | 63/120 [2:25:58<1:59:34, 125.87s/it]04/07/2022 05:25:33 PM [INFO]: [CPU: 9]: Game 63
 51%|█████     | 61/120 [2:26:06<2:24:15, 146.71s/it]04/07/2022 05:25:41 PM [INFO]: [CPU: 7]: Game 61
 52%|█████▏    | 62/120 [2:26:11<2:23:55, 148.89s/it]04/07/2022 05:25:46 PM [INFO]: [CPU: 2]: Game 62
 53%|█████▎    | 64/120 [2:26:49<1:36:37, 103.54s/it]04/07/2022 05:26:25 PM [INFO]: [CPU: 9]: Game 64
 55%|█████▌    | 66/120 [2:26:50<1:27:46, 97.52s/it] 04/07/2022 05:26:26 PM [INFO]: [CPU: 0]: Game 66
 56%|█████▌    | 67/120 [2:26:56<1:32:48, 105.06s/it]04/07/2022 05:26:31 PM [INFO]: [CPU: 8]: Game 67
 52%|█████▎    | 63/120 [2:27:34<2:02:50, 129.30s/it]04/07/2022 05:27:10 PM [INFO]: [CPU: 2]: Game 63
 53%|█████▎    | 64/120 [2:27:34<2:04:25, 133.31s/it]04/07/2022 05:27:10 PM [INFO]: [CPU: 1]: Game 64
 53%|█████▎    | 64/120 [2:27:48<1:54:54, 123.12s/it]04/07/2022 05:27:24 PM [INFO]: [CPU: 10]: Game 64
 53%|█████▎    | 64/120 [2:27:48<2:11:06, 140.46s/it]04/07/2022 05:27:24 PM [INFO]: [CPU: 11]: Game 64
 57%|█████▊    | 69/120 [2:27:54<1:48:37, 127.80s/it]04/07/2022 05:27:29 PM [INFO]: [CPU: 4]: Game 69
 59%|█████▉    | 71/120 [2:28:09<1:32:47, 113.62s/it]04/07/2022 05:27:44 PM [INFO]: [CPU: 5]: Game 71
 57%|█████▊    | 69/120 [2:28:32<2:03:09, 144.89s/it]04/07/2022 05:28:08 PM [INFO]: [CPU: 3]: Game 69
 52%|█████▏    | 62/120 [2:28:34<2:22:09, 147.06s/it]04/07/2022 05:28:09 PM [INFO]: [CPU: 7]: Game 62
 57%|█████▋    | 68/120 [2:29:11<1:38:49, 114.03s/it]04/07/2022 05:28:46 PM [INFO]: [CPU: 8]: Game 68
 53%|█████▎    | 64/120 [2:29:30<1:56:52, 125.22s/it]04/07/2022 05:29:05 PM [INFO]: [CPU: 2]: Game 64
 60%|██████    | 72/120 [2:29:45<1:26:46, 108.47s/it]04/07/2022 05:29:21 PM [INFO]: [CPU: 5]: Game 72
 56%|█████▌    | 67/120 [2:29:50<1:47:59, 122.25s/it]04/07/2022 05:29:26 PM [INFO]: [CPU: 0]: Game 67
 54%|█████▍    | 65/120 [2:30:09<2:07:59, 139.62s/it]04/07/2022 05:29:44 PM [INFO]: [CPU: 1]: Game 65
 54%|█████▍    | 65/120 [2:30:16<1:59:38, 130.53s/it]04/07/2022 05:29:51 PM [INFO]: [CPU: 10]: Game 65
 54%|█████▍    | 65/120 [2:30:22<2:12:34, 144.62s/it]04/07/2022 05:29:58 PM [INFO]: [CPU: 11]: Game 65
 52%|█████▎    | 63/120 [2:30:29<2:10:46, 137.66s/it]04/07/2022 05:30:05 PM [INFO]: [CPU: 7]: Game 63
 54%|█████▍    | 65/120 [2:30:34<2:08:17, 139.95s/it]04/07/2022 05:30:10 PM [INFO]: [CPU: 9]: Game 65
 58%|█████▊    | 70/120 [2:31:00<2:01:08, 145.36s/it]04/07/2022 05:30:36 PM [INFO]: [CPU: 4]: Game 70
 57%|█████▊    | 69/120 [2:31:07<1:37:23, 114.57s/it]04/07/2022 05:30:42 PM [INFO]: [CPU: 8]: Game 69
 58%|█████▊    | 70/120 [2:31:45<2:12:45, 159.31s/it]04/07/2022 05:31:21 PM [INFO]: [CPU: 3]: Game 70
 55%|█████▌    | 66/120 [2:31:52<1:55:44, 128.60s/it]04/07/2022 05:31:27 PM [INFO]: [CPU: 1]: Game 66
 61%|██████    | 73/120 [2:32:00<1:31:12, 116.43s/it]04/07/2022 05:31:36 PM [INFO]: [CPU: 5]: Game 73
 55%|█████▌    | 66/120 [2:32:25<2:04:05, 137.88s/it]04/07/2022 05:32:00 PM [INFO]: [CPU: 11]: Game 66
 53%|█████▎    | 64/120 [2:32:25<2:02:20, 131.08s/it]04/07/2022 05:32:01 PM [INFO]: [CPU: 7]: Game 64
 55%|█████▌    | 66/120 [2:32:30<1:59:24, 132.68s/it]04/07/2022 05:32:05 PM [INFO]: [CPU: 9]: Game 66
 54%|█████▍    | 65/120 [2:32:30<2:09:51, 141.66s/it]04/07/2022 05:32:05 PM [INFO]: [CPU: 2]: Game 65
 59%|█████▉    | 71/120 [2:32:43<1:48:18, 132.62s/it]04/07/2022 05:32:19 PM [INFO]: [CPU: 4]: Game 71
 57%|█████▋    | 68/120 [2:32:50<2:00:58, 139.59s/it]04/07/2022 05:32:26 PM [INFO]: [CPU: 0]: Game 68
 55%|█████▌    | 66/120 [2:33:09<2:09:06, 143.45s/it]04/07/2022 05:32:45 PM [INFO]: [CPU: 10]: Game 66
 56%|█████▌    | 67/120 [2:33:15<1:41:39, 115.08s/it]04/07/2022 05:32:51 PM [INFO]: [CPU: 1]: Game 67
 58%|█████▊    | 70/120 [2:33:22<1:40:35, 120.70s/it]04/07/2022 05:32:57 PM [INFO]: [CPU: 8]: Game 70
 59%|█████▉    | 71/120 [2:33:54<2:02:34, 150.08s/it]04/07/2022 05:33:29 PM [INFO]: [CPU: 3]: Game 71
 62%|██████▏   | 74/120 [2:33:56<1:29:06, 116.22s/it]04/07/2022 05:33:32 PM [INFO]: [CPU: 5]: Game 74
 56%|█████▌    | 67/120 [2:34:06<1:47:35, 121.81s/it]04/07/2022 05:33:42 PM [INFO]: [CPU: 9]: Game 67
 54%|█████▍    | 65/120 [2:34:08<1:52:23, 122.62s/it]04/07/2022 05:33:43 PM [INFO]: [CPU: 7]: Game 65
 59%|█████▉    | 71/120 [2:34:45<1:29:26, 109.53s/it]04/07/2022 05:34:21 PM [INFO]: [CPU: 8]: Game 71
 57%|█████▊    | 69/120 [2:34:59<1:55:49, 136.26s/it]04/07/2022 05:34:34 PM [INFO]: [CPU: 0]: Game 69
 60%|██████    | 72/120 [2:35:05<1:48:12, 135.25s/it]04/07/2022 05:34:40 PM [INFO]: [CPU: 4]: Game 72
 56%|█████▌    | 67/120 [2:35:05<2:07:50, 144.73s/it]04/07/2022 05:34:41 PM [INFO]: [CPU: 11]: Game 67
 62%|██████▎   | 75/120 [2:35:13<1:18:22, 104.50s/it]04/07/2022 05:34:49 PM [INFO]: [CPU: 5]: Game 75
 56%|█████▌    | 67/120 [2:35:31<2:06:10, 142.84s/it]04/07/2022 05:35:06 PM [INFO]: [CPU: 10]: Game 67
 55%|█████▌    | 66/120 [2:35:31<1:39:47, 110.87s/it]04/07/2022 05:35:07 PM [INFO]: [CPU: 7]: Game 66
 60%|██████    | 72/120 [2:36:09<1:21:23, 101.74s/it]04/07/2022 05:35:44 PM [INFO]: [CPU: 8]: Game 72
 55%|█████▌    | 66/120 [2:36:15<2:29:56, 166.60s/it]04/07/2022 05:35:50 PM [INFO]: [CPU: 2]: Game 66
 57%|█████▋    | 68/120 [2:36:29<1:41:41, 117.34s/it]04/07/2022 05:36:04 PM [INFO]: [CPU: 10]: Game 68
 56%|█████▌    | 67/120 [2:36:29<1:23:52, 94.96s/it] 04/07/2022 05:36:05 PM [INFO]: [CPU: 7]: Game 67
 60%|██████    | 72/120 [2:36:41<2:04:08, 155.18s/it]04/07/2022 05:36:16 PM [INFO]: [CPU: 3]: Game 72
 57%|█████▋    | 68/120 [2:36:47<2:04:57, 144.19s/it]04/07/2022 05:36:23 PM [INFO]: [CPU: 1]: Game 68
 57%|█████▋    | 68/120 [2:36:53<1:57:20, 135.40s/it]04/07/2022 05:36:29 PM [INFO]: [CPU: 9]: Game 68
 63%|██████▎   | 76/120 [2:37:41<1:26:08, 117.48s/it]04/07/2022 05:37:17 PM [INFO]: [CPU: 5]: Game 76
 57%|█████▊    | 69/120 [2:37:46<1:29:28, 105.27s/it]04/07/2022 05:37:21 PM [INFO]: [CPU: 10]: Game 69
 58%|█████▊    | 70/120 [2:37:46<2:01:15, 145.51s/it]04/07/2022 05:37:21 PM [INFO]: [CPU: 0]: Game 70
 61%|██████    | 73/120 [2:37:52<1:53:25, 144.81s/it]04/07/2022 05:37:27 PM [INFO]: [CPU: 4]: Game 73
 61%|██████    | 73/120 [2:37:58<1:43:12, 131.75s/it]04/07/2022 05:37:33 PM [INFO]: [CPU: 3]: Game 73
 57%|█████▋    | 68/120 [2:38:12<2:16:15, 157.22s/it]04/07/2022 05:37:47 PM [INFO]: [CPU: 11]: Game 68
 61%|██████    | 73/120 [2:38:30<1:29:00, 113.63s/it]04/07/2022 05:38:06 PM [INFO]: [CPU: 8]: Game 73
 56%|█████▌    | 67/120 [2:38:36<2:20:30, 159.06s/it]04/07/2022 05:38:12 PM [INFO]: [CPU: 2]: Game 67
 57%|█████▋    | 68/120 [2:38:44<1:32:43, 106.99s/it]04/07/2022 05:38:20 PM [INFO]: [CPU: 7]: Game 68
 64%|██████▍   | 77/120 [2:38:52<1:14:09, 103.47s/it]04/07/2022 05:38:27 PM [INFO]: [CPU: 5]: Game 77
 57%|█████▊    | 69/120 [2:39:09<2:01:50, 143.34s/it]04/07/2022 05:38:44 PM [INFO]: [CPU: 1]: Game 69
 62%|██████▏   | 74/120 [2:39:41<1:34:21, 123.08s/it]04/07/2022 05:39:16 PM [INFO]: [CPU: 3]: Game 74
 65%|██████▌   | 78/120 [2:39:43<1:01:28, 87.82s/it] 04/07/2022 05:39:19 PM [INFO]: [CPU: 5]: Game 78
 62%|██████▏   | 74/120 [2:40:07<1:48:45, 141.85s/it]04/07/2022 05:39:42 PM [INFO]: [CPU: 4]: Game 74
 59%|█████▉    | 71/120 [2:40:14<1:59:25, 146.23s/it]04/07/2022 05:39:49 PM [INFO]: [CPU: 0]: Game 71
 57%|█████▊    | 69/120 [2:40:19<2:12:59, 156.46s/it]04/07/2022 05:39:54 PM [INFO]: [CPU: 9]: Game 69
 57%|█████▊    | 69/120 [2:40:33<2:09:36, 152.47s/it]04/07/2022 05:40:09 PM [INFO]: [CPU: 11]: Game 69
 58%|█████▊    | 70/120 [2:40:39<1:44:47, 125.75s/it]04/07/2022 05:40:15 PM [INFO]: [CPU: 10]: Game 70
 58%|█████▊    | 70/120 [2:41:04<1:42:31, 123.03s/it]04/07/2022 05:40:39 PM [INFO]: [CPU: 9]: Game 70
 66%|██████▌   | 79/120 [2:41:20<1:01:47, 90.42s/it]04/07/2022 05:40:55 PM [INFO]: [CPU: 5]: Game 79
 62%|██████▏   | 74/120 [2:41:24<1:40:54, 131.61s/it]04/07/2022 05:40:59 PM [INFO]: [CPU: 8]: Game 74
 58%|█████▊    | 70/120 [2:41:37<2:00:35, 144.71s/it]04/07/2022 05:41:12 PM [INFO]: [CPU: 1]: Game 70
 57%|█████▊    | 69/120 [2:41:38<1:47:54, 126.96s/it]04/07/2022 05:41:13 PM [INFO]: [CPU: 7]: Game 69
 59%|█████▉    | 71/120 [2:42:08<1:26:04, 105.41s/it]04/07/2022 05:41:44 PM [INFO]: [CPU: 9]: Game 71
 57%|█████▋    | 68/120 [2:42:15<2:33:18, 176.89s/it]04/07/2022 05:41:50 PM [INFO]: [CPU: 2]: Game 68
 59%|█████▉    | 71/120 [2:42:22<1:37:06, 118.91s/it]04/07/2022 05:41:58 PM [INFO]: [CPU: 10]: Game 71
 62%|██████▎   | 75/120 [2:42:34<1:47:43, 143.64s/it]04/07/2022 05:42:10 PM [INFO]: [CPU: 4]: Game 75
 62%|██████▎   | 75/120 [2:42:41<1:45:07, 140.17s/it]04/07/2022 05:42:16 PM [INFO]: [CPU: 3]: Game 75
 60%|██████    | 72/120 [2:42:54<2:00:27, 150.56s/it]04/07/2022 05:42:30 PM [INFO]: [CPU: 0]: Game 72
 67%|██████▋   | 80/120 [2:42:56<1:01:29, 92.24s/it]04/07/2022 05:42:32 PM [INFO]: [CPU: 5]: Game 80
 63%|██████▎   | 76/120 [2:43:32<1:26:29, 117.94s/it]04/07/2022 05:43:08 PM [INFO]: [CPU: 4]: Game 76
 58%|█████▊    | 70/120 [2:43:34<1:42:59, 123.60s/it]04/07/2022 05:43:09 PM [INFO]: [CPU: 7]: Game 70
 57%|█████▊    | 69/120 [2:43:45<2:08:12, 150.84s/it]04/07/2022 05:43:20 PM [INFO]: [CPU: 2]: Game 69
 60%|██████    | 72/120 [2:44:10<1:28:20, 110.44s/it]04/07/2022 05:43:46 PM [INFO]: [CPU: 9]: Game 72
 60%|██████    | 72/120 [2:44:12<1:32:49, 116.03s/it]04/07/2022 05:43:47 PM [INFO]: [CPU: 10]: Game 72
 63%|██████▎   | 76/120 [2:44:17<1:33:11, 127.07s/it]04/07/2022 05:43:53 PM [INFO]: [CPU: 3]: Game 76
 62%|██████▎   | 75/120 [2:44:43<1:53:57, 151.94s/it]04/07/2022 05:44:18 PM [INFO]: [CPU: 8]: Game 75
 58%|█████▊    | 70/120 [2:44:50<2:33:14, 183.90s/it]04/07/2022 05:44:26 PM [INFO]: [CPU: 11]: Game 70
 59%|█████▉    | 71/120 [2:45:09<2:14:42, 164.95s/it]04/07/2022 05:44:44 PM [INFO]: [CPU: 1]: Game 71
 64%|██████▍   | 77/120 [2:45:15<1:21:17, 113.42s/it]04/07/2022 05:44:51 PM [INFO]: [CPU: 4]: Game 77
 59%|█████▉    | 71/120 [2:45:23<1:37:27, 119.34s/it]04/07/2022 05:44:59 PM [INFO]: [CPU: 7]: Game 71
 68%|██████▊   | 81/120 [2:45:24<1:10:50, 108.98s/it]04/07/2022 05:45:00 PM [INFO]: [CPU: 5]: Game 81
 61%|██████    | 73/120 [2:45:42<2:01:52, 155.59s/it]04/07/2022 05:45:17 PM [INFO]: [CPU: 0]: Game 73
 58%|█████▊    | 70/120 [2:46:00<2:01:45, 146.11s/it]04/07/2022 05:45:35 PM [INFO]: [CPU: 2]: Game 70
 61%|██████    | 73/120 [2:46:26<1:32:18, 117.84s/it]04/07/2022 05:46:01 PM [INFO]: [CPU: 9]: Game 73
 61%|██████    | 73/120 [2:46:33<1:36:52, 123.66s/it]04/07/2022 05:46:09 PM [INFO]: [CPU: 10]: Game 73
 60%|██████    | 72/120 [2:46:39<1:53:59, 142.48s/it]04/07/2022 05:46:14 PM [INFO]: [CPU: 1]: Game 72
 68%|██████▊   | 82/120 [2:46:48<1:04:10, 101.34s/it]04/07/2022 05:46:23 PM [INFO]: [CPU: 5]: Game 82
 63%|██████▎   | 76/120 [2:46:52<1:46:17, 144.95s/it]04/07/2022 05:46:27 PM [INFO]: [CPU: 8]: Game 76
 59%|█████▉    | 71/120 [2:46:52<2:15:03, 165.37s/it]04/07/2022 05:46:28 PM [INFO]: [CPU: 11]: Game 71
 64%|██████▍   | 77/120 [2:47:17<1:42:27, 142.96s/it]04/07/2022 05:46:53 PM [INFO]: [CPU: 3]: Game 77
 60%|██████    | 72/120 [2:47:50<1:46:29, 133.12s/it]04/07/2022 05:47:26 PM [INFO]: [CPU: 11]: Game 72
 69%|██████▉   | 83/120 [2:47:58<56:49, 92.14s/it]   04/07/2022 05:47:34 PM [INFO]: [CPU: 5]: Game 83
 60%|██████    | 72/120 [2:48:04<1:45:23, 131.73s/it]04/07/2022 05:47:39 PM [INFO]: [CPU: 7]: Game 72
 65%|██████▌   | 78/120 [2:48:15<1:33:22, 133.38s/it]04/07/2022 05:47:51 PM [INFO]: [CPU: 4]: Game 78
 62%|██████▏   | 74/120 [2:48:16<1:58:59, 155.20s/it]04/07/2022 05:47:52 PM [INFO]: [CPU: 0]: Game 74
 62%|██████▏   | 74/120 [2:48:28<1:31:19, 119.13s/it]04/07/2022 05:48:03 PM [INFO]: [CPU: 9]: Game 74
 59%|█████▉    | 71/120 [2:49:06<2:09:11, 158.20s/it]04/07/2022 05:48:42 PM [INFO]: [CPU: 2]: Game 71
 66%|██████▌   | 79/120 [2:49:26<1:18:18, 114.59s/it]04/07/2022 05:49:01 PM [INFO]: [CPU: 4]: Game 79
 62%|██████▎   | 75/120 [2:49:38<1:18:27, 104.61s/it]04/07/2022 05:49:14 PM [INFO]: [CPU: 9]: Game 75
 61%|██████    | 73/120 [2:49:45<2:01:55, 155.65s/it]04/07/2022 05:49:21 PM [INFO]: [CPU: 1]: Game 73
 64%|██████▍   | 77/120 [2:49:45<1:50:01, 153.53s/it]04/07/2022 05:49:21 PM [INFO]: [CPU: 8]: Game 77
 65%|██████▌   | 78/120 [2:49:45<1:41:05, 144.43s/it]04/07/2022 05:49:21 PM [INFO]: [CPU: 3]: Game 78
 62%|██████▏   | 74/120 [2:50:18<1:58:07, 154.08s/it]04/07/2022 05:49:54 PM [INFO]: [CPU: 10]: Game 74
 61%|██████    | 73/120 [2:50:25<1:45:29, 134.66s/it]04/07/2022 05:50:01 PM [INFO]: [CPU: 7]: Game 73
 62%|██████▏   | 74/120 [2:50:30<1:33:52, 122.45s/it]04/07/2022 05:50:06 PM [INFO]: [CPU: 1]: Game 74
 67%|██████▋   | 80/120 [2:50:37<1:07:37, 101.44s/it]04/07/2022 05:50:12 PM [INFO]: [CPU: 4]: Game 80
 61%|██████    | 73/120 [2:50:37<1:52:16, 143.34s/it]04/07/2022 05:50:13 PM [INFO]: [CPU: 11]: Game 73
 70%|███████   | 84/120 [2:50:46<1:08:47, 114.65s/it]04/07/2022 05:50:21 PM [INFO]: [CPU: 5]: Game 84
 66%|██████▌   | 79/120 [2:51:47<1:34:07, 137.74s/it]04/07/2022 05:51:23 PM [INFO]: [CPU: 3]: Game 79
 62%|██████▎   | 75/120 [2:51:48<2:09:12, 172.27s/it]04/07/2022 05:51:24 PM [INFO]: [CPU: 0]: Game 75
 62%|██████▏   | 74/120 [2:52:15<1:37:25, 127.07s/it]04/07/2022 05:51:50 PM [INFO]: [CPU: 7]: Game 74
 62%|██████▎   | 75/120 [2:52:19<1:28:53, 118.52s/it]04/07/2022 05:51:55 PM [INFO]: [CPU: 1]: Game 75
 63%|██████▎   | 76/120 [2:52:26<1:30:29, 123.40s/it]04/07/2022 05:52:01 PM [INFO]: [CPU: 9]: Game 76
 68%|██████▊   | 81/120 [2:52:33<1:08:43, 105.74s/it]04/07/2022 05:52:08 PM [INFO]: [CPU: 4]: Game 81
 60%|██████    | 72/120 [2:52:45<2:21:04, 176.34s/it]04/07/2022 05:52:20 PM [INFO]: [CPU: 2]: Game 72
 65%|██████▌   | 78/120 [2:52:45<1:53:03, 161.51s/it]04/07/2022 05:52:21 PM [INFO]: [CPU: 8]: Game 78
 62%|██████▎   | 75/120 [2:52:59<1:57:04, 156.11s/it]04/07/2022 05:52:34 PM [INFO]: [CPU: 10]: Game 75
 62%|██████▏   | 74/120 [2:52:59<1:49:29, 142.80s/it]04/07/2022 05:52:35 PM [INFO]: [CPU: 11]: Game 74
 61%|██████    | 73/120 [2:53:30<1:47:16, 136.94s/it]04/07/2022 05:53:05 PM [INFO]: [CPU: 2]: Game 73
 71%|███████   | 85/120 [2:53:52<1:19:26, 136.20s/it]04/07/2022 05:53:28 PM [INFO]: [CPU: 5]: Game 85
 62%|██████▎   | 75/120 [2:53:57<1:27:59, 117.32s/it]04/07/2022 05:53:32 PM [INFO]: [CPU: 11]: Game 75
 67%|██████▋   | 80/120 [2:54:09<1:32:35, 138.88s/it]04/07/2022 05:53:44 PM [INFO]: [CPU: 3]: Game 80
 62%|██████▎   | 75/120 [2:54:10<1:32:45, 123.68s/it]04/07/2022 05:53:46 PM [INFO]: [CPU: 7]: Game 75
 68%|██████▊   | 82/120 [2:54:15<1:06:25, 104.88s/it]04/07/2022 05:53:51 PM [INFO]: [CPU: 4]: Game 82
 63%|██████▎   | 76/120 [2:54:29<2:03:46, 168.79s/it]04/07/2022 05:54:04 PM [INFO]: [CPU: 0]: Game 76
 72%|███████▏  | 86/120 [2:54:37<1:01:40, 108.84s/it]04/07/2022 05:54:13 PM [INFO]: [CPU: 5]: Game 86
 62%|██████▏   | 74/120 [2:54:40<1:29:44, 117.06s/it]04/07/2022 05:54:16 PM [INFO]: [CPU: 2]: Game 74
 63%|██████▎   | 76/120 [2:54:42<1:42:45, 140.14s/it]04/07/2022 05:54:17 PM [INFO]: [CPU: 10]: Game 76
 64%|██████▍   | 77/120 [2:55:06<1:36:26, 134.57s/it]04/07/2022 05:54:42 PM [INFO]: [CPU: 9]: Game 77
 63%|██████▎   | 76/120 [2:55:26<1:41:52, 138.92s/it]04/07/2022 05:55:01 PM [INFO]: [CPU: 1]: Game 76
 62%|██████▎   | 75/120 [2:55:45<1:15:54, 101.22s/it]04/07/2022 05:55:20 PM [INFO]: [CPU: 2]: Game 75
 69%|██████▉   | 83/120 [2:55:45<1:01:54, 100.40s/it]04/07/2022 05:55:21 PM [INFO]: [CPU: 4]: Game 83
 63%|██████▎   | 76/120 [2:55:53<1:26:07, 117.43s/it]04/07/2022 05:55:29 PM [INFO]: [CPU: 7]: Game 76
 63%|██████▎   | 76/120 [2:56:05<1:28:30, 120.69s/it]04/07/2022 05:55:41 PM [INFO]: [CPU: 11]: Game 76
 66%|██████▌   | 79/120 [2:56:24<2:02:02, 178.61s/it]04/07/2022 05:55:59 PM [INFO]: [CPU: 8]: Game 79
 64%|██████▍   | 77/120 [2:56:25<1:49:33, 152.87s/it]04/07/2022 05:56:00 PM [INFO]: [CPU: 0]: Game 77
 68%|██████▊   | 81/120 [2:56:37<1:32:00, 141.56s/it]04/07/2022 05:56:12 PM [INFO]: [CPU: 3]: Game 81
 64%|██████▍   | 77/120 [2:56:44<1:36:33, 134.73s/it]04/07/2022 05:56:19 PM [INFO]: [CPU: 10]: Game 77
 65%|██████▌   | 78/120 [2:57:08<1:31:34, 130.83s/it]04/07/2022 05:56:44 PM [INFO]: [CPU: 9]: Game 78
 64%|██████▍   | 77/120 [2:57:16<1:15:44, 105.69s/it]04/07/2022 05:56:52 PM [INFO]: [CPU: 11]: Game 77
 64%|██████▍   | 77/120 [2:57:30<1:19:38, 111.14s/it]04/07/2022 05:57:05 PM [INFO]: [CPU: 7]: Game 77
 72%|███████▎  | 87/120 [2:57:37<1:11:36, 130.19s/it]04/07/2022 05:57:13 PM [INFO]: [CPU: 5]: Game 87
 70%|███████   | 84/120 [2:57:48<1:04:10, 106.95s/it]04/07/2022 05:57:23 PM [INFO]: [CPU: 4]: Game 84
 64%|██████▍   | 77/120 [2:58:00<1:42:51, 143.52s/it]04/07/2022 05:57:36 PM [INFO]: [CPU: 1]: Game 77
 66%|██████▌   | 79/120 [2:58:19<1:17:05, 112.82s/it]04/07/2022 05:57:55 PM [INFO]: [CPU: 9]: Game 79
 65%|██████▌   | 78/120 [2:58:46<1:31:39, 130.95s/it]04/07/2022 05:58:22 PM [INFO]: [CPU: 10]: Game 78
 63%|██████▎   | 76/120 [2:58:51<1:32:58, 126.78s/it]04/07/2022 05:58:27 PM [INFO]: [CPU: 2]: Game 76
 67%|██████▋   | 80/120 [2:58:52<1:52:55, 169.40s/it]04/07/2022 05:58:27 PM [INFO]: [CPU: 8]: Game 80
 68%|██████▊   | 82/120 [2:59:05<1:30:51, 143.45s/it]04/07/2022 05:58:40 PM [INFO]: [CPU: 3]: Game 82
 65%|██████▌   | 78/120 [2:59:12<1:16:06, 108.73s/it]04/07/2022 05:58:47 PM [INFO]: [CPU: 11]: Game 78
 67%|██████▋   | 80/120 [2:59:17<1:04:13, 96.34s/it] 04/07/2022 05:58:53 PM [INFO]: [CPU: 9]: Game 80
 65%|██████▌   | 78/120 [2:59:25<1:18:45, 112.52s/it]04/07/2022 05:59:01 PM [INFO]: [CPU: 7]: Game 78
 73%|███████▎  | 88/120 [2:59:26<1:06:05, 123.91s/it]04/07/2022 05:59:02 PM [INFO]: [CPU: 5]: Game 88
 65%|██████▌   | 78/120 [2:59:37<1:55:23, 164.85s/it]04/07/2022 05:59:13 PM [INFO]: [CPU: 0]: Game 78
 71%|███████   | 85/120 [2:59:50<1:05:02, 111.50s/it]04/07/2022 05:59:25 PM [INFO]: [CPU: 4]: Game 85
 65%|██████▌   | 78/120 [3:00:09<1:37:20, 139.06s/it]04/07/2022 05:59:44 PM [INFO]: [CPU: 1]: Game 78
 66%|██████▌   | 79/120 [3:00:22<1:28:05, 128.90s/it]04/07/2022 05:59:58 PM [INFO]: [CPU: 0]: Game 79
 66%|██████▌   | 79/120 [3:00:23<1:22:24, 120.61s/it]04/07/2022 05:59:58 PM [INFO]: [CPU: 10]: Game 79
 69%|██████▉   | 83/120 [3:00:47<1:20:57, 131.28s/it]04/07/2022 06:00:23 PM [INFO]: [CPU: 3]: Game 83
 66%|██████▌   | 79/120 [3:00:49<1:10:56, 103.82s/it]04/07/2022 06:00:24 PM [INFO]: [CPU: 7]: Game 79
 64%|██████▍   | 77/120 [3:00:53<1:29:51, 125.38s/it]04/07/2022 06:00:29 PM [INFO]: [CPU: 2]: Game 77
 74%|███████▍  | 89/120 [3:01:09<1:00:46, 117.61s/it]04/07/2022 06:00:45 PM [INFO]: [CPU: 5]: Game 89
 68%|██████▊   | 81/120 [3:01:19<1:45:54, 162.92s/it]04/07/2022 06:00:55 PM [INFO]: [CPU: 8]: Game 81
 65%|██████▌   | 78/120 [3:01:38<1:10:54, 101.29s/it]04/07/2022 06:01:14 PM [INFO]: [CPU: 2]: Game 78
 66%|██████▌   | 79/120 [3:02:06<1:27:35, 128.18s/it]04/07/2022 06:01:41 PM [INFO]: [CPU: 11]: Game 79
 70%|███████   | 84/120 [3:02:11<1:10:12, 117.00s/it]04/07/2022 06:01:47 PM [INFO]: [CPU: 3]: Game 84
 68%|██████▊   | 81/120 [3:02:24<1:20:12, 123.39s/it]04/07/2022 06:01:59 PM [INFO]: [CPU: 9]: Game 81
 72%|███████▏  | 86/120 [3:02:24<1:10:27, 124.35s/it]04/07/2022 06:02:00 PM [INFO]: [CPU: 4]: Game 86
 75%|███████▌  | 90/120 [3:02:26<52:44, 105.49s/it]  04/07/2022 06:02:02 PM [INFO]: [CPU: 5]: Game 90
 67%|██████▋   | 80/120 [3:02:57<1:27:09, 130.73s/it]04/07/2022 06:02:32 PM [INFO]: [CPU: 10]: Game 80
 67%|██████▋   | 80/120 [3:02:58<1:14:12, 111.30s/it]04/07/2022 06:02:33 PM [INFO]: [CPU: 7]: Game 80
 67%|██████▋   | 80/120 [3:03:03<1:32:19, 138.49s/it]04/07/2022 06:02:39 PM [INFO]: [CPU: 0]: Game 80
 67%|██████▋   | 80/120 [3:03:36<1:17:50, 116.76s/it]04/07/2022 06:03:11 PM [INFO]: [CPU: 11]: Game 80
 66%|██████▌   | 79/120 [3:03:41<1:50:01, 161.01s/it]04/07/2022 06:03:17 PM [INFO]: [CPU: 1]: Game 79
 76%|███████▌  | 91/120 [3:04:09<50:37, 104.75s/it]04/07/2022 06:03:45 PM [INFO]: [CPU: 5]: Game 91
 72%|███████▎  | 87/120 [3:04:39<1:10:11, 127.61s/it]04/07/2022 06:04:15 PM [INFO]: [CPU: 4]: Game 87
 66%|██████▌   | 79/120 [3:04:45<1:26:42, 126.89s/it]04/07/2022 06:04:20 PM [INFO]: [CPU: 2]: Game 79
 68%|██████▊   | 82/120 [3:04:45<1:51:22, 175.85s/it]04/07/2022 06:04:21 PM [INFO]: [CPU: 8]: Game 82
 68%|██████▊   | 81/120 [3:05:19<1:18:14, 120.36s/it]04/07/2022 06:04:55 PM [INFO]: [CPU: 7]: Game 81
 68%|██████▊   | 81/120 [3:05:25<1:30:36, 139.39s/it]04/07/2022 06:05:00 PM [INFO]: [CPU: 0]: Game 81
 71%|███████   | 85/120 [3:05:31<1:22:40, 141.73s/it]04/07/2022 06:05:06 PM [INFO]: [CPU: 3]: Game 85
 68%|██████▊   | 82/120 [3:05:37<1:31:22, 144.26s/it]04/07/2022 06:05:12 PM [INFO]: [CPU: 9]: Game 82
 67%|██████▋   | 80/120 [3:05:37<1:38:18, 147.46s/it]04/07/2022 06:05:12 PM [INFO]: [CPU: 1]: Game 80
 68%|██████▊   | 81/120 [3:05:38<1:30:50, 139.77s/it]04/07/2022 06:05:13 PM [INFO]: [CPU: 10]: Game 81
 68%|██████▊   | 81/120 [3:06:04<1:21:58, 126.11s/it]04/07/2022 06:05:39 PM [INFO]: [CPU: 11]: Game 81
 73%|███████▎  | 88/120 [3:06:09<1:02:01, 116.29s/it]04/07/2022 06:05:45 PM [INFO]: [CPU: 4]: Game 88
 77%|███████▋  | 92/120 [3:06:31<54:01, 115.75s/it]04/07/2022 06:06:06 PM [INFO]: [CPU: 5]: Game 92
 67%|██████▋   | 80/120 [3:06:41<1:22:20, 123.52s/it]04/07/2022 06:06:16 PM [INFO]: [CPU: 2]: Game 80
 69%|██████▉   | 83/120 [3:06:41<1:37:18, 157.79s/it]04/07/2022 06:06:17 PM [INFO]: [CPU: 8]: Game 83
 68%|██████▊   | 82/120 [3:06:55<1:16:36, 120.97s/it]04/07/2022 06:06:30 PM [INFO]: [CPU: 10]: Game 82
 69%|██████▉   | 83/120 [3:07:13<1:20:06, 129.91s/it]04/07/2022 06:06:48 PM [INFO]: [CPU: 9]: Game 83
 68%|██████▊   | 81/120 [3:07:45<1:32:08, 141.75s/it]04/07/2022 06:07:21 PM [INFO]: [CPU: 1]: Game 81
 68%|██████▊   | 82/120 [3:07:46<1:28:39, 139.99s/it]04/07/2022 06:07:22 PM [INFO]: [CPU: 0]: Game 82
 68%|██████▊   | 82/120 [3:07:53<1:16:39, 121.04s/it]04/07/2022 06:07:28 PM [INFO]: [CPU: 11]: Game 82
 68%|██████▊   | 82/120 [3:08:00<1:23:52, 132.43s/it]04/07/2022 06:07:35 PM [INFO]: [CPU: 7]: Game 82
 70%|███████   | 84/120 [3:08:24<1:07:16, 112.12s/it]04/07/2022 06:07:59 PM [INFO]: [CPU: 9]: Game 84
 78%|███████▊  | 93/120 [3:08:39<53:48, 119.56s/it]04/07/2022 06:08:15 PM [INFO]: [CPU: 5]: Game 93
 74%|███████▍  | 89/120 [3:08:56<1:07:56, 131.51s/it]04/07/2022 06:08:32 PM [INFO]: [CPU: 4]: Game 89
 69%|██████▉   | 83/120 [3:08:57<1:14:47, 121.28s/it]04/07/2022 06:08:32 PM [INFO]: [CPU: 10]: Game 83
 68%|██████▊   | 81/120 [3:09:15<1:26:16, 132.72s/it]04/07/2022 06:08:50 PM [INFO]: [CPU: 2]: Game 81
 70%|███████   | 84/120 [3:09:22<1:35:10, 158.63s/it]04/07/2022 06:08:57 PM [INFO]: [CPU: 8]: Game 84
 69%|██████▉   | 83/120 [3:09:22<1:18:14, 126.88s/it]04/07/2022 06:08:58 PM [INFO]: [CPU: 0]: Game 83
 69%|██████▉   | 83/120 [3:09:30<1:13:48, 119.70s/it]04/07/2022 06:09:05 PM [INFO]: [CPU: 7]: Game 83
 72%|███████▏  | 86/120 [3:09:54<1:40:58, 178.18s/it]04/07/2022 06:09:29 PM [INFO]: [CPU: 3]: Game 86
 71%|███████   | 85/120 [3:10:00<1:02:39, 107.41s/it]04/07/2022 06:09:35 PM [INFO]: [CPU: 9]: Game 85
 69%|██████▉   | 83/120 [3:10:21<1:19:35, 129.07s/it]04/07/2022 06:09:56 PM [INFO]: [CPU: 11]: Game 83
 68%|██████▊   | 82/120 [3:10:32<1:34:34, 149.34s/it]04/07/2022 06:10:08 PM [INFO]: [CPU: 1]: Game 82
 78%|███████▊  | 94/120 [3:10:41<52:08, 120.32s/it]04/07/2022 06:10:17 PM [INFO]: [CPU: 5]: Game 94
 72%|███████▏  | 86/120 [3:11:11<54:36, 96.37s/it]   04/07/2022 06:10:46 PM [INFO]: [CPU: 9]: Game 86
 75%|███████▌  | 90/120 [3:11:17<1:07:13, 134.44s/it]04/07/2022 06:10:53 PM [INFO]: [CPU: 4]: Game 90
 70%|███████   | 84/120 [3:11:25<1:15:16, 125.45s/it]04/07/2022 06:11:00 PM [INFO]: [CPU: 0]: Game 84
 70%|███████   | 84/120 [3:11:38<1:13:23, 122.33s/it]04/07/2022 06:11:14 PM [INFO]: [CPU: 7]: Game 84
 72%|███████▎  | 87/120 [3:11:43<1:26:37, 157.49s/it]04/07/2022 06:11:19 PM [INFO]: [CPU: 3]: Game 87
 68%|██████▊   | 82/120 [3:11:55<1:29:20, 141.07s/it]04/07/2022 06:11:31 PM [INFO]: [CPU: 2]: Game 82
 70%|███████   | 84/120 [3:12:16<1:15:01, 125.04s/it]04/07/2022 06:11:52 PM [INFO]: [CPU: 11]: Game 84
 70%|███████   | 84/120 [3:12:22<1:27:55, 146.55s/it]04/07/2022 06:11:58 PM [INFO]: [CPU: 10]: Game 84
 69%|██████▉   | 83/120 [3:12:34<1:27:02, 141.16s/it]04/07/2022 06:12:10 PM [INFO]: [CPU: 1]: Game 83
 71%|███████   | 85/120 [3:13:20<1:09:57, 119.94s/it]04/07/2022 06:12:56 PM [INFO]: [CPU: 10]: Game 85
 71%|███████   | 85/120 [3:13:33<1:04:33, 110.67s/it]04/07/2022 06:13:09 PM [INFO]: [CPU: 11]: Game 85
 79%|███████▉  | 95/120 [3:13:41<57:34, 138.20s/it]04/07/2022 06:13:17 PM [INFO]: [CPU: 5]: Game 95
 71%|███████   | 85/120 [3:13:45<1:50:52, 190.06s/it]04/07/2022 06:13:21 PM [INFO]: [CPU: 8]: Game 85
 76%|███████▌  | 91/120 [3:13:45<1:06:56, 138.49s/it]04/07/2022 06:13:21 PM [INFO]: [CPU: 4]: Game 91
 72%|███████▎  | 87/120 [3:13:51<1:03:37, 115.69s/it]04/07/2022 06:13:27 PM [INFO]: [CPU: 9]: Game 87
 71%|███████   | 85/120 [3:13:59<1:18:12, 134.08s/it]04/07/2022 06:13:34 PM [INFO]: [CPU: 0]: Game 85
 71%|███████   | 85/120 [3:14:06<1:15:49, 129.97s/it]04/07/2022 06:13:42 PM [INFO]: [CPU: 7]: Game 85
 73%|███████▎  | 88/120 [3:14:17<1:23:28, 156.53s/it]04/07/2022 06:13:53 PM [INFO]: [CPU: 3]: Game 88
 69%|██████▉   | 83/120 [3:14:23<1:28:15, 143.11s/it]04/07/2022 06:13:59 PM [INFO]: [CPU: 2]: Game 83
 73%|███████▎  | 88/120 [3:14:49<52:26, 98.33s/it]   04/07/2022 06:14:25 PM [INFO]: [CPU: 9]: Game 88
 80%|████████  | 96/120 [3:15:11<49:29, 123.74s/it]04/07/2022 06:14:47 PM [INFO]: [CPU: 5]: Game 96
 72%|███████▏  | 86/120 [3:15:21<1:31:45, 161.94s/it]04/07/2022 06:14:57 PM [INFO]: [CPU: 8]: Game 86
 72%|███████▏  | 86/120 [3:15:22<1:08:20, 120.60s/it]04/07/2022 06:14:58 PM [INFO]: [CPU: 10]: Game 86
 72%|███████▏  | 86/120 [3:15:23<1:02:28, 110.25s/it]04/07/2022 06:14:58 PM [INFO]: [CPU: 11]: Game 86
 77%|███████▋  | 92/120 [3:15:28<59:38, 127.79s/it]  04/07/2022 06:15:04 PM [INFO]: [CPU: 4]: Game 92
 70%|███████   | 84/120 [3:15:34<1:31:40, 152.80s/it]04/07/2022 06:15:10 PM [INFO]: [CPU: 1]: Game 84
 72%|███████▏  | 86/120 [3:15:49<1:09:01, 121.82s/it]04/07/2022 06:15:24 PM [INFO]: [CPU: 7]: Game 86
 78%|███████▊  | 93/120 [3:16:20<47:11, 104.87s/it]04/07/2022 06:15:55 PM [INFO]: [CPU: 4]: Game 93
 81%|████████  | 97/120 [3:16:28<42:04, 109.74s/it]04/07/2022 06:16:04 PM [INFO]: [CPU: 5]: Game 97
 71%|███████   | 85/120 [3:16:58<1:17:00, 132.01s/it]04/07/2022 06:16:33 PM [INFO]: [CPU: 1]: Game 85
 74%|███████▍  | 89/120 [3:17:04<1:22:29, 159.67s/it]04/07/2022 06:16:40 PM [INFO]: [CPU: 3]: Game 89
 72%|███████▏  | 86/120 [3:17:12<1:25:57, 151.69s/it]04/07/2022 06:16:47 PM [INFO]: [CPU: 0]: Game 86
 72%|███████▎  | 87/120 [3:17:12<1:00:28, 109.96s/it]04/07/2022 06:16:47 PM [INFO]: [CPU: 11]: Game 87
 74%|███████▍  | 89/120 [3:17:17<58:28, 113.19s/it]04/07/2022 06:16:53 PM [INFO]: [CPU: 9]: Game 89
 72%|███████▎  | 87/120 [3:17:18<1:05:31, 119.13s/it]04/07/2022 06:16:54 PM [INFO]: [CPU: 10]: Game 87
 70%|███████   | 84/120 [3:17:23<1:32:29, 154.17s/it]04/07/2022 06:16:59 PM [INFO]: [CPU: 2]: Game 84
 72%|███████▎  | 87/120 [3:17:57<1:08:07, 123.88s/it]04/07/2022 06:17:33 PM [INFO]: [CPU: 7]: Game 87
 82%|████████▏ | 98/120 [3:18:24<40:53, 111.54s/it]04/07/2022 06:18:00 PM [INFO]: [CPU: 5]: Game 98
 72%|███████▎  | 87/120 [3:18:34<1:34:09, 171.21s/it]04/07/2022 06:18:10 PM [INFO]: [CPU: 8]: Game 87
 72%|███████▏  | 86/120 [3:18:34<1:08:46, 121.36s/it]04/07/2022 06:18:10 PM [INFO]: [CPU: 1]: Game 86
 73%|███████▎  | 88/120 [3:18:42<57:51, 108.48s/it]  04/07/2022 06:18:17 PM [INFO]: [CPU: 10]: Game 88
 72%|███████▎  | 87/120 [3:18:54<1:15:22, 137.04s/it]04/07/2022 06:18:30 PM [INFO]: [CPU: 0]: Game 87
 82%|████████▎ | 99/120 [3:19:22<33:23, 95.42s/it] 04/07/2022 06:18:57 PM [INFO]: [CPU: 5]: Game 99
 71%|███████   | 85/120 [3:19:25<1:24:18, 144.54s/it]04/07/2022 06:19:01 PM [INFO]: [CPU: 2]: Game 85
 73%|███████▎  | 88/120 [3:19:46<1:05:43, 123.24s/it]04/07/2022 06:19:22 PM [INFO]: [CPU: 11]: Game 88
 75%|███████▌  | 90/120 [3:19:51<1:20:56, 161.89s/it]04/07/2022 06:19:27 PM [INFO]: [CPU: 3]: Game 90
 72%|███████▎  | 87/120 [3:19:58<1:00:30, 110.01s/it]04/07/2022 06:19:33 PM [INFO]: [CPU: 1]: Game 87
 78%|███████▊  | 94/120 [3:20:24<1:03:33, 146.66s/it]04/07/2022 06:19:59 PM [INFO]: [CPU: 4]: Game 94
 73%|███████▎  | 88/120 [3:20:31<1:06:34, 124.84s/it]04/07/2022 06:20:06 PM [INFO]: [CPU: 0]: Game 88
 73%|███████▎  | 88/120 [3:20:38<1:11:56, 134.90s/it]04/07/2022 06:20:14 PM [INFO]: [CPU: 7]: Game 88
 74%|███████▍  | 89/120 [3:20:44<58:08, 112.54s/it]04/07/2022 06:20:19 PM [INFO]: [CPU: 10]: Game 89
 74%|███████▍  | 89/120 [3:20:44<53:32, 103.62s/it]  04/07/2022 06:20:19 PM [INFO]: [CPU: 11]: Game 89
 76%|███████▌  | 91/120 [3:20:49<1:03:09, 130.68s/it]04/07/2022 06:20:25 PM [INFO]: [CPU: 3]: Game 91
 73%|███████▎  | 88/120 [3:21:02<1:27:32, 164.15s/it]04/07/2022 06:20:37 PM [INFO]: [CPU: 8]: Game 88
 75%|███████▌  | 90/120 [3:21:28<1:17:11, 154.40s/it]04/07/2022 06:21:03 PM [INFO]: [CPU: 9]: Game 90
 74%|███████▍  | 89/120 [3:21:48<57:06, 110.53s/it]  04/07/2022 06:21:23 PM [INFO]: [CPU: 0]: Game 89
 83%|████████▎ | 100/120 [3:22:09<38:58, 116.92s/it]04/07/2022 06:21:44 PM [INFO]: [CPU: 5]: Game 100
 74%|███████▍  | 89/120 [3:22:21<1:04:42, 125.24s/it]04/07/2022 06:21:56 PM [INFO]: [CPU: 7]: Game 89
 72%|███████▏  | 86/120 [3:22:32<1:29:00, 157.07s/it]04/07/2022 06:22:07 PM [INFO]: [CPU: 2]: Game 86
 74%|███████▍  | 89/120 [3:22:58<1:17:17, 149.61s/it]04/07/2022 06:22:33 PM [INFO]: [CPU: 8]: Game 89
 75%|███████▌  | 90/120 [3:22:59<59:37, 119.26s/it]04/07/2022 06:22:34 PM [INFO]: [CPU: 10]: Game 90
 76%|███████▌  | 91/120 [3:23:04<1:06:12, 136.99s/it]04/07/2022 06:22:39 PM [INFO]: [CPU: 9]: Game 91
 73%|███████▎  | 88/120 [3:23:04<1:10:53, 132.91s/it]04/07/2022 06:22:40 PM [INFO]: [CPU: 1]: Game 88
 75%|███████▌  | 90/120 [3:23:11<51:12, 102.43s/it]04/07/2022 06:22:47 PM [INFO]: [CPU: 0]: Game 90
 75%|███████▌  | 90/120 [3:23:31<1:01:19, 122.66s/it]04/07/2022 06:23:07 PM [INFO]: [CPU: 11]: Game 90
 77%|███████▋  | 92/120 [3:23:43<1:06:58, 143.53s/it]04/07/2022 06:23:18 PM [INFO]: [CPU: 3]: Game 92
 75%|███████▌  | 90/120 [3:23:51<57:20, 114.68s/it]  04/07/2022 06:23:26 PM [INFO]: [CPU: 7]: Game 90
 84%|████████▍ | 101/120 [3:24:24<38:44, 122.35s/it]04/07/2022 06:24:00 PM [INFO]: [CPU: 5]: Game 101
 79%|███████▉  | 95/120 [3:24:34<1:14:05, 177.82s/it]04/07/2022 06:24:10 PM [INFO]: [CPU: 4]: Game 95
 72%|███████▎  | 87/120 [3:24:40<1:21:41, 148.52s/it]04/07/2022 06:24:16 PM [INFO]: [CPU: 2]: Game 87
 77%|███████▋  | 92/120 [3:24:47<59:08, 126.75s/it]  04/07/2022 06:24:22 PM [INFO]: [CPU: 9]: Game 92
 75%|███████▌  | 90/120 [3:24:47<1:08:45, 137.51s/it]04/07/2022 06:24:22 PM [INFO]: [CPU: 8]: Game 90
 74%|███████▍  | 89/120 [3:25:32<1:10:58, 137.37s/it]04/07/2022 06:25:08 PM [INFO]: [CPU: 1]: Game 89
 76%|███████▌  | 91/120 [3:25:52<1:02:00, 128.28s/it]04/07/2022 06:25:28 PM [INFO]: [CPU: 11]: Game 91
 76%|███████▌  | 91/120 [3:26:05<1:07:23, 139.43s/it]04/07/2022 06:25:41 PM [INFO]: [CPU: 10]: Game 91
 76%|███████▌  | 91/120 [3:26:06<58:22, 120.77s/it]04/07/2022 06:25:41 PM [INFO]: [CPU: 7]: Game 91
 78%|███████▊  | 93/120 [3:26:17<1:06:01, 146.74s/it]04/07/2022 06:25:52 PM [INFO]: [CPU: 3]: Game 93
 76%|███████▌  | 91/120 [3:26:18<1:01:41, 127.63s/it]04/07/2022 06:25:53 PM [INFO]: [CPU: 0]: Game 91
 80%|████████  | 96/120 [3:26:36<1:04:26, 161.12s/it]04/07/2022 06:26:12 PM [INFO]: [CPU: 4]: Game 96
 73%|███████▎  | 88/120 [3:26:42<1:14:59, 140.60s/it]04/07/2022 06:26:18 PM [INFO]: [CPU: 2]: Game 88
 85%|████████▌ | 102/120 [3:26:52<38:59, 129.98s/it]04/07/2022 06:26:27 PM [INFO]: [CPU: 5]: Game 102
 78%|███████▊  | 93/120 [3:27:02<58:08, 129.21s/it]04/07/2022 06:26:37 PM [INFO]: [CPU: 9]: Game 93
 76%|███████▌  | 91/120 [3:27:28<1:09:49, 144.46s/it]04/07/2022 06:27:03 PM [INFO]: [CPU: 8]: Game 91
 77%|███████▋  | 92/120 [3:27:42<53:24, 114.43s/it]  04/07/2022 06:27:17 PM [INFO]: [CPU: 0]: Game 92
 78%|███████▊  | 94/120 [3:27:53<57:02, 131.65s/it]  04/07/2022 06:27:29 PM [INFO]: [CPU: 3]: Game 94
 75%|███████▌  | 90/120 [3:27:54<1:09:18, 138.60s/it]04/07/2022 06:27:29 PM [INFO]: [CPU: 1]: Game 90
 77%|███████▋  | 92/120 [3:28:08<1:00:48, 130.32s/it]04/07/2022 06:27:43 PM [INFO]: [CPU: 11]: Game 92
 86%|████████▌ | 103/120 [3:28:09<32:20, 114.15s/it]04/07/2022 06:27:45 PM [INFO]: [CPU: 5]: Game 103
 78%|███████▊  | 94/120 [3:28:19<49:13, 113.60s/it]04/07/2022 06:27:54 PM [INFO]: [CPU: 9]: Game 94
 77%|███████▋  | 92/120 [3:28:52<1:08:55, 147.70s/it]04/07/2022 06:28:28 PM [INFO]: [CPU: 10]: Game 92
 79%|███████▉  | 95/120 [3:29:30<41:57, 100.72s/it]04/07/2022 06:29:05 PM [INFO]: [CPU: 9]: Game 95
 78%|███████▊  | 93/120 [3:29:31<50:46, 112.84s/it]04/07/2022 06:29:06 PM [INFO]: [CPU: 0]: Game 93
 79%|███████▉  | 95/120 [3:29:36<51:15, 123.00s/it]04/07/2022 06:29:12 PM [INFO]: [CPU: 3]: Game 95
 74%|███████▍  | 89/120 [3:30:08<1:22:42, 160.09s/it]04/07/2022 06:29:43 PM [INFO]: [CPU: 2]: Game 89
 81%|████████  | 97/120 [3:30:08<1:07:37, 176.40s/it]04/07/2022 06:29:44 PM [INFO]: [CPU: 4]: Game 97
 76%|███████▌  | 91/120 [3:30:21<1:08:18, 141.34s/it]04/07/2022 06:29:57 PM [INFO]: [CPU: 1]: Game 91
 77%|███████▋  | 92/120 [3:30:28<1:12:23, 155.11s/it]04/07/2022 06:30:03 PM [INFO]: [CPU: 8]: Game 92
 87%|████████▋ | 104/120 [3:30:30<32:36, 122.30s/it]04/07/2022 06:30:06 PM [INFO]: [CPU: 5]: Game 104
 80%|████████  | 96/120 [3:30:40<42:09, 105.38s/it]04/07/2022 06:30:16 PM [INFO]: [CPU: 3]: Game 96
 76%|███████▌  | 91/120 [3:30:42<1:07:08, 138.93s/it]
Process Process-8:
Traceback (most recent call last):
  File "/home/x_aolss/.conda/envs/myownenv/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/x_aolss/.conda/envs/myownenv/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/x_aolss/gym_connect4/gym-connect4/MCTS_c4.py", line 192, in MCTS_self_play
    np.random.choice(np.array([0,1,2,3,4,5,6]), \
  File "mtrand.pyx", line 935, in numpy.random.mtrand.RandomState.choice
ValueError: probabilities contain NaN
 82%|████████▏ | 98/120 [3:31:05<51:26, 140.31s/it]  04/07/2022 06:30:40 PM [INFO]: [CPU: 4]: Game 98
 78%|███████▊  | 93/120 [3:31:22<56:14, 124.99s/it]  04/07/2022 06:30:58 PM [INFO]: [CPU: 8]: Game 93
 78%|███████▊  | 93/120 [3:31:23<1:06:55, 148.71s/it]04/07/2022 06:30:59 PM [INFO]: [CPU: 10]: Game 93
 75%|███████▌  | 90/120 [3:31:34<1:08:56, 137.87s/it]04/07/2022 06:31:09 PM [INFO]: [CPU: 2]: Game 90
 80%|████████  | 96/120 [3:31:34<43:08, 107.84s/it]04/07/2022 06:31:10 PM [INFO]: [CPU: 9]: Game 96
 78%|███████▊  | 93/120 [3:31:41<1:09:54, 155.36s/it]04/07/2022 06:31:17 PM [INFO]: [CPU: 11]: Game 93
 81%|████████  | 97/120 [3:31:52<36:30, 95.25s/it] 04/07/2022 06:31:28 PM [INFO]: [CPU: 3]: Game 97
 82%|████████▎ | 99/120 [3:32:10<41:15, 117.88s/it]04/07/2022 06:31:46 PM [INFO]: [CPU: 4]: Game 99
 88%|████████▊ | 105/120 [3:32:31<30:24, 121.66s/it]04/07/2022 06:32:06 PM [INFO]: [CPU: 5]: Game 105
 78%|███████▊  | 94/120 [3:32:35<58:09, 134.21s/it]04/07/2022 06:32:10 PM [INFO]: [CPU: 0]: Game 94
 77%|███████▋  | 92/120 [3:33:16<1:10:35, 151.27s/it]04/07/2022 06:32:51 PM [INFO]: [CPU: 1]: Game 92
 82%|████████▏ | 98/120 [3:33:39<36:15, 98.88s/it]04/07/2022 06:33:15 PM [INFO]: [CPU: 3]: Game 98
 76%|███████▌  | 91/120 [3:33:57<1:07:24, 139.47s/it]04/07/2022 06:33:33 PM [INFO]: [CPU: 2]: Game 91
 83%|████████▎ | 100/120 [3:33:57<38:14, 114.72s/it]04/07/2022 06:33:33 PM [INFO]: [CPU: 4]: Game 100
 78%|███████▊  | 94/120 [3:34:04<1:06:02, 152.41s/it]04/07/2022 06:33:40 PM [INFO]: [CPU: 10]: Game 94
 78%|███████▊  | 94/120 [3:34:28<1:08:50, 158.85s/it]04/07/2022 06:34:04 PM [INFO]: [CPU: 11]: Game 94
 79%|███████▉  | 95/120 [3:34:34<54:03, 129.73s/it]04/07/2022 06:34:10 PM [INFO]: [CPU: 0]: Game 95
 81%|████████  | 97/120 [3:34:39<50:11, 130.95s/it]04/07/2022 06:34:14 PM [INFO]: [CPU: 9]: Game 97
 78%|███████▊  | 94/120 [3:34:39<1:03:29, 146.53s/it]04/07/2022 06:34:15 PM [INFO]: [CPU: 8]: Game 94
 88%|████████▊ | 106/120 [3:34:54<29:53, 128.09s/it]04/07/2022 06:34:29 PM [INFO]: [CPU: 5]: Game 106
 82%|████████▎ | 99/120 [3:35:09<33:37, 96.07s/it]04/07/2022 06:34:44 PM [INFO]: [CPU: 3]: Game 99
 78%|███████▊  | 93/120 [3:35:27<1:05:22, 145.28s/it]04/07/2022 06:35:03 PM [INFO]: [CPU: 1]: Game 93
 77%|███████▋  | 92/120 [3:35:50<1:01:25, 131.63s/it]04/07/2022 06:35:26 PM [INFO]: [CPU: 2]: Game 92
 84%|████████▍ | 101/120 [3:36:03<37:20, 117.91s/it]04/07/2022 06:35:38 PM [INFO]: [CPU: 4]: Game 101
 79%|███████▉  | 95/120 [3:36:04<58:15, 139.84s/it]  04/07/2022 06:35:39 PM [INFO]: [CPU: 11]: Game 95
 89%|████████▉ | 107/120 [3:36:29<25:37, 118.29s/it]04/07/2022 06:36:05 PM [INFO]: [CPU: 5]: Game 107
 80%|████████  | 96/120 [3:36:39<51:21, 128.41s/it]04/07/2022 06:36:15 PM [INFO]: [CPU: 0]: Game 96
 80%|████████  | 96/120 [3:36:46<44:09, 110.42s/it]04/07/2022 06:36:21 PM [INFO]: [CPU: 11]: Game 96
 82%|████████▏ | 98/120 [3:37:14<50:40, 138.19s/it]04/07/2022 06:36:50 PM [INFO]: [CPU: 9]: Game 98
 79%|███████▉  | 95/120 [3:37:15<1:08:18, 163.95s/it]04/07/2022 06:36:51 PM [INFO]: [CPU: 10]: Game 95
 83%|████████▎ | 100/120 [3:37:32<36:44, 110.21s/it]04/07/2022 06:37:08 PM [INFO]: [CPU: 3]: Game 100
 79%|███████▉  | 95/120 [3:37:38<1:05:06, 156.27s/it]04/07/2022 06:37:14 PM [INFO]: [CPU: 8]: Game 95
 78%|███████▊  | 94/120 [3:37:38<1:01:07, 141.05s/it]04/07/2022 06:37:14 PM [INFO]: [CPU: 1]: Game 94
 81%|████████  | 97/120 [3:38:15<39:54, 104.12s/it]04/07/2022 06:37:51 PM [INFO]: [CPU: 11]: Game 97
 80%|████████  | 96/120 [3:38:21<53:47, 134.47s/it]  04/07/2022 06:37:56 PM [INFO]: [CPU: 10]: Game 96
 78%|███████▊  | 93/120 [3:38:26<1:02:24, 138.69s/it]04/07/2022 06:38:01 PM [INFO]: [CPU: 2]: Game 93
 90%|█████████ | 108/120 [3:38:28<23:43, 118.59s/it]04/07/2022 06:38:04 PM [INFO]: [CPU: 5]: Game 108
 81%|████████  | 97/120 [3:38:45<48:51, 127.46s/it]04/07/2022 06:38:20 PM [INFO]: [CPU: 0]: Game 97
 80%|████████  | 96/120 [3:39:01<53:46, 134.43s/it]  04/07/2022 06:38:37 PM [INFO]: [CPU: 8]: Game 96
 79%|███████▉  | 95/120 [3:39:02<51:35, 123.80s/it]  04/07/2022 06:38:37 PM [INFO]: [CPU: 1]: Game 95
 85%|████████▌ | 102/120 [3:39:08<41:24, 138.01s/it]04/07/2022 06:38:43 PM [INFO]: [CPU: 4]: Game 102
 84%|████████▍ | 101/120 [3:39:20<34:37, 109.36s/it]04/07/2022 06:38:55 PM [INFO]: [CPU: 3]: Game 101
 82%|████████▎ | 99/120 [3:39:31<48:16, 137.91s/it]04/07/2022 06:39:07 PM [INFO]: [CPU: 9]: Game 99
 82%|████████▏ | 98/120 [3:39:32<37:57, 103.54s/it]04/07/2022 06:39:08 PM [INFO]: [CPU: 0]: Game 98
 82%|████████▏ | 98/120 [3:40:02<38:32, 105.13s/it]04/07/2022 06:39:38 PM [INFO]: [CPU: 11]: Game 98
 78%|███████▊  | 94/120 [3:40:19<56:47, 131.08s/it]  04/07/2022 06:39:54 PM [INFO]: [CPU: 2]: Game 94
 91%|█████████ | 109/120 [3:40:52<23:05, 125.97s/it]04/07/2022 06:40:27 PM [INFO]: [CPU: 5]: Game 109
 83%|████████▎ | 100/120 [3:40:55<40:31, 121.57s/it]04/07/2022 06:40:30 PM [INFO]: [CPU: 9]: Game 100
 81%|████████  | 97/120 [3:41:01<49:47, 129.91s/it]04/07/2022 06:40:36 PM [INFO]: [CPU: 8]: Game 97
 86%|████████▌ | 103/120 [3:41:01<37:00, 130.59s/it]04/07/2022 06:40:37 PM [INFO]: [CPU: 4]: Game 103
 80%|████████  | 96/120 [3:41:19<51:06, 127.79s/it]04/07/2022 06:40:54 PM [INFO]: [CPU: 1]: Game 96
 82%|████████▎ | 99/120 [3:41:26<34:31, 98.63s/it] 04/07/2022 06:41:01 PM [INFO]: [CPU: 11]: Game 99
 85%|████████▌ | 102/120 [3:41:37<35:18, 117.71s/it]04/07/2022 06:41:12 PM [INFO]: [CPU: 3]: Game 102
 81%|████████  | 97/120 [3:41:43<59:23, 154.93s/it]04/07/2022 06:41:19 PM [INFO]: [CPU: 10]: Game 97
 87%|████████▋ | 104/120 [3:42:07<29:37, 111.09s/it]04/07/2022 06:41:42 PM [INFO]: [CPU: 4]: Game 104
 79%|███████▉  | 95/120 [3:42:24<53:53, 129.32s/it]04/07/2022 06:42:00 PM [INFO]: [CPU: 2]: Game 95
 82%|████████▎ | 99/120 [3:42:25<43:31, 124.35s/it]04/07/2022 06:42:01 PM [INFO]: [CPU: 0]: Game 99
 86%|████████▌ | 103/120 [3:42:48<29:25, 103.86s/it]04/07/2022 06:42:24 PM [INFO]: [CPU: 3]: Game 103
 82%|████████▏ | 98/120 [3:43:06<47:07, 128.50s/it]04/07/2022 06:42:42 PM [INFO]: [CPU: 8]: Game 98
 84%|████████▍ | 101/120 [3:43:18<40:32, 128.05s/it]04/07/2022 06:42:53 PM [INFO]: [CPU: 9]: Game 101
 83%|████████▎ | 100/120 [3:43:31<35:32, 106.60s/it]04/07/2022 06:43:07 PM [INFO]: [CPU: 11]: Game 100
 80%|████████  | 96/120 [3:43:36<44:48, 112.01s/it]04/07/2022 06:43:11 PM [INFO]: [CPU: 2]: Game 96
 82%|████████▏ | 98/120 [3:43:49<53:33, 146.05s/it]04/07/2022 06:43:24 PM [INFO]: [CPU: 10]: Game 98
 81%|████████  | 97/120 [3:43:54<52:07, 135.98s/it]04/07/2022 06:43:29 PM [INFO]: [CPU: 1]: Game 97
 88%|████████▊ | 105/120 [3:44:06<28:23, 113.58s/it]04/07/2022 06:43:41 PM [INFO]: [CPU: 4]: Game 105
 87%|████████▋ | 104/120 [3:44:18<26:32, 99.55s/it] 04/07/2022 06:43:53 PM [INFO]: [CPU: 3]: Game 104
 92%|█████████▏| 110/120 [3:44:44<26:19, 157.94s/it]04/07/2022 06:44:20 PM [INFO]: [CPU: 5]: Game 110
 84%|████████▍ | 101/120 [3:44:49<31:00, 97.91s/it] 04/07/2022 06:44:24 PM [INFO]: [CPU: 11]: Game 101
 82%|████████▎ | 99/120 [3:45:23<45:53, 131.11s/it]04/07/2022 06:44:59 PM [INFO]: [CPU: 8]: Game 99
 85%|████████▌ | 102/120 [3:45:29<38:42, 129.00s/it]04/07/2022 06:45:05 PM [INFO]: [CPU: 9]: Game 102
 83%|████████▎ | 100/120 [3:45:36<48:06, 144.31s/it]04/07/2022 06:45:12 PM [INFO]: [CPU: 0]: Game 100
 82%|████████▎ | 99/120 [3:45:42<47:41, 136.25s/it]04/07/2022 06:45:18 PM [INFO]: [CPU: 10]: Game 99
 92%|█████████▎| 111/120 [3:45:56<19:48, 132.06s/it]04/07/2022 06:45:31 PM [INFO]: [CPU: 5]: Game 111
 88%|████████▊ | 105/120 [3:46:11<25:55, 103.69s/it]04/07/2022 06:45:47 PM [INFO]: [CPU: 3]: Game 105
 88%|████████▊ | 106/120 [3:46:23<28:09, 120.66s/it]04/07/2022 06:45:59 PM [INFO]: [CPU: 4]: Game 106
 82%|████████▏ | 98/120 [3:46:29<51:58, 141.74s/it]04/07/2022 06:46:05 PM [INFO]: [CPU: 1]: Game 98
 81%|████████  | 97/120 [3:46:47<52:00, 135.69s/it]04/07/2022 06:46:22 PM [INFO]: [CPU: 2]: Game 97
 86%|████████▌ | 103/120 [3:47:28<35:43, 126.11s/it]04/07/2022 06:47:04 PM [INFO]: [CPU: 9]: Game 103
 84%|████████▍ | 101/120 [3:47:29<42:45, 135.04s/it]04/07/2022 06:47:05 PM [INFO]: [CPU: 0]: Game 101
 88%|████████▊ | 106/120 [3:47:41<23:12, 99.44s/it] 04/07/2022 06:47:16 PM [INFO]: [CPU: 3]: Game 106
 85%|████████▌ | 102/120 [3:48:00<37:44, 125.80s/it]04/07/2022 06:47:35 PM [INFO]: [CPU: 11]: Game 102
 87%|████████▋ | 104/120 [3:48:22<27:50, 104.38s/it]04/07/2022 06:47:58 PM [INFO]: [CPU: 9]: Game 104
 82%|████████▎ | 99/120 [3:48:22<46:37, 133.21s/it]04/07/2022 06:47:58 PM [INFO]: [CPU: 1]: Game 99
 85%|████████▌ | 102/120 [3:48:29<33:43, 112.42s/it]04/07/2022 06:48:05 PM [INFO]: [CPU: 0]: Game 102
 82%|████████▏ | 98/120 [3:48:40<47:17, 128.99s/it]04/07/2022 06:48:16 PM [INFO]: [CPU: 2]: Game 98
 83%|████████▎ | 100/120 [3:48:47<50:16, 150.84s/it]04/07/2022 06:48:23 PM [INFO]: [CPU: 10]: Game 100
 83%|████████▎ | 100/120 [3:48:52<51:28, 154.42s/it]04/07/2022 06:48:28 PM [INFO]: [CPU: 8]: Game 100
 89%|████████▉ | 107/120 [3:49:04<28:46, 132.79s/it]04/07/2022 06:48:40 PM [INFO]: [CPU: 4]: Game 107
 89%|████████▉ | 107/120 [3:49:28<22:03, 101.83s/it]04/07/2022 06:49:04 PM [INFO]: [CPU: 3]: Game 107
 93%|█████████▎| 112/120 [3:49:36<21:09, 158.66s/it]04/07/2022 06:49:12 PM [INFO]: [CPU: 5]: Game 112
 86%|████████▌ | 103/120 [3:49:41<33:34, 118.49s/it]04/07/2022 06:49:17 PM [INFO]: [CPU: 11]: Game 103
 94%|█████████▍| 113/120 [3:50:30<14:50, 127.17s/it]04/07/2022 06:50:06 PM [INFO]: [CPU: 5]: Game 113
 86%|████████▌ | 103/120 [3:50:46<33:57, 119.86s/it]04/07/2022 06:50:22 PM [INFO]: [CPU: 0]: Game 103
 82%|████████▎ | 99/120 [3:51:09<47:15, 135.05s/it]04/07/2022 06:50:45 PM [INFO]: [CPU: 2]: Game 99
 88%|████████▊ | 105/120 [3:51:21<31:41, 126.75s/it]04/07/2022 06:50:57 PM [INFO]: [CPU: 9]: Game 105
 95%|█████████▌| 114/120 [3:51:24<10:30, 105.12s/it]04/07/2022 06:50:59 PM [INFO]: [CPU: 5]: Game 114
 90%|█████████ | 108/120 [3:51:27<27:10, 135.91s/it]04/07/2022 06:51:03 PM [INFO]: [CPU: 4]: Game 108
 87%|████████▋ | 104/120 [3:51:28<30:42, 115.16s/it]04/07/2022 06:51:04 PM [INFO]: [CPU: 11]: Game 104
 83%|████████▎ | 100/120 [3:51:33<50:10, 150.54s/it]04/07/2022 06:51:09 PM [INFO]: [CPU: 1]: Game 100
 87%|████████▋ | 104/120 [3:51:34<26:11, 98.22s/it] 04/07/2022 06:51:10 PM [INFO]: [CPU: 0]: Game 104
 84%|████████▍ | 101/120 [3:51:46<50:27, 159.32s/it]04/07/2022 06:51:22 PM [INFO]: [CPU: 10]: Game 101
 90%|█████████ | 108/120 [3:52:03<23:33, 117.80s/it]04/07/2022 06:51:39 PM [INFO]: [CPU: 3]: Game 108
 84%|████████▍ | 101/120 [3:52:27<54:37, 172.51s/it]04/07/2022 06:52:02 PM [INFO]: [CPU: 8]: Game 101
 88%|████████▊ | 106/120 [3:52:51<26:58, 115.58s/it]04/07/2022 06:52:26 PM [INFO]: [CPU: 9]: Game 106
 96%|█████████▌| 115/120 [3:52:59<08:30, 102.19s/it]04/07/2022 06:52:35 PM [INFO]: [CPU: 5]: Game 115
 88%|████████▊ | 105/120 [3:53:21<25:14, 100.97s/it]04/07/2022 06:52:57 PM [INFO]: [CPU: 0]: Game 105
 83%|████████▎ | 100/120 [3:53:26<45:13, 135.69s/it]04/07/2022 06:53:02 PM [INFO]: [CPU: 2]: Game 100
 84%|████████▍ | 101/120 [3:53:27<44:08, 139.37s/it]04/07/2022 06:53:02 PM [INFO]: [CPU: 1]: Game 101
 85%|████████▌ | 102/120 [3:53:51<44:43, 149.08s/it]04/07/2022 06:53:27 PM [INFO]: [CPU: 10]: Game 102
 88%|████████▊ | 105/120 [3:54:10<32:14, 128.94s/it]04/07/2022 06:53:45 PM [INFO]: [CPU: 11]: Game 105
 88%|████████▊ | 106/120 [3:54:33<21:30, 92.15s/it] 04/07/2022 06:54:09 PM [INFO]: [CPU: 0]: Game 106
 84%|████████▍ | 101/120 [3:54:38<36:53, 116.47s/it]04/07/2022 06:54:14 PM [INFO]: [CPU: 2]: Game 101
 91%|█████████ | 109/120 [3:54:38<27:56, 152.41s/it]04/07/2022 06:54:14 PM [INFO]: [CPU: 4]: Game 109
 85%|████████▌ | 102/120 [3:54:44<48:35, 161.98s/it]04/07/2022 06:54:20 PM [INFO]: [CPU: 8]: Game 102
 89%|████████▉ | 107/120 [3:54:56<25:41, 118.61s/it]04/07/2022 06:54:32 PM [INFO]: [CPU: 9]: Game 107
 91%|█████████ | 109/120 [3:54:57<24:39, 134.50s/it]04/07/2022 06:54:32 PM [INFO]: [CPU: 3]: Game 109
 97%|█████████▋| 116/120 [3:55:11<07:24, 111.14s/it]04/07/2022 06:54:47 PM [INFO]: [CPU: 5]: Game 116
 89%|████████▉ | 107/120 [3:55:28<17:32, 80.93s/it]04/07/2022 06:55:03 PM [INFO]: [CPU: 0]: Game 107
 86%|████████▌ | 103/120 [3:55:28<37:46, 133.33s/it]04/07/2022 06:55:03 PM [INFO]: [CPU: 10]: Game 103
 85%|████████▌ | 102/120 [3:56:03<32:08, 107.13s/it]04/07/2022 06:55:39 PM [INFO]: [CPU: 2]: Game 102
 88%|████████▊ | 106/120 [3:56:05<29:07, 124.79s/it]04/07/2022 06:55:40 PM [INFO]: [CPU: 11]: Game 106
 86%|████████▌ | 103/120 [3:56:10<39:22, 138.98s/it]04/07/2022 06:55:45 PM [INFO]: [CPU: 8]: Game 103
 85%|████████▌ | 102/120 [3:56:22<45:01, 150.11s/it]04/07/2022 06:55:57 PM [INFO]: [CPU: 1]: Game 102
 90%|█████████ | 108/120 [3:56:35<15:21, 76.77s/it]04/07/2022 06:56:10 PM [INFO]: [CPU: 0]: Game 108
 92%|█████████▏| 110/120 [3:56:46<24:10, 145.06s/it]04/07/2022 06:56:22 PM [INFO]: [CPU: 4]: Game 110
 92%|█████████▏| 110/120 [3:56:52<21:28, 128.84s/it]04/07/2022 06:56:28 PM [INFO]: [CPU: 3]: Game 110
 90%|█████████ | 108/120 [3:57:10<24:38, 123.20s/it]04/07/2022 06:56:46 PM [INFO]: [CPU: 9]: Game 108
 86%|████████▌ | 103/120 [3:57:23<34:56, 123.33s/it]04/07/2022 06:56:58 PM [INFO]: [CPU: 1]: Game 103
 87%|████████▋ | 104/120 [3:57:24<34:08, 128.01s/it]04/07/2022 06:56:59 PM [INFO]: [CPU: 10]: Game 104
 98%|█████████▊| 117/120 [3:57:37<06:04, 121.65s/it]04/07/2022 06:57:13 PM [INFO]: [CPU: 5]: Game 117
 86%|████████▌ | 103/120 [3:58:36<34:11, 120.68s/it]04/07/2022 06:58:11 PM [INFO]: [CPU: 2]: Game 103
 87%|████████▋ | 104/120 [3:58:36<37:38, 141.13s/it]04/07/2022 06:58:11 PM [INFO]: [CPU: 8]: Game 104
 92%|█████████▎| 111/120 [3:58:36<18:11, 121.25s/it]04/07/2022 06:58:11 PM [INFO]: [CPU: 3]: Game 111
 91%|█████████ | 109/120 [3:58:49<17:13, 93.92s/it]04/07/2022 06:58:24 PM [INFO]: [CPU: 0]: Game 109
 92%|█████████▎| 111/120 [3:58:54<20:59, 139.91s/it]04/07/2022 06:58:30 PM [INFO]: [CPU: 4]: Game 111
 89%|████████▉ | 107/120 [3:59:13<31:11, 143.96s/it]04/07/2022 06:58:49 PM [INFO]: [CPU: 11]: Game 107
 87%|████████▋ | 104/120 [3:59:25<32:46, 122.88s/it]04/07/2022 06:59:00 PM [INFO]: [CPU: 1]: Game 104
 91%|█████████ | 109/120 [3:59:42<24:10, 131.89s/it]04/07/2022 06:59:18 PM [INFO]: [CPU: 9]: Game 109
 88%|████████▊ | 105/120 [3:59:56<33:49, 135.29s/it]04/07/2022 06:59:31 PM [INFO]: [CPU: 10]: Game 105
 98%|█████████▊| 118/120 [3:59:57<04:14, 127.17s/it]04/07/2022 06:59:33 PM [INFO]: [CPU: 5]: Game 118
 87%|████████▋ | 104/120 [4:00:19<30:48, 115.55s/it]04/07/2022 06:59:55 PM [INFO]: [CPU: 2]: Game 104
 88%|████████▊ | 105/120 [4:01:08<36:06, 144.43s/it]04/07/2022 07:00:43 PM [INFO]: [CPU: 8]: Game 105
 88%|████████▊ | 105/120 [4:01:14<29:43, 118.90s/it]04/07/2022 07:00:50 PM [INFO]: [CPU: 1]: Game 105
 90%|█████████ | 108/120 [4:01:21<27:49, 139.17s/it]04/07/2022 07:00:57 PM [INFO]: [CPU: 11]: Game 108
 99%|█████████▉| 119/120 [4:01:23<01:54, 114.60s/it]04/07/2022 07:00:58 PM [INFO]: [CPU: 5]: Game 119
 88%|████████▊ | 106/120 [4:01:27<28:29, 122.08s/it]04/07/2022 07:01:03 PM [INFO]: [CPU: 10]: Game 106
 93%|█████████▎| 112/120 [4:01:39<19:38, 147.26s/it]04/07/2022 07:01:14 PM [INFO]: [CPU: 4]: Game 112
 92%|█████████▏| 110/120 [4:01:56<22:04, 132.50s/it]04/07/2022 07:01:32 PM [INFO]: [CPU: 9]: Game 110
 93%|█████████▎| 112/120 [4:02:27<20:34, 154.26s/it]04/07/2022 07:02:03 PM [INFO]: [CPU: 3]: Game 112
 92%|█████████▏| 110/120 [4:02:34<22:13, 133.32s/it]04/07/2022 07:02:10 PM [INFO]: [CPU: 0]: Game 110
 91%|█████████ | 109/120 [4:03:05<23:33, 128.46s/it]04/07/2022 07:02:40 PM [INFO]: [CPU: 11]: Game 109
 88%|████████▊ | 105/120 [4:03:16<33:27, 133.86s/it]04/07/2022 07:02:51 PM [INFO]: [CPU: 2]: Game 105
 89%|████████▉ | 107/120 [4:03:17<25:38, 118.33s/it]04/07/2022 07:02:52 PM [INFO]: [CPU: 10]: Game 107
 88%|████████▊ | 106/120 [4:03:28<28:47, 123.40s/it]04/07/2022 07:03:04 PM [INFO]: [CPU: 1]: Game 106
 92%|█████████▎| 111/120 [4:03:46<18:50, 125.63s/it]04/07/2022 07:03:21 PM [INFO]: [CPU: 9]: Game 111
 94%|█████████▍| 113/120 [4:04:11<16:13, 139.04s/it]04/07/2022 07:03:46 PM [INFO]: [CPU: 3]: Game 113
100%|██████████| 120/120 [4:04:13<00:00, 131.35s/it]100%|██████████| 120/120 [4:04:13<00:00, 122.11s/it]
 88%|████████▊ | 106/120 [4:04:27<37:33, 160.93s/it]04/07/2022 07:04:03 PM [INFO]: [CPU: 8]: Game 106
 88%|████████▊ | 106/120 [4:04:39<27:39, 118.54s/it]04/07/2022 07:04:14 PM [INFO]: [CPU: 2]: Game 106
 92%|█████████▎| 111/120 [4:04:45<19:53, 132.57s/it]04/07/2022 07:04:20 PM [INFO]: [CPU: 0]: Game 111
 94%|█████████▍| 113/120 [4:04:50<18:43, 160.45s/it]04/07/2022 07:04:25 PM [INFO]: [CPU: 4]: Game 113
 89%|████████▉ | 107/120 [4:04:55<24:22, 112.53s/it]04/07/2022 07:04:31 PM [INFO]: [CPU: 1]: Game 107
 90%|█████████ | 108/120 [4:05:18<23:50, 119.24s/it]04/07/2022 07:04:54 PM [INFO]: [CPU: 10]: Game 108
 92%|█████████▏| 110/120 [4:05:18<21:39, 129.98s/it]04/07/2022 07:04:54 PM [INFO]: [CPU: 11]: Game 110
 89%|████████▉ | 107/120 [4:05:39<29:05, 134.24s/it]04/07/2022 07:05:15 PM [INFO]: [CPU: 8]: Game 107
 95%|█████████▌| 114/120 [4:05:50<12:43, 127.26s/it]04/07/2022 07:05:26 PM [INFO]: [CPU: 3]: Game 114
 95%|█████████▌| 114/120 [4:06:02<13:23, 133.87s/it]04/07/2022 07:05:37 PM [INFO]: [CPU: 4]: Game 114
 91%|█████████ | 109/120 [4:06:08<18:02, 98.41s/it] 04/07/2022 07:05:43 PM [INFO]: [CPU: 10]: Game 109
 93%|█████████▎| 112/120 [4:06:40<18:41, 140.18s/it]04/07/2022 07:06:16 PM [INFO]: [CPU: 9]: Game 112
 93%|█████████▎| 112/120 [4:06:41<17:01, 127.66s/it]04/07/2022 07:06:17 PM [INFO]: [CPU: 0]: Game 112
 90%|█████████ | 108/120 [4:06:46<22:23, 111.96s/it]04/07/2022 07:06:21 PM [INFO]: [CPU: 1]: Game 108
 89%|████████▉ | 107/120 [4:06:57<26:57, 124.46s/it]04/07/2022 07:06:32 PM [INFO]: [CPU: 2]: Game 107
 96%|█████████▌| 115/120 [4:07:24<09:46, 117.30s/it]04/07/2022 07:07:00 PM [INFO]: [CPU: 3]: Game 115
 96%|█████████▌| 115/120 [4:07:25<09:53, 118.63s/it]04/07/2022 07:07:00 PM [INFO]: [CPU: 4]: Game 115
 92%|█████████▎| 111/120 [4:07:31<19:37, 130.81s/it]04/07/2022 07:07:07 PM [INFO]: [CPU: 11]: Game 111
 90%|█████████ | 108/120 [4:08:20<28:25, 142.10s/it]04/07/2022 07:07:55 PM [INFO]: [CPU: 8]: Game 108
 97%|█████████▋| 116/120 [4:08:36<06:54, 103.71s/it]04/07/2022 07:08:12 PM [INFO]: [CPU: 3]: Game 116
 97%|█████████▋| 116/120 [4:08:37<06:58, 104.62s/it]04/07/2022 07:08:12 PM [INFO]: [CPU: 4]: Game 116
 90%|█████████ | 108/120 [4:08:59<24:43, 123.66s/it]04/07/2022 07:08:34 PM [INFO]: [CPU: 2]: Game 108
 94%|█████████▍| 113/120 [4:09:20<17:03, 146.25s/it]04/07/2022 07:08:56 PM [INFO]: [CPU: 9]: Game 113
 91%|█████████ | 109/120 [4:09:21<22:53, 124.86s/it]04/07/2022 07:08:56 PM [INFO]: [CPU: 1]: Game 109
 92%|█████████▏| 110/120 [4:09:38<21:59, 131.95s/it]04/07/2022 07:09:14 PM [INFO]: [CPU: 10]: Game 110
 94%|█████████▍| 113/120 [4:09:38<16:37, 142.50s/it]04/07/2022 07:09:14 PM [INFO]: [CPU: 0]: Game 113
 95%|█████████▌| 114/120 [4:09:59<11:23, 113.98s/it]04/07/2022 07:09:35 PM [INFO]: [CPU: 9]: Game 114
 98%|█████████▊| 117/120 [4:10:05<04:57, 99.16s/it] 04/07/2022 07:09:40 PM [INFO]: [CPU: 3]: Game 117
 92%|█████████▏| 110/120 [4:10:11<17:03, 102.34s/it]04/07/2022 07:09:46 PM [INFO]: [CPU: 1]: Game 110
 91%|█████████ | 109/120 [4:10:11<19:49, 108.16s/it]04/07/2022 07:09:46 PM [INFO]: [CPU: 2]: Game 109
 93%|█████████▎| 112/120 [4:10:28<19:17, 144.66s/it]04/07/2022 07:10:04 PM [INFO]: [CPU: 11]: Game 112
 98%|█████████▊| 117/120 [4:10:44<05:34, 111.46s/it]04/07/2022 07:10:20 PM [INFO]: [CPU: 4]: Game 117
 95%|█████████▌| 114/120 [4:10:56<12:18, 123.02s/it]04/07/2022 07:10:31 PM [INFO]: [CPU: 0]: Game 114
 91%|█████████ | 109/120 [4:11:22<28:17, 154.28s/it]04/07/2022 07:10:58 PM [INFO]: [CPU: 8]: Game 109
 98%|█████████▊| 118/120 [4:11:45<03:18, 99.29s/it]04/07/2022 07:11:20 PM [INFO]: [CPU: 3]: Game 118
 92%|█████████▎| 111/120 [4:11:50<15:13, 101.53s/it]04/07/2022 07:11:26 PM [INFO]: [CPU: 1]: Game 111
 92%|█████████▎| 111/120 [4:12:02<20:19, 135.53s/it]04/07/2022 07:11:37 PM [INFO]: [CPU: 10]: Game 111
 96%|█████████▌| 115/120 [4:12:06<09:49, 117.98s/it]04/07/2022 07:11:42 PM [INFO]: [CPU: 9]: Game 115
 96%|█████████▌| 115/120 [4:12:08<08:58, 107.70s/it]04/07/2022 07:11:43 PM [INFO]: [CPU: 0]: Game 115
 92%|█████████▏| 110/120 [4:12:18<20:46, 124.61s/it]04/07/2022 07:11:53 PM [INFO]: [CPU: 8]: Game 110
 92%|█████████▏| 110/120 [4:12:24<19:16, 115.61s/it]04/07/2022 07:11:59 PM [INFO]: [CPU: 2]: Game 110
 99%|█████████▉| 119/120 [4:12:51<01:29, 89.46s/it]04/07/2022 07:12:27 PM [INFO]: [CPU: 3]: Game 119
 98%|█████████▊| 118/120 [4:13:03<03:59, 119.56s/it]04/07/2022 07:12:38 PM [INFO]: [CPU: 4]: Game 118
 93%|█████████▎| 112/120 [4:13:24<13:14, 99.31s/it] 04/07/2022 07:13:00 PM [INFO]: [CPU: 1]: Game 112
 93%|█████████▎| 112/120 [4:13:31<16:11, 121.49s/it]04/07/2022 07:13:06 PM [INFO]: [CPU: 10]: Game 112
 94%|█████████▍| 113/120 [4:13:31<18:12, 156.05s/it]04/07/2022 07:13:06 PM [INFO]: [CPU: 11]: Game 113
 97%|█████████▋| 116/120 [4:13:42<06:54, 103.64s/it]04/07/2022 07:13:17 PM [INFO]: [CPU: 0]: Game 116
 97%|█████████▋| 116/120 [4:14:03<07:49, 117.46s/it]04/07/2022 07:13:38 PM [INFO]: [CPU: 9]: Game 116
 94%|█████████▍| 113/120 [4:14:09<11:16, 96.67s/it] 04/07/2022 07:13:45 PM [INFO]: [CPU: 10]: Game 113
 92%|█████████▎| 111/120 [4:14:14<17:07, 114.15s/it]04/07/2022 07:13:50 PM [INFO]: [CPU: 2]: Game 111
100%|██████████| 120/120 [4:14:47<00:00, 97.48s/it]100%|██████████| 120/120 [4:14:47<00:00, 127.40s/it]
 94%|█████████▍| 113/120 [4:14:47<11:00, 94.40s/it]04/07/2022 07:14:23 PM [INFO]: [CPU: 1]: Game 113
 92%|█████████▎| 111/120 [4:14:57<20:15, 135.02s/it]04/07/2022 07:14:33 PM [INFO]: [CPU: 8]: Game 111
 99%|█████████▉| 119/120 [4:14:57<01:58, 118.18s/it]04/07/2022 07:14:33 PM [INFO]: [CPU: 4]: Game 119
 98%|█████████▊| 117/120 [4:15:28<05:12, 104.28s/it]04/07/2022 07:15:03 PM [INFO]: [CPU: 0]: Game 117
100%|██████████| 120/120 [4:15:32<00:00, 93.09s/it] 100%|██████████| 120/120 [4:15:32<00:00, 127.77s/it]
 95%|█████████▌| 114/120 [4:15:50<15:06, 151.07s/it]04/07/2022 07:15:26 PM [INFO]: [CPU: 11]: Game 114
 98%|█████████▊| 117/120 [4:15:54<05:46, 115.51s/it]04/07/2022 07:15:29 PM [INFO]: [CPU: 9]: Game 117
 93%|█████████▎| 112/120 [4:16:16<15:31, 116.48s/it]04/07/2022 07:15:52 PM [INFO]: [CPU: 2]: Game 112
 95%|█████████▌| 114/120 [4:16:30<10:58, 109.79s/it]04/07/2022 07:16:05 PM [INFO]: [CPU: 10]: Game 114
 95%|█████████▌| 114/120 [4:16:51<10:19, 103.29s/it]04/07/2022 07:16:27 PM [INFO]: [CPU: 1]: Game 114
 98%|█████████▊| 118/120 [4:16:57<03:19, 99.66s/it] 04/07/2022 07:16:32 PM [INFO]: [CPU: 0]: Game 118
 98%|█████████▊| 118/120 [4:17:00<03:21, 100.73s/it]04/07/2022 07:16:35 PM [INFO]: [CPU: 9]: Game 118
 93%|█████████▎| 112/120 [4:17:22<18:24, 138.03s/it]04/07/2022 07:16:58 PM [INFO]: [CPU: 8]: Game 112
 96%|█████████▌| 115/120 [4:17:50<11:47, 141.58s/it]04/07/2022 07:17:25 PM [INFO]: [CPU: 11]: Game 115
 96%|█████████▌| 115/120 [4:17:58<07:40, 92.19s/it] 04/07/2022 07:17:33 PM [INFO]: [CPU: 1]: Game 115
 96%|█████████▌| 115/120 [4:17:58<08:36, 103.35s/it]04/07/2022 07:17:34 PM [INFO]: [CPU: 10]: Game 115
 94%|█████████▍| 113/120 [4:18:11<13:32, 116.02s/it]04/07/2022 07:17:47 PM [INFO]: [CPU: 2]: Game 113
 99%|█████████▉| 119/120 [4:18:16<01:33, 93.61s/it]04/07/2022 07:17:52 PM [INFO]: [CPU: 0]: Game 119
 97%|█████████▋| 116/120 [4:18:51<07:50, 117.64s/it]04/07/2022 07:18:27 PM [INFO]: [CPU: 11]: Game 116
 95%|█████████▌| 114/120 [4:19:04<09:42, 97.11s/it] 04/07/2022 07:18:40 PM [INFO]: [CPU: 2]: Game 114
 99%|█████████▉| 119/120 [4:19:12<01:50, 110.29s/it]04/07/2022 07:18:48 PM [INFO]: [CPU: 9]: Game 119
 97%|█████████▋| 116/120 [4:19:13<05:48, 87.07s/it]04/07/2022 07:18:48 PM [INFO]: [CPU: 1]: Game 116
 94%|█████████▍| 113/120 [4:19:21<15:26, 132.41s/it]04/07/2022 07:18:57 PM [INFO]: [CPU: 8]: Game 113
 98%|█████████▊| 117/120 [4:19:44<04:54, 98.27s/it] 04/07/2022 07:19:20 PM [INFO]: [CPU: 11]: Game 117
100%|██████████| 120/120 [4:20:11<00:00, 99.97s/it]100%|██████████| 120/120 [4:20:11<00:00, 130.09s/it]
 97%|█████████▋| 116/120 [4:20:19<07:37, 114.48s/it]04/07/2022 07:19:54 PM [INFO]: [CPU: 10]: Game 116
 95%|█████████▌| 114/120 [4:20:22<11:04, 110.82s/it]04/07/2022 07:19:57 PM [INFO]: [CPU: 8]: Game 114
 98%|█████████▊| 117/120 [4:20:42<04:22, 87.66s/it]04/07/2022 07:20:17 PM [INFO]: [CPU: 1]: Game 117
 96%|█████████▌| 115/120 [4:20:42<08:06, 97.33s/it]04/07/2022 07:20:18 PM [INFO]: [CPU: 2]: Game 115
 98%|█████████▊| 117/120 [4:20:46<04:25, 88.41s/it] 04/07/2022 07:20:22 PM [INFO]: [CPU: 10]: Game 117
100%|██████████| 120/120 [4:21:01<00:00, 109.79s/it]100%|██████████| 120/120 [4:21:01<00:00, 130.51s/it]
 98%|█████████▊| 118/120 [4:21:09<03:08, 94.10s/it]04/07/2022 07:20:44 PM [INFO]: [CPU: 11]: Game 118
 98%|█████████▊| 118/120 [4:21:46<02:39, 79.96s/it]04/07/2022 07:21:22 PM [INFO]: [CPU: 10]: Game 118
 98%|█████████▊| 118/120 [4:22:00<02:49, 84.73s/it]04/07/2022 07:21:35 PM [INFO]: [CPU: 1]: Game 118
 96%|█████████▌| 115/120 [4:22:17<09:19, 111.99s/it]04/07/2022 07:21:52 PM [INFO]: [CPU: 8]: Game 115
 99%|█████████▉| 119/120 [4:22:48<01:13, 73.73s/it]04/07/2022 07:22:23 PM [INFO]: [CPU: 1]: Game 119
 99%|█████████▉| 119/120 [4:23:02<01:18, 78.59s/it]04/07/2022 07:22:37 PM [INFO]: [CPU: 10]: Game 119
 96%|█████████▌| 115/120 [4:23:12<11:26, 137.33s/it]
Process Process-3:
Traceback (most recent call last):
  File "/home/x_aolss/.conda/envs/myownenv/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/x_aolss/.conda/envs/myownenv/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/x_aolss/gym_connect4/gym-connect4/MCTS_c4.py", line 192, in MCTS_self_play
    np.random.choice(np.array([0,1,2,3,4,5,6]), \
  File "mtrand.pyx", line 935, in numpy.random.mtrand.RandomState.choice
ValueError: probabilities contain NaN
 99%|█████████▉| 119/120 [4:23:12<01:42, 102.86s/it]04/07/2022 07:22:48 PM [INFO]: [CPU: 11]: Game 119
100%|██████████| 120/120 [4:23:34<00:00, 78.68s/it] 100%|██████████| 120/120 [4:23:34<00:00, 131.79s/it]
 97%|█████████▋| 116/120 [4:23:41<06:54, 103.72s/it]04/07/2022 07:23:16 PM [INFO]: [CPU: 8]: Game 116
100%|██████████| 120/120 [4:24:00<00:00, 72.61s/it]100%|██████████| 120/120 [4:24:00<00:00, 132.01s/it]
100%|██████████| 120/120 [4:24:09<00:00, 75.84s/it]100%|██████████| 120/120 [4:24:09<00:00, 132.08s/it]
 98%|█████████▊| 117/120 [4:24:58<04:47, 95.85s/it] 04/07/2022 07:24:34 PM [INFO]: [CPU: 8]: Game 117
 98%|█████████▊| 118/120 [4:25:38<02:38, 79.09s/it]04/07/2022 07:25:14 PM [INFO]: [CPU: 8]: Game 118
 99%|█████████▉| 119/120 [4:26:40<01:13, 73.87s/it]04/07/2022 07:26:16 PM [INFO]: [CPU: 8]: Game 119
100%|██████████| 120/120 [4:26:54<00:00, 55.89s/it]100%|██████████| 120/120 [4:26:54<00:00, 133.45s/it]
04/07/2022 07:26:30 PM [INFO]: Finished multi-process MCTS!
04/07/2022 07:26:30 PM [INFO]: Loading training data...
/home/x_aolss/gym_connect4/gym-connect4/train_c4.py:141: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  datasets = np.array(datasets)
04/07/2022 07:26:33 PM [INFO]: Loaded data from ./datasets/iter_5/.
04/07/2022 07:26:33 PM [INFO]: Loaded checkpoint model cc4_current_net__iter5.pth.tar.
04/07/2022 07:26:33 PM [INFO]: Starting training process...
04/07/2022 08:25:14 PM [INFO]: Finished Training!
FINISHED SELF PLAY:  19:26:30
Update step size: 211
[Iteration 5] Process ID: 181441 [Epoch: 1,  6752/ 27057 points] total loss per batch: 2.876
Policy (actual, predicted): 4 6
Policy data: tensor([0.0976, 0.1830, 0.1071, 0.0890, 0.2367, 0.0500, 0.2367],
       device='cuda:0')
Policy pred: tensor([0.1249, 0.1508, 0.1342, 0.1435, 0.1551, 0.0818, 0.2096],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.16116367280483246
 
[Iteration 5] Process ID: 181441 [Epoch: 1, 13504/ 27057 points] total loss per batch: 2.791
Policy (actual, predicted): 4 6
Policy data: tensor([0.1240, 0.1619, 0.0943, 0.1133, 0.2488, 0.0290, 0.2286],
       device='cuda:0')
Policy pred: tensor([0.1195, 0.1251, 0.1417, 0.1077, 0.2066, 0.0844, 0.2150],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.34282127022743225
 
[Iteration 5] Process ID: 181441 [Epoch: 1, 20256/ 27057 points] total loss per batch: 2.728
Policy (actual, predicted): 6 6
Policy data: tensor([0.1489, 0.1395, 0.1477, 0.1372, 0.1442, 0.1325, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1283, 0.1292, 0.1567, 0.1297, 0.1405, 0.1300, 0.1856],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.033929478377103806
 
[Iteration 5] Process ID: 181441 [Epoch: 1, 27008/ 27057 points] total loss per batch: 2.669
Policy (actual, predicted): 6 6
Policy data: tensor([0.1430, 0.1706, 0.1430, 0.1090, 0.1307, 0.0416, 0.2621],
       device='cuda:0')
Policy pred: tensor([0.1101, 0.1567, 0.1135, 0.1357, 0.1637, 0.0826, 0.2377],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.06258012354373932
 
[Iteration 5] Process ID: 181441 [Epoch: 2,  6752/ 27057 points] total loss per batch: 2.584
Policy (actual, predicted): 0 4
Policy data: tensor([0.1477, 0.1419, 0.1442, 0.1407, 0.1477, 0.1301, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1332, 0.1500, 0.1358, 0.1338, 0.1681, 0.1188, 0.1603],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.03941751644015312
 
[Iteration 5] Process ID: 181441 [Epoch: 2, 13504/ 27057 points] total loss per batch: 2.547
Policy (actual, predicted): 3 6
Policy data: tensor([0.1252, 0.2482, 0.0771, 0.2671, 0.0000, 0.0838, 0.1986],
       device='cuda:0')
Policy pred: tensor([1.0932e-01, 1.9012e-01, 1.5319e-01, 2.0945e-01, 2.0486e-04, 7.0176e-02,
        2.6755e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.8782896399497986
 
[Iteration 5] Process ID: 181441 [Epoch: 2, 20256/ 27057 points] total loss per batch: 2.505
Policy (actual, predicted): 6 6
Policy data: tensor([0.2488, 0.1159, 0.1711, 0.0988, 0.0000, 0.0773, 0.2880],
       device='cuda:0')
Policy pred: tensor([1.8405e-01, 1.9303e-01, 1.1399e-01, 1.6254e-01, 1.0093e-04, 9.9526e-02,
        2.4676e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.2253641039133072
 
[Iteration 5] Process ID: 181441 [Epoch: 2, 27008/ 27057 points] total loss per batch: 2.473
Policy (actual, predicted): 4 1
Policy data: tensor([0.1287, 0.1684, 0.1287, 0.1409, 0.1840, 0.0808, 0.1684],
       device='cuda:0')
Policy pred: tensor([0.1231, 0.2117, 0.1030, 0.0961, 0.1943, 0.0770, 0.1949],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9835793375968933
 
[Iteration 5] Process ID: 181441 [Epoch: 3,  6752/ 27057 points] total loss per batch: 2.414
Policy (actual, predicted): 4 0
Policy data: tensor([0.1442, 0.1442, 0.1442, 0.1383, 0.1500, 0.1372, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1575, 0.1464, 0.1557, 0.1353, 0.1377, 0.1389, 0.1285],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.3927631080150604
 
[Iteration 5] Process ID: 181441 [Epoch: 3, 13504/ 27057 points] total loss per batch: 2.397
Policy (actual, predicted): 6 6
Policy data: tensor([0.1512, 0.1395, 0.1372, 0.1348, 0.1477, 0.1372, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1396, 0.1351, 0.1403, 0.1494, 0.1397, 0.1440, 0.1520],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.2702378034591675
 
[Iteration 5] Process ID: 181441 [Epoch: 3, 20256/ 27057 points] total loss per batch: 2.366
Policy (actual, predicted): 4 4
Policy data: tensor([0.0563, 0.0997, 0.1198, 0.1312, 0.2418, 0.1094, 0.2418],
       device='cuda:0')
Policy pred: tensor([0.0936, 0.1414, 0.1153, 0.1263, 0.2304, 0.0678, 0.2252],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.11689433455467224
 
[Iteration 5] Process ID: 181441 [Epoch: 3, 27008/ 27057 points] total loss per batch: 2.345
Policy (actual, predicted): 4 4
Policy data: tensor([0.1454, 0.1442, 0.1348, 0.1383, 0.1500, 0.1442, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1460, 0.1450, 0.1381, 0.1416, 0.1522, 0.1387, 0.1385],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.30268096923828125
 
[Iteration 5] Process ID: 181441 [Epoch: 4,  6752/ 27057 points] total loss per batch: 2.301
Policy (actual, predicted): 6 6
Policy data: tensor([0.1407, 0.1430, 0.1395, 0.1407, 0.1430, 0.1395, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1383, 0.1438, 0.1360, 0.1282, 0.1650, 0.1170, 0.1717],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.565123975276947
 
[Iteration 5] Process ID: 181441 [Epoch: 4, 13504/ 27057 points] total loss per batch: 2.314
Policy (actual, predicted): 6 6
Policy data: tensor([0.1233, 0.1613, 0.1613, 0.1125, 0.1349, 0.0579, 0.2487],
       device='cuda:0')
Policy pred: tensor([0.1075, 0.1735, 0.1042, 0.1278, 0.1589, 0.0592, 0.2689],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9587711691856384
 
[Iteration 5] Process ID: 181441 [Epoch: 4, 20256/ 27057 points] total loss per batch: 2.294
Policy (actual, predicted): 2 2
Policy data: tensor([0.1477, 0.1430, 0.1489, 0.1383, 0.1442, 0.1301, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1446, 0.1442, 0.1489, 0.1437, 0.1370, 0.1378, 0.1438],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.004509455524384975
 
[Iteration 5] Process ID: 181441 [Epoch: 4, 27008/ 27057 points] total loss per batch: 2.290
Policy (actual, predicted): 3 6
Policy data: tensor([0.1216, 0.2089, 0.1795, 0.2425, 0.0000, 0.0811, 0.1663],
       device='cuda:0')
Policy pred: tensor([1.6723e-01, 1.7763e-01, 1.5263e-01, 1.8772e-01, 1.9478e-06, 8.5962e-02,
        2.2882e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9988275170326233
 
[Iteration 5] Process ID: 181441 [Epoch: 5,  6752/ 27057 points] total loss per batch: 2.261
Policy (actual, predicted): 6 6
Policy data: tensor([0.1360, 0.1501, 0.1336, 0.1430, 0.1489, 0.1360, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1257, 0.1462, 0.1111, 0.1510, 0.1636, 0.1239, 0.1785],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.79375159740448
 
[Iteration 5] Process ID: 181441 [Epoch: 5, 13504/ 27057 points] total loss per batch: 2.252
Policy (actual, predicted): 4 4
Policy data: tensor([0.1483, 0.1603, 0.0000, 0.1603, 0.2175, 0.1267, 0.1869],
       device='cuda:0')
Policy pred: tensor([1.4225e-01, 1.9875e-01, 9.9981e-05, 1.7189e-01, 2.2819e-01, 1.0097e-01,
        1.5785e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.18512912094593048
 
[Iteration 5] Process ID: 181441 [Epoch: 5, 20256/ 27057 points] total loss per batch: 2.261
Policy (actual, predicted): 1 4
Policy data: tensor([0.1221, 0.2263, 0.1904, 0.0843, 0.2077, 0.0767, 0.0926],
       device='cuda:0')
Policy pred: tensor([0.1350, 0.1988, 0.1193, 0.0939, 0.2238, 0.0824, 0.1467],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999703764915466
 
[Iteration 5] Process ID: 181441 [Epoch: 5, 27008/ 27057 points] total loss per batch: 2.237
Policy (actual, predicted): 0 4
Policy data: tensor([0.1698, 0.1184, 0.1184, 0.1698, 0.1698, 0.0984, 0.1554],
       device='cuda:0')
Policy pred: tensor([0.1426, 0.1565, 0.1219, 0.1266, 0.1910, 0.0971, 0.1644],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.8445623517036438
 
[Iteration 5] Process ID: 181441 [Epoch: 6,  6752/ 27057 points] total loss per batch: 2.211
Policy (actual, predicted): 4 4
Policy data: tensor([0.1454, 0.1465, 0.1430, 0.1395, 0.1500, 0.1348, 0.1407],
       device='cuda:0')
Policy pred: tensor([0.1310, 0.1419, 0.1433, 0.1261, 0.1677, 0.1341, 0.1558],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.7556173205375671
 
[Iteration 5] Process ID: 181441 [Epoch: 6, 13504/ 27057 points] total loss per batch: 2.224
Policy (actual, predicted): 4 4
Policy data: tensor([0.1454, 0.1395, 0.1325, 0.1489, 0.1524, 0.1419, 0.1395],
       device='cuda:0')
Policy pred: tensor([0.1601, 0.1573, 0.1319, 0.1288, 0.1618, 0.1270, 0.1329],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9182775020599365
 
[Iteration 5] Process ID: 181441 [Epoch: 6, 20256/ 27057 points] total loss per batch: 2.222
Policy (actual, predicted): 6 2
Policy data: tensor([0.1442, 0.1383, 0.1395, 0.1383, 0.1477, 0.1360, 0.1559],
       device='cuda:0')
Policy pred: tensor([0.1386, 0.1469, 0.1528, 0.1359, 0.1519, 0.1214, 0.1524],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.3825626075267792
 
[Iteration 5] Process ID: 181441 [Epoch: 6, 27008/ 27057 points] total loss per batch: 2.219
Policy (actual, predicted): 4 4
Policy data: tensor([0.0722, 0.1376, 0.0957, 0.1049, 0.2981, 0.0596, 0.2319],
       device='cuda:0')
Policy pred: tensor([0.1048, 0.1332, 0.1318, 0.1481, 0.2081, 0.0859, 0.1882],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.994046151638031
 
[Iteration 5] Process ID: 181441 [Epoch: 7,  6752/ 27057 points] total loss per batch: 2.178
Policy (actual, predicted): 4 4
Policy data: tensor([0.1383, 0.1454, 0.1430, 0.1383, 0.1500, 0.1372, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1426, 0.1406, 0.1448, 0.1388, 0.1463, 0.1415, 0.1454],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.0847807377576828
 
[Iteration 5] Process ID: 181441 [Epoch: 7, 13504/ 27057 points] total loss per batch: 2.203
Policy (actual, predicted): 6 2
Policy data: tensor([0.1480, 0.0000, 0.2328, 0.1581, 0.0000, 0.1802, 0.2810],
       device='cuda:0')
Policy pred: tensor([2.0033e-01, 1.7521e-04, 2.2711e-01, 1.5361e-01, 8.6618e-06, 1.9883e-01,
        2.1994e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 7, 20256/ 27057 points] total loss per batch: 2.203
Policy (actual, predicted): 4 4
Policy data: tensor([0.1442, 0.1419, 0.1383, 0.1407, 0.1500, 0.1454, 0.1395],
       device='cuda:0')
Policy pred: tensor([0.1531, 0.1396, 0.1403, 0.1281, 0.1603, 0.1456, 0.1329],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9009554386138916
 
[Iteration 5] Process ID: 181441 [Epoch: 7, 27008/ 27057 points] total loss per batch: 2.190
Policy (actual, predicted): 1 6
Policy data: tensor([0.0672, 0.2376, 0.1410, 0.0813, 0.1683, 0.0672, 0.2376],
       device='cuda:0')
Policy pred: tensor([0.1023, 0.1800, 0.1482, 0.1140, 0.1706, 0.0819, 0.2030],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9982417821884155
 
[Iteration 5] Process ID: 181441 [Epoch: 8,  6752/ 27057 points] total loss per batch: 2.148
Policy (actual, predicted): 1 6
Policy data: tensor([0.1419, 0.1465, 0.1454, 0.1407, 0.1442, 0.1383, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1373, 0.1436, 0.1435, 0.1419, 0.1424, 0.1399, 0.1513],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.08556155115365982
 
[Iteration 5] Process ID: 181441 [Epoch: 8, 13504/ 27057 points] total loss per batch: 2.176
Policy (actual, predicted): 2 4
Policy data: tensor([0.0819, 0.0000, 0.3018, 0.1130, 0.2611, 0.0754, 0.1668],
       device='cuda:0')
Policy pred: tensor([1.2478e-01, 1.4425e-05, 1.7146e-01, 1.9347e-01, 2.0965e-01, 1.3667e-01,
        1.6396e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998773336410522
 
[Iteration 5] Process ID: 181441 [Epoch: 8, 20256/ 27057 points] total loss per batch: 2.183
Policy (actual, predicted): 4 4
Policy data: tensor([0.0866, 0.1501, 0.0951, 0.1373, 0.2133, 0.1044, 0.2133],
       device='cuda:0')
Policy pred: tensor([0.1201, 0.1478, 0.1219, 0.1306, 0.1964, 0.1127, 0.1704],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9903912544250488
 
[Iteration 5] Process ID: 181441 [Epoch: 8, 27008/ 27057 points] total loss per batch: 2.188
Policy (actual, predicted): 4 4
Policy data: tensor([0.0790, 0.1370, 0.1497, 0.1635, 0.3222, 0.0441, 0.1044],
       device='cuda:0')
Policy pred: tensor([0.1092, 0.1331, 0.1124, 0.1537, 0.2617, 0.0625, 0.1673],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999904036521912
 
[Iteration 5] Process ID: 181441 [Epoch: 9,  6752/ 27057 points] total loss per batch: 2.139
Policy (actual, predicted): 3 4
Policy data: tensor([0.1407, 0.1407, 0.1407, 0.1454, 0.1454, 0.1442, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1396, 0.1398, 0.1430, 0.1352, 0.1609, 0.1414, 0.1401],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.13014797866344452
 
[Iteration 5] Process ID: 181441 [Epoch: 9, 13504/ 27057 points] total loss per batch: 2.168
Policy (actual, predicted): 3 4
Policy data: tensor([0.1465, 0.1407, 0.1442, 0.1477, 0.1442, 0.1383, 0.1383],
       device='cuda:0')
Policy pred: tensor([0.1530, 0.1340, 0.1388, 0.1309, 0.1680, 0.1310, 0.1442],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9404916763305664
 
[Iteration 5] Process ID: 181441 [Epoch: 9, 20256/ 27057 points] total loss per batch: 2.170
Policy (actual, predicted): 1 4
Policy data: tensor([0.1798, 0.2140, 0.1148, 0.1377, 0.1798, 0.0869, 0.0869],
       device='cuda:0')
Policy pred: tensor([0.1451, 0.1816, 0.1091, 0.1226, 0.1892, 0.0989, 0.1535],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9980865716934204
 
[Iteration 5] Process ID: 181441 [Epoch: 9, 27008/ 27057 points] total loss per batch: 2.166
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000, 0.0000, 0.1091, 0.0000, 0.5017, 0.1091, 0.2801],
       device='cuda:0')
Policy pred: tensor([0.0019, 0.0004, 0.2377, 0.0009, 0.3589, 0.1419, 0.2583],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 10,  6752/ 27057 points] total loss per batch: 2.143
Policy (actual, predicted): 6 4
Policy data: tensor([0.1091, 0.1432, 0.0995, 0.0620, 0.1565, 0.1196, 0.3101],
       device='cuda:0')
Policy pred: tensor([0.1450, 0.1503, 0.1277, 0.1338, 0.1732, 0.1244, 0.1455],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.7804762125015259
 
[Iteration 5] Process ID: 181441 [Epoch: 10, 13504/ 27057 points] total loss per batch: 2.148
Policy (actual, predicted): 6 6
Policy data: tensor([0.0936, 0.1346, 0.0776, 0.1124, 0.2468, 0.0433, 0.2916],
       device='cuda:0')
Policy pred: tensor([0.1327, 0.1450, 0.1026, 0.1138, 0.1536, 0.0441, 0.3082],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998478293418884
 
[Iteration 5] Process ID: 181441 [Epoch: 10, 20256/ 27057 points] total loss per batch: 2.161
Policy (actual, predicted): 3 2
Policy data: tensor([0.1799, 0.0000, 0.1427, 0.2430, 0.1799, 0.0748, 0.1799],
       device='cuda:0')
Policy pred: tensor([1.5042e-01, 5.0091e-05, 2.1693e-01, 1.9900e-01, 1.5816e-01, 9.6699e-02,
        1.7875e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 10, 27008/ 27057 points] total loss per batch: 2.136
Policy (actual, predicted): 6 6
Policy data: tensor([0.1089, 0.1706, 0.1193, 0.0681, 0.2030, 0.0681, 0.2620],
       device='cuda:0')
Policy pred: tensor([0.1087, 0.1440, 0.1078, 0.1237, 0.1902, 0.0713, 0.2542],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999030232429504
 
[Iteration 5] Process ID: 181441 [Epoch: 11,  6752/ 27057 points] total loss per batch: 2.130
Policy (actual, predicted): 2 0
Policy data: tensor([0.1383, 0.1419, 0.1512, 0.1395, 0.1501, 0.1313, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1626, 0.1557, 0.1396, 0.1312, 0.1525, 0.1136, 0.1448],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9661787748336792
 
[Iteration 5] Process ID: 181441 [Epoch: 11, 13504/ 27057 points] total loss per batch: 2.148
Policy (actual, predicted): 6 6
Policy data: tensor([0.0563, 0.1849, 0.0751, 0.0825, 0.2387, 0.0563, 0.3062],
       device='cuda:0')
Policy pred: tensor([0.1019, 0.1541, 0.0989, 0.1068, 0.2265, 0.0596, 0.2524],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999783635139465
 
[Iteration 5] Process ID: 181441 [Epoch: 11, 20256/ 27057 points] total loss per batch: 2.134
Policy (actual, predicted): 0 6
Policy data: tensor([0.1524, 0.1454, 0.1372, 0.1384, 0.1512, 0.1254, 0.1501],
       device='cuda:0')
Policy pred: tensor([0.1496, 0.1476, 0.1404, 0.1421, 0.1428, 0.1214, 0.1562],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.5503423810005188
 
[Iteration 5] Process ID: 181441 [Epoch: 11, 27008/ 27057 points] total loss per batch: 2.146
Policy (actual, predicted): 0 6
Policy data: tensor([0.2625, 0.1547, 0.0886, 0.1672, 0.0000, 0.1323, 0.1947],
       device='cuda:0')
Policy pred: tensor([0.1866, 0.1886, 0.1267, 0.1555, 0.0004, 0.1090, 0.2332],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9987233877182007
 
[Iteration 5] Process ID: 181441 [Epoch: 12,  6752/ 27057 points] total loss per batch: 2.132
Policy (actual, predicted): 0 0
Policy data: tensor([0.4183, 0.0000, 0.3079, 0.0000, 0.0000, 0.2738, 0.0000],
       device='cuda:0')
Policy pred: tensor([4.5642e-01, 1.1065e-05, 2.8906e-01, 4.6135e-06, 5.1386e-04, 2.5376e-01,
        2.2456e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 12, 13504/ 27057 points] total loss per batch: 2.131
Policy (actual, predicted): 6 6
Policy data: tensor([0.2488, 0.1159, 0.1711, 0.0988, 0.0000, 0.0773, 0.2880],
       device='cuda:0')
Policy pred: tensor([1.8040e-01, 1.5645e-01, 1.3046e-01, 1.5812e-01, 3.6019e-05, 8.7567e-02,
        2.8696e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9983415007591248
 
[Iteration 5] Process ID: 181441 [Epoch: 12, 20256/ 27057 points] total loss per batch: 2.127
Policy (actual, predicted): 4 2
Policy data: tensor([0.1383, 0.1407, 0.1430, 0.1419, 0.1454, 0.1454, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1377, 0.1423, 0.1472, 0.1448, 0.1419, 0.1395, 0.1465],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.42670297622680664
 
[Iteration 5] Process ID: 181441 [Epoch: 12, 27008/ 27057 points] total loss per batch: 2.140
Policy (actual, predicted): 4 6
Policy data: tensor([0.0792, 0.1509, 0.1801, 0.1260, 0.1966, 0.0870, 0.1801],
       device='cuda:0')
Policy pred: tensor([0.1120, 0.1548, 0.1349, 0.1340, 0.1701, 0.0876, 0.2066],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999948143959045
 
[Iteration 5] Process ID: 181441 [Epoch: 13,  6752/ 27057 points] total loss per batch: 2.119
Policy (actual, predicted): 6 6
Policy data: tensor([0.1383, 0.1430, 0.1466, 0.1383, 0.1489, 0.1313, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1459, 0.1406, 0.1455, 0.1403, 0.1453, 0.1360, 0.1465],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.043781526386737823
 
[Iteration 5] Process ID: 181441 [Epoch: 13, 13504/ 27057 points] total loss per batch: 2.122
Policy (actual, predicted): 4 4
Policy data: tensor([0.1407, 0.1407, 0.1477, 0.1419, 0.1524, 0.1348, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1230, 0.1549, 0.1552, 0.1327, 0.1829, 0.1137, 0.1376],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9938679933547974
 
[Iteration 5] Process ID: 181441 [Epoch: 13, 20256/ 27057 points] total loss per batch: 2.127
Policy (actual, predicted): 0 4
Policy data: tensor([0.1465, 0.1407, 0.1442, 0.1430, 0.1442, 0.1360, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1407, 0.1470, 0.1409, 0.1401, 0.1511, 0.1369, 0.1433],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.028242750093340874
 
[Iteration 5] Process ID: 181441 [Epoch: 13, 27008/ 27057 points] total loss per batch: 2.132
Policy (actual, predicted): 2 6
Policy data: tensor([0.1419, 0.1419, 0.1500, 0.1383, 0.1477, 0.1325, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1376, 0.1388, 0.1448, 0.1468, 0.1494, 0.1306, 0.1520],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.8877614140510559
 
[Iteration 5] Process ID: 181441 [Epoch: 14,  6752/ 27057 points] total loss per batch: 2.111
Policy (actual, predicted): 2 2
Policy data: tensor([0.1372, 0.1384, 0.1547, 0.1395, 0.1454, 0.1325, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1415, 0.1385, 0.1497, 0.1427, 0.1429, 0.1357, 0.1490],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.011470958590507507
 
[Iteration 5] Process ID: 181441 [Epoch: 14, 13504/ 27057 points] total loss per batch: 2.110
Policy (actual, predicted): 4 4
Policy data: tensor([0.1372, 0.1395, 0.1407, 0.1360, 0.1559, 0.1360, 0.1547],
       device='cuda:0')
Policy pred: tensor([0.1476, 0.1485, 0.1340, 0.1235, 0.1724, 0.1106, 0.1633],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9755093455314636
 
[Iteration 5] Process ID: 181441 [Epoch: 14, 20256/ 27057 points] total loss per batch: 2.123
Policy (actual, predicted): 4 2
Policy data: tensor([0.1395, 0.1407, 0.1419, 0.1454, 0.1512, 0.1348, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1452, 0.1430, 0.1525, 0.1386, 0.1410, 0.1355, 0.1443],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.09583333879709244
 
[Iteration 5] Process ID: 181441 [Epoch: 14, 27008/ 27057 points] total loss per batch: 2.131
Policy (actual, predicted): 6 6
Policy data: tensor([0.1332, 0.1739, 0.0923, 0.1110, 0.2069, 0.0572, 0.2255],
       device='cuda:0')
Policy pred: tensor([0.0827, 0.1372, 0.1164, 0.1121, 0.2342, 0.0533, 0.2641],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999979138374329
 
[Iteration 5] Process ID: 181441 [Epoch: 15,  6752/ 27057 points] total loss per batch: 2.101
Policy (actual, predicted): 6 4
Policy data: tensor([0.1454, 0.1419, 0.1477, 0.1407, 0.1477, 0.1242, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1422, 0.1439, 0.1473, 0.1394, 0.1483, 0.1338, 0.1451],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.25632616877555847
 
[Iteration 5] Process ID: 181441 [Epoch: 15, 13504/ 27057 points] total loss per batch: 2.111
Policy (actual, predicted): 4 0
Policy data: tensor([0.1430, 0.1465, 0.1383, 0.1419, 0.1477, 0.1348, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1609, 0.1258, 0.1434, 0.1266, 0.1523, 0.1384, 0.1526],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.6515666842460632
 
[Iteration 5] Process ID: 181441 [Epoch: 15, 20256/ 27057 points] total loss per batch: 2.110
Policy (actual, predicted): 0 1
Policy data: tensor([0.2844, 0.0459, 0.1565, 0.1967, 0.0000, 0.1341, 0.1824],
       device='cuda:0')
Policy pred: tensor([1.9981e-01, 2.1007e-01, 1.3695e-01, 1.4182e-01, 1.5946e-06, 1.0833e-01,
        2.0303e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 15, 27008/ 27057 points] total loss per batch: 2.123
Policy (actual, predicted): 1 4
Policy data: tensor([0.1377, 0.2131, 0.1150, 0.1505, 0.1956, 0.0239, 0.1643],
       device='cuda:0')
Policy pred: tensor([0.1267, 0.1511, 0.1219, 0.1356, 0.2497, 0.0461, 0.1689],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999861717224121
 
[Iteration 5] Process ID: 181441 [Epoch: 16,  6752/ 27057 points] total loss per batch: 2.104
Policy (actual, predicted): 4 4
Policy data: tensor([0.1929, 0.1768, 0.1129, 0.0938, 0.2292, 0.0706, 0.1237],
       device='cuda:0')
Policy pred: tensor([0.1524, 0.1368, 0.0968, 0.1016, 0.2956, 0.0845, 0.1322],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999783635139465
 
[Iteration 5] Process ID: 181441 [Epoch: 16, 13504/ 27057 points] total loss per batch: 2.106
Policy (actual, predicted): 4 0
Policy data: tensor([0.1454, 0.1419, 0.1407, 0.1419, 0.1477, 0.1360, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1681, 0.1442, 0.1360, 0.1229, 0.1503, 0.1370, 0.1414],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9757751822471619
 
[Iteration 5] Process ID: 181441 [Epoch: 16, 20256/ 27057 points] total loss per batch: 2.119
Policy (actual, predicted): 6 6
Policy data: tensor([0.1776, 0.0000, 0.1776, 0.1558, 0.0000, 0.1558, 0.3332],
       device='cuda:0')
Policy pred: tensor([2.1175e-01, 7.7465e-05, 1.9532e-01, 2.1186e-01, 4.9492e-08, 1.4843e-01,
        2.3256e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 16, 27008/ 27057 points] total loss per batch: 2.106
Policy (actual, predicted): 4 4
Policy data: tensor([0.1419, 0.1442, 0.1383, 0.1383, 0.1489, 0.1430, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1363, 0.1447, 0.1424, 0.1465, 0.1470, 0.1397, 0.1435],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.3781585097312927
 
[Iteration 5] Process ID: 181441 [Epoch: 17,  6752/ 27057 points] total loss per batch: 2.095
Policy (actual, predicted): 6 4
Policy data: tensor([0.0817, 0.0898, 0.1549, 0.0898, 0.2194, 0.0817, 0.2826],
       device='cuda:0')
Policy pred: tensor([0.0998, 0.1370, 0.1230, 0.1333, 0.2275, 0.1008, 0.1785],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9996724128723145
 
[Iteration 5] Process ID: 181441 [Epoch: 17, 13504/ 27057 points] total loss per batch: 2.100
Policy (actual, predicted): 1 1
Policy data: tensor([0.1419, 0.1536, 0.1442, 0.1348, 0.1489, 0.1301, 0.1466],
       device='cuda:0')
Policy pred: tensor([0.1360, 0.1719, 0.1407, 0.1204, 0.1570, 0.1166, 0.1574],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9850070476531982
 
[Iteration 5] Process ID: 181441 [Epoch: 17, 20256/ 27057 points] total loss per batch: 2.108
Policy (actual, predicted): 4 4
Policy data: tensor([0.1419, 0.1442, 0.1372, 0.1395, 0.1524, 0.1360, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1287, 0.1534, 0.1465, 0.1287, 0.1619, 0.1260, 0.1548],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9663118124008179
 
[Iteration 5] Process ID: 181441 [Epoch: 17, 27008/ 27057 points] total loss per batch: 2.114
Policy (actual, predicted): 3 4
Policy data: tensor([0.0496, 0.0000, 0.0694, 0.2983, 0.2777, 0.0817, 0.2233],
       device='cuda:0')
Policy pred: tensor([9.7256e-02, 9.9043e-06, 1.1344e-01, 1.5231e-01, 3.0460e-01, 7.0181e-02,
        2.6221e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 18,  6752/ 27057 points] total loss per batch: 2.088
Policy (actual, predicted): 6 1
Policy data: tensor([0.1407, 0.1430, 0.1383, 0.1465, 0.1454, 0.1383, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1420, 0.1471, 0.1344, 0.1398, 0.1466, 0.1441, 0.1460],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.11552625894546509
 
[Iteration 5] Process ID: 181441 [Epoch: 18, 13504/ 27057 points] total loss per batch: 2.097
Policy (actual, predicted): 6 6
Policy data: tensor([0.1089, 0.1706, 0.1193, 0.0681, 0.2030, 0.0681, 0.2620],
       device='cuda:0')
Policy pred: tensor([0.0946, 0.1492, 0.1104, 0.1153, 0.1993, 0.0783, 0.2530],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999987483024597
 
[Iteration 5] Process ID: 181441 [Epoch: 18, 20256/ 27057 points] total loss per batch: 2.106
Policy (actual, predicted): 4 4
Policy data: tensor([0.1800, 0.1150, 0.1048, 0.0870, 0.2334, 0.1150, 0.1648],
       device='cuda:0')
Policy pred: tensor([0.1212, 0.1609, 0.1091, 0.1189, 0.2226, 0.1014, 0.1659],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9754505157470703
 
[Iteration 5] Process ID: 181441 [Epoch: 18, 27008/ 27057 points] total loss per batch: 2.108
Policy (actual, predicted): 4 1
Policy data: tensor([0.0756, 0.1098, 0.2230, 0.0831, 0.2642, 0.1441, 0.1002],
       device='cuda:0')
Policy pred: tensor([0.1207, 0.2174, 0.1060, 0.1247, 0.2035, 0.0947, 0.1331],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999897480010986
 
[Iteration 5] Process ID: 181441 [Epoch: 19,  6752/ 27057 points] total loss per batch: 2.082
Policy (actual, predicted): 4 4
Policy data: tensor([0.0754, 0.2809, 0.1324, 0.1131, 0.3019, 0.0964, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.1833e-01, 2.3061e-01, 1.5624e-01, 1.5069e-01, 2.3096e-01, 1.1315e-01,
        6.2628e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 19, 13504/ 27057 points] total loss per batch: 2.097
Policy (actual, predicted): 6 4
Policy data: tensor([0.1372, 0.1465, 0.1430, 0.1407, 0.1477, 0.1336, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1392, 0.1400, 0.1418, 0.1353, 0.1578, 0.1365, 0.1494],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9956941604614258
 
[Iteration 5] Process ID: 181441 [Epoch: 19, 20256/ 27057 points] total loss per batch: 2.097
Policy (actual, predicted): 6 3
Policy data: tensor([0.1395, 0.1465, 0.1430, 0.1407, 0.1465, 0.1348, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1363, 0.1369, 0.1328, 0.1613, 0.1426, 0.1399, 0.1502],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9997906684875488
 
[Iteration 5] Process ID: 181441 [Epoch: 19, 27008/ 27057 points] total loss per batch: 2.095
Policy (actual, predicted): 6 0
Policy data: tensor([0.1395, 0.1477, 0.1395, 0.1360, 0.1501, 0.1336, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1547, 0.1488, 0.1358, 0.1420, 0.1400, 0.1357, 0.1429],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9984349608421326
 
[Iteration 5] Process ID: 181441 [Epoch: 20,  6752/ 27057 points] total loss per batch: 2.094
Policy (actual, predicted): 4 4
Policy data: tensor([0.0947, 0.1039, 0.1363, 0.1246, 0.3478, 0.0439, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1045, 0.1371, 0.1035, 0.0936, 0.3148, 0.0920, 0.1545],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999982118606567
 
[Iteration 5] Process ID: 181441 [Epoch: 20, 13504/ 27057 points] total loss per batch: 2.092
Policy (actual, predicted): 0 0
Policy data: tensor([0.5456, 0.0000, 0.0000, 0.2182, 0.0000, 0.2362, 0.0000],
       device='cuda:0')
Policy pred: tensor([4.0748e-01, 3.7849e-08, 1.3917e-04, 3.6042e-01, 8.6625e-05, 2.3187e-01,
        1.9552e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 20, 20256/ 27057 points] total loss per batch: 2.093
Policy (actual, predicted): 6 4
Policy data: tensor([0.1430, 0.1430, 0.1430, 0.1372, 0.1489, 0.1325, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1351, 0.1411, 0.1388, 0.1336, 0.1570, 0.1497, 0.1447],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9981641173362732
 
[Iteration 5] Process ID: 181441 [Epoch: 20, 27008/ 27057 points] total loss per batch: 2.097
Policy (actual, predicted): 4 5
Policy data: tensor([0.1419, 0.1430, 0.1419, 0.1454, 0.1477, 0.1395, 0.1407],
       device='cuda:0')
Policy pred: tensor([0.1557, 0.1380, 0.1449, 0.1416, 0.1257, 0.1578, 0.1363],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.7646028995513916
 
[Iteration 5] Process ID: 181441 [Epoch: 21,  6752/ 27057 points] total loss per batch: 2.084
Policy (actual, predicted): 6 4
Policy data: tensor([0.1129, 0.1672, 0.1432, 0.1042, 0.2100, 0.0000, 0.2625],
       device='cuda:0')
Policy pred: tensor([8.5819e-02, 1.3746e-01, 1.2292e-01, 1.6767e-01, 2.5854e-01, 2.4754e-06,
        2.2758e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999996423721313
 
[Iteration 5] Process ID: 181441 [Epoch: 21, 13504/ 27057 points] total loss per batch: 2.094
Policy (actual, predicted): 6 6
Policy data: tensor([0.1419, 0.1407, 0.1465, 0.1419, 0.1465, 0.1301, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1426, 0.1410, 0.1451, 0.1430, 0.1455, 0.1343, 0.1486],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.004713625181466341
 
[Iteration 5] Process ID: 181441 [Epoch: 21, 20256/ 27057 points] total loss per batch: 2.087
Policy (actual, predicted): 6 6
Policy data: tensor([0.1430, 0.1407, 0.1489, 0.1407, 0.1477, 0.1289, 0.1501],
       device='cuda:0')
Policy pred: tensor([0.1427, 0.1442, 0.1430, 0.1406, 0.1487, 0.1299, 0.1509],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.002837477019056678
 
[Iteration 5] Process ID: 181441 [Epoch: 21, 27008/ 27057 points] total loss per batch: 2.095
Policy (actual, predicted): 2 2
Policy data: tensor([0.1139, 0.1946, 0.2122, 0.1946, 0.1039, 0.0946, 0.0862],
       device='cuda:0')
Policy pred: tensor([0.1429, 0.1644, 0.1853, 0.1607, 0.1617, 0.0973, 0.0877],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9733742475509644
 
[Iteration 5] Process ID: 181441 [Epoch: 22,  6752/ 27057 points] total loss per batch: 2.099
Policy (actual, predicted): 4 4
Policy data: tensor([0.1360, 0.1430, 0.1407, 0.1430, 0.1547, 0.1313, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1385, 0.1442, 0.1491, 0.1347, 0.1643, 0.1216, 0.1475],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9957615733146667
 
[Iteration 5] Process ID: 181441 [Epoch: 22, 13504/ 27057 points] total loss per batch: 2.088
Policy (actual, predicted): 2 2
Policy data: tensor([0.1348, 0.1454, 0.1524, 0.1419, 0.1454, 0.1325, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1432, 0.1414, 0.1516, 0.1381, 0.1434, 0.1390, 0.1433],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.984771192073822
 
[Iteration 5] Process ID: 181441 [Epoch: 22, 20256/ 27057 points] total loss per batch: 2.079
Policy (actual, predicted): 4 6
Policy data: tensor([0.1383, 0.1454, 0.1407, 0.1430, 0.1500, 0.1395, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1365, 0.1444, 0.1388, 0.1400, 0.1474, 0.1433, 0.1495],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.39516663551330566
 
[Iteration 5] Process ID: 181441 [Epoch: 22, 27008/ 27057 points] total loss per batch: 2.104
Policy (actual, predicted): 4 6
Policy data: tensor([0.1348, 0.1454, 0.1384, 0.1431, 0.1559, 0.1266, 0.1559],
       device='cuda:0')
Policy pred: tensor([0.1397, 0.1585, 0.1432, 0.1329, 0.1445, 0.1129, 0.1682],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9992940425872803
 
[Iteration 5] Process ID: 181441 [Epoch: 23,  6752/ 27057 points] total loss per batch: 2.083
Policy (actual, predicted): 6 0
Policy data: tensor([0.1522, 0.1817, 0.1522, 0.0964, 0.1392, 0.0798, 0.1983],
       device='cuda:0')
Policy pred: tensor([0.1860, 0.1289, 0.1494, 0.1108, 0.1702, 0.0838, 0.1709],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 23, 13504/ 27057 points] total loss per batch: 2.088
Policy (actual, predicted): 6 4
Policy data: tensor([0.1395, 0.1430, 0.1501, 0.1430, 0.1430, 0.1301, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1360, 0.1601, 0.1240, 0.1315, 0.1795, 0.1177, 0.1512],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9937395453453064
 
[Iteration 5] Process ID: 181441 [Epoch: 23, 20256/ 27057 points] total loss per batch: 2.083
Policy (actual, predicted): 6 4
Policy data: tensor([0.1407, 0.1419, 0.1372, 0.1395, 0.1500, 0.1383, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1469, 0.1339, 0.1404, 0.1431, 0.1508, 0.1404, 0.1444],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.7404539585113525
 
[Iteration 5] Process ID: 181441 [Epoch: 23, 27008/ 27057 points] total loss per batch: 2.091
Policy (actual, predicted): 4 4
Policy data: tensor([0.1419, 0.1454, 0.1372, 0.1419, 0.1512, 0.1372, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1480, 0.1474, 0.1372, 0.1424, 0.1594, 0.1224, 0.1432],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9993336200714111
 
[Iteration 5] Process ID: 181441 [Epoch: 24,  6752/ 27057 points] total loss per batch: 2.085
Policy (actual, predicted): 6 4
Policy data: tensor([0.1254, 0.1997, 0.1357, 0.0000, 0.1714, 0.1357, 0.2321],
       device='cuda:0')
Policy pred: tensor([1.4820e-01, 2.1906e-01, 1.1210e-01, 1.3854e-04, 2.2696e-01, 1.3150e-01,
        1.6204e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 24, 13504/ 27057 points] total loss per batch: 2.080
Policy (actual, predicted): 2 1
Policy data: tensor([0.1484, 0.3065, 0.4120, 0.1332, 0.0000, 0.0000, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.5685e-01, 3.6009e-01, 3.0542e-01, 1.7763e-01, 7.1247e-08, 3.3331e-06,
        5.3222e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 24, 20256/ 27057 points] total loss per batch: 2.091
Policy (actual, predicted): 1 4
Policy data: tensor([0.1913, 0.2273, 0.0930, 0.0700, 0.1913, 0.0930, 0.1342],
       device='cuda:0')
Policy pred: tensor([0.1687, 0.1955, 0.1107, 0.1075, 0.2002, 0.0628, 0.1546],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999312162399292
 
[Iteration 5] Process ID: 181441 [Epoch: 24, 27008/ 27057 points] total loss per batch: 2.082
Policy (actual, predicted): 4 4
Policy data: tensor([0.1442, 0.1419, 0.1442, 0.1442, 0.1454, 0.1383, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1419, 0.1420, 0.1436, 0.1388, 0.1530, 0.1349, 0.1458],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.0492788664996624
 
[Iteration 5] Process ID: 181441 [Epoch: 25,  6752/ 27057 points] total loss per batch: 2.067
Policy (actual, predicted): 4 6
Policy data: tensor([0.1754, 0.0847, 0.1120, 0.1469, 0.2087, 0.0636, 0.2087],
       device='cuda:0')
Policy pred: tensor([0.1171, 0.1452, 0.1542, 0.1088, 0.1980, 0.0619, 0.2148],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 25, 13504/ 27057 points] total loss per batch: 2.085
Policy (actual, predicted): 2 6
Policy data: tensor([0.1395, 0.1442, 0.1500, 0.1407, 0.1430, 0.1348, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1397, 0.1445, 0.1446, 0.1345, 0.1477, 0.1389, 0.1502],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.5967288017272949
 
[Iteration 5] Process ID: 181441 [Epoch: 25, 20256/ 27057 points] total loss per batch: 2.084
Policy (actual, predicted): 6 4
Policy data: tensor([0.1419, 0.1407, 0.1419, 0.1407, 0.1454, 0.1430, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1430, 0.1372, 0.1353, 0.1451, 0.1545, 0.1372, 0.1477],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.3736414909362793
 
[Iteration 5] Process ID: 181441 [Epoch: 25, 27008/ 27057 points] total loss per batch: 2.087
Policy (actual, predicted): 6 6
Policy data: tensor([0.1906, 0.2009, 0.1808, 0.0000, 0.0000, 0.0000, 0.4278],
       device='cuda:0')
Policy pred: tensor([1.8393e-01, 1.8643e-01, 2.1427e-01, 3.4775e-06, 2.3692e-08, 1.9007e-06,
        4.1537e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999992847442627
 
[Iteration 5] Process ID: 181441 [Epoch: 26,  6752/ 27057 points] total loss per batch: 2.078
Policy (actual, predicted): 4 4
Policy data: tensor([0.1407, 0.1419, 0.1454, 0.1407, 0.1500, 0.1336, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1431, 0.1408, 0.1472, 0.1429, 0.1477, 0.1319, 0.1464],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.011862958781421185
 
[Iteration 5] Process ID: 181441 [Epoch: 26, 13504/ 27057 points] total loss per batch: 2.074
Policy (actual, predicted): 0 0
Policy data: tensor([0.2663, 0.1734, 0.1213, 0.0920, 0.1734, 0.0629, 0.1107],
       device='cuda:0')
Policy pred: tensor([0.2030, 0.1613, 0.1441, 0.0830, 0.1945, 0.0835, 0.1307],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 26, 20256/ 27057 points] total loss per batch: 2.081
Policy (actual, predicted): 4 4
Policy data: tensor([0.1419, 0.1465, 0.1442, 0.1360, 0.1500, 0.1383, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1337, 0.1361, 0.1399, 0.1455, 0.1531, 0.1408, 0.1509],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.2654969394207001
 
[Iteration 5] Process ID: 181441 [Epoch: 26, 27008/ 27057 points] total loss per batch: 2.080
Policy (actual, predicted): 6 2
Policy data: tensor([0.1313, 0.1395, 0.1465, 0.1442, 0.1477, 0.1383, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1235, 0.1578, 0.1673, 0.1313, 0.1286, 0.1350, 0.1566],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9961387515068054
 
[Iteration 5] Process ID: 181441 [Epoch: 27,  6752/ 27057 points] total loss per batch: 2.066
Policy (actual, predicted): 3 6
Policy data: tensor([0.1419, 0.1477, 0.1383, 0.1489, 0.1466, 0.1289, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1217, 0.1567, 0.1480, 0.1523, 0.1557, 0.0963, 0.1692],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999991238117218
 
[Iteration 5] Process ID: 181441 [Epoch: 27, 13504/ 27057 points] total loss per batch: 2.086
Policy (actual, predicted): 0 4
Policy data: tensor([0.1477, 0.1454, 0.1395, 0.1372, 0.1477, 0.1348, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1490, 0.1684, 0.1074, 0.1353, 0.1947, 0.1068, 0.1384],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9786554574966431
 
[Iteration 5] Process ID: 181441 [Epoch: 27, 20256/ 27057 points] total loss per batch: 2.080
Policy (actual, predicted): 4 4
Policy data: tensor([0.0687, 0.1906, 0.0746, 0.0000, 0.3172, 0.0535, 0.2954],
       device='cuda:0')
Policy pred: tensor([7.0066e-02, 2.3319e-01, 1.0860e-01, 5.6568e-09, 2.8096e-01, 3.7819e-02,
        2.6936e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 27, 27008/ 27057 points] total loss per batch: 2.077
Policy (actual, predicted): 4 4
Policy data: tensor([0.1489, 0.1442, 0.1383, 0.1395, 0.1512, 0.1372, 0.1407],
       device='cuda:0')
Policy pred: tensor([0.1411, 0.1454, 0.1394, 0.1385, 0.1499, 0.1399, 0.1457],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.026520289480686188
 
[Iteration 5] Process ID: 181441 [Epoch: 28,  6752/ 27057 points] total loss per batch: 2.065
Policy (actual, predicted): 4 4
Policy data: tensor([0.1360, 0.1407, 0.1442, 0.1430, 0.1570, 0.1360, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1295, 0.1304, 0.1225, 0.1486, 0.2066, 0.1192, 0.1431],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999918341636658
 
[Iteration 5] Process ID: 181441 [Epoch: 28, 13504/ 27057 points] total loss per batch: 2.080
Policy (actual, predicted): 4 4
Policy data: tensor([0.1442, 0.1419, 0.1395, 0.1454, 0.1477, 0.1348, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1249, 0.1447, 0.1738, 0.1217, 0.1769, 0.0965, 0.1614],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999595880508423
 
[Iteration 5] Process ID: 181441 [Epoch: 28, 20256/ 27057 points] total loss per batch: 2.079
Policy (actual, predicted): 6 4
Policy data: tensor([0.1310, 0.1310, 0.1310, 0.1434, 0.1569, 0.1196, 0.1872],
       device='cuda:0')
Policy pred: tensor([0.1215, 0.1731, 0.1334, 0.1268, 0.1815, 0.1052, 0.1585],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 28, 27008/ 27057 points] total loss per batch: 2.079
Policy (actual, predicted): 6 6
Policy data: tensor([0.1407, 0.1430, 0.1477, 0.1395, 0.1465, 0.1336, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1422, 0.1414, 0.1435, 0.1418, 0.1445, 0.1367, 0.1498],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.024331681430339813
 
[Iteration 5] Process ID: 181441 [Epoch: 29,  6752/ 27057 points] total loss per batch: 2.081
Policy (actual, predicted): 1 1
Policy data: tensor([0.1372, 0.1489, 0.1442, 0.1372, 0.1489, 0.1372, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1453, 0.1481, 0.1436, 0.1333, 0.1448, 0.1393, 0.1456],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9962583184242249
 
[Iteration 5] Process ID: 181441 [Epoch: 29, 13504/ 27057 points] total loss per batch: 2.068
Policy (actual, predicted): 0 0
Policy data: tensor([0.1512, 0.1430, 0.1383, 0.1395, 0.1465, 0.1395, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1528, 0.1487, 0.1325, 0.1390, 0.1389, 0.1451, 0.1430],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9966755509376526
 
[Iteration 5] Process ID: 181441 [Epoch: 29, 20256/ 27057 points] total loss per batch: 2.080
Policy (actual, predicted): 1 1
Policy data: tensor([0.1024, 0.2279, 0.1024, 0.1122, 0.2092, 0.0702, 0.1758],
       device='cuda:0')
Policy pred: tensor([0.0853, 0.2724, 0.1391, 0.0955, 0.1590, 0.0877, 0.1610],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 29, 27008/ 27057 points] total loss per batch: 2.074
Policy (actual, predicted): 4 4
Policy data: tensor([0.1325, 0.1454, 0.1430, 0.1430, 0.1547, 0.1383, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1403, 0.1491, 0.1340, 0.1419, 0.1571, 0.1318, 0.1457],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.3740514814853668
 
[Iteration 5] Process ID: 181441 [Epoch: 30,  6752/ 27057 points] total loss per batch: 2.063
Policy (actual, predicted): 4 4
Policy data: tensor([0.1348, 0.1442, 0.1430, 0.1430, 0.1489, 0.1407, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1408, 0.1422, 0.1430, 0.1436, 0.1486, 0.1368, 0.1450],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.08333051949739456
 
[Iteration 5] Process ID: 181441 [Epoch: 30, 13504/ 27057 points] total loss per batch: 2.066
Policy (actual, predicted): 4 4
Policy data: tensor([0.1430, 0.1407, 0.1360, 0.1407, 0.1547, 0.1419, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1362, 0.1295, 0.1504, 0.1404, 0.1656, 0.1390, 0.1389],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9560375213623047
 
[Iteration 5] Process ID: 181441 [Epoch: 30, 20256/ 27057 points] total loss per batch: 2.075
Policy (actual, predicted): 6 2
Policy data: tensor([0.1454, 0.1407, 0.1465, 0.1395, 0.1395, 0.1395, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1368, 0.1372, 0.1573, 0.1379, 0.1441, 0.1329, 0.1538],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.07737305015325546
 
[Iteration 5] Process ID: 181441 [Epoch: 30, 27008/ 27057 points] total loss per batch: 2.076
Policy (actual, predicted): 4 4
Policy data: tensor([0.1360, 0.1419, 0.1383, 0.1454, 0.1512, 0.1395, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1413, 0.1457, 0.1411, 0.1435, 0.1487, 0.1359, 0.1437],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.029857242479920387
 
[Iteration 5] Process ID: 181441 [Epoch: 31,  6752/ 27057 points] total loss per batch: 2.067
Policy (actual, predicted): 1 6
Policy data: tensor([0.1393, 0.1984, 0.0965, 0.1523, 0.1272, 0.0878, 0.1984],
       device='cuda:0')
Policy pred: tensor([0.1432, 0.1346, 0.1049, 0.1282, 0.1858, 0.0742, 0.2291],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9995368719100952
 
[Iteration 5] Process ID: 181441 [Epoch: 31, 13504/ 27057 points] total loss per batch: 2.065
Policy (actual, predicted): 6 4
Policy data: tensor([0.0949, 0.0000, 0.1303, 0.1303, 0.2389, 0.0629, 0.3428],
       device='cuda:0')
Policy pred: tensor([1.3756e-01, 1.5574e-08, 1.1019e-01, 1.3552e-01, 2.7305e-01, 8.1718e-02,
        2.6195e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 31, 20256/ 27057 points] total loss per batch: 2.078
Policy (actual, predicted): 1 1
Policy data: tensor([0.1379, 0.2542, 0.1048, 0.1379, 0.1048, 0.0955, 0.1648],
       device='cuda:0')
Policy pred: tensor([0.0988, 0.1985, 0.1395, 0.1527, 0.1084, 0.1397, 0.1624],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 5] Process ID: 181441 [Epoch: 31, 27008/ 27057 points] total loss per batch: 2.077
Policy (actual, predicted): 6 4
Policy data: tensor([0.1325, 0.1454, 0.1501, 0.1395, 0.1477, 0.1313, 0.1536],
       device='cuda:0')
Policy pred: tensor([0.1387, 0.1428, 0.1409, 0.1434, 0.1525, 0.1336, 0.1481],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.2107921540737152
 
[Iteration 5] Process ID: 181441 [Epoch: 32,  6752/ 27057 points] total loss per batch: 2.068
Policy (actual, predicted): 6 6
Policy data: tensor([0.1395, 0.1465, 0.1430, 0.1407, 0.1465, 0.1348, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1434, 0.1435, 0.1418, 0.1424, 0.1449, 0.1329, 0.1511],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 5] Process ID: 181441 [Epoch: 32, 13504/ 27057 points] total loss per batch: 2.076
Policy (actual, predicted): 6 6
Policy data: tensor([0.1477, 0.1395, 0.1442, 0.1407, 0.1489, 0.1289, 0.1501],
       device='cuda:0')
Policy pred: tensor([0.1416, 0.1407, 0.1472, 0.1407, 0.1473, 0.1330, 0.1495],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.02144252508878708
 
[Iteration 5] Process ID: 181441 [Epoch: 32, 20256/ 27057 points] total loss per batch: 2.072
Policy (actual, predicted): 5 1
Policy data: tensor([0.1826, 0.1691, 0.0896, 0.1339, 0.0000, 0.2124, 0.2124],
       device='cuda:0')
Policy pred: tensor([1.7960e-01, 2.0487e-01, 1.3885e-01, 1.2272e-01, 3.2510e-05, 1.8287e-01,
        1.7106e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 32, 27008/ 27057 points] total loss per batch: 2.070
Policy (actual, predicted): 4 4
Policy data: tensor([0.1509, 0.1965, 0.1049, 0.0956, 0.2143, 0.0870, 0.1509],
       device='cuda:0')
Policy pred: tensor([0.1283, 0.1435, 0.1117, 0.0929, 0.2856, 0.1025, 0.1355],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 33,  6752/ 27057 points] total loss per batch: 2.055
Policy (actual, predicted): 4 4
Policy data: tensor([0.1407, 0.1442, 0.1395, 0.1442, 0.1454, 0.1419, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1423, 0.1430, 0.1440, 0.1442, 0.1443, 0.1403, 0.1420],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.09548082947731018
 
[Iteration 5] Process ID: 181441 [Epoch: 33, 13504/ 27057 points] total loss per batch: 2.063
Policy (actual, predicted): 6 6
Policy data: tensor([0.1052, 0.1152, 0.1261, 0.1380, 0.1508, 0.0402, 0.3245],
       device='cuda:0')
Policy pred: tensor([0.0834, 0.1340, 0.1036, 0.1687, 0.1588, 0.0630, 0.2885],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 33, 20256/ 27057 points] total loss per batch: 2.078
Policy (actual, predicted): 6 6
Policy data: tensor([0.1430, 0.1383, 0.1466, 0.1419, 0.1489, 0.1301, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1400, 0.1443, 0.1425, 0.1399, 0.1494, 0.1304, 0.1536],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.012395850382745266
 
[Iteration 5] Process ID: 181441 [Epoch: 33, 27008/ 27057 points] total loss per batch: 2.075
Policy (actual, predicted): 4 1
Policy data: tensor([0.1407, 0.1442, 0.1383, 0.1372, 0.1524, 0.1372, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1442, 0.1497, 0.1446, 0.1472, 0.1429, 0.1284, 0.1430],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999995231628418
 
[Iteration 5] Process ID: 181441 [Epoch: 34,  6752/ 27057 points] total loss per batch: 2.058
Policy (actual, predicted): 4 4
Policy data: tensor([0.1380, 0.1798, 0.0658, 0.0960, 0.2752, 0.0491, 0.1961],
       device='cuda:0')
Policy pred: tensor([0.1026, 0.1458, 0.1061, 0.1086, 0.2381, 0.0742, 0.2246],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999911785125732
 
[Iteration 5] Process ID: 181441 [Epoch: 34, 13504/ 27057 points] total loss per batch: 2.069
Policy (actual, predicted): 6 6
Policy data: tensor([0.1431, 0.1431, 0.1372, 0.1372, 0.1501, 0.1277, 0.1617],
       device='cuda:0')
Policy pred: tensor([0.1294, 0.1600, 0.1316, 0.1318, 0.1560, 0.1111, 0.1801],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999879002571106
 
[Iteration 5] Process ID: 181441 [Epoch: 34, 20256/ 27057 points] total loss per batch: 2.070
Policy (actual, predicted): 2 4
Policy data: tensor([0.1465, 0.1407, 0.1489, 0.1383, 0.1477, 0.1325, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1406, 0.1419, 0.1428, 0.1379, 0.1511, 0.1351, 0.1506],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.11070920526981354
 
[Iteration 5] Process ID: 181441 [Epoch: 34, 27008/ 27057 points] total loss per batch: 2.066
Policy (actual, predicted): 0 0
Policy data: tensor([0.4106, 0.0000, 0.1174, 0.0000, 0.2866, 0.0679, 0.1174],
       device='cuda:0')
Policy pred: tensor([2.7037e-01, 3.9575e-06, 1.5295e-01, 3.8115e-06, 2.5462e-01, 1.2184e-01,
        2.0021e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 35,  6752/ 27057 points] total loss per batch: 2.061
Policy (actual, predicted): 4 6
Policy data: tensor([0.1430, 0.1383, 0.1489, 0.1430, 0.1501, 0.1289, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1410, 0.1406, 0.1460, 0.1416, 0.1486, 0.1315, 0.1506],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.31053483486175537
 
[Iteration 5] Process ID: 181441 [Epoch: 35, 13504/ 27057 points] total loss per batch: 2.062
Policy (actual, predicted): 6 6
Policy data: tensor([0.1383, 0.1430, 0.1419, 0.1372, 0.1500, 0.1383, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1216, 0.1493, 0.1301, 0.1496, 0.1464, 0.1433, 0.1597],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999535322189331
 
[Iteration 5] Process ID: 181441 [Epoch: 35, 20256/ 27057 points] total loss per batch: 2.068
Policy (actual, predicted): 3 4
Policy data: tensor([0.1372, 0.1395, 0.1407, 0.1512, 0.1465, 0.1383, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1422, 0.1443, 0.1422, 0.1446, 0.1460, 0.1368, 0.1438],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.13756002485752106
 
[Iteration 5] Process ID: 181441 [Epoch: 35, 27008/ 27057 points] total loss per batch: 2.076
Policy (actual, predicted): 4 4
Policy data: tensor([0.1347, 0.1347, 0.1611, 0.1123, 0.2702, 0.0638, 0.1231],
       device='cuda:0')
Policy pred: tensor([0.1258, 0.1444, 0.1250, 0.1331, 0.2279, 0.1054, 0.1385],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999997019767761
 
[Iteration 5] Process ID: 181441 [Epoch: 36,  6752/ 27057 points] total loss per batch: 2.064
Policy (actual, predicted): 6 0
Policy data: tensor([0.1407, 0.1419, 0.1442, 0.1407, 0.1430, 0.1395, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1505, 0.1378, 0.1422, 0.1421, 0.1404, 0.1477, 0.1393],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 5] Process ID: 181441 [Epoch: 36, 13504/ 27057 points] total loss per batch: 2.067
Policy (actual, predicted): 2 6
Policy data: tensor([0.1360, 0.1430, 0.1536, 0.1360, 0.1466, 0.1325, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1392, 0.1451, 0.1427, 0.1402, 0.1501, 0.1324, 0.1503],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.26382872462272644
 
[Iteration 5] Process ID: 181441 [Epoch: 36, 20256/ 27057 points] total loss per batch: 2.060
Policy (actual, predicted): 4 4
Policy data: tensor([0.1372, 0.1454, 0.1442, 0.1395, 0.1524, 0.1395, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1455, 0.1423, 0.1347, 0.1402, 0.1508, 0.1444, 0.1420],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999677538871765
 
[Iteration 5] Process ID: 181441 [Epoch: 36, 27008/ 27057 points] total loss per batch: 2.072
Policy (actual, predicted): 6 6
Policy data: tensor([0.1135, 0.1813, 0.1330, 0.1330, 0.0000, 0.1555, 0.2838],
       device='cuda:0')
Policy pred: tensor([1.4398e-01, 1.8519e-01, 1.0865e-01, 1.2874e-01, 3.2238e-07, 1.0242e-01,
        3.3103e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 37,  6752/ 27057 points] total loss per batch: 2.067
Policy (actual, predicted): 6 6
Policy data: tensor([0.1045, 0.1253, 0.0953, 0.0719, 0.1371, 0.0868, 0.3792],
       device='cuda:0')
Policy pred: tensor([0.0861, 0.1288, 0.1058, 0.0952, 0.1527, 0.0613, 0.3701],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 37, 13504/ 27057 points] total loss per batch: 2.064
Policy (actual, predicted): 4 4
Policy data: tensor([0.0629, 0.1735, 0.0838, 0.0921, 0.2249, 0.1893, 0.1735],
       device='cuda:0')
Policy pred: tensor([0.0867, 0.1656, 0.0935, 0.1127, 0.2368, 0.1284, 0.1764],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 5] Process ID: 181441 [Epoch: 37, 20256/ 27057 points] total loss per batch: 2.064
Policy (actual, predicted): 4 4
Policy data: tensor([0.1336, 0.1442, 0.1407, 0.1430, 0.1512, 0.1407, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1361, 0.1472, 0.1403, 0.1401, 0.1496, 0.1420, 0.1447],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.681118905544281
 
[Iteration 5] Process ID: 181441 [Epoch: 37, 27008/ 27057 points] total loss per batch: 2.064
Policy (actual, predicted): 6 6
Policy data: tensor([0.1454, 0.1383, 0.1489, 0.1407, 0.1454, 0.1289, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1445, 0.1415, 0.1467, 0.1395, 0.1456, 0.1311, 0.1511],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.013238039799034595
 
[Iteration 5] Process ID: 181441 [Epoch: 38,  6752/ 27057 points] total loss per batch: 2.072
Policy (actual, predicted): 2 2
Policy data: tensor([0.0762, 0.1209, 0.3965, 0.1445, 0.0837, 0.0572, 0.1209],
       device='cuda:0')
Policy pred: tensor([0.1056, 0.1775, 0.2540, 0.1274, 0.1193, 0.0742, 0.1420],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 38, 13504/ 27057 points] total loss per batch: 2.051
Policy (actual, predicted): 4 4
Policy data: tensor([0.0952, 0.1794, 0.1374, 0.1045, 0.2326, 0.0867, 0.1643],
       device='cuda:0')
Policy pred: tensor([0.1269, 0.1526, 0.1440, 0.1021, 0.2318, 0.0946, 0.1480],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 38, 20256/ 27057 points] total loss per batch: 2.064
Policy (actual, predicted): 4 4
Policy data: tensor([0.1407, 0.1430, 0.1360, 0.1383, 0.1500, 0.1419, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1307, 0.1371, 0.1385, 0.1432, 0.1583, 0.1446, 0.1476],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.999993622303009
 
[Iteration 5] Process ID: 181441 [Epoch: 38, 27008/ 27057 points] total loss per batch: 2.059
Policy (actual, predicted): 4 4
Policy data: tensor([0.0931, 0.1732, 0.1378, 0.1866, 0.3833, 0.0259, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.5981e-01, 1.5267e-01, 1.0048e-01, 1.7740e-01, 3.7415e-01, 3.5488e-02,
        2.2155e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 39,  6752/ 27057 points] total loss per batch: 2.053
Policy (actual, predicted): 4 4
Policy data: tensor([0.1731, 0.1008, 0.0919, 0.0761, 0.2891, 0.1585, 0.1105],
       device='cuda:0')
Policy pred: tensor([0.1611, 0.1434, 0.1280, 0.0991, 0.2068, 0.1353, 0.1264],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998211860657
 
[Iteration 5] Process ID: 181441 [Epoch: 39, 13504/ 27057 points] total loss per batch: 2.059
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1407, 0.1442, 0.1419, 0.1500, 0.1348, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1380, 0.1422, 0.1409, 0.1468, 0.1520, 0.1304, 0.1497],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.6619851589202881
 
[Iteration 5] Process ID: 181441 [Epoch: 39, 20256/ 27057 points] total loss per batch: 2.072
Policy (actual, predicted): 4 4
Policy data: tensor([0.1157, 0.1708, 0.1354, 0.2307, 0.2874, 0.0600, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.3822e-01, 1.7340e-01, 1.1911e-01, 2.4336e-01, 2.5761e-01, 6.8311e-02,
        1.4923e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 39, 27008/ 27057 points] total loss per batch: 2.062
Policy (actual, predicted): 2 2
Policy data: tensor([0.1407, 0.1430, 0.1512, 0.1383, 0.1477, 0.1313, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1428, 0.1390, 0.1482, 0.1414, 0.1479, 0.1329, 0.1478],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.09322190284729004
 
[Iteration 5] Process ID: 181441 [Epoch: 40,  6752/ 27057 points] total loss per batch: 2.059
Policy (actual, predicted): 4 4
Policy data: tensor([0.1678, 0.1067, 0.1067, 0.1535, 0.2181, 0.1404, 0.1067],
       device='cuda:0')
Policy pred: tensor([0.1597, 0.1313, 0.1149, 0.1173, 0.2407, 0.1224, 0.1137],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999878406524658
 
[Iteration 5] Process ID: 181441 [Epoch: 40, 13504/ 27057 points] total loss per batch: 2.070
Policy (actual, predicted): 6 6
Policy data: tensor([0.1361, 0.2003, 0.1361, 0.1856, 0.0000, 0.1258, 0.2160],
       device='cuda:0')
Policy pred: tensor([1.3203e-01, 2.0456e-01, 1.5673e-01, 1.8877e-01, 1.8422e-05, 1.0477e-01,
        2.1312e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 40, 20256/ 27057 points] total loss per batch: 2.065
Policy (actual, predicted): 6 6
Policy data: tensor([0.1395, 0.1454, 0.1419, 0.1383, 0.1477, 0.1360, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1398, 0.1437, 0.1416, 0.1382, 0.1486, 0.1371, 0.1510],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.24129585921764374
 
[Iteration 5] Process ID: 181441 [Epoch: 40, 27008/ 27057 points] total loss per batch: 2.056
Policy (actual, predicted): 6 6
Policy data: tensor([0.1292, 0.1134, 0.0811, 0.0000, 0.0000, 0.0616, 0.6148],
       device='cuda:0')
Policy pred: tensor([9.0016e-02, 1.7099e-01, 1.1109e-01, 5.5418e-07, 1.6979e-08, 6.8940e-02,
        5.5897e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 41,  6752/ 27057 points] total loss per batch: 2.050
Policy (actual, predicted): 2 6
Policy data: tensor([0.0830, 0.1316, 0.2228, 0.2045, 0.0912, 0.0623, 0.2045],
       device='cuda:0')
Policy pred: tensor([0.0659, 0.1522, 0.1477, 0.1745, 0.1745, 0.0629, 0.2222],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 41, 13504/ 27057 points] total loss per batch: 2.064
Policy (actual, predicted): 6 4
Policy data: tensor([0.1284, 0.1535, 0.0810, 0.0890, 0.1830, 0.0608, 0.3043],
       device='cuda:0')
Policy pred: tensor([0.1147, 0.1409, 0.0916, 0.1287, 0.2724, 0.0422, 0.2094],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 41, 20256/ 27057 points] total loss per batch: 2.056
Policy (actual, predicted): 2 2
Policy data: tensor([0.4154, 0.0000, 0.4815, 0.0000, 0.0000, 0.1031, 0.0000],
       device='cuda:0')
Policy pred: tensor([3.2065e-01, 1.2917e-08, 4.6614e-01, 6.2669e-07, 3.8421e-05, 2.1296e-01,
        2.1380e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 41, 27008/ 27057 points] total loss per batch: 2.066
Policy (actual, predicted): 4 4
Policy data: tensor([0.1372, 0.1407, 0.1383, 0.1442, 0.1500, 0.1454, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1428, 0.1437, 0.1400, 0.1427, 0.1444, 0.1439, 0.1425],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.21523936092853546
 
[Iteration 5] Process ID: 181441 [Epoch: 42,  6752/ 27057 points] total loss per batch: 2.055
Policy (actual, predicted): 4 2
Policy data: tensor([0.1372, 0.1465, 0.1419, 0.1442, 0.1477, 0.1372, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1368, 0.1390, 0.1502, 0.1484, 0.1451, 0.1436, 0.1369],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.05278073251247406
 
[Iteration 5] Process ID: 181441 [Epoch: 42, 13504/ 27057 points] total loss per batch: 2.055
Policy (actual, predicted): 6 6
Policy data: tensor([0.1053, 0.1384, 0.1154, 0.1808, 0.1384, 0.0873, 0.2344],
       device='cuda:0')
Policy pred: tensor([0.1233, 0.1485, 0.1238, 0.1358, 0.1647, 0.0820, 0.2219],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 42, 20256/ 27057 points] total loss per batch: 2.063
Policy (actual, predicted): 3 3
Policy data: tensor([0.1430, 0.1383, 0.1360, 0.1512, 0.1407, 0.1419, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1512, 0.1404, 0.1361, 0.1602, 0.1378, 0.1286, 0.1457],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 42, 27008/ 27057 points] total loss per batch: 2.062
Policy (actual, predicted): 4 4
Policy data: tensor([0.1717, 0.1589, 0.1359, 0.1470, 0.2504, 0.1359, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.3919e-01, 1.6789e-01, 1.4363e-01, 1.9673e-01, 2.7272e-01, 7.9815e-02,
        2.7286e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 43,  6752/ 27057 points] total loss per batch: 2.059
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1430, 0.1454, 0.1407, 0.1500, 0.1325, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1407, 0.1437, 0.1483, 0.1372, 0.1494, 0.1313, 0.1493],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.015510143712162971
 
[Iteration 5] Process ID: 181441 [Epoch: 43, 13504/ 27057 points] total loss per batch: 2.065
Policy (actual, predicted): 6 6
Policy data: tensor([0.1348, 0.1466, 0.1384, 0.1395, 0.1536, 0.1301, 0.1570],
       device='cuda:0')
Policy pred: tensor([0.1464, 0.1669, 0.1174, 0.1514, 0.1406, 0.1081, 0.1692],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 43, 20256/ 27057 points] total loss per batch: 2.062
Policy (actual, predicted): 2 4
Policy data: tensor([0.1395, 0.1442, 0.1454, 0.1454, 0.1454, 0.1383, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1443, 0.1432, 0.1406, 0.1435, 0.1463, 0.1397, 0.1425],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.08365688472986221
 
[Iteration 5] Process ID: 181441 [Epoch: 43, 27008/ 27057 points] total loss per batch: 2.057
Policy (actual, predicted): 4 6
Policy data: tensor([0.1477, 0.1442, 0.1395, 0.1360, 0.1489, 0.1383, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1436, 0.1389, 0.1461, 0.1387, 0.1475, 0.1367, 0.1485],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.7496169805526733
 
[Iteration 5] Process ID: 181441 [Epoch: 44,  6752/ 27057 points] total loss per batch: 2.047
Policy (actual, predicted): 4 0
Policy data: tensor([0.1442, 0.1465, 0.1372, 0.1465, 0.1500, 0.1348, 0.1407],
       device='cuda:0')
Policy pred: tensor([0.1569, 0.1373, 0.1290, 0.1421, 0.1545, 0.1331, 0.1471],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9983815550804138
 
[Iteration 5] Process ID: 181441 [Epoch: 44, 13504/ 27057 points] total loss per batch: 2.065
Policy (actual, predicted): 6 6
Policy data: tensor([0.1430, 0.1395, 0.1454, 0.1383, 0.1489, 0.1336, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1449, 0.1409, 0.1467, 0.1402, 0.1456, 0.1304, 0.1513],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.006768181920051575
 
[Iteration 5] Process ID: 181441 [Epoch: 44, 20256/ 27057 points] total loss per batch: 2.055
Policy (actual, predicted): 4 4
Policy data: tensor([0.0708, 0.1935, 0.1358, 0.1624, 0.2110, 0.0779, 0.1486],
       device='cuda:0')
Policy pred: tensor([0.1023, 0.1595, 0.1300, 0.1342, 0.2245, 0.0947, 0.1548],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 44, 27008/ 27057 points] total loss per batch: 2.066
Policy (actual, predicted): 2 2
Policy data: tensor([0.1211, 0.1731, 0.2659, 0.0919, 0.1585, 0.0569, 0.1326],
       device='cuda:0')
Policy pred: tensor([0.1085, 0.1605, 0.2188, 0.0924, 0.1809, 0.0849, 0.1541],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 45,  6752/ 27057 points] total loss per batch: 2.047
Policy (actual, predicted): 6 6
Policy data: tensor([0.1442, 0.1430, 0.1477, 0.1383, 0.1454, 0.1313, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1431, 0.1412, 0.1455, 0.1414, 0.1480, 0.1300, 0.1509],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.0030030563939362764
 
[Iteration 5] Process ID: 181441 [Epoch: 45, 13504/ 27057 points] total loss per batch: 2.056
Policy (actual, predicted): 4 4
Policy data: tensor([0.1360, 0.1360, 0.1034, 0.1360, 0.2303, 0.0644, 0.1938],
       device='cuda:0')
Policy pred: tensor([0.1392, 0.1375, 0.1200, 0.1340, 0.2078, 0.0982, 0.1632],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998489022254944
 
[Iteration 5] Process ID: 181441 [Epoch: 45, 20256/ 27057 points] total loss per batch: 2.061
Policy (actual, predicted): 1 1
Policy data: tensor([0.0692, 0.2446, 0.1212, 0.1106, 0.1891, 0.0761, 0.1891],
       device='cuda:0')
Policy pred: tensor([0.0892, 0.2208, 0.1185, 0.1311, 0.1746, 0.0781, 0.1878],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 45, 27008/ 27057 points] total loss per batch: 2.057
Policy (actual, predicted): 6 6
Policy data: tensor([0.1512, 0.1407, 0.1348, 0.1360, 0.1489, 0.1336, 0.1547],
       device='cuda:0')
Policy pred: tensor([0.1421, 0.1373, 0.1449, 0.1434, 0.1488, 0.1333, 0.1501],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.31117281317710876
 
[Iteration 5] Process ID: 181441 [Epoch: 46,  6752/ 27057 points] total loss per batch: 2.046
Policy (actual, predicted): 4 6
Policy data: tensor([0.1407, 0.1419, 0.1372, 0.1395, 0.1535, 0.1360, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1438, 0.1469, 0.1371, 0.1416, 0.1402, 0.1421, 0.1482],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9710955619812012
 
[Iteration 5] Process ID: 181441 [Epoch: 46, 13504/ 27057 points] total loss per batch: 2.040
Policy (actual, predicted): 6 6
Policy data: tensor([0.1407, 0.1407, 0.1407, 0.1442, 0.1442, 0.1372, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1430, 0.1425, 0.1454, 0.1420, 0.1457, 0.1315, 0.1499],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.12385323643684387
 
[Iteration 5] Process ID: 181441 [Epoch: 46, 20256/ 27057 points] total loss per batch: 2.070
Policy (actual, predicted): 1 3
Policy data: tensor([0.0437, 0.2660, 0.0708, 0.1342, 0.1901, 0.0292, 0.2660],
       device='cuda:0')
Policy pred: tensor([0.0656, 0.1367, 0.1459, 0.2029, 0.2024, 0.0462, 0.2003],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 46, 27008/ 27057 points] total loss per batch: 2.061
Policy (actual, predicted): 1 6
Policy data: tensor([0.0993, 0.2210, 0.0681, 0.1428, 0.2210, 0.0618, 0.1860],
       device='cuda:0')
Policy pred: tensor([0.0852, 0.1393, 0.0871, 0.1532, 0.2235, 0.0609, 0.2507],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999532699584961
 
[Iteration 5] Process ID: 181441 [Epoch: 47,  6752/ 27057 points] total loss per batch: 2.060
Policy (actual, predicted): 6 6
Policy data: tensor([0.1477, 0.1407, 0.1372, 0.1454, 0.1454, 0.1336, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1410, 0.1433, 0.1362, 0.1436, 0.1474, 0.1361, 0.1524],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.6855931282043457
 
[Iteration 5] Process ID: 181441 [Epoch: 47, 13504/ 27057 points] total loss per batch: 2.045
Policy (actual, predicted): 2 6
Policy data: tensor([0.0675, 0.0000, 0.2935, 0.1888, 0.1391, 0.0571, 0.2539],
       device='cuda:0')
Policy pred: tensor([1.0061e-01, 2.9926e-08, 2.3346e-01, 1.5939e-01, 1.9028e-01, 7.1157e-02,
        2.4510e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 47, 20256/ 27057 points] total loss per batch: 2.056
Policy (actual, predicted): 4 4
Policy data: tensor([0.0923, 0.1740, 0.0923, 0.2070, 0.2256, 0.0631, 0.1457],
       device='cuda:0')
Policy pred: tensor([0.1151, 0.1737, 0.1250, 0.1558, 0.2124, 0.0913, 0.1268],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 47, 27008/ 27057 points] total loss per batch: 2.064
Policy (actual, predicted): 2 6
Policy data: tensor([0.1048, 0.1048, 0.2742, 0.1048, 0.1149, 0.0443, 0.2522],
       device='cuda:0')
Policy pred: tensor([0.1359, 0.1218, 0.1573, 0.1106, 0.1637, 0.0843, 0.2264],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999337196350098
 
[Iteration 5] Process ID: 181441 [Epoch: 48,  6752/ 27057 points] total loss per batch: 2.058
Policy (actual, predicted): 4 4
Policy data: tensor([0.1056, 0.1694, 0.0000, 0.1973, 0.2470, 0.1239, 0.1568],
       device='cuda:0')
Policy pred: tensor([8.1881e-02, 1.6347e-01, 4.5627e-07, 1.5296e-01, 3.0517e-01, 1.1711e-01,
        1.7941e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 48, 13504/ 27057 points] total loss per batch: 2.050
Policy (actual, predicted): 1 1
Policy data: tensor([0.1495, 0.2741, 0.1248, 0.0862, 0.1248, 0.1039, 0.1367],
       device='cuda:0')
Policy pred: tensor([0.1226, 0.2912, 0.0922, 0.1133, 0.1778, 0.0841, 0.1188],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 48, 20256/ 27057 points] total loss per batch: 2.049
Policy (actual, predicted): 0 6
Policy data: tensor([0.1512, 0.1383, 0.1430, 0.1407, 0.1512, 0.1325, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1503, 0.1387, 0.1486, 0.1424, 0.1466, 0.1219, 0.1515],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999988079071045
 
[Iteration 5] Process ID: 181441 [Epoch: 48, 27008/ 27057 points] total loss per batch: 2.056
Policy (actual, predicted): 4 4
Policy data: tensor([0.1945, 0.1247, 0.0946, 0.0783, 0.2311, 0.1632, 0.1138],
       device='cuda:0')
Policy pred: tensor([0.1552, 0.1428, 0.1221, 0.1025, 0.2007, 0.1410, 0.1356],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 5] Process ID: 181441 [Epoch: 49,  6752/ 27057 points] total loss per batch: 2.046
Policy (actual, predicted): 3 3
Policy data: tensor([0.1067, 0.1678, 0.0973, 0.2000, 0.1536, 0.1067, 0.1678],
       device='cuda:0')
Policy pred: tensor([0.1000, 0.1454, 0.1422, 0.2015, 0.1647, 0.0965, 0.1497],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 49, 13504/ 27057 points] total loss per batch: 2.056
Policy (actual, predicted): 4 4
Policy data: tensor([0.1374, 0.1643, 0.1374, 0.1256, 0.2533, 0.0867, 0.0952],
       device='cuda:0')
Policy pred: tensor([0.1438, 0.1321, 0.1266, 0.1106, 0.2484, 0.1125, 0.1260],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 49, 20256/ 27057 points] total loss per batch: 2.060
Policy (actual, predicted): 1 4
Policy data: tensor([0.1407, 0.1489, 0.1336, 0.1430, 0.1477, 0.1372, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1419, 0.1441, 0.1399, 0.1418, 0.1473, 0.1396, 0.1453],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.12628024816513062
 
[Iteration 5] Process ID: 181441 [Epoch: 49, 27008/ 27057 points] total loss per batch: 2.061
Policy (actual, predicted): 4 4
Policy data: tensor([0.1076, 0.1719, 0.1165, 0.1855, 0.3341, 0.0844, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.2906e-01, 1.7617e-01, 1.3958e-01, 1.6819e-01, 2.9723e-01, 8.9716e-02,
        5.2230e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 50,  6752/ 27057 points] total loss per batch: 2.045
Policy (actual, predicted): 6 6
Policy data: tensor([0.0889, 0.1070, 0.1534, 0.1070, 0.2365, 0.0499, 0.2573],
       device='cuda:0')
Policy pred: tensor([0.1261, 0.1409, 0.1398, 0.1274, 0.1688, 0.0376, 0.2593],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 50, 13504/ 27057 points] total loss per batch: 2.060
Policy (actual, predicted): 4 6
Policy data: tensor([0.1430, 0.1383, 0.1395, 0.1407, 0.1535, 0.1348, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1369, 0.1480, 0.1371, 0.1392, 0.1486, 0.1383, 0.1520],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9786792397499084
 
[Iteration 5] Process ID: 181441 [Epoch: 50, 20256/ 27057 points] total loss per batch: 2.049
Policy (actual, predicted): 4 4
Policy data: tensor([0.0446, 0.1386, 0.1655, 0.1057, 0.3003, 0.0799, 0.1655],
       device='cuda:0')
Policy pred: tensor([0.0666, 0.1102, 0.1231, 0.1609, 0.2642, 0.0808, 0.1942],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 50, 27008/ 27057 points] total loss per batch: 2.058
Policy (actual, predicted): 6 6
Policy data: tensor([0.1360, 0.1442, 0.1407, 0.1419, 0.1465, 0.1407, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1400, 0.1412, 0.1407, 0.1407, 0.1469, 0.1435, 0.1471],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.9131202697753906
 
[Iteration 5] Process ID: 181441 [Epoch: 51,  6752/ 27057 points] total loss per batch: 2.040
Policy (actual, predicted): 6 6
Policy data: tensor([0.0810, 0.1284, 0.1284, 0.0976, 0.1676, 0.0669, 0.3302],
       device='cuda:0')
Policy pred: tensor([0.0899, 0.1481, 0.1179, 0.1185, 0.1968, 0.0710, 0.2578],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 51, 13504/ 27057 points] total loss per batch: 2.045
Policy (actual, predicted): 6 4
Policy data: tensor([0.1348, 0.1442, 0.1360, 0.1442, 0.1524, 0.1348, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1250, 0.1418, 0.1407, 0.1327, 0.1699, 0.1364, 0.1535],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 51, 20256/ 27057 points] total loss per batch: 2.044
Policy (actual, predicted): 2 2
Policy data: tensor([0.1395, 0.1407, 0.1512, 0.1407, 0.1512, 0.1277, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1348, 0.1371, 0.1667, 0.1499, 0.1383, 0.1242, 0.1490],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998345375061035
 
[Iteration 5] Process ID: 181441 [Epoch: 51, 27008/ 27057 points] total loss per batch: 2.053
Policy (actual, predicted): 6 6
Policy data: tensor([0.0536, 0.1140, 0.1140, 0.1629, 0.2300, 0.0536, 0.2721],
       device='cuda:0')
Policy pred: tensor([0.0817, 0.1333, 0.1260, 0.1589, 0.2024, 0.0681, 0.2296],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 52,  6752/ 27057 points] total loss per batch: 2.038
Policy (actual, predicted): 6 6
Policy data: tensor([0.1419, 0.1383, 0.1489, 0.1395, 0.1454, 0.1336, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1414, 0.1394, 0.1444, 0.1399, 0.1480, 0.1367, 0.1502],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.00634012371301651
 
[Iteration 5] Process ID: 181441 [Epoch: 52, 13504/ 27057 points] total loss per batch: 2.050
Policy (actual, predicted): 0 4
Policy data: tensor([0.1512, 0.1407, 0.1348, 0.1372, 0.1465, 0.1419, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1421, 0.1397, 0.1436, 0.1429, 0.1496, 0.1334, 0.1488],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.41226926445961
 
[Iteration 5] Process ID: 181441 [Epoch: 52, 20256/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 1 1
Policy data: tensor([0.1225, 0.2830, 0.0000, 0.1675, 0.1044, 0.1550, 0.1675],
       device='cuda:0')
Policy pred: tensor([1.3191e-01, 2.9857e-01, 4.5053e-06, 1.6498e-01, 1.3086e-01, 1.0733e-01,
        1.6635e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 52, 27008/ 27057 points] total loss per batch: 2.055
Policy (actual, predicted): 2 4
Policy data: tensor([0.1360, 0.1337, 0.1536, 0.1442, 0.1524, 0.1289, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1384, 0.1385, 0.1589, 0.1168, 0.1774, 0.1156, 0.1544],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999917149543762
 
[Iteration 5] Process ID: 181441 [Epoch: 53,  6752/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 6 6
Policy data: tensor([0.1419, 0.1407, 0.1442, 0.1407, 0.1477, 0.1325, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1336, 0.1437, 0.1320, 0.1435, 0.1479, 0.1356, 0.1637],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9575645923614502
 
[Iteration 5] Process ID: 181441 [Epoch: 53, 13504/ 27057 points] total loss per batch: 2.046
Policy (actual, predicted): 3 3
Policy data: tensor([0.1467, 0.0000, 0.0896, 0.4462, 0.0000, 0.0000, 0.3174],
       device='cuda:0')
Policy pred: tensor([1.5001e-01, 2.2618e-06, 1.2648e-01, 3.9971e-01, 9.1833e-07, 3.7647e-06,
        3.2380e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999995231628418
 
[Iteration 5] Process ID: 181441 [Epoch: 53, 20256/ 27057 points] total loss per batch: 2.042
Policy (actual, predicted): 4 6
Policy data: tensor([0.1442, 0.1383, 0.1465, 0.1419, 0.1489, 0.1313, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1442, 0.1405, 0.1452, 0.1401, 0.1469, 0.1314, 0.1516],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.003504362655803561
 
[Iteration 5] Process ID: 181441 [Epoch: 53, 27008/ 27057 points] total loss per batch: 2.050
Policy (actual, predicted): 4 4
Policy data: tensor([0.1430, 0.1395, 0.1430, 0.1372, 0.1512, 0.1395, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1560, 0.1249, 0.1473, 0.1174, 0.1766, 0.1469, 0.1309],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 54,  6752/ 27057 points] total loss per batch: 2.039
Policy (actual, predicted): 6 6
Policy data: tensor([0.1442, 0.1454, 0.1383, 0.1430, 0.1466, 0.1289, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1529, 0.1455, 0.1298, 0.1552, 0.1362, 0.1170, 0.1634],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 54, 13504/ 27057 points] total loss per batch: 2.048
Policy (actual, predicted): 6 6
Policy data: tensor([0.1140, 0.1634, 0.1140, 0.1039, 0.1948, 0.0784, 0.2314],
       device='cuda:0')
Policy pred: tensor([0.1053, 0.1390, 0.1180, 0.1265, 0.1949, 0.0783, 0.2379],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999973773956299
 
[Iteration 5] Process ID: 181441 [Epoch: 54, 20256/ 27057 points] total loss per batch: 2.047
Policy (actual, predicted): 4 5
Policy data: tensor([0.1419, 0.1419, 0.1419, 0.1395, 0.1524, 0.1454, 0.1372],
       device='cuda:0')
Policy pred: tensor([0.1428, 0.1342, 0.1451, 0.1218, 0.1676, 0.1680, 0.1205],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999890923500061
 
[Iteration 5] Process ID: 181441 [Epoch: 54, 27008/ 27057 points] total loss per batch: 2.044
Policy (actual, predicted): 1 1
Policy data: tensor([0.1163, 0.2162, 0.2005, 0.1474, 0.1721, 0.1474, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.1626e-01, 2.4590e-01, 1.7488e-01, 1.8791e-01, 1.9752e-01, 7.7532e-02,
        2.7768e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 55,  6752/ 27057 points] total loss per batch: 2.039
Policy (actual, predicted): 6 4
Policy data: tensor([0.1395, 0.1442, 0.1383, 0.1407, 0.1477, 0.1407, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1389, 0.1379, 0.1418, 0.1423, 0.1468, 0.1459, 0.1464],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999682307243347
 
[Iteration 5] Process ID: 181441 [Epoch: 55, 13504/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 4 4
Policy data: tensor([0.1336, 0.1442, 0.1489, 0.1383, 0.1535, 0.1372, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1161, 0.1405, 0.1738, 0.1199, 0.1798, 0.1231, 0.1467],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 55, 20256/ 27057 points] total loss per batch: 2.045
Policy (actual, predicted): 6 6
Policy data: tensor([0.1465, 0.1395, 0.1430, 0.1442, 0.1442, 0.1301, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1424, 0.1412, 0.1458, 0.1407, 0.1471, 0.1311, 0.1519],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.004186816047877073
 
[Iteration 5] Process ID: 181441 [Epoch: 55, 27008/ 27057 points] total loss per batch: 2.051
Policy (actual, predicted): 4 4
Policy data: tensor([0.0622, 0.0907, 0.0994, 0.1304, 0.3911, 0.0564, 0.1699],
       device='cuda:0')
Policy pred: tensor([0.0928, 0.1342, 0.1065, 0.1266, 0.3216, 0.0531, 0.1653],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 56,  6752/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 4 2
Policy data: tensor([0.1384, 0.1419, 0.1524, 0.1372, 0.1547, 0.1301, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1380, 0.1416, 0.1558, 0.1413, 0.1498, 0.1298, 0.1438],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.03165841102600098
 
[Iteration 5] Process ID: 181441 [Epoch: 56, 13504/ 27057 points] total loss per batch: 2.038
Policy (actual, predicted): 6 6
Policy data: tensor([0.1161, 0.0000, 0.2651, 0.0722, 0.0000, 0.0674, 0.4792],
       device='cuda:0')
Policy pred: tensor([9.8779e-02, 1.3763e-10, 2.1351e-01, 8.1984e-02, 6.3429e-08, 6.3133e-02,
        5.4259e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 56, 20256/ 27057 points] total loss per batch: 2.052
Policy (actual, predicted): 6 3
Policy data: tensor([0.1372, 0.1454, 0.1419, 0.1442, 0.1489, 0.1289, 0.1536],
       device='cuda:0')
Policy pred: tensor([0.1414, 0.1424, 0.1346, 0.1550, 0.1463, 0.1279, 0.1524],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9967960119247437
 
[Iteration 5] Process ID: 181441 [Epoch: 56, 27008/ 27057 points] total loss per batch: 2.042
Policy (actual, predicted): 4 4
Policy data: tensor([0.1782, 0.1365, 0.1365, 0.1038, 0.2311, 0.0646, 0.1493],
       device='cuda:0')
Policy pred: tensor([0.1385, 0.1513, 0.1466, 0.1152, 0.2239, 0.0762, 0.1482],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 57,  6752/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 6 6
Policy data: tensor([0.0961, 0.1651, 0.0725, 0.1964, 0.1964, 0.0403, 0.2331],
       device='cuda:0')
Policy pred: tensor([0.0908, 0.1662, 0.0992, 0.1523, 0.2129, 0.0395, 0.2392],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 57, 13504/ 27057 points] total loss per batch: 2.035
Policy (actual, predicted): 6 6
Policy data: tensor([0.1036, 0.1490, 0.0944, 0.1136, 0.1941, 0.0944, 0.2511],
       device='cuda:0')
Policy pred: tensor([0.1177, 0.1312, 0.1103, 0.1001, 0.1699, 0.0706, 0.3003],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 57, 20256/ 27057 points] total loss per batch: 2.045
Policy (actual, predicted): 4 4
Policy data: tensor([0.1372, 0.1454, 0.1430, 0.1407, 0.1477, 0.1395, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1401, 0.1406, 0.1405, 0.1448, 0.1473, 0.1395, 0.1471],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.027220001444220543
 
[Iteration 5] Process ID: 181441 [Epoch: 57, 27008/ 27057 points] total loss per batch: 2.055
Policy (actual, predicted): 6 6
Policy data: tensor([0.1454, 0.1372, 0.1395, 0.1419, 0.1442, 0.1395, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1435, 0.1410, 0.1427, 0.1399, 0.1482, 0.1351, 0.1496],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.08910907059907913
 
[Iteration 5] Process ID: 181441 [Epoch: 58,  6752/ 27057 points] total loss per batch: 2.035
Policy (actual, predicted): 4 1
Policy data: tensor([0.1395, 0.1442, 0.1454, 0.1395, 0.1512, 0.1325, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1175, 0.1646, 0.1492, 0.1346, 0.1518, 0.1312, 0.1511],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 58, 13504/ 27057 points] total loss per batch: 2.040
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000, 0.5442, 0.2008, 0.2550, 0.0000, 0.0000, 0.0000],
       device='cuda:0')
Policy pred: tensor([4.6241e-08, 5.6482e-01, 1.8641e-01, 2.4876e-01, 1.2917e-07, 4.1206e-06,
        1.2260e-12], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 58, 20256/ 27057 points] total loss per batch: 2.054
Policy (actual, predicted): 4 4
Policy data: tensor([0.1454, 0.1395, 0.1360, 0.1360, 0.1512, 0.1465, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1394, 0.1423, 0.1511, 0.1417, 0.1515, 0.1396, 0.1342],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999821782112122
 
[Iteration 5] Process ID: 181441 [Epoch: 58, 27008/ 27057 points] total loss per batch: 2.044
Policy (actual, predicted): 4 4
Policy data: tensor([0.0916, 0.2287, 0.0000, 0.0000, 0.4447, 0.0980, 0.1370],
       device='cuda:0')
Policy pred: tensor([9.4003e-02, 2.0694e-01, 6.7285e-05, 1.7575e-08, 4.6774e-01, 6.8571e-02,
        1.6268e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 59,  6752/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 4 4
Policy data: tensor([0.0839, 0.1895, 0.1011, 0.1011, 0.2901, 0.1011, 0.1330],
       device='cuda:0')
Policy pred: tensor([0.0741, 0.2203, 0.0685, 0.1169, 0.3063, 0.0599, 0.1540],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 59, 13504/ 27057 points] total loss per batch: 2.047
Policy (actual, predicted): 6 6
Policy data: tensor([0.1337, 0.1395, 0.1477, 0.1419, 0.1512, 0.1277, 0.1582],
       device='cuda:0')
Policy pred: tensor([0.1403, 0.1406, 0.1508, 0.1379, 0.1479, 0.1294, 0.1530],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.12395091354846954
 
[Iteration 5] Process ID: 181441 [Epoch: 59, 20256/ 27057 points] total loss per batch: 2.047
Policy (actual, predicted): 1 4
Policy data: tensor([0.1312, 0.1571, 0.1092, 0.1571, 0.1571, 0.1312, 0.1571],
       device='cuda:0')
Policy pred: tensor([0.1388, 0.1561, 0.0996, 0.1263, 0.1866, 0.1103, 0.1823],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 59, 27008/ 27057 points] total loss per batch: 2.038
Policy (actual, predicted): 4 6
Policy data: tensor([0.1360, 0.1430, 0.1465, 0.1360, 0.1512, 0.1430, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1242, 0.1351, 0.1426, 0.1517, 0.1516, 0.1404, 0.1545],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999992847442627
 
[Iteration 5] Process ID: 181441 [Epoch: 60,  6752/ 27057 points] total loss per batch: 2.049
Policy (actual, predicted): 6 3
Policy data: tensor([0.1235, 0.0000, 0.0000, 0.3819, 0.0000, 0.0937, 0.4009],
       device='cuda:0')
Policy pred: tensor([1.3398e-01, 1.0432e-06, 8.1311e-08, 3.7795e-01, 1.3344e-06, 1.2138e-01,
        3.6669e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 60, 13504/ 27057 points] total loss per batch: 2.045
Policy (actual, predicted): 6 6
Policy data: tensor([0.1407, 0.1407, 0.1407, 0.1442, 0.1442, 0.1372, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1403, 0.1429, 0.1424, 0.1414, 0.1489, 0.1327, 0.1514],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.0020517073571681976
 
[Iteration 5] Process ID: 181441 [Epoch: 60, 20256/ 27057 points] total loss per batch: 2.044
Policy (actual, predicted): 4 6
Policy data: tensor([0.1419, 0.1465, 0.1442, 0.1407, 0.1500, 0.1348, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1355, 0.1519, 0.1349, 0.1453, 0.1415, 0.1288, 0.1621],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 60, 27008/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 6 6
Policy data: tensor([0.1616, 0.0000, 0.2334, 0.0000, 0.0000, 0.1797, 0.4253],
       device='cuda:0')
Policy pred: tensor([2.4228e-01, 7.0228e-07, 1.9585e-01, 1.1189e-07, 1.2341e-07, 1.6734e-01,
        3.9454e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 61,  6752/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 4 6
Policy data: tensor([0.1407, 0.1395, 0.1442, 0.1465, 0.1489, 0.1325, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1439, 0.1396, 0.1476, 0.1411, 0.1467, 0.1314, 0.1497],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.021261461079120636
 
[Iteration 5] Process ID: 181441 [Epoch: 61, 13504/ 27057 points] total loss per batch: 2.040
Policy (actual, predicted): 6 6
Policy data: tensor([0.1454, 0.1419, 0.1407, 0.1407, 0.1477, 0.1301, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1511, 0.1468, 0.1434, 0.1335, 0.1491, 0.1180, 0.1581],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9969445466995239
 
[Iteration 5] Process ID: 181441 [Epoch: 61, 20256/ 27057 points] total loss per batch: 2.050
Policy (actual, predicted): 6 6
Policy data: tensor([0.1477, 0.1419, 0.1372, 0.1430, 0.1477, 0.1301, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1437, 0.1384, 0.1436, 0.1414, 0.1490, 0.1339, 0.1501],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.0738404169678688
 
[Iteration 5] Process ID: 181441 [Epoch: 61, 27008/ 27057 points] total loss per batch: 2.040
Policy (actual, predicted): 0 6
Policy data: tensor([0.1500, 0.1407, 0.1348, 0.1407, 0.1430, 0.1419, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1428, 0.1475, 0.1266, 0.1346, 0.1330, 0.1541, 0.1613],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 62,  6752/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 6 6
Policy data: tensor([0.1036, 0.1243, 0.1486, 0.1036, 0.1931, 0.0323, 0.2945],
       device='cuda:0')
Policy pred: tensor([0.0757, 0.1097, 0.1325, 0.1228, 0.2319, 0.0389, 0.2885],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 62, 13504/ 27057 points] total loss per batch: 2.044
Policy (actual, predicted): 3 3
Policy data: tensor([0.0743, 0.1785, 0.1210, 0.2239, 0.2239, 0.0000, 0.1785],
       device='cuda:0')
Policy pred: tensor([7.8323e-02, 1.8598e-01, 1.1273e-01, 2.4361e-01, 2.2540e-01, 9.1805e-05,
        1.5387e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 62, 20256/ 27057 points] total loss per batch: 2.045
Policy (actual, predicted): 0 4
Policy data: tensor([0.1489, 0.1383, 0.1372, 0.1419, 0.1477, 0.1442, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1412, 0.1445, 0.1418, 0.1429, 0.1456, 0.1395, 0.1445],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.0933808758854866
 
[Iteration 5] Process ID: 181441 [Epoch: 62, 27008/ 27057 points] total loss per batch: 2.041
Policy (actual, predicted): 4 4
Policy data: tensor([0.1430, 0.1395, 0.1442, 0.1395, 0.1477, 0.1395, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1403, 0.1441, 0.1419, 0.1435, 0.1481, 0.1366, 0.1455],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.7559599280357361
 
[Iteration 5] Process ID: 181441 [Epoch: 63,  6752/ 27057 points] total loss per batch: 2.035
Policy (actual, predicted): 0 0
Policy data: tensor([0.1454, 0.1407, 0.1454, 0.1419, 0.1454, 0.1407, 0.1407],
       device='cuda:0')
Policy pred: tensor([0.1540, 0.1515, 0.1440, 0.1308, 0.1391, 0.1297, 0.1508],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 63, 13504/ 27057 points] total loss per batch: 2.042
Policy (actual, predicted): 3 1
Policy data: tensor([0.1359, 0.2682, 0.0841, 0.2884, 0.1161, 0.1072, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.6311e-01, 2.7095e-01, 7.8163e-02, 2.4973e-01, 1.4960e-01, 8.8452e-02,
        3.5289e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 63, 20256/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 0 4
Policy data: tensor([0.1489, 0.1395, 0.1454, 0.1395, 0.1430, 0.1407, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1425, 0.1441, 0.1418, 0.1403, 0.1487, 0.1374, 0.1452],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.3328237533569336
 
[Iteration 5] Process ID: 181441 [Epoch: 63, 27008/ 27057 points] total loss per batch: 2.048
Policy (actual, predicted): 6 6
Policy data: tensor([0.1056, 0.1964, 0.0974, 0.0763, 0.1964, 0.0000, 0.3280],
       device='cuda:0')
Policy pred: tensor([1.2765e-01, 1.8360e-01, 1.2699e-01, 1.1300e-01, 1.8921e-01, 3.7215e-06,
        2.5954e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 64,  6752/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 6 6
Policy data: tensor([0.1419, 0.1430, 0.1465, 0.1419, 0.1465, 0.1324, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1413, 0.1416, 0.1409, 0.1417, 0.1487, 0.1346, 0.1512],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.2655656337738037
 
[Iteration 5] Process ID: 181441 [Epoch: 64, 13504/ 27057 points] total loss per batch: 2.046
Policy (actual, predicted): 3 2
Policy data: tensor([0.1675, 0.1326, 0.2104, 0.2268, 0.0000, 0.0817, 0.1809],
       device='cuda:0')
Policy pred: tensor([1.3681e-01, 1.6483e-01, 2.2686e-01, 2.2030e-01, 2.3268e-07, 5.5259e-02,
        1.9594e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 64, 20256/ 27057 points] total loss per batch: 2.043
Policy (actual, predicted): 5 4
Policy data: tensor([0.1348, 0.1407, 0.1407, 0.1465, 0.1465, 0.1477, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1374, 0.1472, 0.1368, 0.1454, 0.1540, 0.1379, 0.1415],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.2438550442457199
 
[Iteration 5] Process ID: 181441 [Epoch: 64, 27008/ 27057 points] total loss per batch: 2.044
Policy (actual, predicted): 4 5
Policy data: tensor([0.1372, 0.1442, 0.1419, 0.1407, 0.1512, 0.1395, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1401, 0.1418, 0.1305, 0.1493, 0.1329, 0.1729, 0.1325],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 65,  6752/ 27057 points] total loss per batch: 2.042
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1395, 0.1465, 0.1372, 0.1500, 0.1372, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1185, 0.1509, 0.1499, 0.1147, 0.1892, 0.1295, 0.1473],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 65, 13504/ 27057 points] total loss per batch: 2.040
Policy (actual, predicted): 6 4
Policy data: tensor([0.1372, 0.1454, 0.1500, 0.1407, 0.1407, 0.1348, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1375, 0.1410, 0.1482, 0.1406, 0.1508, 0.1341, 0.1479],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9978559613227844
 
[Iteration 5] Process ID: 181441 [Epoch: 65, 20256/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 4 4
Policy data: tensor([0.1430, 0.1419, 0.1430, 0.1430, 0.1477, 0.1336, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1440, 0.1445, 0.1414, 0.1391, 0.1505, 0.1338, 0.1467],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9816581010818481
 
[Iteration 5] Process ID: 181441 [Epoch: 65, 27008/ 27057 points] total loss per batch: 2.041
Policy (actual, predicted): 4 6
Policy data: tensor([0.1281, 0.1531, 0.0887, 0.1170, 0.2361, 0.0408, 0.2361],
       device='cuda:0')
Policy pred: tensor([0.1034, 0.1556, 0.1024, 0.1605, 0.1883, 0.0671, 0.2227],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9985306262969971
 
[Iteration 5] Process ID: 181441 [Epoch: 66,  6752/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 6 6
Policy data: tensor([0.1430, 0.1419, 0.1466, 0.1454, 0.1442, 0.1265, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1419, 0.1412, 0.1441, 0.1432, 0.1482, 0.1317, 0.1497],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.026370123028755188
 
[Iteration 5] Process ID: 181441 [Epoch: 66, 13504/ 27057 points] total loss per batch: 2.039
Policy (actual, predicted): 4 4
Policy data: tensor([0.1633, 0.1139, 0.1139, 0.1366, 0.2518, 0.0712, 0.1494],
       device='cuda:0')
Policy pred: tensor([0.1417, 0.1355, 0.1088, 0.1415, 0.2410, 0.0956, 0.1359],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 66, 20256/ 27057 points] total loss per batch: 2.038
Policy (actual, predicted): 4 4
Policy data: tensor([0.1224, 0.1019, 0.1019, 0.1602, 0.2688, 0.0699, 0.1750],
       device='cuda:0')
Policy pred: tensor([0.1088, 0.0897, 0.0920, 0.1202, 0.3001, 0.0670, 0.2222],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 66, 27008/ 27057 points] total loss per batch: 2.047
Policy (actual, predicted): 4 2
Policy data: tensor([0.1582, 0.1991, 0.1154, 0.0000, 0.2314, 0.1250, 0.1709],
       device='cuda:0')
Policy pred: tensor([0.1248, 0.1867, 0.1908, 0.0038, 0.1825, 0.1523, 0.1591],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 67,  6752/ 27057 points] total loss per batch: 2.047
Policy (actual, predicted): 0 6
Policy data: tensor([0.1477, 0.1360, 0.1465, 0.1419, 0.1465, 0.1336, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1436, 0.1396, 0.1449, 0.1417, 0.1464, 0.1327, 0.1511],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.005121747963130474
 
[Iteration 5] Process ID: 181441 [Epoch: 67, 13504/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 6 6
Policy data: tensor([0.0877, 0.1157, 0.2334, 0.1266, 0.1157, 0.0446, 0.2762],
       device='cuda:0')
Policy pred: tensor([0.1009, 0.1399, 0.1939, 0.1487, 0.1205, 0.0357, 0.2605],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 67, 20256/ 27057 points] total loss per batch: 2.041
Policy (actual, predicted): 5 5
Policy data: tensor([0.1256, 0.0867, 0.1256, 0.1146, 0.1146, 0.2534, 0.1795],
       device='cuda:0')
Policy pred: tensor([0.1151, 0.0971, 0.1166, 0.1068, 0.1729, 0.2628, 0.1287],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 67, 27008/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1430, 0.1465, 0.1430, 0.1500, 0.1348, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1364, 0.1451, 0.1412, 0.1463, 0.1487, 0.1392, 0.1431],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.06811829656362534
 
[Iteration 5] Process ID: 181441 [Epoch: 68,  6752/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 0 6
Policy data: tensor([0.1454, 0.1383, 0.1454, 0.1430, 0.1442, 0.1407, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1422, 0.1425, 0.1438, 0.1426, 0.1449, 0.1347, 0.1492],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9944542050361633
 
[Iteration 5] Process ID: 181441 [Epoch: 68, 13504/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 2 2
Policy data: tensor([0.0937, 0.1617, 0.2493, 0.0853, 0.1766, 0.0853, 0.1480],
       device='cuda:0')
Policy pred: tensor([0.1337, 0.1798, 0.2075, 0.1000, 0.1858, 0.0937, 0.0996],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 68, 20256/ 27057 points] total loss per batch: 2.042
Policy (actual, predicted): 1 6
Policy data: tensor([0.0847, 0.2087, 0.0847, 0.1606, 0.1754, 0.0771, 0.2087],
       device='cuda:0')
Policy pred: tensor([0.0639, 0.1586, 0.0991, 0.1896, 0.2076, 0.0693, 0.2118],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 68, 27008/ 27057 points] total loss per batch: 2.043
Policy (actual, predicted): 1 6
Policy data: tensor([0.1383, 0.1477, 0.1465, 0.1395, 0.1477, 0.1383, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1314, 0.1365, 0.1506, 0.1361, 0.1494, 0.1416, 0.1543],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 5] Process ID: 181441 [Epoch: 69,  6752/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 6 6
Policy data: tensor([0.0525, 0.0000, 0.0619, 0.1169, 0.2826, 0.0288, 0.4573],
       device='cuda:0')
Policy pred: tensor([6.0871e-02, 1.9826e-08, 7.1822e-02, 1.2150e-01, 3.4793e-01, 3.4783e-02,
        3.6310e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 69, 13504/ 27057 points] total loss per batch: 2.042
Policy (actual, predicted): 4 2
Policy data: tensor([0.1166, 0.1363, 0.2675, 0.0000, 0.2875, 0.0332, 0.1589],
       device='cuda:0')
Policy pred: tensor([7.5267e-02, 1.2922e-01, 2.9063e-01, 3.6925e-10, 2.6185e-01, 5.0517e-02,
        1.9251e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 69, 20256/ 27057 points] total loss per batch: 2.045
Policy (actual, predicted): 4 4
Policy data: tensor([0.1454, 0.1419, 0.1419, 0.1407, 0.1535, 0.1289, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1372, 0.1445, 0.1400, 0.1427, 0.1487, 0.1423, 0.1446],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.12232358008623123
 
[Iteration 5] Process ID: 181441 [Epoch: 69, 27008/ 27057 points] total loss per batch: 2.040
Policy (actual, predicted): 4 4
Policy data: tensor([0.1360, 0.1419, 0.1465, 0.1372, 0.1500, 0.1395, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1411, 0.1400, 0.1422, 0.1419, 0.1493, 0.1367, 0.1487],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.09215759485960007
 
[Iteration 5] Process ID: 181441 [Epoch: 70,  6752/ 27057 points] total loss per batch: 2.039
Policy (actual, predicted): 4 4
Policy data: tensor([0.1264, 0.0000, 0.0851, 0.1169, 0.4358, 0.0367, 0.1991],
       device='cuda:0')
Policy pred: tensor([1.1581e-01, 9.5177e-07, 1.0716e-01, 1.1996e-01, 4.6125e-01, 4.0422e-02,
        1.5539e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 70, 13504/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1477, 0.1430, 0.1383, 0.1512, 0.1372, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1417, 0.1417, 0.1428, 0.1411, 0.1479, 0.1395, 0.1453],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.3835410177707672
 
[Iteration 5] Process ID: 181441 [Epoch: 70, 20256/ 27057 points] total loss per batch: 2.042
Policy (actual, predicted): 1 1
Policy data: tensor([0.1751, 0.2905, 0.0000, 0.2262, 0.0000, 0.0959, 0.2123],
       device='cuda:0')
Policy pred: tensor([1.5790e-01, 3.2101e-01, 7.4468e-07, 2.6652e-01, 2.2425e-09, 5.3051e-02,
        2.0152e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 70, 27008/ 27057 points] total loss per batch: 2.043
Policy (actual, predicted): 6 4
Policy data: tensor([0.1383, 0.1419, 0.1465, 0.1395, 0.1454, 0.1383, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1321, 0.1398, 0.1484, 0.1353, 0.1555, 0.1370, 0.1519],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999989867210388
 
[Iteration 5] Process ID: 181441 [Epoch: 71,  6752/ 27057 points] total loss per batch: 2.035
Policy (actual, predicted): 6 6
Policy data: tensor([0.1454, 0.1384, 0.1489, 0.1384, 0.1489, 0.1289, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1425, 0.1435, 0.1467, 0.1388, 0.1491, 0.1278, 0.1516],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.00324517535045743
 
[Iteration 5] Process ID: 181441 [Epoch: 71, 13504/ 27057 points] total loss per batch: 2.041
Policy (actual, predicted): 6 6
Policy data: tensor([0.1430, 0.1395, 0.1477, 0.1442, 0.1466, 0.1277, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1431, 0.1408, 0.1430, 0.1391, 0.1508, 0.1303, 0.1528],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999888002872467
 
[Iteration 5] Process ID: 181441 [Epoch: 71, 20256/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 2 4
Policy data: tensor([0.1360, 0.1442, 0.1477, 0.1395, 0.1477, 0.1395, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1388, 0.1435, 0.1432, 0.1427, 0.1471, 0.1390, 0.1458],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9368840456008911
 
[Iteration 5] Process ID: 181441 [Epoch: 71, 27008/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 5 5
Policy data: tensor([0.1119, 0.1020, 0.0929, 0.0846, 0.2271, 0.2473, 0.1342],
       device='cuda:0')
Policy pred: tensor([0.0993, 0.1463, 0.0943, 0.0931, 0.2036, 0.2328, 0.1306],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 72,  6752/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 1 1
Policy data: tensor([0.3537, 0.5150, 0.0375, 0.0000, 0.0000, 0.0937, 0.0000],
       device='cuda:0')
Policy pred: tensor([3.0835e-01, 5.0348e-01, 7.4647e-02, 7.4162e-09, 2.6841e-11, 1.1353e-01,
        5.6232e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 72, 13504/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 4 6
Policy data: tensor([0.1275, 0.0000, 0.1118, 0.0000, 0.3658, 0.0291, 0.3658],
       device='cuda:0')
Policy pred: tensor([1.2898e-01, 1.9928e-08, 8.9816e-02, 4.7603e-07, 3.2495e-01, 3.8808e-02,
        4.1745e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 5] Process ID: 181441 [Epoch: 72, 20256/ 27057 points] total loss per batch: 2.042
Policy (actual, predicted): 4 4
Policy data: tensor([0.1442, 0.1454, 0.1360, 0.1383, 0.1489, 0.1383, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1463, 0.1466, 0.1339, 0.1409, 0.1483, 0.1368, 0.1473],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9991909861564636
 
[Iteration 5] Process ID: 181441 [Epoch: 72, 27008/ 27057 points] total loss per batch: 2.039
Policy (actual, predicted): 4 4
Policy data: tensor([0.1442, 0.1395, 0.1419, 0.1442, 0.1512, 0.1289, 0.1501],
       device='cuda:0')
Policy pred: tensor([0.1458, 0.1446, 0.1419, 0.1374, 0.1520, 0.1319, 0.1464],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9928070902824402
 
[Iteration 5] Process ID: 181441 [Epoch: 73,  6752/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 0 2
Policy data: tensor([0.1501, 0.1336, 0.1501, 0.1419, 0.1454, 0.1336, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1474, 0.1395, 0.1527, 0.1383, 0.1521, 0.1265, 0.1436],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999962449073792
 
[Iteration 5] Process ID: 181441 [Epoch: 73, 13504/ 27057 points] total loss per batch: 2.042
Policy (actual, predicted): 5 5
Policy data: tensor([0.1489, 0.0000, 0.2273, 0.2652, 0.0000, 0.3586, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.4284e-01, 5.9053e-05, 2.2307e-01, 2.9484e-01, 6.6584e-06, 3.3911e-01,
        7.6941e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 73, 20256/ 27057 points] total loss per batch: 2.039
Policy (actual, predicted): 4 6
Policy data: tensor([0.0809, 0.1993, 0.1533, 0.0809, 0.2364, 0.0499, 0.1993],
       device='cuda:0')
Policy pred: tensor([0.0933, 0.1386, 0.1344, 0.0774, 0.2309, 0.0689, 0.2565],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999992847442627
 
[Iteration 5] Process ID: 181441 [Epoch: 73, 27008/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 6 6
Policy data: tensor([0.1395, 0.1395, 0.1466, 0.1430, 0.1489, 0.1301, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1431, 0.1410, 0.1451, 0.1409, 0.1487, 0.1311, 0.1501],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.004660457372665405
 
[Iteration 5] Process ID: 181441 [Epoch: 74,  6752/ 27057 points] total loss per batch: 2.038
Policy (actual, predicted): 2 6
Policy data: tensor([0.1454, 0.1419, 0.1501, 0.1383, 0.1477, 0.1301, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1434, 0.1403, 0.1459, 0.1404, 0.1477, 0.1300, 0.1523],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.021005721762776375
 
[Iteration 5] Process ID: 181441 [Epoch: 74, 13504/ 27057 points] total loss per batch: 2.038
Policy (actual, predicted): 4 4
Policy data: tensor([0.1383, 0.1442, 0.1360, 0.1442, 0.1512, 0.1430, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1418, 0.1437, 0.1403, 0.1416, 0.1490, 0.1375, 0.1462],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.12353669106960297
 
[Iteration 5] Process ID: 181441 [Epoch: 74, 20256/ 27057 points] total loss per batch: 2.042
Policy (actual, predicted): 4 4
Policy data: tensor([0.0800, 0.1910, 0.0000, 0.1108, 0.2771, 0.1640, 0.1771],
       device='cuda:0')
Policy pred: tensor([0.0765, 0.1909, 0.0011, 0.1094, 0.2627, 0.1724, 0.1870],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 74, 27008/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 4 1
Policy data: tensor([0.1430, 0.1465, 0.1395, 0.1442, 0.1489, 0.1372, 0.1407],
       device='cuda:0')
Policy pred: tensor([0.1332, 0.1538, 0.1460, 0.1409, 0.1382, 0.1375, 0.1504],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999810457229614
 
[Iteration 5] Process ID: 181441 [Epoch: 75,  6752/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 4 4
Policy data: tensor([0.1060, 0.1667, 0.1274, 0.1060, 0.1987, 0.0966, 0.1987],
       device='cuda:0')
Policy pred: tensor([0.0899, 0.1587, 0.1118, 0.1359, 0.2036, 0.1007, 0.1993],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 75, 13504/ 27057 points] total loss per batch: 2.055
Policy (actual, predicted): 6 6
Policy data: tensor([0.1384, 0.1477, 0.1419, 0.1430, 0.1501, 0.1277, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1417, 0.1414, 0.1438, 0.1419, 0.1477, 0.1351, 0.1484],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9850141406059265
 
[Iteration 5] Process ID: 181441 [Epoch: 75, 20256/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 4 6
Policy data: tensor([0.1407, 0.1465, 0.1430, 0.1407, 0.1477, 0.1336, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1437, 0.1426, 0.1444, 0.1429, 0.1505, 0.1148, 0.1612],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 75, 27008/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 1 1
Policy data: tensor([0.0700, 0.2475, 0.1227, 0.1469, 0.1753, 0.0770, 0.1605],
       device='cuda:0')
Policy pred: tensor([0.0720, 0.2250, 0.1276, 0.1722, 0.1973, 0.0853, 0.1207],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 76,  6752/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 1 4
Policy data: tensor([0.1402, 0.1831, 0.1066, 0.0972, 0.1831, 0.1066, 0.1831],
       device='cuda:0')
Policy pred: tensor([0.1361, 0.1559, 0.1349, 0.1059, 0.2047, 0.1069, 0.1556],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 76, 13504/ 27057 points] total loss per batch: 2.045
Policy (actual, predicted): 2 6
Policy data: tensor([0.1419, 0.1419, 0.1489, 0.1407, 0.1465, 0.1313, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1424, 0.1408, 0.1455, 0.1411, 0.1459, 0.1325, 0.1517],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.02016737498342991
 
[Iteration 5] Process ID: 181441 [Epoch: 76, 20256/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 4 4
Policy data: tensor([0.1442, 0.1430, 0.1407, 0.1395, 0.1454, 0.1430, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1408, 0.1435, 0.1394, 0.1418, 0.1466, 0.1418, 0.1460],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.8177119493484497
 
[Iteration 5] Process ID: 181441 [Epoch: 76, 27008/ 27057 points] total loss per batch: 2.042
Policy (actual, predicted): 6 6
Policy data: tensor([0.1047, 0.1147, 0.1047, 0.0792, 0.1374, 0.0792, 0.3801],
       device='cuda:0')
Policy pred: tensor([0.1203, 0.1317, 0.1215, 0.1017, 0.1342, 0.0721, 0.3186],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 77,  6752/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 0 4
Policy data: tensor([0.2258, 0.1459, 0.1219, 0.0573, 0.2258, 0.1219, 0.1014],
       device='cuda:0')
Policy pred: tensor([0.1815, 0.1561, 0.1083, 0.0682, 0.2502, 0.1389, 0.0967],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 77, 13504/ 27057 points] total loss per batch: 2.035
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1430, 0.1336, 0.1442, 0.1500, 0.1419, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1256, 0.1395, 0.1220, 0.1562, 0.1646, 0.1300, 0.1621],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 77, 20256/ 27057 points] total loss per batch: 2.038
Policy (actual, predicted): 6 1
Policy data: tensor([0.0960, 0.2799, 0.1220, 0.1319, 0.0000, 0.0692, 0.3009],
       device='cuda:0')
Policy pred: tensor([1.1662e-01, 2.8536e-01, 1.4080e-01, 1.2571e-01, 2.6188e-06, 9.3527e-02,
        2.3797e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 77, 27008/ 27057 points] total loss per batch: 2.039
Policy (actual, predicted): 4 4
Policy data: tensor([0.1383, 0.1442, 0.1442, 0.1360, 0.1535, 0.1360, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1361, 0.1451, 0.1418, 0.1427, 0.1521, 0.1386, 0.1437],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999060034751892
 
[Iteration 5] Process ID: 181441 [Epoch: 78,  6752/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 0 0
Policy data: tensor([0.3523, 0.1830, 0.0000, 0.0466, 0.2288, 0.0908, 0.0984],
       device='cuda:0')
Policy pred: tensor([2.7453e-01, 1.8274e-01, 7.9931e-06, 6.2308e-02, 2.7079e-01, 1.0665e-01,
        1.0298e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 78, 13504/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 4 4
Policy data: tensor([0.1493, 0.1247, 0.1038, 0.1138, 0.2517, 0.0783, 0.1783],
       device='cuda:0')
Policy pred: tensor([0.1284, 0.1257, 0.1033, 0.1246, 0.2665, 0.0732, 0.1783],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 78, 20256/ 27057 points] total loss per batch: 2.040
Policy (actual, predicted): 4 4
Policy data: tensor([0.1422, 0.1422, 0.0746, 0.1084, 0.3344, 0.0900, 0.1084],
       device='cuda:0')
Policy pred: tensor([0.1449, 0.1760, 0.0844, 0.1164, 0.2789, 0.0740, 0.1255],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 78, 27008/ 27057 points] total loss per batch: 2.038
Policy (actual, predicted): 2 2
Policy data: tensor([0.1983, 0.1818, 0.2783, 0.0884, 0.0970, 0.0497, 0.1064],
       device='cuda:0')
Policy pred: tensor([0.1961, 0.1633, 0.2837, 0.0711, 0.0895, 0.0649, 0.1314],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 79,  6752/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 4 6
Policy data: tensor([0.1442, 0.1360, 0.1419, 0.1384, 0.1536, 0.1325, 0.1536],
       device='cuda:0')
Policy pred: tensor([0.1445, 0.1391, 0.1476, 0.1405, 0.1465, 0.1324, 0.1494],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.021774902939796448
 
[Iteration 5] Process ID: 181441 [Epoch: 79, 13504/ 27057 points] total loss per batch: 2.039
Policy (actual, predicted): 4 4
Policy data: tensor([0.1419, 0.1442, 0.1419, 0.1395, 0.1465, 0.1395, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1402, 0.1438, 0.1393, 0.1427, 0.1474, 0.1405, 0.1459],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.16571278870105743
 
[Iteration 5] Process ID: 181441 [Epoch: 79, 20256/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1442, 0.1442, 0.1407, 0.1489, 0.1430, 0.1395],
       device='cuda:0')
Policy pred: tensor([0.1398, 0.1443, 0.1413, 0.1427, 0.1469, 0.1402, 0.1447],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.14643369615077972
 
[Iteration 5] Process ID: 181441 [Epoch: 79, 27008/ 27057 points] total loss per batch: 2.044
Policy (actual, predicted): 4 4
Policy data: tensor([0.0788, 0.2405, 0.1445, 0.0000, 0.4394, 0.0968, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.1817e-01, 2.5375e-01, 1.2921e-01, 1.2682e-05, 3.8266e-01, 1.1581e-01,
        3.9012e-04], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 80,  6752/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 4 4
Policy data: tensor([0.1936, 0.1624, 0.0857, 0.0941, 0.2300, 0.0857, 0.1486],
       device='cuda:0')
Policy pred: tensor([0.1845, 0.1627, 0.1209, 0.0948, 0.2072, 0.0786, 0.1512],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 80, 13504/ 27057 points] total loss per batch: 2.038
Policy (actual, predicted): 6 6
Policy data: tensor([0.1073, 0.0674, 0.0980, 0.1175, 0.2166, 0.0374, 0.3557],
       device='cuda:0')
Policy pred: tensor([0.1228, 0.0726, 0.1193, 0.1344, 0.1881, 0.0392, 0.3237],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 80, 20256/ 27057 points] total loss per batch: 2.044
Policy (actual, predicted): 4 6
Policy data: tensor([0.1442, 0.1454, 0.1419, 0.1372, 0.1524, 0.1372, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1398, 0.1411, 0.1452, 0.1441, 0.1455, 0.1383, 0.1459],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.008642234839498997
 
[Iteration 5] Process ID: 181441 [Epoch: 80, 27008/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 6 6
Policy data: tensor([0.1267, 0.1870, 0.1371, 0.1603, 0.1870, 0.0000, 0.2018],
       device='cuda:0')
Policy pred: tensor([9.5743e-02, 1.5065e-01, 1.4362e-01, 1.6120e-01, 2.1288e-01, 9.8577e-07,
        2.3591e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999794960021973
 
[Iteration 5] Process ID: 181441 [Epoch: 81,  6752/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 4 4
Policy data: tensor([0.1376, 0.1797, 0.1376, 0.0790, 0.2330, 0.1376, 0.0954],
       device='cuda:0')
Policy pred: tensor([0.1339, 0.1314, 0.1141, 0.0859, 0.2618, 0.1717, 0.1012],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 81, 13504/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 1 6
Policy data: tensor([0.1442, 0.1477, 0.1372, 0.1419, 0.1454, 0.1419, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1417, 0.1423, 0.1439, 0.1376, 0.1465, 0.1404, 0.1477],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 81, 20256/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 4 4
Policy data: tensor([0.1104, 0.1104, 0.0572, 0.0919, 0.2864, 0.0572, 0.2864],
       device='cuda:0')
Policy pred: tensor([0.1269, 0.1394, 0.0724, 0.1028, 0.2502, 0.0780, 0.2302],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 81, 27008/ 27057 points] total loss per batch: 2.043
Policy (actual, predicted): 6 6
Policy data: tensor([0.1407, 0.1419, 0.1512, 0.1360, 0.1454, 0.1313, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1416, 0.1410, 0.1462, 0.1386, 0.1469, 0.1338, 0.1519],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.39661329984664917
 
[Iteration 5] Process ID: 181441 [Epoch: 82,  6752/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 3 3
Policy data: tensor([0.1780, 0.1780, 0.0580, 0.2776, 0.2399, 0.0686, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.7368e-01, 1.9330e-01, 5.2053e-02, 2.6929e-01, 2.5522e-01, 5.6457e-02,
        3.3138e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 82, 13504/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 6 6
Policy data: tensor([0.1419, 0.1395, 0.1477, 0.1395, 0.1454, 0.1372, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1430, 0.1383, 0.1430, 0.1418, 0.1472, 0.1336, 0.1532],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.07357008010149002
 
[Iteration 5] Process ID: 181441 [Epoch: 82, 20256/ 27057 points] total loss per batch: 2.045
Policy (actual, predicted): 6 6
Policy data: tensor([0.1419, 0.1419, 0.1419, 0.1430, 0.1501, 0.1289, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1283, 0.1336, 0.1444, 0.1424, 0.1556, 0.1325, 0.1632],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 82, 27008/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 4 4
Policy data: tensor([0.0765, 0.1014, 0.1594, 0.1594, 0.2908, 0.1014, 0.1112],
       device='cuda:0')
Policy pred: tensor([0.1204, 0.1347, 0.1148, 0.1345, 0.3016, 0.0837, 0.1104],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 83,  6752/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 6 4
Policy data: tensor([0.1430, 0.1383, 0.1419, 0.1395, 0.1501, 0.1336, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1423, 0.1415, 0.1418, 0.1428, 0.1499, 0.1332, 0.1485],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9860712885856628
 
[Iteration 5] Process ID: 181441 [Epoch: 83, 13504/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 4 6
Policy data: tensor([0.0796, 0.1381, 0.1052, 0.1262, 0.2532, 0.0445, 0.2532],
       device='cuda:0')
Policy pred: tensor([0.0733, 0.1381, 0.0967, 0.0980, 0.2379, 0.0572, 0.2989],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 83, 20256/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 2 6
Policy data: tensor([0.0746, 0.0989, 0.2837, 0.0901, 0.1423, 0.0901, 0.2202],
       device='cuda:0')
Policy pred: tensor([0.0893, 0.1109, 0.2033, 0.0976, 0.1713, 0.0967, 0.2309],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 83, 27008/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 5 5
Policy data: tensor([0.1577, 0.2468, 0.1461, 0.0774, 0.0000, 0.3291, 0.0429],
       device='cuda:0')
Policy pred: tensor([1.8264e-01, 1.9512e-01, 1.8275e-01, 7.6028e-02, 1.0609e-08, 2.8256e-01,
        8.0907e-02], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 84,  6752/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 6 4
Policy data: tensor([0.1477, 0.1395, 0.1395, 0.1454, 0.1489, 0.1277, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1419, 0.1454, 0.1346, 0.1381, 0.1629, 0.1279, 0.1492],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999898672103882
 
[Iteration 5] Process ID: 181441 [Epoch: 84, 13504/ 27057 points] total loss per batch: 2.041
Policy (actual, predicted): 1 1
Policy data: tensor([0.1158, 0.3067, 0.1252, 0.0988, 0.3067, 0.0468, 0.0000],
       device='cuda:0')
Policy pred: tensor([8.5244e-02, 2.9036e-01, 1.4727e-01, 1.2632e-01, 2.8986e-01, 6.0945e-02,
        3.7627e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 84, 20256/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 2 6
Policy data: tensor([0.1430, 0.1430, 0.1465, 0.1348, 0.1465, 0.1407, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1427, 0.1434, 0.1426, 0.1393, 0.1443, 0.1388, 0.1488],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.008523352444171906
 
[Iteration 5] Process ID: 181441 [Epoch: 84, 27008/ 27057 points] total loss per batch: 2.048
Policy (actual, predicted): 1 1
Policy data: tensor([0.1725, 0.5409, 0.0000, 0.1395, 0.0000, 0.1471, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.5783e-01, 5.2475e-01, 7.2660e-07, 1.4588e-01, 1.4171e-08, 1.7154e-01,
        1.8040e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 85,  6752/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 6 6
Policy data: tensor([0.1407, 0.1395, 0.1489, 0.1407, 0.1454, 0.1313, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1421, 0.1405, 0.1473, 0.1414, 0.1481, 0.1303, 0.1504],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 7.652842214156408e-06
 
[Iteration 5] Process ID: 181441 [Epoch: 85, 13504/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 4 6
Policy data: tensor([0.0796, 0.1381, 0.1052, 0.1262, 0.2532, 0.0445, 0.2532],
       device='cuda:0')
Policy pred: tensor([0.0797, 0.1378, 0.1151, 0.0958, 0.2430, 0.0582, 0.2702],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 85, 20256/ 27057 points] total loss per batch: 2.046
Policy (actual, predicted): 6 6
Policy data: tensor([0.1274, 0.1394, 0.1274, 0.0969, 0.1664, 0.0406, 0.3019],
       device='cuda:0')
Policy pred: tensor([0.0973, 0.1455, 0.1215, 0.1117, 0.1868, 0.0586, 0.2786],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 85, 27008/ 27057 points] total loss per batch: 2.040
Policy (actual, predicted): 4 4
Policy data: tensor([0.1360, 0.1466, 0.1466, 0.1348, 0.1512, 0.1348, 0.1501],
       device='cuda:0')
Policy pred: tensor([0.1420, 0.1441, 0.1402, 0.1411, 0.1515, 0.1359, 0.1453],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9985435009002686
 
[Iteration 5] Process ID: 181441 [Epoch: 86,  6752/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 6 2
Policy data: tensor([0.1407, 0.1395, 0.1477, 0.1430, 0.1477, 0.1301, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1369, 0.1387, 0.1607, 0.1367, 0.1455, 0.1304, 0.1511],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 86, 13504/ 27057 points] total loss per batch: 2.041
Policy (actual, predicted): 6 6
Policy data: tensor([0.0592, 0.1496, 0.1783, 0.1369, 0.1634, 0.0399, 0.2728],
       device='cuda:0')
Policy pred: tensor([0.0649, 0.1486, 0.1882, 0.1453, 0.1488, 0.0268, 0.2774],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 86, 20256/ 27057 points] total loss per batch: 2.039
Policy (actual, predicted): 6 4
Policy data: tensor([0.1442, 0.1419, 0.1454, 0.1454, 0.1430, 0.1301, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1369, 0.1460, 0.1408, 0.1436, 0.1545, 0.1263, 0.1519],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.1426408439874649
 
[Iteration 5] Process ID: 181441 [Epoch: 86, 27008/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 1 6
Policy data: tensor([0.1789, 0.2129, 0.1499, 0.0864, 0.1143, 0.0786, 0.1789],
       device='cuda:0')
Policy pred: tensor([0.1779, 0.1781, 0.1510, 0.1005, 0.1114, 0.0862, 0.1948],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 87,  6752/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 2 2
Policy data: tensor([0.1395, 0.1442, 0.1477, 0.1372, 0.1477, 0.1360, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1363, 0.1391, 0.1639, 0.1300, 0.1470, 0.1244, 0.1595],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 87, 13504/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 4 4
Policy data: tensor([0.1430, 0.1477, 0.1407, 0.1383, 0.1489, 0.1360, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1419, 0.1398, 0.1414, 0.1367, 0.1513, 0.1409, 0.1480],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998211860657
 
[Iteration 5] Process ID: 181441 [Epoch: 87, 20256/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 4 4
Policy data: tensor([0.1302, 0.1644, 0.1025, 0.1408, 0.3212, 0.1408, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.2805e-01, 1.6655e-01, 1.2125e-01, 1.1846e-01, 3.4797e-01, 1.1772e-01,
        1.9998e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 87, 27008/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 4 2
Policy data: tensor([0.1430, 0.1454, 0.1407, 0.1454, 0.1477, 0.1324, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1349, 0.1380, 0.1610, 0.1448, 0.1442, 0.1299, 0.1471],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 88,  6752/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 6 6
Policy data: tensor([0.0695, 0.1325, 0.0921, 0.1325, 0.2233, 0.0386, 0.3116],
       device='cuda:0')
Policy pred: tensor([0.0834, 0.1285, 0.0852, 0.1204, 0.2193, 0.0406, 0.3227],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 5] Process ID: 181441 [Epoch: 88, 13504/ 27057 points] total loss per batch: 2.035
Policy (actual, predicted): 4 4
Policy data: tensor([0.0795, 0.1260, 0.1051, 0.1151, 0.3243, 0.0541, 0.1958],
       device='cuda:0')
Policy pred: tensor([0.0901, 0.1751, 0.0951, 0.0923, 0.2915, 0.0611, 0.1948],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 88, 20256/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 6 6
Policy data: tensor([0.1465, 0.1407, 0.1442, 0.1419, 0.1477, 0.1301, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1432, 0.1400, 0.1470, 0.1413, 0.1464, 0.1310, 0.1511],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.006801311392337084
 
[Iteration 5] Process ID: 181441 [Epoch: 88, 27008/ 27057 points] total loss per batch: 2.045
Policy (actual, predicted): 2 4
Policy data: tensor([0.1489, 0.1395, 0.1512, 0.1372, 0.1465, 0.1336, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1430, 0.1442, 0.1412, 0.1416, 0.1495, 0.1323, 0.1483],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9930124282836914
 
[Iteration 5] Process ID: 181441 [Epoch: 89,  6752/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 0 4
Policy data: tensor([0.1524, 0.1360, 0.1407, 0.1419, 0.1477, 0.1407, 0.1407],
       device='cuda:0')
Policy pred: tensor([0.1401, 0.1441, 0.1412, 0.1434, 0.1516, 0.1388, 0.1407],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9894471764564514
 
[Iteration 5] Process ID: 181441 [Epoch: 89, 13504/ 27057 points] total loss per batch: 2.038
Policy (actual, predicted): 4 4
Policy data: tensor([0.1419, 0.1477, 0.1395, 0.1407, 0.1489, 0.1372, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1406, 0.1450, 0.1390, 0.1435, 0.1487, 0.1385, 0.1448],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.1402679681777954
 
[Iteration 5] Process ID: 181441 [Epoch: 89, 20256/ 27057 points] total loss per batch: 2.038
Policy (actual, predicted): 4 4
Policy data: tensor([0.1442, 0.1430, 0.1430, 0.1383, 0.1535, 0.1348, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1434, 0.1418, 0.1379, 0.1436, 0.1525, 0.1336, 0.1472],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9993392825126648
 
[Iteration 5] Process ID: 181441 [Epoch: 89, 27008/ 27057 points] total loss per batch: 2.040
Policy (actual, predicted): 6 6
Policy data: tensor([0.1237, 0.1031, 0.1031, 0.0709, 0.2279, 0.0531, 0.3181],
       device='cuda:0')
Policy pred: tensor([0.1208, 0.1033, 0.1072, 0.1189, 0.2065, 0.0395, 0.3039],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 90,  6752/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 6 6
Policy data: tensor([0.1157, 0.1388, 0.0875, 0.1055, 0.1659, 0.1518, 0.2349],
       device='cuda:0')
Policy pred: tensor([0.1114, 0.1450, 0.0935, 0.1371, 0.2041, 0.0921, 0.2168],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9997768402099609
 
[Iteration 5] Process ID: 181441 [Epoch: 90, 13504/ 27057 points] total loss per batch: 2.040
Policy (actual, predicted): 6 4
Policy data: tensor([0.1383, 0.1442, 0.1430, 0.1442, 0.1430, 0.1395, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1417, 0.1441, 0.1433, 0.1427, 0.1467, 0.1369, 0.1446],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.0897979810833931
 
[Iteration 5] Process ID: 181441 [Epoch: 90, 20256/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 6 6
Policy data: tensor([0.1937, 0.1487, 0.1034, 0.1487, 0.1359, 0.0584, 0.2112],
       device='cuda:0')
Policy pred: tensor([0.1791, 0.1593, 0.0860, 0.1671, 0.1620, 0.0565, 0.1901],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 90, 27008/ 27057 points] total loss per batch: 2.038
Policy (actual, predicted): 2 0
Policy data: tensor([0.1360, 0.1454, 0.1500, 0.1360, 0.1430, 0.1419, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1489, 0.1456, 0.1407, 0.1437, 0.1409, 0.1371, 0.1432],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 91,  6752/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 6 6
Policy data: tensor([0.1047, 0.1946, 0.1549, 0.0000, 0.1327, 0.0640, 0.3491],
       device='cuda:0')
Policy pred: tensor([8.4865e-02, 2.0360e-01, 1.9579e-01, 1.8136e-09, 1.4970e-01, 5.1980e-02,
        3.1406e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 91, 13504/ 27057 points] total loss per batch: 2.040
Policy (actual, predicted): 4 6
Policy data: tensor([0.0839, 0.1011, 0.1109, 0.0922, 0.2452, 0.1215, 0.2452],
       device='cuda:0')
Policy pred: tensor([0.0903, 0.1194, 0.1191, 0.1027, 0.2299, 0.0858, 0.2528],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 91, 20256/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 6 6
Policy data: tensor([0.1108, 0.1329, 0.1329, 0.1108, 0.1893, 0.0570, 0.2664],
       device='cuda:0')
Policy pred: tensor([0.0780, 0.1156, 0.1247, 0.1136, 0.1888, 0.0532, 0.3262],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 91, 27008/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 1 1
Policy data: tensor([0.1014, 0.2674, 0.2072, 0.0765, 0.1218, 0.0924, 0.1333],
       device='cuda:0')
Policy pred: tensor([0.0835, 0.2418, 0.1732, 0.0968, 0.1462, 0.1229, 0.1357],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 92,  6752/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 4 1
Policy data: tensor([0.1372, 0.1489, 0.1360, 0.1395, 0.1547, 0.1301, 0.1536],
       device='cuda:0')
Policy pred: tensor([0.1448, 0.1525, 0.1316, 0.1406, 0.1517, 0.1317, 0.1471],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 92, 13504/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 4 4
Policy data: tensor([0.1430, 0.1465, 0.1360, 0.1419, 0.1500, 0.1407, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1410, 0.1455, 0.1400, 0.1426, 0.1500, 0.1343, 0.1466],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.118418388068676
 
[Iteration 5] Process ID: 181441 [Epoch: 92, 20256/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 4 2
Policy data: tensor([0.1489, 0.1430, 0.1395, 0.1372, 0.1512, 0.1419, 0.1383],
       device='cuda:0')
Policy pred: tensor([0.1430, 0.1423, 0.1482, 0.1385, 0.1463, 0.1384, 0.1433],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999780058860779
 
[Iteration 5] Process ID: 181441 [Epoch: 92, 27008/ 27057 points] total loss per batch: 2.039
Policy (actual, predicted): 1 4
Policy data: tensor([0.1407, 0.1477, 0.1419, 0.1407, 0.1430, 0.1395, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1425, 0.1441, 0.1430, 0.1434, 0.1464, 0.1372, 0.1434],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.05023723095655441
 
[Iteration 5] Process ID: 181441 [Epoch: 93,  6752/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 6 6
Policy data: tensor([0.1384, 0.1512, 0.1372, 0.1442, 0.1431, 0.1289, 0.1570],
       device='cuda:0')
Policy pred: tensor([0.1363, 0.1471, 0.1414, 0.1410, 0.1520, 0.1301, 0.1521],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999918341636658
 
[Iteration 5] Process ID: 181441 [Epoch: 93, 13504/ 27057 points] total loss per batch: 2.046
Policy (actual, predicted): 6 6
Policy data: tensor([0.1430, 0.1442, 0.1419, 0.1407, 0.1477, 0.1325, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1418, 0.1412, 0.1451, 0.1396, 0.1491, 0.1323, 0.1510],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.13346874713897705
 
[Iteration 5] Process ID: 181441 [Epoch: 93, 20256/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 4 4
Policy data: tensor([0.0884, 0.1818, 0.0970, 0.1166, 0.3282, 0.0604, 0.1276],
       device='cuda:0')
Policy pred: tensor([0.1019, 0.1565, 0.1112, 0.1055, 0.3147, 0.0630, 0.1472],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 93, 27008/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 6 6
Policy data: tensor([0.1336, 0.1442, 0.1419, 0.1383, 0.1489, 0.1430, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1346, 0.1476, 0.1368, 0.1424, 0.1462, 0.1358, 0.1565],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 5] Process ID: 181441 [Epoch: 94,  6752/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 4 4
Policy data: tensor([0.1419, 0.1693, 0.0899, 0.0899, 0.2391, 0.0505, 0.2196],
       device='cuda:0')
Policy pred: tensor([0.1153, 0.1590, 0.0956, 0.0980, 0.2664, 0.0612, 0.2045],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 94, 13504/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 6 6
Policy data: tensor([0.1407, 0.1407, 0.1430, 0.1407, 0.1465, 0.1348, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1366, 0.1374, 0.1238, 0.1394, 0.1561, 0.1426, 0.1640],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999984502792358
 
[Iteration 5] Process ID: 181441 [Epoch: 94, 20256/ 27057 points] total loss per batch: 2.041
Policy (actual, predicted): 3 3
Policy data: tensor([0.1252, 0.2482, 0.0771, 0.2671, 0.0000, 0.0838, 0.1986],
       device='cuda:0')
Policy pred: tensor([1.1355e-01, 2.1832e-01, 9.9277e-02, 2.6197e-01, 1.9975e-06, 1.1357e-01,
        1.9331e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 94, 27008/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 4 4
Policy data: tensor([0.0620, 0.1432, 0.1196, 0.1309, 0.3103, 0.0907, 0.1432],
       device='cuda:0')
Policy pred: tensor([0.0729, 0.1524, 0.1030, 0.1387, 0.3054, 0.0816, 0.1460],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 95,  6752/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 3 3
Policy data: tensor([0.1676, 0.2607, 0.2163, 0.3132, 0.0000, 0.0421, 0.0000],
       device='cuda:0')
Policy pred: tensor([2.0107e-01, 2.3222e-01, 1.9674e-01, 2.9308e-01, 1.2440e-08, 7.6891e-02,
        1.5079e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 95, 13504/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 6 6
Policy data: tensor([0.1044, 0.1957, 0.0866, 0.1255, 0.1793, 0.0951, 0.2134],
       device='cuda:0')
Policy pred: tensor([0.0982, 0.1699, 0.1071, 0.1692, 0.1515, 0.0927, 0.2115],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 95, 20256/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 3 4
Policy data: tensor([0.1383, 0.1430, 0.1419, 0.1465, 0.1465, 0.1372, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1413, 0.1457, 0.1402, 0.1427, 0.1476, 0.1363, 0.1462],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.2947887182235718
 
[Iteration 5] Process ID: 181441 [Epoch: 95, 27008/ 27057 points] total loss per batch: 2.046
Policy (actual, predicted): 3 4
Policy data: tensor([0.0870, 0.1109, 0.1642, 0.2578, 0.2395, 0.1406, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.0168e-01, 7.5947e-02, 1.5307e-01, 2.1159e-01, 3.1782e-01, 1.3989e-01,
        4.6598e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 96,  6752/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 4 4
Policy data: tensor([0.1372, 0.1419, 0.1407, 0.1419, 0.1512, 0.1407, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1399, 0.1384, 0.1419, 0.1429, 0.1580, 0.1389, 0.1399],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9942278265953064
 
[Iteration 5] Process ID: 181441 [Epoch: 96, 13504/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 4 4
Policy data: tensor([0.1383, 0.1395, 0.1442, 0.1442, 0.1477, 0.1430, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1430, 0.1388, 0.1414, 0.1441, 0.1473, 0.1409, 0.1446],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.008927581831812859
 
[Iteration 5] Process ID: 181441 [Epoch: 96, 20256/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000, 0.0000, 0.2800, 0.0000, 0.3257, 0.1415, 0.2528],
       device='cuda:0')
Policy pred: tensor([1.9056e-06, 8.2822e-08, 2.9498e-01, 4.1178e-07, 3.6503e-01, 1.2560e-01,
        2.1439e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 96, 27008/ 27057 points] total loss per batch: 2.035
Policy (actual, predicted): 4 4
Policy data: tensor([0.0503, 0.1547, 0.0742, 0.1547, 0.2821, 0.1294, 0.1547],
       device='cuda:0')
Policy pred: tensor([0.0533, 0.1818, 0.0688, 0.1473, 0.2588, 0.1334, 0.1566],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 97,  6752/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 5 6
Policy data: tensor([0.0680, 0.0000, 0.1304, 0.1778, 0.1778, 0.2230, 0.2230],
       device='cuda:0')
Policy pred: tensor([7.2322e-02, 1.4984e-06, 1.3597e-01, 1.7279e-01, 2.1547e-01, 1.7898e-01,
        2.2448e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 97, 13504/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 4 1
Policy data: tensor([0.1407, 0.1442, 0.1395, 0.1442, 0.1454, 0.1419, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1411, 0.1464, 0.1422, 0.1420, 0.1463, 0.1382, 0.1437],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.028222238644957542
 
[Iteration 5] Process ID: 181441 [Epoch: 97, 20256/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 4 6
Policy data: tensor([0.1430, 0.1395, 0.1466, 0.1407, 0.1524, 0.1289, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1403, 0.1388, 0.1454, 0.1445, 0.1446, 0.1307, 0.1557],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9984185695648193
 
[Iteration 5] Process ID: 181441 [Epoch: 97, 27008/ 27057 points] total loss per batch: 2.041
Policy (actual, predicted): 4 4
Policy data: tensor([0.1762, 0.2209, 0.1632, 0.1102, 0.2562, 0.0733, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.5380e-01, 2.3993e-01, 1.3647e-01, 1.3351e-01, 2.4907e-01, 8.7224e-02,
        2.4497e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 98,  6752/ 27057 points] total loss per batch: 2.038
Policy (actual, predicted): 6 6
Policy data: tensor([0.1407, 0.1465, 0.1454, 0.1372, 0.1489, 0.1313, 0.1501],
       device='cuda:0')
Policy pred: tensor([0.1425, 0.1426, 0.1413, 0.1409, 0.1492, 0.1326, 0.1508],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.002672038273885846
 
[Iteration 5] Process ID: 181441 [Epoch: 98, 13504/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 0 0
Policy data: tensor([0.2412, 0.1864, 0.0995, 0.0751, 0.1708, 0.0562, 0.1708],
       device='cuda:0')
Policy pred: tensor([0.2140, 0.1651, 0.1190, 0.0944, 0.1886, 0.0497, 0.1691],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 98, 20256/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 4 4
Policy data: tensor([0.1656, 0.1265, 0.1515, 0.0960, 0.2345, 0.0874, 0.1385],
       device='cuda:0')
Policy pred: tensor([0.1884, 0.1385, 0.1445, 0.0874, 0.2036, 0.0824, 0.1552],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 98, 27008/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 4 4
Policy data: tensor([0.1291, 0.0897, 0.0984, 0.0615, 0.3871, 0.0507, 0.1834],
       device='cuda:0')
Policy pred: tensor([0.1158, 0.1139, 0.0843, 0.0526, 0.3605, 0.0393, 0.2336],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 99,  6752/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 4 4
Policy data: tensor([0.1422, 0.1422, 0.0746, 0.1084, 0.3344, 0.0900, 0.1084],
       device='cuda:0')
Policy pred: tensor([0.1306, 0.1363, 0.1182, 0.1247, 0.3118, 0.0757, 0.1026],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 99, 13504/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 6 6
Policy data: tensor([0.1419, 0.1395, 0.1360, 0.1395, 0.1477, 0.1395, 0.1559],
       device='cuda:0')
Policy pred: tensor([0.1399, 0.1292, 0.1343, 0.1413, 0.1473, 0.1420, 0.1660],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 99, 20256/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 6 4
Policy data: tensor([0.1501, 0.1454, 0.1419, 0.1395, 0.1430, 0.1277, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1529, 0.1517, 0.1469, 0.1337, 0.1555, 0.1057, 0.1535],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 99, 27008/ 27057 points] total loss per batch: 2.041
Policy (actual, predicted): 3 4
Policy data: tensor([0.1465, 0.1407, 0.1442, 0.1477, 0.1442, 0.1336, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1430, 0.1429, 0.1399, 0.1420, 0.1478, 0.1389, 0.1456],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.17222340404987335
 
[Iteration 5] Process ID: 181441 [Epoch: 100,  6752/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 3 1
Policy data: tensor([0.1383, 0.1442, 0.1442, 0.1500, 0.1454, 0.1336, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1299, 0.1641, 0.1393, 0.1302, 0.1497, 0.1378, 0.1489],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999982118606567
 
[Iteration 5] Process ID: 181441 [Epoch: 100, 13504/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 4 4
Policy data: tensor([0.1466, 0.1395, 0.1384, 0.1430, 0.1524, 0.1277, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1437, 0.1411, 0.1445, 0.1398, 0.1510, 0.1309, 0.1490],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9993709921836853
 
[Iteration 5] Process ID: 181441 [Epoch: 100, 20256/ 27057 points] total loss per batch: 2.035
Policy (actual, predicted): 0 0
Policy data: tensor([0.2785, 0.0885, 0.1065, 0.0733, 0.2561, 0.0805, 0.1167],
       device='cuda:0')
Policy pred: tensor([0.2381, 0.1310, 0.1086, 0.0881, 0.2172, 0.0857, 0.1313],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 100, 27008/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 6 6
Policy data: tensor([0.1383, 0.1442, 0.1395, 0.1442, 0.1477, 0.1348, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1410, 0.1493, 0.1367, 0.1504, 0.1379, 0.1263, 0.1584],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 101,  6752/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 4 4
Policy data: tensor([0.1396, 0.1527, 0.1062, 0.1062, 0.2364, 0.1062, 0.1527],
       device='cuda:0')
Policy pred: tensor([0.1771, 0.1606, 0.1310, 0.0966, 0.2135, 0.0906, 0.1307],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999993443489075
 
[Iteration 5] Process ID: 181441 [Epoch: 101, 13504/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 4 4
Policy data: tensor([0.1611, 0.1347, 0.1123, 0.1347, 0.2702, 0.0638, 0.1231],
       device='cuda:0')
Policy pred: tensor([0.1337, 0.1569, 0.1085, 0.1369, 0.2382, 0.0749, 0.1509],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 101, 20256/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 6 4
Policy data: tensor([0.1430, 0.1430, 0.1430, 0.1348, 0.1419, 0.1442, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1424, 0.1423, 0.1453, 0.1348, 0.1486, 0.1426, 0.1440],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999921917915344
 
[Iteration 5] Process ID: 181441 [Epoch: 101, 27008/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 1 1
Policy data: tensor([0.0632, 0.2781, 0.1783, 0.2781, 0.0000, 0.0811, 0.1212],
       device='cuda:0')
Policy pred: tensor([7.6365e-02, 2.7222e-01, 1.8565e-01, 2.4731e-01, 1.8646e-06, 8.7238e-02,
        1.3122e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 102,  6752/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 2 2
Policy data: tensor([0.1080, 0.1296, 0.2388, 0.0743, 0.1549, 0.0556, 0.2388],
       device='cuda:0')
Policy pred: tensor([0.1183, 0.1265, 0.2147, 0.1091, 0.1762, 0.0532, 0.2021],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 102, 13504/ 27057 points] total loss per batch: 2.035
Policy (actual, predicted): 4 4
Policy data: tensor([0.1936, 0.1624, 0.0857, 0.0941, 0.2300, 0.0857, 0.1486],
       device='cuda:0')
Policy pred: tensor([0.1970, 0.1590, 0.0935, 0.0953, 0.2228, 0.0803, 0.1521],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 102, 20256/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 6 6
Policy data: tensor([0.1122, 0.1230, 0.1230, 0.0849, 0.1609, 0.1024, 0.2936],
       device='cuda:0')
Policy pred: tensor([0.1119, 0.1350, 0.1167, 0.1004, 0.1679, 0.0904, 0.2778],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 102, 27008/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 6 6
Policy data: tensor([0.0808, 0.1170, 0.1170, 0.1401, 0.1068, 0.0808, 0.3575],
       device='cuda:0')
Policy pred: tensor([0.1077, 0.1392, 0.1122, 0.1328, 0.1340, 0.0813, 0.2928],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 103,  6752/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 4 1
Policy data: tensor([0.1442, 0.1430, 0.1407, 0.1407, 0.1536, 0.1277, 0.1501],
       device='cuda:0')
Policy pred: tensor([0.1500, 0.1500, 0.1453, 0.1343, 0.1464, 0.1273, 0.1467],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 103, 13504/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 4 4
Policy data: tensor([0.0931, 0.1915, 0.0771, 0.1344, 0.2276, 0.0848, 0.1915],
       device='cuda:0')
Policy pred: tensor([0.0996, 0.1976, 0.0717, 0.1825, 0.2013, 0.0807, 0.1666],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 103, 20256/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 6 6
Policy data: tensor([0.1148, 0.2288, 0.1452, 0.1452, 0.0000, 0.0596, 0.3064],
       device='cuda:0')
Policy pred: tensor([1.1645e-01, 2.2691e-01, 1.5323e-01, 1.3567e-01, 5.3444e-07, 7.2011e-02,
        2.9573e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 103, 27008/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 6 6
Policy data: tensor([0.1419, 0.1383, 0.1383, 0.1419, 0.1512, 0.1325, 0.1559],
       device='cuda:0')
Policy pred: tensor([0.1437, 0.1348, 0.1438, 0.1429, 0.1520, 0.1287, 0.1541],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 104,  6752/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 3 4
Policy data: tensor([0.1419, 0.1395, 0.1442, 0.1465, 0.1442, 0.1407, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1403, 0.1432, 0.1422, 0.1426, 0.1489, 0.1380, 0.1448],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -8.93427204573527e-05
 
[Iteration 5] Process ID: 181441 [Epoch: 104, 13504/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 6 6
Policy data: tensor([0.1477, 0.1407, 0.1395, 0.1430, 0.1454, 0.1313, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1444, 0.1409, 0.1390, 0.1443, 0.1479, 0.1313, 0.1521],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.0644429475069046
 
[Iteration 5] Process ID: 181441 [Epoch: 104, 20256/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 1 1
Policy data: tensor([0.0680, 0.2617, 0.2027, 0.1560, 0.0618, 0.1305, 0.1192],
       device='cuda:0')
Policy pred: tensor([0.0725, 0.2970, 0.1938, 0.1417, 0.0634, 0.1297, 0.1019],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 104, 27008/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 6 6
Policy data: tensor([0.1395, 0.1454, 0.1407, 0.1395, 0.1442, 0.1383, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1457, 0.1543, 0.1373, 0.1256, 0.1486, 0.1212, 0.1672],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 105,  6752/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 6 6
Policy data: tensor([0.1074, 0.1409, 0.1540, 0.1074, 0.1682, 0.0410, 0.2810],
       device='cuda:0')
Policy pred: tensor([0.1029, 0.1474, 0.1621, 0.1148, 0.2020, 0.0354, 0.2354],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 105, 13504/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 6 6
Policy data: tensor([0.1383, 0.1466, 0.1454, 0.1372, 0.1466, 0.1313, 0.1547],
       device='cuda:0')
Policy pred: tensor([0.1417, 0.1419, 0.1422, 0.1423, 0.1483, 0.1340, 0.1495],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.0019945811945945024
 
[Iteration 5] Process ID: 181441 [Epoch: 105, 20256/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 6 6
Policy data: tensor([0.1027, 0.1232, 0.0707, 0.1347, 0.2085, 0.0434, 0.3169],
       device='cuda:0')
Policy pred: tensor([0.0940, 0.1207, 0.0722, 0.1181, 0.2167, 0.0356, 0.3426],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 105, 27008/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 6 6
Policy data: tensor([0.1454, 0.1454, 0.1329, 0.1736, 0.1108, 0.0468, 0.2450],
       device='cuda:0')
Policy pred: tensor([0.1327, 0.1193, 0.1455, 0.1412, 0.1610, 0.0543, 0.2460],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 106,  6752/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 4 4
Policy data: tensor([0.0919, 0.1327, 0.1212, 0.0837, 0.2894, 0.1891, 0.0919],
       device='cuda:0')
Policy pred: tensor([0.0907, 0.1106, 0.1200, 0.0788, 0.2888, 0.2179, 0.0933],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 106, 13504/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 4 4
Policy data: tensor([0.1442, 0.1372, 0.1430, 0.1419, 0.1477, 0.1407, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1415, 0.1425, 0.1423, 0.1437, 0.1473, 0.1379, 0.1447],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.01886451244354248
 
[Iteration 5] Process ID: 181441 [Epoch: 106, 20256/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 3 3
Policy data: tensor([0.1918, 0.0000, 0.0000, 0.7043, 0.0000, 0.1039, 0.0000],
       device='cuda:0')
Policy pred: tensor([2.0991e-01, 1.4878e-06, 1.9506e-07, 6.9368e-01, 6.1648e-09, 9.6405e-02,
        2.5539e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 106, 27008/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 1 1
Policy data: tensor([0.1371, 0.2175, 0.1483, 0.1731, 0.0000, 0.1371, 0.1869],
       device='cuda:0')
Policy pred: tensor([1.4529e-01, 2.0342e-01, 1.3303e-01, 1.8161e-01, 8.2935e-06, 1.4276e-01,
        1.9389e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 107,  6752/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1419, 0.1442, 0.1383, 0.1535, 0.1395, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1408, 0.1442, 0.1412, 0.1418, 0.1470, 0.1416, 0.1435],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.36425095796585083
 
[Iteration 5] Process ID: 181441 [Epoch: 107, 13504/ 27057 points] total loss per batch: 2.013
Policy (actual, predicted): 6 6
Policy data: tensor([0.1348, 0.1430, 0.1489, 0.1419, 0.1501, 0.1301, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1294, 0.1367, 0.1456, 0.1457, 0.1486, 0.1264, 0.1675],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 107, 20256/ 27057 points] total loss per batch: 2.038
Policy (actual, predicted): 6 6
Policy data: tensor([0.1395, 0.1442, 0.1430, 0.1383, 0.1454, 0.1395, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1370, 0.1356, 0.1416, 0.1490, 0.1397, 0.1439, 0.1532],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9998987913131714
 
[Iteration 5] Process ID: 181441 [Epoch: 107, 27008/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 6 6
Policy data: tensor([0.0857, 0.1237, 0.0857, 0.1353, 0.1762, 0.0481, 0.3453],
       device='cuda:0')
Policy pred: tensor([0.0938, 0.1116, 0.0727, 0.1254, 0.1854, 0.0464, 0.3647],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 108,  6752/ 27057 points] total loss per batch: 2.013
Policy (actual, predicted): 4 2
Policy data: tensor([0.1430, 0.1419, 0.1407, 0.1407, 0.1500, 0.1372, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1457, 0.1335, 0.1570, 0.1390, 0.1478, 0.1314, 0.1456],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998217225074768
 
[Iteration 5] Process ID: 181441 [Epoch: 108, 13504/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 4 4
Policy data: tensor([0.1724, 0.1445, 0.1445, 0.0833, 0.2880, 0.0758, 0.0915],
       device='cuda:0')
Policy pred: tensor([0.1725, 0.1524, 0.1188, 0.0772, 0.2791, 0.0946, 0.1054],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 108, 20256/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 4 1
Policy data: tensor([0.1419, 0.1465, 0.1395, 0.1395, 0.1489, 0.1348, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1288, 0.1521, 0.1449, 0.1386, 0.1493, 0.1377, 0.1485],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 108, 27008/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 6 6
Policy data: tensor([0.0810, 0.1284, 0.1284, 0.0976, 0.1676, 0.0669, 0.3302],
       device='cuda:0')
Policy pred: tensor([0.0741, 0.1381, 0.1262, 0.1274, 0.1547, 0.0753, 0.3041],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 109,  6752/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 6 6
Policy data: tensor([0.0574, 0.1326, 0.0922, 0.1107, 0.2431, 0.0520, 0.3119],
       device='cuda:0')
Policy pred: tensor([0.0566, 0.1285, 0.0880, 0.1202, 0.2336, 0.0618, 0.3112],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 109, 13504/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 6 4
Policy data: tensor([0.1348, 0.1442, 0.1466, 0.1430, 0.1477, 0.1289, 0.1547],
       device='cuda:0')
Policy pred: tensor([0.1402, 0.1418, 0.1442, 0.1406, 0.1504, 0.1332, 0.1496],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 109, 20256/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 6 6
Policy data: tensor([0.0892, 0.0000, 0.1675, 0.0892, 0.2621, 0.0892, 0.3029],
       device='cuda:0')
Policy pred: tensor([9.9585e-02, 5.3038e-09, 1.5255e-01, 9.4712e-02, 2.6566e-01, 7.3883e-02,
        3.1361e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 109, 27008/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 4 4
Policy data: tensor([0.1465, 0.1372, 0.1407, 0.1477, 0.1535, 0.1336, 0.1407],
       device='cuda:0')
Policy pred: tensor([0.1451, 0.1414, 0.1458, 0.1416, 0.1458, 0.1377, 0.1427],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9673171043395996
 
[Iteration 5] Process ID: 181441 [Epoch: 110,  6752/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 6 4
Policy data: tensor([0.1348, 0.1454, 0.1442, 0.1407, 0.1536, 0.1254, 0.1559],
       device='cuda:0')
Policy pred: tensor([0.1413, 0.1418, 0.1410, 0.1410, 0.1514, 0.1324, 0.1511],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9517929553985596
 
[Iteration 5] Process ID: 181441 [Epoch: 110, 13504/ 27057 points] total loss per batch: 2.019
Policy (actual, predicted): 3 3
Policy data: tensor([0.2146, 0.0000, 0.0773, 0.2677, 0.1846, 0.0712, 0.1846],
       device='cuda:0')
Policy pred: tensor([1.7193e-01, 1.4067e-07, 9.1117e-02, 2.9058e-01, 1.6890e-01, 8.1493e-02,
        1.9598e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 110, 20256/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 4 4
Policy data: tensor([0.0635, 0.1218, 0.2062, 0.1218, 0.2657, 0.0316, 0.1893],
       device='cuda:0')
Policy pred: tensor([0.0802, 0.1150, 0.1914, 0.1196, 0.2540, 0.0391, 0.2006],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 110, 27008/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 4 0
Policy data: tensor([0.2305, 0.1251, 0.1068, 0.1580, 0.3086, 0.0710, 0.0000],
       device='cuda:0')
Policy pred: tensor([2.7699e-01, 1.1063e-01, 1.2051e-01, 1.7721e-01, 2.5192e-01, 6.2731e-02,
        1.1737e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 111,  6752/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 2 1
Policy data: tensor([0.0916, 0.2157, 0.2691, 0.2157, 0.0000, 0.0715, 0.1364],
       device='cuda:0')
Policy pred: tensor([1.3797e-01, 2.3783e-01, 2.2474e-01, 1.9026e-01, 1.3114e-06, 7.6232e-02,
        1.3298e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 111, 13504/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 4 4
Policy data: tensor([0.0693, 0.1444, 0.1721, 0.1007, 0.3657, 0.0470, 0.1007],
       device='cuda:0')
Policy pred: tensor([0.0737, 0.1337, 0.1511, 0.0954, 0.3943, 0.0495, 0.1024],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 111, 20256/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 6 6
Policy data: tensor([0.1383, 0.1395, 0.1465, 0.1395, 0.1501, 0.1336, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1424, 0.1396, 0.1477, 0.1395, 0.1477, 0.1317, 0.1514],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.02634163200855255
 
[Iteration 5] Process ID: 181441 [Epoch: 111, 27008/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000, 0.2330, 0.1169, 0.1598, 0.2699, 0.0607, 0.1598],
       device='cuda:0')
Policy pred: tensor([7.4482e-08, 2.5491e-01, 1.1628e-01, 1.3503e-01, 2.7928e-01, 5.9328e-02,
        1.5517e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 112,  6752/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 2 6
Policy data: tensor([0.1442, 0.1407, 0.1489, 0.1372, 0.1489, 0.1313, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1420, 0.1394, 0.1470, 0.1377, 0.1465, 0.1329, 0.1545],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.13749061524868011
 
[Iteration 5] Process ID: 181441 [Epoch: 112, 13504/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 6 6
Policy data: tensor([0.1330, 0.1455, 0.1215, 0.1215, 0.2066, 0.0468, 0.2251],
       device='cuda:0')
Policy pred: tensor([0.1467, 0.1569, 0.1523, 0.1257, 0.1840, 0.0414, 0.1930],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 112, 20256/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 4 4
Policy data: tensor([0.1705, 0.1561, 0.1089, 0.0749, 0.2848, 0.0618, 0.1429],
       device='cuda:0')
Policy pred: tensor([0.1489, 0.1538, 0.1250, 0.1178, 0.2537, 0.0726, 0.1283],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 112, 27008/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 3 4
Policy data: tensor([0.0767, 0.1337, 0.1462, 0.2263, 0.2077, 0.0633, 0.1462],
       device='cuda:0')
Policy pred: tensor([0.0847, 0.1531, 0.1458, 0.2094, 0.2263, 0.0424, 0.1383],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 113,  6752/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 4 6
Policy data: tensor([0.1395, 0.1407, 0.1372, 0.1442, 0.1524, 0.1372, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1385, 0.1394, 0.1385, 0.1428, 0.1489, 0.1385, 0.1533],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9950659871101379
 
[Iteration 5] Process ID: 181441 [Epoch: 113, 13504/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 4 4
Policy data: tensor([0.1254, 0.1477, 0.1407, 0.1442, 0.1547, 0.1395, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1212, 0.1480, 0.1388, 0.1418, 0.1565, 0.1454, 0.1482],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9983267188072205
 
[Iteration 5] Process ID: 181441 [Epoch: 113, 20256/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 4 4
Policy data: tensor([0.1430, 0.1407, 0.1360, 0.1407, 0.1524, 0.1372, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1526, 0.1227, 0.1467, 0.1363, 0.1582, 0.1513, 0.1324],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999990463256836
 
[Iteration 5] Process ID: 181441 [Epoch: 113, 27008/ 27057 points] total loss per batch: 2.035
Policy (actual, predicted): 6 6
Policy data: tensor([0.1213, 0.0000, 0.0814, 0.1036, 0.1779, 0.0636, 0.4521],
       device='cuda:0')
Policy pred: tensor([1.0419e-01, 1.5223e-07, 9.9092e-02, 1.2353e-01, 1.8909e-01, 6.4988e-02,
        4.1910e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 5] Process ID: 181441 [Epoch: 114,  6752/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 1 1
Policy data: tensor([0.1013, 0.3890, 0.0862, 0.1884, 0.1619, 0.0732, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.4016e-01, 3.2683e-01, 8.3814e-02, 2.1780e-01, 1.5364e-01, 7.7736e-02,
        1.6036e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 114, 13504/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 4 4
Policy data: tensor([0.1454, 0.1407, 0.1395, 0.1383, 0.1535, 0.1419, 0.1407],
       device='cuda:0')
Policy pred: tensor([0.1403, 0.1446, 0.1397, 0.1430, 0.1486, 0.1394, 0.1444],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.06070135906338692
 
[Iteration 5] Process ID: 181441 [Epoch: 114, 20256/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 6 6
Policy data: tensor([0.0943, 0.1135, 0.1135, 0.1244, 0.1777, 0.1035, 0.2730],
       device='cuda:0')
Policy pred: tensor([0.1063, 0.1245, 0.1262, 0.1248, 0.1703, 0.0903, 0.2577],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 114, 27008/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 6 6
Policy data: tensor([0.1348, 0.1465, 0.1407, 0.1383, 0.1465, 0.1407, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1074, 0.1863, 0.1236, 0.1239, 0.1484, 0.1230, 0.1873],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 115,  6752/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 2 6
Policy data: tensor([0.1442, 0.1430, 0.1465, 0.1442, 0.1407, 0.1348, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1415, 0.1426, 0.1389, 0.1405, 0.1500, 0.1356, 0.1509],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999994039535522
 
[Iteration 5] Process ID: 181441 [Epoch: 115, 13504/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 6 6
Policy data: tensor([0.0792, 0.1500, 0.0720, 0.1046, 0.2313, 0.0654, 0.2974],
       device='cuda:0')
Policy pred: tensor([0.0858, 0.1637, 0.0817, 0.0826, 0.2192, 0.0609, 0.3061],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 115, 20256/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 2 6
Policy data: tensor([0.1442, 0.1419, 0.1512, 0.1383, 0.1512, 0.1289, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1438, 0.1399, 0.1454, 0.1409, 0.1461, 0.1337, 0.1503],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.054991014301776886
 
[Iteration 5] Process ID: 181441 [Epoch: 115, 27008/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 6 6
Policy data: tensor([0.2043, 0.0754, 0.1000, 0.1096, 0.1717, 0.0754, 0.2637],
       device='cuda:0')
Policy pred: tensor([0.1870, 0.0927, 0.1132, 0.0985, 0.1694, 0.0615, 0.2777],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 116,  6752/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 6 4
Policy data: tensor([0.1395, 0.1454, 0.1395, 0.1407, 0.1465, 0.1407, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1395, 0.1438, 0.1418, 0.1405, 0.1483, 0.1414, 0.1447],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.2254757136106491
 
[Iteration 5] Process ID: 181441 [Epoch: 116, 13504/ 27057 points] total loss per batch: 2.019
Policy (actual, predicted): 0 0
Policy data: tensor([0.2306, 0.1136, 0.1036, 0.0710, 0.1941, 0.1244, 0.1628],
       device='cuda:0')
Policy pred: tensor([0.2255, 0.1525, 0.0879, 0.0724, 0.1776, 0.1052, 0.1790],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 116, 20256/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 4 4
Policy data: tensor([0.1302, 0.2204, 0.1556, 0.0559, 0.2399, 0.0679, 0.1302],
       device='cuda:0')
Policy pred: tensor([0.1217, 0.1911, 0.1497, 0.0685, 0.2534, 0.0749, 0.1408],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 116, 27008/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 6 6
Policy data: tensor([0.1360, 0.1466, 0.1419, 0.1419, 0.1489, 0.1289, 0.1559],
       device='cuda:0')
Policy pred: tensor([0.1433, 0.1441, 0.1415, 0.1406, 0.1494, 0.1312, 0.1500],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.937208354473114
 
[Iteration 5] Process ID: 181441 [Epoch: 117,  6752/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 6 6
Policy data: tensor([0.1117, 0.1224, 0.0634, 0.1749, 0.2081, 0.0928, 0.2268],
       device='cuda:0')
Policy pred: tensor([0.1194, 0.1242, 0.0875, 0.1724, 0.1842, 0.0745, 0.2378],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 117, 13504/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 4 4
Policy data: tensor([0.1357, 0.1485, 0.0642, 0.1357, 0.2109, 0.0940, 0.2109],
       device='cuda:0')
Policy pred: tensor([0.1273, 0.1696, 0.0764, 0.1208, 0.2057, 0.0978, 0.2024],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 117, 20256/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 6 6
Policy data: tensor([0.1442, 0.1383, 0.1477, 0.1395, 0.1465, 0.1325, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1434, 0.1410, 0.1453, 0.1415, 0.1477, 0.1312, 0.1499],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.000669279950670898
 
[Iteration 5] Process ID: 181441 [Epoch: 117, 27008/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 4 4
Policy data: tensor([0.1045, 0.1318, 0.0548, 0.0000, 0.4775, 0.0251, 0.2062],
       device='cuda:0')
Policy pred: tensor([1.0153e-01, 1.2764e-01, 6.6580e-02, 3.0198e-08, 4.4936e-01, 4.2820e-02,
        2.1206e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 118,  6752/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 6 6
Policy data: tensor([0.1442, 0.1442, 0.1419, 0.1407, 0.1442, 0.1360, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1435, 0.1451, 0.1370, 0.1352, 0.1485, 0.1324, 0.1583],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999997615814209
 
[Iteration 5] Process ID: 181441 [Epoch: 118, 13504/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1442, 0.1407, 0.1407, 0.1465, 0.1419, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1403, 0.1453, 0.1413, 0.1413, 0.1469, 0.1406, 0.1442],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9936517477035522
 
[Iteration 5] Process ID: 181441 [Epoch: 118, 20256/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 5 5
Policy data: tensor([0.0768, 0.0000, 0.0667, 0.1941, 0.2343, 0.4280, 0.0000],
       device='cuda:0')
Policy pred: tensor([7.6802e-02, 2.5677e-13, 7.1254e-02, 1.7360e-01, 2.3223e-01, 4.4611e-01,
        2.6799e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 118, 27008/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 4 4
Policy data: tensor([0.1480, 0.1353, 0.1128, 0.1029, 0.2951, 0.1029, 0.1029],
       device='cuda:0')
Policy pred: tensor([0.1619, 0.1378, 0.0994, 0.0825, 0.2856, 0.1075, 0.1253],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 119,  6752/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 4 4
Policy data: tensor([0.1922, 0.1124, 0.0934, 0.0851, 0.2705, 0.1232, 0.1232],
       device='cuda:0')
Policy pred: tensor([0.1665, 0.1304, 0.0971, 0.0997, 0.2531, 0.1328, 0.1204],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 119, 13504/ 27057 points] total loss per batch: 2.017
Policy (actual, predicted): 0 6
Policy data: tensor([0.2050, 0.1723, 0.0625, 0.0757, 0.2050, 0.0914, 0.1880],
       device='cuda:0')
Policy pred: tensor([0.1972, 0.1594, 0.0791, 0.0811, 0.2066, 0.0659, 0.2107],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999979734420776
 
[Iteration 5] Process ID: 181441 [Epoch: 119, 20256/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 0 0
Policy data: tensor([0.2348, 0.1387, 0.0961, 0.1267, 0.1811, 0.0961, 0.1267],
       device='cuda:0')
Policy pred: tensor([0.2639, 0.1170, 0.0900, 0.1235, 0.1856, 0.1021, 0.1180],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 119, 27008/ 27057 points] total loss per batch: 2.035
Policy (actual, predicted): 4 4
Policy data: tensor([0.1442, 0.1430, 0.1383, 0.1430, 0.1477, 0.1419, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1412, 0.1422, 0.1430, 0.1414, 0.1471, 0.1389, 0.1462],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9210412502288818
 
[Iteration 5] Process ID: 181441 [Epoch: 120,  6752/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 1 4
Policy data: tensor([0.1125, 0.2096, 0.1232, 0.1125, 0.1922, 0.0579, 0.1922],
       device='cuda:0')
Policy pred: tensor([0.1227, 0.1661, 0.1681, 0.1181, 0.1859, 0.0599, 0.1792],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 120, 13504/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 6 6
Policy data: tensor([0.0824, 0.1194, 0.0681, 0.1562, 0.2212, 0.0905, 0.2621],
       device='cuda:0')
Policy pred: tensor([0.0958, 0.1274, 0.0821, 0.1467, 0.2184, 0.0985, 0.2311],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9996238946914673
 
[Iteration 5] Process ID: 181441 [Epoch: 120, 20256/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 6 4
Policy data: tensor([0.1465, 0.1430, 0.1395, 0.1407, 0.1465, 0.1325, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1558, 0.1489, 0.1272, 0.1394, 0.1653, 0.1271, 0.1364],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 120, 27008/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 6 2
Policy data: tensor([0.1466, 0.1407, 0.1348, 0.1384, 0.1489, 0.1336, 0.1570],
       device='cuda:0')
Policy pred: tensor([0.1426, 0.1338, 0.1523, 0.1509, 0.1443, 0.1253, 0.1508],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999983310699463
 
[Iteration 5] Process ID: 181441 [Epoch: 121,  6752/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 4 4
Policy data: tensor([0.0732, 0.1983, 0.1983, 0.0548, 0.2353, 0.0732, 0.1667],
       device='cuda:0')
Policy pred: tensor([0.0969, 0.1847, 0.1722, 0.0804, 0.2161, 0.0730, 0.1768],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 121, 13504/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 0 0
Policy data: tensor([0.1843, 0.1290, 0.0890, 0.1412, 0.1544, 0.1177, 0.1843],
       device='cuda:0')
Policy pred: tensor([0.2249, 0.1049, 0.0749, 0.1446, 0.1551, 0.1040, 0.1917],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 121, 20256/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 6 6
Policy data: tensor([0.1395, 0.1407, 0.1477, 0.1372, 0.1489, 0.1336, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1404, 0.1422, 0.1440, 0.1411, 0.1503, 0.1302, 0.1518],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.16706202924251556
 
[Iteration 5] Process ID: 181441 [Epoch: 121, 27008/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 6 6
Policy data: tensor([0.1036, 0.1036, 0.0537, 0.1036, 0.2274, 0.0361, 0.3720],
       device='cuda:0')
Policy pred: tensor([0.1026, 0.1052, 0.0918, 0.1100, 0.2294, 0.0357, 0.3253],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 122,  6752/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 6 6
Policy data: tensor([0.1372, 0.1466, 0.1407, 0.1395, 0.1489, 0.1313, 0.1559],
       device='cuda:0')
Policy pred: tensor([0.1399, 0.1431, 0.1418, 0.1416, 0.1495, 0.1336, 0.1504],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9974785447120667
 
[Iteration 5] Process ID: 181441 [Epoch: 122, 13504/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1442, 0.1407, 0.1430, 0.1489, 0.1360, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1401, 0.1444, 0.1462, 0.1409, 0.1477, 0.1365, 0.1441],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9954941272735596
 
[Iteration 5] Process ID: 181441 [Epoch: 122, 20256/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 4 1
Policy data: tensor([0.1667, 0.1820, 0.1394, 0.1060, 0.1986, 0.0800, 0.1273],
       device='cuda:0')
Policy pred: tensor([0.1676, 0.1997, 0.1257, 0.0928, 0.1882, 0.0762, 0.1497],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999997615814209
 
[Iteration 5] Process ID: 181441 [Epoch: 122, 27008/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 4 4
Policy data: tensor([0.1407, 0.1419, 0.1395, 0.1395, 0.1512, 0.1407, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1439, 0.1443, 0.1403, 0.1394, 0.1459, 0.1403, 0.1458],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9099838733673096
 
[Iteration 5] Process ID: 181441 [Epoch: 123,  6752/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 6 6
Policy data: tensor([0.1419, 0.1419, 0.1407, 0.1407, 0.1489, 0.1336, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1445, 0.1419, 0.1416, 0.1423, 0.1485, 0.1323, 0.1489],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.00016884945216588676
 
[Iteration 5] Process ID: 181441 [Epoch: 123, 13504/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 4 6
Policy data: tensor([0.1372, 0.1372, 0.1489, 0.1372, 0.1512, 0.1407, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1410, 0.1420, 0.1436, 0.1398, 0.1489, 0.1329, 0.1519],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.1596951186656952
 
[Iteration 5] Process ID: 181441 [Epoch: 123, 20256/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 2 3
Policy data: tensor([0.1689, 0.2051, 0.2482, 0.2482, 0.0000, 0.1296, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.8218e-01, 1.7458e-01, 2.5459e-01, 2.6274e-01, 5.3506e-05, 1.2581e-01,
        4.3309e-05], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 123, 27008/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 4 6
Policy data: tensor([0.1419, 0.1419, 0.1454, 0.1348, 0.1500, 0.1360, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1467, 0.1366, 0.1386, 0.1399, 0.1448, 0.1350, 0.1584],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9641208052635193
 
[Iteration 5] Process ID: 181441 [Epoch: 124,  6752/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 2 2
Policy data: tensor([0.1527, 0.0000, 0.5575, 0.0000, 0.0000, 0.1372, 0.1527],
       device='cuda:0')
Policy pred: tensor([1.8589e-01, 2.8763e-09, 5.1415e-01, 1.2546e-06, 6.8087e-07, 1.5310e-01,
        1.4686e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 124, 13504/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 6 6
Policy data: tensor([0.0844, 0.1116, 0.1339, 0.1339, 0.1908, 0.0768, 0.2685],
       device='cuda:0')
Policy pred: tensor([0.0926, 0.1172, 0.1297, 0.1516, 0.2111, 0.0555, 0.2423],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 124, 20256/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 6 6
Policy data: tensor([0.1395, 0.1407, 0.1501, 0.1442, 0.1466, 0.1277, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1443, 0.1396, 0.1479, 0.1401, 0.1458, 0.1306, 0.1517],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.0015518144937232137
 
[Iteration 5] Process ID: 181441 [Epoch: 124, 27008/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 4 4
Policy data: tensor([0.0436, 0.1237, 0.1032, 0.0941, 0.2932, 0.0941, 0.2482],
       device='cuda:0')
Policy pred: tensor([0.0692, 0.1243, 0.0973, 0.0811, 0.2877, 0.0760, 0.2643],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 125,  6752/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 6 4
Policy data: tensor([0.1407, 0.1454, 0.1407, 0.1383, 0.1477, 0.1383, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1381, 0.1479, 0.1384, 0.1400, 0.1490, 0.1417, 0.1450],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9955487847328186
 
[Iteration 5] Process ID: 181441 [Epoch: 125, 13504/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 1 1
Policy data: tensor([0.1387, 0.2154, 0.0875, 0.0961, 0.1810, 0.1156, 0.1658],
       device='cuda:0')
Policy pred: tensor([0.1390, 0.2100, 0.0826, 0.1282, 0.2000, 0.0902, 0.1500],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 125, 20256/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 6 6
Policy data: tensor([0.1383, 0.1430, 0.1360, 0.1477, 0.1501, 0.1336, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1428, 0.1427, 0.1272, 0.1523, 0.1415, 0.1354, 0.1580],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 125, 27008/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 6 1
Policy data: tensor([0.1395, 0.1454, 0.1419, 0.1442, 0.1489, 0.1289, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1404, 0.1523, 0.1454, 0.1433, 0.1459, 0.1294, 0.1432],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999990463256836
 
[Iteration 5] Process ID: 181441 [Epoch: 126,  6752/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 4 6
Policy data: tensor([0.1383, 0.1442, 0.1336, 0.1407, 0.1535, 0.1360, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1419, 0.1410, 0.1431, 0.1407, 0.1480, 0.1344, 0.1509],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.20454950630664825
 
[Iteration 5] Process ID: 181441 [Epoch: 126, 13504/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 6 4
Policy data: tensor([0.0546, 0.0728, 0.0878, 0.0602, 0.2970, 0.1054, 0.3222],
       device='cuda:0')
Policy pred: tensor([0.0671, 0.0758, 0.0807, 0.0734, 0.3345, 0.0908, 0.2778],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 126, 20256/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 6 6
Policy data: tensor([0.1073, 0.0674, 0.0980, 0.1175, 0.2166, 0.0374, 0.3557],
       device='cuda:0')
Policy pred: tensor([0.1158, 0.0675, 0.0871, 0.1180, 0.2067, 0.0345, 0.3703],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 126, 27008/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 6 6
Policy data: tensor([0.0869, 0.1046, 0.1500, 0.0869, 0.1949, 0.0539, 0.3228],
       device='cuda:0')
Policy pred: tensor([0.0873, 0.0971, 0.1673, 0.0863, 0.1782, 0.0489, 0.3349],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 127,  6752/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 6 6
Policy data: tensor([0.0581, 0.0933, 0.1602, 0.1467, 0.2077, 0.0432, 0.2907],
       device='cuda:0')
Policy pred: tensor([0.0712, 0.0957, 0.1409, 0.1332, 0.2152, 0.0442, 0.2995],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 127, 13504/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 3 4
Policy data: tensor([0.1383, 0.1407, 0.1419, 0.1500, 0.1442, 0.1395, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1390, 0.1468, 0.1408, 0.1490, 0.1554, 0.1347, 0.1342],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 127, 20256/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 3 4
Policy data: tensor([0.1360, 0.1419, 0.1372, 0.1477, 0.1477, 0.1419, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1398, 0.1459, 0.1399, 0.1442, 0.1473, 0.1386, 0.1444],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.04774608835577965
 
[Iteration 5] Process ID: 181441 [Epoch: 127, 27008/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 6 2
Policy data: tensor([0.1372, 0.1430, 0.1501, 0.1372, 0.1430, 0.1360, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1412, 0.1392, 0.1502, 0.1387, 0.1485, 0.1329, 0.1493],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.13489271700382233
 
[Iteration 5] Process ID: 181441 [Epoch: 128,  6752/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 4 1
Policy data: tensor([0.1155, 0.1809, 0.1809, 0.0722, 0.1974, 0.1266, 0.1266],
       device='cuda:0')
Policy pred: tensor([0.1173, 0.1970, 0.1940, 0.0834, 0.1731, 0.1198, 0.1155],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 128, 13504/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 6 6
Policy data: tensor([0.1383, 0.1430, 0.1465, 0.1395, 0.1477, 0.1325, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1421, 0.1418, 0.1428, 0.1431, 0.1485, 0.1330, 0.1487],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999957084655762
 
[Iteration 5] Process ID: 181441 [Epoch: 128, 20256/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 6 6
Policy data: tensor([0.1132, 0.1241, 0.1241, 0.1241, 0.1935, 0.0708, 0.2503],
       device='cuda:0')
Policy pred: tensor([0.1078, 0.1391, 0.1216, 0.1294, 0.2113, 0.0688, 0.2220],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 128, 27008/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 1 0
Policy data: tensor([0.1705, 0.2487, 0.1705, 0.1579, 0.0000, 0.1063, 0.1460],
       device='cuda:0')
Policy pred: tensor([2.0144e-01, 1.9214e-01, 1.5576e-01, 1.6761e-01, 3.4486e-09, 1.0692e-01,
        1.7613e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 129,  6752/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 4 4
Policy data: tensor([0.1454, 0.1419, 0.1430, 0.1407, 0.1477, 0.1360, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1425, 0.1447, 0.1378, 0.1419, 0.1493, 0.1347, 0.1491],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9864673018455505
 
[Iteration 5] Process ID: 181441 [Epoch: 129, 13504/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 2 6
Policy data: tensor([0.0589, 0.1501, 0.1792, 0.1641, 0.1792, 0.1044, 0.1641],
       device='cuda:0')
Policy pred: tensor([0.0722, 0.1438, 0.1938, 0.1304, 0.1664, 0.0972, 0.1962],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 129, 20256/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 0 0
Policy data: tensor([0.2306, 0.1629, 0.1036, 0.1941, 0.1362, 0.0944, 0.0782],
       device='cuda:0')
Policy pred: tensor([0.2221, 0.1688, 0.1049, 0.1891, 0.1302, 0.1021, 0.0828],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 129, 27008/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 2 6
Policy data: tensor([0.1419, 0.1395, 0.1501, 0.1419, 0.1465, 0.1301, 0.1501],
       device='cuda:0')
Policy pred: tensor([0.1424, 0.1420, 0.1454, 0.1395, 0.1472, 0.1327, 0.1508],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.32248786091804504
 
[Iteration 5] Process ID: 181441 [Epoch: 130,  6752/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 6 6
Policy data: tensor([0.1489, 0.1395, 0.1372, 0.1384, 0.1512, 0.1313, 0.1536],
       device='cuda:0')
Policy pred: tensor([0.1445, 0.1414, 0.1409, 0.1422, 0.1468, 0.1323, 0.1519],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.08352179080247879
 
[Iteration 5] Process ID: 181441 [Epoch: 130, 13504/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 1 1
Policy data: tensor([0.1103, 0.2654, 0.0835, 0.1728, 0.1886, 0.0690, 0.1103],
       device='cuda:0')
Policy pred: tensor([0.1015, 0.2687, 0.0862, 0.2052, 0.1476, 0.0858, 0.1052],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 130, 20256/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 1 1
Policy data: tensor([0.1744, 0.2934, 0.0928, 0.1279, 0.2187, 0.0928, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.6106e-01, 3.0605e-01, 1.0275e-01, 1.3404e-01, 2.0557e-01, 9.0529e-02,
        1.2772e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 130, 27008/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1465, 0.1348, 0.1442, 0.1535, 0.1383, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1489, 0.1342, 0.1171, 0.1414, 0.1744, 0.1444, 0.1396],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 131,  6752/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 2 4
Policy data: tensor([0.1407, 0.1442, 0.1489, 0.1407, 0.1454, 0.1383, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1458, 0.1391, 0.1405, 0.1419, 0.1461, 0.1409, 0.1458],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.5565854907035828
 
[Iteration 5] Process ID: 181441 [Epoch: 131, 13504/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 6 6
Policy data: tensor([0.0923, 0.0923, 0.1109, 0.1214, 0.1730, 0.0428, 0.3674],
       device='cuda:0')
Policy pred: tensor([0.0931, 0.0761, 0.0976, 0.1233, 0.1539, 0.0381, 0.4179],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 131, 20256/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 6 6
Policy data: tensor([0.0917, 0.1728, 0.1728, 0.0835, 0.1448, 0.0690, 0.2654],
       device='cuda:0')
Policy pred: tensor([0.1120, 0.1685, 0.1565, 0.0949, 0.1613, 0.0827, 0.2241],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 131, 27008/ 27057 points] total loss per batch: 2.037
Policy (actual, predicted): 6 6
Policy data: tensor([0.1383, 0.1430, 0.1419, 0.1442, 0.1430, 0.1360, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1414, 0.1421, 0.1434, 0.1408, 0.1481, 0.1345, 0.1497],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.2798715829849243
 
[Iteration 5] Process ID: 181441 [Epoch: 132,  6752/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 0 0
Policy data: tensor([0.3023, 0.1944, 0.1548, 0.0695, 0.2095, 0.0695, 0.0000],
       device='cuda:0')
Policy pred: tensor([3.1545e-01, 1.8692e-01, 1.4055e-01, 8.0002e-02, 2.0776e-01, 6.9312e-02,
        7.6135e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 132, 13504/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 6 6
Policy data: tensor([0.0970, 0.1063, 0.1063, 0.1275, 0.2351, 0.0496, 0.2781],
       device='cuda:0')
Policy pred: tensor([0.1067, 0.1117, 0.1121, 0.1172, 0.2151, 0.0602, 0.2770],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 132, 20256/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 4 4
Policy data: tensor([0.1454, 0.1430, 0.1442, 0.1383, 0.1477, 0.1383, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1410, 0.1450, 0.1414, 0.1432, 0.1460, 0.1402, 0.1432],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.03634677082300186
 
[Iteration 5] Process ID: 181441 [Epoch: 132, 27008/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 4 6
Policy data: tensor([0.0613, 0.1295, 0.1548, 0.1080, 0.2597, 0.0675, 0.2192],
       device='cuda:0')
Policy pred: tensor([0.0588, 0.1146, 0.1448, 0.1266, 0.2266, 0.0725, 0.2562],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 133,  6752/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 1 4
Policy data: tensor([0.1395, 0.1465, 0.1430, 0.1395, 0.1454, 0.1430, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1403, 0.1435, 0.1395, 0.1419, 0.1480, 0.1408, 0.1461],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.29541438817977905
 
[Iteration 5] Process ID: 181441 [Epoch: 133, 13504/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 6 6
Policy data: tensor([0.1454, 0.1395, 0.1466, 0.1372, 0.1501, 0.1301, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1409, 0.1412, 0.1451, 0.1394, 0.1477, 0.1343, 0.1514],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.00391883309930563
 
[Iteration 5] Process ID: 181441 [Epoch: 133, 20256/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 6 6
Policy data: tensor([0.1419, 0.1442, 0.1442, 0.1395, 0.1430, 0.1348, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1413, 0.1423, 0.1432, 0.1407, 0.1483, 0.1336, 0.1506],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.1172117367386818
 
[Iteration 5] Process ID: 181441 [Epoch: 133, 27008/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 6 6
Policy data: tensor([0.1383, 0.1454, 0.1442, 0.1383, 0.1465, 0.1383, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1454, 0.1464, 0.1487, 0.1385, 0.1442, 0.1256, 0.1512],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 134,  6752/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 4 4
Policy data: tensor([0.0670, 0.1067, 0.0553, 0.0888, 0.3536, 0.0737, 0.2548],
       device='cuda:0')
Policy pred: tensor([0.0621, 0.1197, 0.0642, 0.0971, 0.3179, 0.0762, 0.2629],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 134, 13504/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 4 4
Policy data: tensor([0.1454, 0.1407, 0.1477, 0.1372, 0.1489, 0.1383, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1451, 0.1405, 0.1428, 0.1414, 0.1486, 0.1358, 0.1457],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.04165531322360039
 
[Iteration 5] Process ID: 181441 [Epoch: 134, 20256/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 6 6
Policy data: tensor([0.1442, 0.1407, 0.1348, 0.1442, 0.1465, 0.1419, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1455, 0.1401, 0.1367, 0.1329, 0.1495, 0.1409, 0.1544],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 134, 27008/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 2 1
Policy data: tensor([0.1349, 0.1840, 0.2141, 0.1704, 0.1985, 0.0980, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.2732e-01, 2.1336e-01, 2.0713e-01, 1.6807e-01, 2.0107e-01, 8.3046e-02,
        2.7058e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 135,  6752/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 1 4
Policy data: tensor([0.1372, 0.1477, 0.1383, 0.1442, 0.1454, 0.1430, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1385, 0.1455, 0.1400, 0.1400, 0.1467, 0.1442, 0.1450],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.2015172392129898
 
[Iteration 5] Process ID: 181441 [Epoch: 135, 13504/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 4 4
Policy data: tensor([0.1372, 0.1466, 0.1360, 0.1430, 0.1570, 0.1372, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1331, 0.1443, 0.1410, 0.1387, 0.1555, 0.1404, 0.1470],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999880790710449
 
[Iteration 5] Process ID: 181441 [Epoch: 135, 20256/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000, 0.1533, 0.0878, 0.1212, 0.2243, 0.1533, 0.2601],
       device='cuda:0')
Policy pred: tensor([1.6673e-06, 1.5623e-01, 7.9370e-02, 1.4690e-01, 2.3147e-01, 1.2380e-01,
        2.6223e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 135, 27008/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 4 4
Policy data: tensor([0.1419, 0.1430, 0.1430, 0.1372, 0.1465, 0.1419, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1417, 0.1427, 0.1455, 0.1376, 0.1477, 0.1402, 0.1446],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 136,  6752/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 4 4
Policy data: tensor([0.0457, 0.0972, 0.2135, 0.0504, 0.3491, 0.0306, 0.2135],
       device='cuda:0')
Policy pred: tensor([0.0543, 0.1142, 0.1830, 0.0691, 0.3181, 0.0431, 0.2183],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 136, 13504/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 6 6
Policy data: tensor([0.1466, 0.1395, 0.1489, 0.1383, 0.1477, 0.1289, 0.1501],
       device='cuda:0')
Policy pred: tensor([0.1434, 0.1401, 0.1476, 0.1408, 0.1471, 0.1306, 0.1503],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.003551238914951682
 
[Iteration 5] Process ID: 181441 [Epoch: 136, 20256/ 27057 points] total loss per batch: 2.017
Policy (actual, predicted): 4 4
Policy data: tensor([0.1372, 0.1454, 0.1442, 0.1419, 0.1477, 0.1407, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1393, 0.1435, 0.1400, 0.1438, 0.1483, 0.1386, 0.1464],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.12258190661668777
 
[Iteration 5] Process ID: 181441 [Epoch: 136, 27008/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 6 4
Policy data: tensor([0.1395, 0.1383, 0.1419, 0.1395, 0.1489, 0.1407, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1405, 0.1440, 0.1403, 0.1411, 0.1490, 0.1362, 0.1488],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9312437176704407
 
[Iteration 5] Process ID: 181441 [Epoch: 137,  6752/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 4 4
Policy data: tensor([0.1098, 0.0000, 0.1638, 0.1865, 0.3279, 0.0000, 0.2120],
       device='cuda:0')
Policy pred: tensor([1.3492e-01, 7.5712e-09, 1.6333e-01, 1.8083e-01, 3.1334e-01, 6.8834e-10,
        2.0759e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 137, 13504/ 27057 points] total loss per batch: 2.014
Policy (actual, predicted): 6 4
Policy data: tensor([0.1465, 0.1407, 0.1407, 0.1419, 0.1442, 0.1383, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1417, 0.1399, 0.1436, 0.1420, 0.1477, 0.1376, 0.1475],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.03310899809002876
 
[Iteration 5] Process ID: 181441 [Epoch: 137, 20256/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 6 6
Policy data: tensor([0.0533, 0.1036, 0.1036, 0.1135, 0.1930, 0.0861, 0.3468],
       device='cuda:0')
Policy pred: tensor([0.0603, 0.1075, 0.1010, 0.1339, 0.1797, 0.0932, 0.3244],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 137, 27008/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 4 4
Policy data: tensor([0.2084, 0.2365, 0.1008, 0.0000, 0.3223, 0.1321, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.8760e-01, 2.5208e-01, 1.0910e-01, 1.7257e-09, 3.3225e-01, 1.1897e-01,
        9.0328e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 138,  6752/ 27057 points] total loss per batch: 2.017
Policy (actual, predicted): 6 6
Policy data: tensor([0.1442, 0.1383, 0.1454, 0.1395, 0.1477, 0.1336, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1427, 0.1411, 0.1465, 0.1406, 0.1472, 0.1312, 0.1507],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.011430795304477215
 
[Iteration 5] Process ID: 181441 [Epoch: 138, 13504/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 6 6
Policy data: tensor([0.1430, 0.1407, 0.1454, 0.1360, 0.1489, 0.1313, 0.1547],
       device='cuda:0')
Policy pred: tensor([0.1406, 0.1425, 0.1420, 0.1410, 0.1494, 0.1333, 0.1512],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999186396598816
 
[Iteration 5] Process ID: 181441 [Epoch: 138, 20256/ 27057 points] total loss per batch: 2.035
Policy (actual, predicted): 4 4
Policy data: tensor([0.1215, 0.0839, 0.1012, 0.0922, 0.2901, 0.1215, 0.1896],
       device='cuda:0')
Policy pred: tensor([0.1282, 0.0892, 0.1218, 0.1031, 0.3041, 0.0916, 0.1620],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 138, 27008/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 4 6
Policy data: tensor([0.1465, 0.1372, 0.1477, 0.1419, 0.1489, 0.1301, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1422, 0.1412, 0.1453, 0.1397, 0.1493, 0.1294, 0.1528],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.37794730067253113
 
[Iteration 5] Process ID: 181441 [Epoch: 139,  6752/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 1 1
Policy data: tensor([0.1266, 0.2154, 0.1386, 0.1156, 0.1657, 0.0723, 0.1657],
       device='cuda:0')
Policy pred: tensor([0.1269, 0.1932, 0.1470, 0.0953, 0.1866, 0.0804, 0.1707],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 139, 13504/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 4 6
Policy data: tensor([0.1179, 0.1414, 0.1179, 0.0979, 0.2014, 0.1546, 0.1690],
       device='cuda:0')
Policy pred: tensor([0.1371, 0.1223, 0.1086, 0.1100, 0.1875, 0.1291, 0.2054],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 139, 20256/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 4 1
Policy data: tensor([0.1419, 0.1465, 0.1442, 0.1407, 0.1500, 0.1348, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1432, 0.1512, 0.1395, 0.1500, 0.1469, 0.1278, 0.1413],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 139, 27008/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 1 1
Policy data: tensor([0.1229, 0.2278, 0.1472, 0.1122, 0.2091, 0.0578, 0.1229],
       device='cuda:0')
Policy pred: tensor([0.1079, 0.2315, 0.1480, 0.1177, 0.2091, 0.0629, 0.1228],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 140,  6752/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 1 1
Policy data: tensor([0.0715, 0.2129, 0.1371, 0.1371, 0.2129, 0.1143, 0.1143],
       device='cuda:0')
Policy pred: tensor([0.0907, 0.2059, 0.1445, 0.1410, 0.1958, 0.1079, 0.1143],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 140, 13504/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 4 6
Policy data: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.3891, 0.2640, 0.3469],
       device='cuda:0')
Policy pred: tensor([4.0918e-08, 6.4485e-08, 3.6097e-07, 7.5310e-06, 3.4570e-01, 2.7716e-01,
        3.7713e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 140, 20256/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 1 6
Policy data: tensor([0.0871, 0.2558, 0.1108, 0.0000, 0.2558, 0.0528, 0.2377],
       device='cuda:0')
Policy pred: tensor([8.1294e-02, 2.2907e-01, 1.1283e-01, 1.3478e-05, 2.3856e-01, 6.9344e-02,
        2.6889e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 140, 27008/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 4 4
Policy data: tensor([0.1383, 0.1465, 0.1360, 0.1442, 0.1500, 0.1430, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1425, 0.1430, 0.1389, 0.1410, 0.1479, 0.1394, 0.1472],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 5] Process ID: 181441 [Epoch: 141,  6752/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000, 0.2255, 0.1940, 0.1319, 0.1798, 0.0748, 0.1940],
       device='cuda:0')
Policy pred: tensor([0.0002, 0.1981, 0.1966, 0.1549, 0.1533, 0.1306, 0.1663],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999938607215881
 
[Iteration 5] Process ID: 181441 [Epoch: 141, 13504/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 4 4
Policy data: tensor([0.2097, 0.1476, 0.0851, 0.0935, 0.2488, 0.1026, 0.1125],
       device='cuda:0')
Policy pred: tensor([0.1952, 0.1578, 0.1001, 0.0662, 0.2542, 0.0947, 0.1318],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 141, 20256/ 27057 points] total loss per batch: 2.019
Policy (actual, predicted): 6 6
Policy data: tensor([0.1419, 0.1465, 0.1383, 0.1395, 0.1489, 0.1348, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1408, 0.1450, 0.1384, 0.1426, 0.1463, 0.1391, 0.1478],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.02051375061273575
 
[Iteration 5] Process ID: 181441 [Epoch: 141, 27008/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 2 2
Policy data: tensor([0.1695, 0.0000, 0.2991, 0.2812, 0.0000, 0.0808, 0.1695],
       device='cuda:0')
Policy pred: tensor([1.8424e-01, 2.1085e-07, 2.7245e-01, 2.7031e-01, 3.5827e-10, 6.8615e-02,
        2.0439e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 142,  6752/ 27057 points] total loss per batch: 2.019
Policy (actual, predicted): 6 6
Policy data: tensor([0.1430, 0.1395, 0.1419, 0.1407, 0.1454, 0.1360, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1412, 0.1424, 0.1432, 0.1407, 0.1471, 0.1362, 0.1493],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.13490575551986694
 
[Iteration 5] Process ID: 181441 [Epoch: 142, 13504/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 1 3
Policy data: tensor([0.1252, 0.2889, 0.0000, 0.2889, 0.0000, 0.1338, 0.1631],
       device='cuda:0')
Policy pred: tensor([1.4365e-01, 2.5529e-01, 7.1606e-07, 2.9222e-01, 5.8875e-08, 1.4268e-01,
        1.6616e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 142, 20256/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 4 4
Policy data: tensor([0.1256, 0.1795, 0.1146, 0.0717, 0.2327, 0.1256, 0.1504],
       device='cuda:0')
Policy pred: tensor([0.1129, 0.2093, 0.1240, 0.0835, 0.2212, 0.1120, 0.1371],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 142, 27008/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 1 1
Policy data: tensor([0.1600, 0.2266, 0.0927, 0.1338, 0.1600, 0.0521, 0.1748],
       device='cuda:0')
Policy pred: tensor([0.1564, 0.2452, 0.0903, 0.1573, 0.1458, 0.0659, 0.1390],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 143,  6752/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 4 4
Policy data: tensor([0.1383, 0.1442, 0.1442, 0.1407, 0.1465, 0.1430, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1400, 0.1439, 0.1418, 0.1433, 0.1468, 0.1415, 0.1428],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.0928247720003128
 
[Iteration 5] Process ID: 181441 [Epoch: 143, 13504/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 4 4
Policy data: tensor([0.1454, 0.1442, 0.1372, 0.1407, 0.1500, 0.1348, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1427, 0.1445, 0.1400, 0.1410, 0.1478, 0.1384, 0.1456],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999992847442627
 
[Iteration 5] Process ID: 181441 [Epoch: 143, 20256/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 6 6
Policy data: tensor([0.1395, 0.1419, 0.1395, 0.1430, 0.1489, 0.1348, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1320, 0.1405, 0.1472, 0.1447, 0.1439, 0.1375, 0.1542],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 143, 27008/ 27057 points] total loss per batch: 2.019
Policy (actual, predicted): 1 1
Policy data: tensor([0.1445, 0.2851, 0.1688, 0.1235, 0.1445, 0.1336, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.4292e-01, 2.7735e-01, 1.8367e-01, 1.2826e-01, 1.4870e-01, 1.1909e-01,
        1.8824e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 144,  6752/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 4 4
Policy data: tensor([0.1419, 0.1419, 0.1383, 0.1383, 0.1489, 0.1477, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1392, 0.1365, 0.1364, 0.1463, 0.1736, 0.1319, 0.1362],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 144, 13504/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 4 4
Policy data: tensor([0.0815, 0.1077, 0.0612, 0.1413, 0.3061, 0.1180, 0.1841],
       device='cuda:0')
Policy pred: tensor([0.0977, 0.1224, 0.0557, 0.1530, 0.2814, 0.1183, 0.1715],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 144, 20256/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 6 6
Policy data: tensor([0.1313, 0.2236, 0.0000, 0.2236, 0.1214, 0.0412, 0.2590],
       device='cuda:0')
Policy pred: tensor([1.3821e-01, 2.0557e-01, 4.3078e-09, 2.3924e-01, 1.2176e-01, 4.5808e-02,
        2.4941e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 144, 27008/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 6 1
Policy data: tensor([0.1847, 0.3225, 0.0956, 0.0000, 0.0000, 0.0547, 0.3425],
       device='cuda:0')
Policy pred: tensor([2.0478e-01, 3.2956e-01, 8.9127e-02, 4.8331e-08, 2.3624e-08, 5.7667e-02,
        3.1886e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 145,  6752/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 6 6
Policy data: tensor([0.1430, 0.1442, 0.1407, 0.1372, 0.1489, 0.1360, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1395, 0.1420, 0.1440, 0.1402, 0.1488, 0.1348, 0.1508],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.1602870672941208
 
[Iteration 5] Process ID: 181441 [Epoch: 145, 13504/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 1 1
Policy data: tensor([0.3055, 0.3548, 0.1473, 0.0000, 0.0000, 0.1923, 0.0000],
       device='cuda:0')
Policy pred: tensor([3.0362e-01, 3.2261e-01, 1.3499e-01, 1.2223e-06, 8.7224e-09, 2.3877e-01,
        2.3783e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 145, 20256/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 4 4
Policy data: tensor([0.0803, 0.1531, 0.1400, 0.1167, 0.1994, 0.1278, 0.1827],
       device='cuda:0')
Policy pred: tensor([0.0971, 0.1630, 0.1546, 0.1036, 0.2105, 0.1183, 0.1529],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 145, 27008/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 3 3
Policy data: tensor([0.0661, 0.2543, 0.1158, 0.2765, 0.1268, 0.0878, 0.0727],
       device='cuda:0')
Policy pred: tensor([0.0672, 0.2496, 0.1162, 0.2728, 0.1109, 0.0891, 0.0942],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 146,  6752/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 1 1
Policy data: tensor([0.1142, 0.2638, 0.0000, 0.1686, 0.2114, 0.0458, 0.1962],
       device='cuda:0')
Policy pred: tensor([1.1088e-01, 2.2941e-01, 8.7718e-07, 1.7675e-01, 2.2231e-01, 6.1371e-02,
        1.9928e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 146, 13504/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 2 0
Policy data: tensor([0.3032, 0.0000, 0.3188, 0.0000, 0.0000, 0.1175, 0.2605],
       device='cuda:0')
Policy pred: tensor([3.0897e-01, 2.6298e-12, 2.9948e-01, 5.4922e-06, 2.0433e-06, 1.2341e-01,
        2.6813e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 146, 20256/ 27057 points] total loss per batch: 2.033
Policy (actual, predicted): 6 6
Policy data: tensor([0.1454, 0.1383, 0.1477, 0.1407, 0.1465, 0.1301, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1421, 0.1387, 0.1454, 0.1414, 0.1478, 0.1318, 0.1527],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.000617468380369246
 
[Iteration 5] Process ID: 181441 [Epoch: 146, 27008/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 4 4
Policy data: tensor([0.1570, 0.1437, 0.1871, 0.0910, 0.2223, 0.0418, 0.1570],
       device='cuda:0')
Policy pred: tensor([0.1492, 0.1527, 0.1474, 0.1133, 0.2252, 0.0463, 0.1659],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 147,  6752/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 3 3
Policy data: tensor([0.2246, 0.0000, 0.1728, 0.4106, 0.0000, 0.1920, 0.0000],
       device='cuda:0')
Policy pred: tensor([2.1160e-01, 6.8410e-07, 1.9801e-01, 4.0533e-01, 6.4104e-08, 1.8506e-01,
        9.5818e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 147, 13504/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 1 1
Policy data: tensor([0.0838, 0.3059, 0.0773, 0.0000, 0.2649, 0.0554, 0.2127],
       device='cuda:0')
Policy pred: tensor([7.1650e-02, 3.2018e-01, 8.1682e-02, 6.9446e-07, 2.8610e-01, 5.5337e-02,
        1.8505e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 147, 20256/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 0 0
Policy data: tensor([0.2129, 0.1371, 0.1790, 0.1252, 0.1371, 0.0588, 0.1499],
       device='cuda:0')
Policy pred: tensor([0.2249, 0.1433, 0.1640, 0.1192, 0.1465, 0.0610, 0.1410],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9987521171569824
 
[Iteration 5] Process ID: 181441 [Epoch: 147, 27008/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 2 2
Policy data: tensor([0.0717, 0.0951, 0.2507, 0.1368, 0.1942, 0.0398, 0.2117],
       device='cuda:0')
Policy pred: tensor([0.0685, 0.0921, 0.2601, 0.1296, 0.1951, 0.0340, 0.2207],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 148,  6752/ 27057 points] total loss per batch: 2.019
Policy (actual, predicted): 6 6
Policy data: tensor([0.0965, 0.1159, 0.1388, 0.1388, 0.1388, 0.0447, 0.3265],
       device='cuda:0')
Policy pred: tensor([0.0950, 0.1249, 0.1498, 0.1401, 0.1436, 0.0445, 0.3021],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 148, 13504/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 6 6
Policy data: tensor([0.1442, 0.1407, 0.1419, 0.1383, 0.1501, 0.1325, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1407, 0.1461, 0.1428, 0.1375, 0.1491, 0.1344, 0.1494],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 148, 20256/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 1 1
Policy data: tensor([0.1436, 0.3110, 0.0909, 0.1569, 0.0909, 0.1313, 0.0753],
       device='cuda:0')
Policy pred: tensor([0.1575, 0.2750, 0.1113, 0.1611, 0.0745, 0.1462, 0.0744],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 148, 27008/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 3 3
Policy data: tensor([0.1117, 0.0000, 0.1884, 0.4426, 0.1884, 0.0690, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.1323e-01, 8.3355e-10, 1.7729e-01, 4.6812e-01, 1.7084e-01, 7.0524e-02,
        7.0806e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 149,  6752/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 4 4
Policy data: tensor([0.1532, 0.1532, 0.1674, 0.1065, 0.1995, 0.0803, 0.1400],
       device='cuda:0')
Policy pred: tensor([0.1531, 0.1435, 0.1559, 0.1233, 0.1983, 0.0885, 0.1374],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 149, 13504/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 0 5
Policy data: tensor([0.4212, 0.0000, 0.0000, 0.1576, 0.0000, 0.4212, 0.0000],
       device='cuda:0')
Policy pred: tensor([3.9108e-01, 2.7341e-07, 1.1808e-06, 1.6077e-01, 1.9765e-05, 4.4813e-01,
        1.4835e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 149, 20256/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 6 6
Policy data: tensor([0.2028, 0.1305, 0.0618, 0.1192, 0.2028, 0.0618, 0.2210],
       device='cuda:0')
Policy pred: tensor([0.1741, 0.1428, 0.0627, 0.1107, 0.1702, 0.0825, 0.2570],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 149, 27008/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 4 4
Policy data: tensor([0.0470, 0.1322, 0.0630, 0.2424, 0.3109, 0.0837, 0.1208],
       device='cuda:0')
Policy pred: tensor([0.0478, 0.1300, 0.0711, 0.2386, 0.3011, 0.0748, 0.1365],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 150,  6752/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 2 6
Policy data: tensor([0.1407, 0.1395, 0.1512, 0.1466, 0.1442, 0.1265, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1470, 0.1406, 0.1484, 0.1386, 0.1470, 0.1290, 0.1494],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 150, 13504/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 6 6
Policy data: tensor([0.1048, 0.1954, 0.0793, 0.0871, 0.1503, 0.0595, 0.3235],
       device='cuda:0')
Policy pred: tensor([0.1078, 0.1813, 0.0884, 0.0948, 0.1473, 0.0616, 0.3187],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 150, 20256/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 6 6
Policy data: tensor([0.1395, 0.1407, 0.1465, 0.1442, 0.1442, 0.1348, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1407, 0.1435, 0.1424, 0.1411, 0.1491, 0.1329, 0.1503],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 150, 27008/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 1 4
Policy data: tensor([0.1348, 0.1477, 0.1419, 0.1430, 0.1477, 0.1372, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1453, 0.1449, 0.1409, 0.1366, 0.1496, 0.1371, 0.1455],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.17766369879245758
 
[Iteration 5] Process ID: 181441 [Epoch: 151,  6752/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 4 4
Policy data: tensor([0.1407, 0.1430, 0.1430, 0.1407, 0.1477, 0.1395, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1402, 0.1445, 0.1407, 0.1422, 0.1477, 0.1404, 0.1444],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.16478826105594635
 
[Iteration 5] Process ID: 181441 [Epoch: 151, 13504/ 27057 points] total loss per batch: 2.019
Policy (actual, predicted): 6 6
Policy data: tensor([0.1325, 0.1395, 0.1489, 0.1430, 0.1454, 0.1360, 0.1547],
       device='cuda:0')
Policy pred: tensor([0.1401, 0.1432, 0.1433, 0.1409, 0.1467, 0.1356, 0.1502],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9933814406394958
 
[Iteration 5] Process ID: 181441 [Epoch: 151, 20256/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 4 4
Policy data: tensor([0.1360, 0.1407, 0.1465, 0.1383, 0.1489, 0.1430, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1399, 0.1424, 0.1401, 0.1431, 0.1469, 0.1434, 0.1441],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9842808246612549
 
[Iteration 5] Process ID: 181441 [Epoch: 151, 27008/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 4 4
Policy data: tensor([0.1465, 0.1442, 0.1360, 0.1430, 0.1500, 0.1395, 0.1407],
       device='cuda:0')
Policy pred: tensor([0.1448, 0.1417, 0.1453, 0.1383, 0.1503, 0.1373, 0.1422],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 152,  6752/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 6 6
Policy data: tensor([0.0000, 0.1165, 0.1850, 0.1424, 0.0000, 0.2103, 0.3457],
       device='cuda:0')
Policy pred: tensor([8.5898e-06, 1.3352e-01, 1.9876e-01, 1.3437e-01, 2.0724e-08, 2.1505e-01,
        3.1829e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 152, 13504/ 27057 points] total loss per batch: 2.015
Policy (actual, predicted): 0 0
Policy data: tensor([0.3081, 0.0746, 0.1422, 0.0678, 0.1188, 0.1188, 0.1698],
       device='cuda:0')
Policy pred: tensor([0.2805, 0.0787, 0.1373, 0.0847, 0.1383, 0.1163, 0.1642],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 152, 20256/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 4 4
Policy data: tensor([0.1489, 0.1372, 0.1348, 0.1407, 0.1559, 0.1442, 0.1383],
       device='cuda:0')
Policy pred: tensor([0.1396, 0.1428, 0.1407, 0.1419, 0.1523, 0.1390, 0.1437],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999997019767761
 
[Iteration 5] Process ID: 181441 [Epoch: 152, 27008/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 2 4
Policy data: tensor([0.1477, 0.1360, 0.1512, 0.1348, 0.1477, 0.1407, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1420, 0.1439, 0.1414, 0.1412, 0.1473, 0.1407, 0.1434],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.002795211039483547
 
[Iteration 5] Process ID: 181441 [Epoch: 153,  6752/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 3 3
Policy data: tensor([0.1221, 0.0696, 0.0000, 0.3212, 0.2079, 0.0383, 0.2409],
       device='cuda:0')
Policy pred: tensor([1.1754e-01, 8.0572e-02, 4.1536e-09, 3.1876e-01, 2.1127e-01, 3.8176e-02,
        2.3368e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 153, 13504/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 6 6
Policy data: tensor([0.0743, 0.1417, 0.0897, 0.1183, 0.2193, 0.0743, 0.2824],
       device='cuda:0')
Policy pred: tensor([0.0735, 0.1621, 0.0813, 0.1161, 0.2250, 0.0662, 0.2758],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 153, 20256/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 6 6
Policy data: tensor([0.1395, 0.1419, 0.1477, 0.1395, 0.1442, 0.1348, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1414, 0.1394, 0.1502, 0.1374, 0.1478, 0.1335, 0.1504],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.16387693583965302
 
[Iteration 5] Process ID: 181441 [Epoch: 153, 27008/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 6 4
Policy data: tensor([0.1395, 0.1454, 0.1430, 0.1372, 0.1466, 0.1325, 0.1559],
       device='cuda:0')
Policy pred: tensor([0.1396, 0.1438, 0.1468, 0.1418, 0.1512, 0.1299, 0.1469],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 154,  6752/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 6 6
Policy data: tensor([0.1442, 0.1442, 0.1442, 0.1395, 0.1442, 0.1360, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1398, 0.1419, 0.1439, 0.1406, 0.1477, 0.1345, 0.1516],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.15068916976451874
 
[Iteration 5] Process ID: 181441 [Epoch: 154, 13504/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 4 4
Policy data: tensor([0.1241, 0.1486, 0.1358, 0.0708, 0.2725, 0.1241, 0.1241],
       device='cuda:0')
Policy pred: tensor([0.1344, 0.1550, 0.1282, 0.0734, 0.2574, 0.1114, 0.1400],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 154, 20256/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 1 1
Policy data: tensor([0.1032, 0.2297, 0.1032, 0.1131, 0.2108, 0.0778, 0.1622],
       device='cuda:0')
Policy pred: tensor([0.1045, 0.2215, 0.1036, 0.1195, 0.2189, 0.0802, 0.1518],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 154, 27008/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1430, 0.1477, 0.1372, 0.1489, 0.1419, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1414, 0.1443, 0.1423, 0.1410, 0.1474, 0.1407, 0.1430],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.14266791939735413
 
[Iteration 5] Process ID: 181441 [Epoch: 155,  6752/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 6 6
Policy data: tensor([0.0735, 0.1068, 0.0735, 0.1281, 0.2169, 0.0974, 0.3036],
       device='cuda:0')
Policy pred: tensor([0.0732, 0.1118, 0.0781, 0.1390, 0.2020, 0.0838, 0.3122],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 155, 13504/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 4 4
Policy data: tensor([0.1430, 0.1419, 0.1336, 0.1465, 0.1500, 0.1383, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1413, 0.1448, 0.1415, 0.1408, 0.1490, 0.1380, 0.1445],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.26703545451164246
 
[Iteration 5] Process ID: 181441 [Epoch: 155, 20256/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 4 4
Policy data: tensor([0.1454, 0.1442, 0.1430, 0.1395, 0.1465, 0.1383, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1401, 0.1510, 0.1382, 0.1372, 0.1517, 0.1356, 0.1462],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999991059303284
 
[Iteration 5] Process ID: 181441 [Epoch: 155, 27008/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 6 6
Policy data: tensor([0.1430, 0.1430, 0.1489, 0.1360, 0.1489, 0.1301, 0.1501],
       device='cuda:0')
Policy pred: tensor([0.1422, 0.1407, 0.1463, 0.1393, 0.1464, 0.1342, 0.1508],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.16710418462753296
 
[Iteration 5] Process ID: 181441 [Epoch: 156,  6752/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 4 4
Policy data: tensor([0.1407, 0.1419, 0.1430, 0.1383, 0.1477, 0.1465, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1424, 0.1443, 0.1394, 0.1422, 0.1492, 0.1401, 0.1425],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9769821166992188
 
[Iteration 5] Process ID: 181441 [Epoch: 156, 13504/ 27057 points] total loss per batch: 2.008
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1758, 0.0936, 0.1629, 0.3181, 0.1100, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.5397e-01, 1.6066e-01, 8.9576e-02, 1.6971e-01, 3.1570e-01, 1.1038e-01,
        6.7709e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 156, 20256/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 4 4
Policy data: tensor([0.1372, 0.1419, 0.1336, 0.1430, 0.1524, 0.1407, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1375, 0.1502, 0.1361, 0.1361, 0.1509, 0.1415, 0.1476],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.006540682632476091
 
[Iteration 5] Process ID: 181441 [Epoch: 156, 27008/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 4 4
Policy data: tensor([0.1360, 0.1442, 0.1430, 0.1430, 0.1500, 0.1383, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1456, 0.1449, 0.1357, 0.1398, 0.1494, 0.1405, 0.1441],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.09465974569320679
 
[Iteration 5] Process ID: 181441 [Epoch: 157,  6752/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 4 4
Policy data: tensor([0.1465, 0.1419, 0.1395, 0.1407, 0.1500, 0.1407, 0.1407],
       device='cuda:0')
Policy pred: tensor([0.1328, 0.1412, 0.1437, 0.1316, 0.1542, 0.1520, 0.1445],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 157, 13504/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 6 6
Policy data: tensor([0.1395, 0.1407, 0.1489, 0.1395, 0.1477, 0.1325, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1414, 0.1408, 0.1455, 0.1417, 0.1475, 0.1302, 0.1530],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9997790455818176
 
[Iteration 5] Process ID: 181441 [Epoch: 157, 20256/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1442, 0.1407, 0.1454, 0.1465, 0.1395, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1398, 0.1437, 0.1410, 0.1432, 0.1469, 0.1404, 0.1450],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.17851194739341736
 
[Iteration 5] Process ID: 181441 [Epoch: 157, 27008/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 6 6
Policy data: tensor([0.1407, 0.1419, 0.1407, 0.1372, 0.1465, 0.1407, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1401, 0.1429, 0.1426, 0.1402, 0.1496, 0.1318, 0.1529],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 158,  6752/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 6 6
Policy data: tensor([0.1419, 0.1407, 0.1407, 0.1348, 0.1477, 0.1419, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1395, 0.1428, 0.1472, 0.1399, 0.1462, 0.1321, 0.1523],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.3220333158969879
 
[Iteration 5] Process ID: 181441 [Epoch: 158, 13504/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 6 6
Policy data: tensor([0.1780, 0.0000, 0.1604, 0.1663, 0.1616, 0.1534, 0.1803],
       device='cuda:0')
Policy pred: tensor([1.7700e-01, 2.4140e-07, 1.5370e-01, 1.6234e-01, 1.5887e-01, 1.5873e-01,
        1.8936e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 158, 20256/ 27057 points] total loss per batch: 2.016
Policy (actual, predicted): 4 4
Policy data: tensor([0.2072, 0.1333, 0.0924, 0.0924, 0.2458, 0.0695, 0.1594],
       device='cuda:0')
Policy pred: tensor([0.2002, 0.1433, 0.0940, 0.0904, 0.2496, 0.0717, 0.1507],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 158, 27008/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000, 0.2583, 0.1107, 0.2278, 0.2583, 0.1448, 0.0000],
       device='cuda:0')
Policy pred: tensor([2.8665e-06, 2.7457e-01, 1.1715e-01, 2.2059e-01, 2.5425e-01, 1.3344e-01,
        1.1949e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 159,  6752/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 2 4
Policy data: tensor([0.1454, 0.1395, 0.1465, 0.1372, 0.1454, 0.1395, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1416, 0.1442, 0.1418, 0.1405, 0.1478, 0.1398, 0.1442],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.999989926815033
 
[Iteration 5] Process ID: 181441 [Epoch: 159, 13504/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 1 4
Policy data: tensor([0.1395, 0.1465, 0.1442, 0.1383, 0.1465, 0.1395, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1373, 0.1458, 0.1423, 0.1396, 0.1520, 0.1324, 0.1506],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999995231628418
 
[Iteration 5] Process ID: 181441 [Epoch: 159, 20256/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 4 4
Policy data: tensor([0.0870, 0.1649, 0.1150, 0.1379, 0.2542, 0.1150, 0.1260],
       device='cuda:0')
Policy pred: tensor([0.0864, 0.1758, 0.1041, 0.1304, 0.2517, 0.1054, 0.1463],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 159, 27008/ 27057 points] total loss per batch: 2.016
Policy (actual, predicted): 6 6
Policy data: tensor([0.1459, 0.1065, 0.0000, 0.1248, 0.1350, 0.1065, 0.3812],
       device='cuda:0')
Policy pred: tensor([1.4115e-01, 1.0660e-01, 1.7641e-08, 1.0981e-01, 1.5446e-01, 1.1087e-01,
        3.7711e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 160,  6752/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 1 1
Policy data: tensor([0.1499, 0.1789, 0.1638, 0.1499, 0.1252, 0.0533, 0.1789],
       device='cuda:0')
Policy pred: tensor([0.1645, 0.2007, 0.1383, 0.1537, 0.1134, 0.0642, 0.1653],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 160, 13504/ 27057 points] total loss per batch: 2.012
Policy (actual, predicted): 0 4
Policy data: tensor([0.1524, 0.1372, 0.1430, 0.1372, 0.1489, 0.1383, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1444, 0.1428, 0.1427, 0.1381, 0.1473, 0.1391, 0.1457],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9990719556808472
 
[Iteration 5] Process ID: 181441 [Epoch: 160, 20256/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1465, 0.1419, 0.1430, 0.1477, 0.1383, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1484, 0.1418, 0.1405, 0.1437, 0.1489, 0.1340, 0.1428],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9994021058082581
 
[Iteration 5] Process ID: 181441 [Epoch: 160, 27008/ 27057 points] total loss per batch: 2.039
Policy (actual, predicted): 4 4
Policy data: tensor([0.1372, 0.1465, 0.1430, 0.1407, 0.1489, 0.1407, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1399, 0.1452, 0.1424, 0.1405, 0.1493, 0.1382, 0.1444],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.00888206996023655
 
[Iteration 5] Process ID: 181441 [Epoch: 161,  6752/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 6 6
Policy data: tensor([0.1018, 0.1116, 0.1018, 0.0698, 0.1601, 0.2080, 0.2468],
       device='cuda:0')
Policy pred: tensor([0.1069, 0.1085, 0.1024, 0.0683, 0.1700, 0.2160, 0.2279],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 161, 13504/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 2 6
Policy data: tensor([0.1360, 0.1419, 0.1535, 0.1430, 0.1395, 0.1360, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1411, 0.1425, 0.1432, 0.1414, 0.1483, 0.1332, 0.1502],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 161, 20256/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 1 1
Policy data: tensor([0.2001, 0.3680, 0.3016, 0.0000, 0.0000, 0.1304, 0.0000],
       device='cuda:0')
Policy pred: tensor([2.0083e-01, 3.6035e-01, 3.0864e-01, 7.1158e-07, 2.9084e-11, 1.3019e-01,
        3.3616e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 161, 27008/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 6 6
Policy data: tensor([0.1057, 0.1655, 0.0727, 0.1158, 0.2146, 0.0493, 0.2764],
       device='cuda:0')
Policy pred: tensor([0.0966, 0.1615, 0.0830, 0.1050, 0.2358, 0.0440, 0.2740],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 162,  6752/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 4 4
Policy data: tensor([0.1419, 0.1395, 0.1372, 0.1395, 0.1535, 0.1465, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1411, 0.1442, 0.1419, 0.1406, 0.1489, 0.1374, 0.1459],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 162, 13504/ 27057 points] total loss per batch: 2.038
Policy (actual, predicted): 6 6
Policy data: tensor([0.3688, 0.0000, 0.0000, 0.1185, 0.0000, 0.1062, 0.4064],
       device='cuda:0')
Policy pred: tensor([3.5851e-01, 9.0191e-11, 4.5746e-08, 1.3046e-01, 7.6060e-11, 9.7439e-02,
        4.1359e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 162, 20256/ 27057 points] total loss per batch: 2.019
Policy (actual, predicted): 2 4
Policy data: tensor([0.1465, 0.1407, 0.1489, 0.1454, 0.1442, 0.1360, 0.1383],
       device='cuda:0')
Policy pred: tensor([0.1415, 0.1444, 0.1411, 0.1425, 0.1476, 0.1398, 0.1431],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.983622133731842
 
[Iteration 5] Process ID: 181441 [Epoch: 162, 27008/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 4 4
Policy data: tensor([0.1348, 0.1430, 0.1430, 0.1419, 0.1489, 0.1430, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1407, 0.1437, 0.1404, 0.1417, 0.1472, 0.1409, 0.1453],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.4672482907772064
 
[Iteration 5] Process ID: 181441 [Epoch: 163,  6752/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 4 6
Policy data: tensor([0.1192, 0.1429, 0.1306, 0.1306, 0.1866, 0.1192, 0.1709],
       device='cuda:0')
Policy pred: tensor([0.1202, 0.1370, 0.1377, 0.1401, 0.1678, 0.1251, 0.1721],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 163, 13504/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 4 4
Policy data: tensor([0.0992, 0.1560, 0.1192, 0.0992, 0.2845, 0.0560, 0.1859],
       device='cuda:0')
Policy pred: tensor([0.1212, 0.1530, 0.1229, 0.1028, 0.2530, 0.0576, 0.1895],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 163, 20256/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 4 4
Policy data: tensor([0.1372, 0.1430, 0.1395, 0.1430, 0.1512, 0.1430, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1425, 0.1466, 0.1401, 0.1422, 0.1493, 0.1366, 0.1427],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.7670738101005554
 
[Iteration 5] Process ID: 181441 [Epoch: 163, 27008/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 4 4
Policy data: tensor([0.1208, 0.1444, 0.1104, 0.0919, 0.3657, 0.0348, 0.1321],
       device='cuda:0')
Policy pred: tensor([0.1155, 0.1373, 0.1214, 0.1091, 0.3463, 0.0395, 0.1309],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 164,  6752/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 6 6
Policy data: tensor([0.1360, 0.1372, 0.1489, 0.1407, 0.1465, 0.1383, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1419, 0.1418, 0.1430, 0.1412, 0.1470, 0.1371, 0.1479],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9996238946914673
 
[Iteration 5] Process ID: 181441 [Epoch: 164, 13504/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 4 6
Policy data: tensor([0.1442, 0.1383, 0.1454, 0.1419, 0.1501, 0.1301, 0.1501],
       device='cuda:0')
Policy pred: tensor([0.1430, 0.1402, 0.1474, 0.1404, 0.1467, 0.1312, 0.1512],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.005549260880798101
 
[Iteration 5] Process ID: 181441 [Epoch: 164, 20256/ 27057 points] total loss per batch: 2.017
Policy (actual, predicted): 6 6
Policy data: tensor([0.1395, 0.1442, 0.1465, 0.1419, 0.1465, 0.1336, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1415, 0.1411, 0.1451, 0.1414, 0.1448, 0.1350, 0.1510],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.13685721158981323
 
[Iteration 5] Process ID: 181441 [Epoch: 164, 27008/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 4 4
Policy data: tensor([0.0698, 0.1907, 0.1600, 0.1338, 0.2467, 0.0768, 0.1223],
       device='cuda:0')
Policy pred: tensor([0.0660, 0.1765, 0.1617, 0.1366, 0.2567, 0.0707, 0.1317],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 165,  6752/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 0 0
Policy data: tensor([0.3376, 0.0000, 0.2767, 0.3213, 0.0000, 0.0644, 0.0000],
       device='cuda:0')
Policy pred: tensor([3.5172e-01, 5.7811e-07, 2.6280e-01, 2.9767e-01, 7.7359e-07, 8.7807e-02,
        2.5380e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 165, 13504/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 6 6
Policy data: tensor([0.1276, 0.1670, 0.0802, 0.1062, 0.1670, 0.1528, 0.1991],
       device='cuda:0')
Policy pred: tensor([0.1187, 0.1624, 0.0845, 0.1078, 0.1787, 0.1498, 0.1981],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 165, 20256/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 4 4
Policy data: tensor([0.1819, 0.1666, 0.1524, 0.0965, 0.1985, 0.0879, 0.1162],
       device='cuda:0')
Policy pred: tensor([0.1944, 0.1443, 0.1623, 0.1035, 0.1977, 0.0751, 0.1227],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 165, 27008/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 6 6
Policy data: tensor([0.1786, 0.0000, 0.0882, 0.0882, 0.1786, 0.0956, 0.3708],
       device='cuda:0')
Policy pred: tensor([1.6240e-01, 9.4010e-10, 9.1659e-02, 1.0348e-01, 1.8935e-01, 8.8582e-02,
        3.6453e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 166,  6752/ 27057 points] total loss per batch: 2.019
Policy (actual, predicted): 6 6
Policy data: tensor([0.1986, 0.0000, 0.1534, 0.1437, 0.0000, 0.0897, 0.4147],
       device='cuda:0')
Policy pred: tensor([1.9238e-01, 1.2855e-08, 1.6506e-01, 1.4583e-01, 2.4511e-10, 1.0039e-01,
        3.9634e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 166, 13504/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 4 4
Policy data: tensor([0.1442, 0.1454, 0.1419, 0.1383, 0.1524, 0.1336, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1416, 0.1451, 0.1468, 0.1490, 0.1583, 0.1275, 0.1316],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 166, 20256/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 3 3
Policy data: tensor([0.2821, 0.0000, 0.0938, 0.3187, 0.0000, 0.0710, 0.2343],
       device='cuda:0')
Policy pred: tensor([2.7008e-01, 1.8332e-09, 1.0562e-01, 3.3404e-01, 3.8534e-11, 7.1348e-02,
        2.1891e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 166, 27008/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 6 6
Policy data: tensor([0.1407, 0.1419, 0.1466, 0.1383, 0.1466, 0.1301, 0.1559],
       device='cuda:0')
Policy pred: tensor([0.1418, 0.1421, 0.1435, 0.1408, 0.1485, 0.1319, 0.1514],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.010902944020926952
 
[Iteration 5] Process ID: 181441 [Epoch: 167,  6752/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 5 4
Policy data: tensor([0.1360, 0.1407, 0.1407, 0.1407, 0.1489, 0.1500, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1396, 0.1457, 0.1420, 0.1389, 0.1502, 0.1401, 0.1435],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9619551301002502
 
[Iteration 5] Process ID: 181441 [Epoch: 167, 13504/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 4 4
Policy data: tensor([0.0811, 0.1286, 0.2177, 0.1407, 0.2371, 0.0410, 0.1538],
       device='cuda:0')
Policy pred: tensor([0.0776, 0.1352, 0.2255, 0.1517, 0.2310, 0.0375, 0.1415],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 167, 20256/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 4 4
Policy data: tensor([0.1489, 0.1454, 0.1407, 0.1383, 0.1500, 0.1348, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1411, 0.1435, 0.1412, 0.1412, 0.1491, 0.1383, 0.1455],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.01428907923400402
 
[Iteration 5] Process ID: 181441 [Epoch: 167, 27008/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 4 4
Policy data: tensor([0.1465, 0.1407, 0.1407, 0.1419, 0.1477, 0.1348, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1415, 0.1444, 0.1419, 0.1401, 0.1484, 0.1377, 0.1460],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9332445859909058
 
[Iteration 5] Process ID: 181441 [Epoch: 168,  6752/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 4 4
Policy data: tensor([0.1430, 0.1395, 0.1442, 0.1395, 0.1465, 0.1454, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1396, 0.1480, 0.1384, 0.1369, 0.1526, 0.1383, 0.1461],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999579191207886
 
[Iteration 5] Process ID: 181441 [Epoch: 168, 13504/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 4 4
Policy data: tensor([0.1419, 0.1407, 0.1419, 0.1419, 0.1454, 0.1442, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1394, 0.1445, 0.1396, 0.1432, 0.1474, 0.1416, 0.1442],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.21007125079631805
 
[Iteration 5] Process ID: 181441 [Epoch: 168, 20256/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 4 4
Policy data: tensor([0.2047, 0.1204, 0.0756, 0.1002, 0.2874, 0.0913, 0.1204],
       device='cuda:0')
Policy pred: tensor([0.2104, 0.1170, 0.0842, 0.0903, 0.2794, 0.1106, 0.1081],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 168, 27008/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 4 4
Policy data: tensor([0.1430, 0.1442, 0.1407, 0.1395, 0.1489, 0.1395, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1400, 0.1438, 0.1452, 0.1377, 0.1496, 0.1407, 0.1430],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.01857912167906761
 
[Iteration 5] Process ID: 181441 [Epoch: 169,  6752/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 4 4
Policy data: tensor([0.1471, 0.1608, 0.1471, 0.1229, 0.2277, 0.0474, 0.1471],
       device='cuda:0')
Policy pred: tensor([0.1444, 0.1593, 0.1390, 0.1241, 0.2376, 0.0572, 0.1384],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 169, 13504/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 1 1
Policy data: tensor([0.0783, 0.2516, 0.1493, 0.1138, 0.1632, 0.0946, 0.1493],
       device='cuda:0')
Policy pred: tensor([0.0947, 0.2602, 0.1388, 0.1217, 0.1611, 0.0777, 0.1458],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 169, 20256/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 1 1
Policy data: tensor([0.0671, 0.3611, 0.0000, 0.1092, 0.2022, 0.0729, 0.1876],
       device='cuda:0')
Policy pred: tensor([7.8759e-02, 3.5108e-01, 1.1082e-07, 1.1342e-01, 1.9424e-01, 7.5779e-02,
        1.8673e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 169, 27008/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 4 4
Policy data: tensor([0.1465, 0.1419, 0.1372, 0.1430, 0.1489, 0.1395, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1477, 0.1485, 0.1413, 0.1437, 0.1486, 0.1385, 0.1317],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9914414286613464
 
[Iteration 5] Process ID: 181441 [Epoch: 170,  6752/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 4 4
Policy data: tensor([0.1745, 0.1221, 0.1114, 0.1016, 0.2915, 0.0767, 0.1221],
       device='cuda:0')
Policy pred: tensor([0.1724, 0.1190, 0.1079, 0.1006, 0.2877, 0.0691, 0.1433],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 170, 13504/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 6 6
Policy data: tensor([0.1348, 0.1430, 0.1477, 0.1383, 0.1465, 0.1360, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1364, 0.1419, 0.1440, 0.1450, 0.1459, 0.1362, 0.1507],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 170, 20256/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 4 4
Policy data: tensor([0.1407, 0.1442, 0.1383, 0.1407, 0.1500, 0.1407, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1404, 0.1430, 0.1406, 0.1434, 0.1477, 0.1406, 0.1443],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.19935640692710876
 
[Iteration 5] Process ID: 181441 [Epoch: 170, 27008/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 4 4
Policy data: tensor([0.1275, 0.0804, 0.0804, 0.1275, 0.3020, 0.0665, 0.2158],
       device='cuda:0')
Policy pred: tensor([0.1238, 0.0889, 0.0932, 0.1452, 0.2734, 0.0589, 0.2167],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 171,  6752/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 6 6
Policy data: tensor([0.1360, 0.1454, 0.1360, 0.1454, 0.1501, 0.1301, 0.1570],
       device='cuda:0')
Policy pred: tensor([0.1413, 0.1446, 0.1430, 0.1403, 0.1493, 0.1322, 0.1493],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9995465874671936
 
[Iteration 5] Process ID: 181441 [Epoch: 171, 13504/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 4 4
Policy data: tensor([0.0830, 0.1573, 0.1316, 0.1875, 0.2639, 0.0565, 0.1202],
       device='cuda:0')
Policy pred: tensor([0.0832, 0.1648, 0.1290, 0.1608, 0.2892, 0.0574, 0.1158],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 171, 20256/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 6 6
Policy data: tensor([0.0813, 0.1535, 0.0957, 0.0000, 0.2593, 0.0882, 0.3220],
       device='cuda:0')
Policy pred: tensor([7.3532e-02, 1.6415e-01, 9.4451e-02, 4.6323e-07, 2.5610e-01, 8.7519e-02,
        3.2426e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 171, 27008/ 27057 points] total loss per batch: 2.017
Policy (actual, predicted): 4 4
Policy data: tensor([0.1454, 0.1454, 0.1419, 0.1395, 0.1465, 0.1383, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1417, 0.1415, 0.1406, 0.1442, 0.1473, 0.1392, 0.1455],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.0033345469273626804
 
[Iteration 5] Process ID: 181441 [Epoch: 172,  6752/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 4 4
Policy data: tensor([0.1372, 0.1430, 0.1407, 0.1454, 0.1524, 0.1395, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1407, 0.1446, 0.1411, 0.1412, 0.1479, 0.1380, 0.1467],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9976171851158142
 
[Iteration 5] Process ID: 181441 [Epoch: 172, 13504/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 0 0
Policy data: tensor([0.1477, 0.1419, 0.1372, 0.1419, 0.1477, 0.1383, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1522, 0.1411, 0.1405, 0.1405, 0.1464, 0.1377, 0.1415],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9998871088027954
 
[Iteration 5] Process ID: 181441 [Epoch: 172, 20256/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 4 4
Policy data: tensor([0.1442, 0.1442, 0.1395, 0.1407, 0.1489, 0.1360, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1394, 0.1456, 0.1426, 0.1408, 0.1474, 0.1382, 0.1460],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.2576924264431
 
[Iteration 5] Process ID: 181441 [Epoch: 172, 27008/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 4 4
Policy data: tensor([0.1341, 0.1225, 0.1341, 0.0576, 0.2689, 0.1225, 0.1603],
       device='cuda:0')
Policy pred: tensor([0.1348, 0.1332, 0.1237, 0.0670, 0.2828, 0.1151, 0.1434],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 173,  6752/ 27057 points] total loss per batch: 2.035
Policy (actual, predicted): 6 6
Policy data: tensor([0.1228, 0.1554, 0.1437, 0.1812, 0.0000, 0.1134, 0.2836],
       device='cuda:0')
Policy pred: tensor([1.0962e-01, 1.6817e-01, 1.2932e-01, 2.0265e-01, 5.7881e-10, 1.2354e-01,
        2.6670e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 173, 13504/ 27057 points] total loss per batch: 2.014
Policy (actual, predicted): 6 6
Policy data: tensor([0.1103, 0.0000, 0.0966, 0.1961, 0.0000, 0.0313, 0.5658],
       device='cuda:0')
Policy pred: tensor([1.0958e-01, 3.2707e-07, 9.3101e-02, 2.4188e-01, 3.9584e-11, 3.4576e-02,
        5.2086e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 173, 20256/ 27057 points] total loss per batch: 2.019
Policy (actual, predicted): 4 4
Policy data: tensor([0.1383, 0.1454, 0.1442, 0.1395, 0.1465, 0.1430, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1417, 0.1445, 0.1416, 0.1404, 0.1482, 0.1391, 0.1446],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9991458654403687
 
[Iteration 5] Process ID: 181441 [Epoch: 173, 27008/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 2 4
Policy data: tensor([0.1395, 0.1454, 0.1465, 0.1442, 0.1442, 0.1360, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1416, 0.1437, 0.1415, 0.1411, 0.1482, 0.1400, 0.1440],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9774857759475708
 
[Iteration 5] Process ID: 181441 [Epoch: 174,  6752/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 4 4
Policy data: tensor([0.0836, 0.1006, 0.1320, 0.1206, 0.3957, 0.0469, 0.1206],
       device='cuda:0')
Policy pred: tensor([0.0842, 0.1037, 0.1380, 0.1188, 0.3666, 0.0618, 0.1269],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 174, 13504/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 3 3
Policy data: tensor([0.0795, 0.1378, 0.0596, 0.2985, 0.2322, 0.0873, 0.1050],
       device='cuda:0')
Policy pred: tensor([0.0848, 0.1378, 0.0634, 0.2833, 0.2325, 0.0839, 0.1143],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 174, 20256/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 6 5
Policy data: tensor([0.1383, 0.1395, 0.1465, 0.1383, 0.1477, 0.1407, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1436, 0.1421, 0.1485, 0.1284, 0.1411, 0.1515, 0.1447],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 174, 27008/ 27057 points] total loss per batch: 2.015
Policy (actual, predicted): 6 6
Policy data: tensor([0.0696, 0.0922, 0.1583, 0.1108, 0.2432, 0.0386, 0.2873],
       device='cuda:0')
Policy pred: tensor([0.0676, 0.1013, 0.1527, 0.1075, 0.2581, 0.0400, 0.2728],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 175,  6752/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 1 1
Policy data: tensor([0.0970, 0.2781, 0.2159, 0.0804, 0.1395, 0.0496, 0.1395],
       device='cuda:0')
Policy pred: tensor([0.0985, 0.3089, 0.1826, 0.0822, 0.1394, 0.0484, 0.1400],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 175, 13504/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 6 6
Policy data: tensor([0.1341, 0.1750, 0.1466, 0.0929, 0.1910, 0.0522, 0.2083],
       device='cuda:0')
Policy pred: tensor([0.1378, 0.1657, 0.1506, 0.1042, 0.1747, 0.0634, 0.2036],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 175, 20256/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 4 6
Policy data: tensor([0.1466, 0.1407, 0.1419, 0.1419, 0.1501, 0.1289, 0.1501],
       device='cuda:0')
Policy pred: tensor([0.1402, 0.1401, 0.1455, 0.1421, 0.1489, 0.1329, 0.1503],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.3740139305591583
 
[Iteration 5] Process ID: 181441 [Epoch: 175, 27008/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 4 2
Policy data: tensor([0.1419, 0.1407, 0.1465, 0.1407, 0.1500, 0.1325, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1417, 0.1425, 0.1519, 0.1361, 0.1453, 0.1349, 0.1477],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999809861183167
 
[Iteration 5] Process ID: 181441 [Epoch: 176,  6752/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 2 6
Policy data: tensor([0.1442, 0.1430, 0.1501, 0.1407, 0.1489, 0.1277, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1429, 0.1408, 0.1461, 0.1412, 0.1471, 0.1327, 0.1493],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.0004735766560770571
 
[Iteration 5] Process ID: 181441 [Epoch: 176, 13504/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 1 1
Policy data: tensor([0.0879, 0.2164, 0.1162, 0.1819, 0.1393, 0.1059, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1109, 0.1863, 0.1226, 0.1430, 0.1542, 0.1162, 0.1668],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 176, 20256/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 4 4
Policy data: tensor([0.1454, 0.1454, 0.1419, 0.1395, 0.1465, 0.1383, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1403, 0.1415, 0.1415, 0.1452, 0.1463, 0.1396, 0.1456],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.008689210750162601
 
[Iteration 5] Process ID: 181441 [Epoch: 176, 27008/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 1 1
Policy data: tensor([0.0000, 0.2314, 0.1250, 0.1353, 0.2147, 0.1582, 0.1353],
       device='cuda:0')
Policy pred: tensor([5.6274e-07, 2.3097e-01, 1.3440e-01, 1.4072e-01, 2.0145e-01, 1.6918e-01,
        1.2328e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 177,  6752/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 2 2
Policy data: tensor([0.1129, 0.0000, 0.2623, 0.1671, 0.1946, 0.0961, 0.1671],
       device='cuda:0')
Policy pred: tensor([1.2471e-01, 1.4458e-05, 2.5600e-01, 1.5400e-01, 2.0010e-01, 8.7891e-02,
        1.7728e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 177, 13504/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 4 4
Policy data: tensor([0.0960, 0.1656, 0.1656, 0.0960, 0.2152, 0.0960, 0.1656],
       device='cuda:0')
Policy pred: tensor([0.0968, 0.1530, 0.1611, 0.1123, 0.2245, 0.0972, 0.1550],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 177, 20256/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 6 6
Policy data: tensor([0.1407, 0.1383, 0.1442, 0.1395, 0.1465, 0.1407, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1407, 0.1414, 0.1446, 0.1391, 0.1471, 0.1359, 0.1512],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.26049575209617615
 
[Iteration 5] Process ID: 181441 [Epoch: 177, 27008/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 6 6
Policy data: tensor([0.1454, 0.1383, 0.1442, 0.1383, 0.1477, 0.1360, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1405, 0.1412, 0.1435, 0.1394, 0.1467, 0.1379, 0.1508],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.007319021970033646
 
[Iteration 5] Process ID: 181441 [Epoch: 178,  6752/ 27057 points] total loss per batch: 2.012
Policy (actual, predicted): 5 5
Policy data: tensor([0.0000, 0.0000, 0.0000, 0.2938, 0.0000, 0.7062, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.2548e-05, 2.6611e-06, 2.7001e-09, 2.5801e-01, 1.4226e-07, 7.4197e-01,
        2.0078e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 178, 13504/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 4 6
Policy data: tensor([0.1360, 0.1407, 0.1454, 0.1442, 0.1489, 0.1360, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1377, 0.1426, 0.1396, 0.1426, 0.1503, 0.1352, 0.1521],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 178, 20256/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 1 1
Policy data: tensor([0.1266, 0.2154, 0.1386, 0.1156, 0.1657, 0.0723, 0.1657],
       device='cuda:0')
Policy pred: tensor([0.1238, 0.1851, 0.1447, 0.1031, 0.1840, 0.0828, 0.1765],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 178, 27008/ 27057 points] total loss per batch: 2.034
Policy (actual, predicted): 6 6
Policy data: tensor([0.1477, 0.1372, 0.1348, 0.1407, 0.1454, 0.1419, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1450, 0.1411, 0.1420, 0.1402, 0.1484, 0.1328, 0.1504],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.15938423573970795
 
[Iteration 5] Process ID: 181441 [Epoch: 179,  6752/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 4 6
Policy data: tensor([0.1383, 0.1454, 0.1395, 0.1430, 0.1512, 0.1325, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1430, 0.1413, 0.1416, 0.1420, 0.1477, 0.1326, 0.1519],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.20986905694007874
 
[Iteration 5] Process ID: 181441 [Epoch: 179, 13504/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 4 4
Policy data: tensor([0.0000, 0.0000, 0.0000, 0.2223, 0.4265, 0.1803, 0.1709],
       device='cuda:0')
Policy pred: tensor([6.0421e-05, 3.9225e-07, 5.2453e-07, 2.0222e-01, 4.3948e-01, 1.9140e-01,
        1.6684e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 179, 20256/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 6 6
Policy data: tensor([0.1477, 0.1407, 0.1395, 0.1372, 0.1477, 0.1348, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1447, 0.1399, 0.1430, 0.1413, 0.1491, 0.1320, 0.1501],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.05299556255340576
 
[Iteration 5] Process ID: 181441 [Epoch: 179, 27008/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 2 2
Policy data: tensor([0.1701, 0.0000, 0.6056, 0.0712, 0.0000, 0.1532, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.8395e-01, 6.4305e-08, 6.1028e-01, 7.6679e-02, 6.2042e-09, 1.2908e-01,
        1.9865e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 180,  6752/ 27057 points] total loss per batch: 2.017
Policy (actual, predicted): 4 4
Policy data: tensor([0.0598, 0.1962, 0.1153, 0.1053, 0.3248, 0.0724, 0.1263],
       device='cuda:0')
Policy pred: tensor([0.0584, 0.1818, 0.1142, 0.1049, 0.3182, 0.0786, 0.1439],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 180, 13504/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 3 4
Policy data: tensor([0.1395, 0.1454, 0.1360, 0.1465, 0.1465, 0.1395, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1336, 0.1456, 0.1364, 0.1453, 0.1502, 0.1429, 0.1460],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 180, 20256/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 4 4
Policy data: tensor([0.1383, 0.1454, 0.1383, 0.1430, 0.1500, 0.1383, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1399, 0.1445, 0.1401, 0.1434, 0.1488, 0.1375, 0.1457],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.12254199385643005
 
[Iteration 5] Process ID: 181441 [Epoch: 180, 27008/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 3 3
Policy data: tensor([0.0635, 0.0000, 0.0690, 0.3419, 0.3186, 0.1035, 0.1035],
       device='cuda:0')
Policy pred: tensor([5.3625e-02, 1.9873e-10, 6.3133e-02, 3.4964e-01, 3.3208e-01, 9.3155e-02,
        1.0837e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 181,  6752/ 27057 points] total loss per batch: 2.012
Policy (actual, predicted): 1 4
Policy data: tensor([0.1348, 0.1477, 0.1454, 0.1407, 0.1477, 0.1419, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1377, 0.1470, 0.1390, 0.1418, 0.1477, 0.1421, 0.1447],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9893355965614319
 
[Iteration 5] Process ID: 181441 [Epoch: 181, 13504/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 6 6
Policy data: tensor([0.1442, 0.1407, 0.1419, 0.1383, 0.1501, 0.1325, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1391, 0.1444, 0.1421, 0.1394, 0.1493, 0.1339, 0.1519],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999990463256836
 
[Iteration 5] Process ID: 181441 [Epoch: 181, 20256/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1442, 0.1465, 0.1360, 0.1500, 0.1372, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1402, 0.1464, 0.1409, 0.1407, 0.1478, 0.1379, 0.1460],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9995229840278625
 
[Iteration 5] Process ID: 181441 [Epoch: 181, 27008/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 6 6
Policy data: tensor([0.1074, 0.1689, 0.1546, 0.1178, 0.1689, 0.0979, 0.1845],
       device='cuda:0')
Policy pred: tensor([0.1117, 0.1588, 0.1675, 0.1176, 0.1598, 0.0957, 0.1889],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 182,  6752/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 2 4
Policy data: tensor([0.1430, 0.1442, 0.1465, 0.1395, 0.1465, 0.1407, 0.1395],
       device='cuda:0')
Policy pred: tensor([0.1395, 0.1447, 0.1404, 0.1435, 0.1467, 0.1416, 0.1435],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.19115693867206573
 
[Iteration 5] Process ID: 181441 [Epoch: 182, 13504/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 1 4
Policy data: tensor([0.1372, 0.1477, 0.1419, 0.1454, 0.1442, 0.1407, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1410, 0.1440, 0.1410, 0.1420, 0.1470, 0.1405, 0.1444],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.11253954470157623
 
[Iteration 5] Process ID: 181441 [Epoch: 182, 20256/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 0 0
Policy data: tensor([0.2512, 0.0280, 0.1273, 0.2335, 0.0000, 0.1868, 0.1732],
       device='cuda:0')
Policy pred: tensor([2.5465e-01, 5.9365e-02, 1.1748e-01, 2.2658e-01, 8.2926e-10, 1.8229e-01,
        1.5964e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 182, 27008/ 27057 points] total loss per batch: 2.017
Policy (actual, predicted): 6 6
Policy data: tensor([0.0841, 0.1872, 0.0698, 0.1106, 0.1322, 0.0233, 0.3928],
       device='cuda:0')
Policy pred: tensor([0.0762, 0.1852, 0.0653, 0.1059, 0.1275, 0.0350, 0.4048],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 183,  6752/ 27057 points] total loss per batch: 2.016
Policy (actual, predicted): 4 4
Policy data: tensor([0.1536, 0.1171, 0.0886, 0.1833, 0.2000, 0.1171, 0.1404],
       device='cuda:0')
Policy pred: tensor([0.1489, 0.1124, 0.0997, 0.1900, 0.1958, 0.1114, 0.1418],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 183, 13504/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 6 6
Policy data: tensor([0.1372, 0.1430, 0.1384, 0.1454, 0.1512, 0.1301, 0.1547],
       device='cuda:0')
Policy pred: tensor([0.1426, 0.1425, 0.1408, 0.1414, 0.1479, 0.1336, 0.1513],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.20632228255271912
 
[Iteration 5] Process ID: 181441 [Epoch: 183, 20256/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 6 6
Policy data: tensor([0.1442, 0.1395, 0.1454, 0.1395, 0.1489, 0.1313, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1436, 0.1398, 0.1464, 0.1411, 0.1478, 0.1315, 0.1498],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.009760942310094833
 
[Iteration 5] Process ID: 181441 [Epoch: 183, 27008/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 4 4
Policy data: tensor([0.0615, 0.1621, 0.1750, 0.0000, 0.2738, 0.1388, 0.1888],
       device='cuda:0')
Policy pred: tensor([5.5124e-02, 1.7384e-01, 1.6127e-01, 2.2372e-09, 2.9731e-01, 1.2805e-01,
        1.8441e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 184,  6752/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 3 3
Policy data: tensor([0.1403, 0.1403, 0.1674, 0.2171, 0.0809, 0.0369, 0.2171],
       device='cuda:0')
Policy pred: tensor([0.1335, 0.1496, 0.1694, 0.2238, 0.0770, 0.0420, 0.2046],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 184, 13504/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 2 6
Policy data: tensor([0.1395, 0.1372, 0.1524, 0.1407, 0.1501, 0.1289, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1430, 0.1404, 0.1459, 0.1421, 0.1459, 0.1327, 0.1499],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.10385340452194214
 
[Iteration 5] Process ID: 181441 [Epoch: 184, 20256/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 6 6
Policy data: tensor([0.1430, 0.1454, 0.1383, 0.1407, 0.1442, 0.1407, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1426, 0.1446, 0.1410, 0.1403, 0.1470, 0.1335, 0.1510],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 184, 27008/ 27057 points] total loss per batch: 2.031
Policy (actual, predicted): 6 6
Policy data: tensor([0.1430, 0.1407, 0.1477, 0.1395, 0.1477, 0.1277, 0.1536],
       device='cuda:0')
Policy pred: tensor([0.1445, 0.1397, 0.1476, 0.1403, 0.1473, 0.1300, 0.1505],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.011500300839543343
 
[Iteration 5] Process ID: 181441 [Epoch: 185,  6752/ 27057 points] total loss per batch: 2.038
Policy (actual, predicted): 6 6
Policy data: tensor([0.1442, 0.1430, 0.1407, 0.1407, 0.1465, 0.1325, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1429, 0.1423, 0.1427, 0.1398, 0.1489, 0.1307, 0.1527],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.46752285957336426
 
[Iteration 5] Process ID: 181441 [Epoch: 185, 13504/ 27057 points] total loss per batch: 2.015
Policy (actual, predicted): 4 4
Policy data: tensor([0.0939, 0.1482, 0.1238, 0.1238, 0.2293, 0.0706, 0.2105],
       device='cuda:0')
Policy pred: tensor([0.0953, 0.1476, 0.1238, 0.1133, 0.2421, 0.0656, 0.2123],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 185, 20256/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 4 4
Policy data: tensor([0.1393, 0.1161, 0.1985, 0.1059, 0.2164, 0.1272, 0.0965],
       device='cuda:0')
Policy pred: tensor([0.1440, 0.1308, 0.1852, 0.1149, 0.2095, 0.1179, 0.0978],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999887347221375
 
[Iteration 5] Process ID: 181441 [Epoch: 185, 27008/ 27057 points] total loss per batch: 2.015
Policy (actual, predicted): 6 6
Policy data: tensor([0.0894, 0.1286, 0.0675, 0.0742, 0.1991, 0.0557, 0.3857],
       device='cuda:0')
Policy pred: tensor([0.0974, 0.1331, 0.0699, 0.0778, 0.1990, 0.0533, 0.3695],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 186,  6752/ 27057 points] total loss per batch: 2.014
Policy (actual, predicted): 4 1
Policy data: tensor([0.1419, 0.1512, 0.1360, 0.1372, 0.1535, 0.1360, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1442, 0.1503, 0.1419, 0.1335, 0.1478, 0.1340, 0.1483],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999998807907104
 
[Iteration 5] Process ID: 181441 [Epoch: 186, 13504/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 6 6
Policy data: tensor([0.0920, 0.1600, 0.1600, 0.1600, 0.0000, 0.0920, 0.3358],
       device='cuda:0')
Policy pred: tensor([9.6747e-02, 1.5672e-01, 1.3060e-01, 1.7610e-01, 6.0456e-08, 1.0068e-01,
        3.3916e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 186, 20256/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 6 6
Policy data: tensor([0.1442, 0.1430, 0.1383, 0.1372, 0.1477, 0.1348, 0.1547],
       device='cuda:0')
Policy pred: tensor([0.1421, 0.1448, 0.1434, 0.1378, 0.1454, 0.1344, 0.1521],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999682903289795
 
[Iteration 5] Process ID: 181441 [Epoch: 186, 27008/ 27057 points] total loss per batch: 2.029
Policy (actual, predicted): 6 6
Policy data: tensor([0.1434, 0.1198, 0.0827, 0.1311, 0.2037, 0.0563, 0.2630],
       device='cuda:0')
Policy pred: tensor([0.1382, 0.1342, 0.0863, 0.1385, 0.1891, 0.0583, 0.2553],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 187,  6752/ 27057 points] total loss per batch: 2.015
Policy (actual, predicted): 4 4
Policy data: tensor([0.1454, 0.1407, 0.1430, 0.1383, 0.1465, 0.1419, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1418, 0.1439, 0.1413, 0.1410, 0.1485, 0.1396, 0.1439],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9987543225288391
 
[Iteration 5] Process ID: 181441 [Epoch: 187, 13504/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 4 4
Policy data: tensor([0.0569, 0.1315, 0.0516, 0.1438, 0.2849, 0.0690, 0.2622],
       device='cuda:0')
Policy pred: tensor([0.0608, 0.1335, 0.0528, 0.1467, 0.2835, 0.0670, 0.2557],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 187, 20256/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1465, 0.1383, 0.1407, 0.1547, 0.1360, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1414, 0.1430, 0.1419, 0.1409, 0.1489, 0.1363, 0.1475],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999999403953552
 
[Iteration 5] Process ID: 181441 [Epoch: 187, 27008/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 6 6
Policy data: tensor([0.0759, 0.1714, 0.0627, 0.2217, 0.1714, 0.0346, 0.2623],
       device='cuda:0')
Policy pred: tensor([0.0740, 0.1739, 0.0679, 0.2224, 0.1668, 0.0392, 0.2557],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 188,  6752/ 27057 points] total loss per batch: 2.016
Policy (actual, predicted): 4 4
Policy data: tensor([0.0704, 0.1603, 0.0851, 0.1343, 0.3159, 0.0432, 0.1908],
       device='cuda:0')
Policy pred: tensor([0.0697, 0.1544, 0.0972, 0.1146, 0.3416, 0.0388, 0.1836],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 188, 13504/ 27057 points] total loss per batch: 2.019
Policy (actual, predicted): 4 6
Policy data: tensor([0.1466, 0.1419, 0.1477, 0.1372, 0.1512, 0.1289, 0.1466],
       device='cuda:0')
Policy pred: tensor([0.1441, 0.1401, 0.1464, 0.1406, 0.1473, 0.1310, 0.1503],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 -0.00034404423786327243
 
[Iteration 5] Process ID: 181441 [Epoch: 188, 20256/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 6 4
Policy data: tensor([0.1407, 0.1442, 0.1372, 0.1430, 0.1477, 0.1372, 0.1500],
       device='cuda:0')
Policy pred: tensor([0.1414, 0.1443, 0.1404, 0.1420, 0.1472, 0.1396, 0.1450],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 -0.02204621583223343
 
[Iteration 5] Process ID: 181441 [Epoch: 188, 27008/ 27057 points] total loss per batch: 2.035
Policy (actual, predicted): 4 4
Policy data: tensor([0.1407, 0.1430, 0.1430, 0.1407, 0.1477, 0.1407, 0.1442],
       device='cuda:0')
Policy pred: tensor([0.1394, 0.1440, 0.1410, 0.1437, 0.1470, 0.1411, 0.1438],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.17298981547355652
 
[Iteration 5] Process ID: 181441 [Epoch: 189,  6752/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 3 3
Policy data: tensor([0.0866, 0.2384, 0.1765, 0.2567, 0.0000, 0.1019, 0.1400],
       device='cuda:0')
Policy pred: tensor([7.8332e-02, 2.4049e-01, 1.6987e-01, 2.7593e-01, 4.9846e-09, 9.7131e-02,
        1.3825e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 189, 13504/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 6 4
Policy data: tensor([0.1383, 0.1407, 0.1442, 0.1430, 0.1430, 0.1430, 0.1477],
       device='cuda:0')
Policy pred: tensor([0.1388, 0.1430, 0.1418, 0.1425, 0.1483, 0.1410, 0.1446],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.006330532021820545
 
[Iteration 5] Process ID: 181441 [Epoch: 189, 20256/ 27057 points] total loss per batch: 2.017
Policy (actual, predicted): 4 4
Policy data: tensor([0.1707, 0.1428, 0.1086, 0.1305, 0.1865, 0.1305, 0.1305],
       device='cuda:0')
Policy pred: tensor([0.1594, 0.1476, 0.0991, 0.1298, 0.2017, 0.1388, 0.1236],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999998807907104
 
[Iteration 5] Process ID: 181441 [Epoch: 189, 27008/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 4 4
Policy data: tensor([0.1668, 0.1274, 0.1526, 0.1163, 0.1821, 0.0727, 0.1821],
       device='cuda:0')
Policy pred: tensor([0.1645, 0.1308, 0.1485, 0.1150, 0.1945, 0.0829, 0.1639],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 190,  6752/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 4 4
Policy data: tensor([0.1407, 0.1465, 0.1407, 0.1348, 0.1547, 0.1360, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1379, 0.1441, 0.1433, 0.1399, 0.1496, 0.1392, 0.1460],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.5466029047966003
 
[Iteration 5] Process ID: 181441 [Epoch: 190, 13504/ 27057 points] total loss per batch: 2.019
Policy (actual, predicted): 4 4
Policy data: tensor([0.1380, 0.1798, 0.0658, 0.0960, 0.2752, 0.0491, 0.1961],
       device='cuda:0')
Policy pred: tensor([0.1222, 0.1667, 0.0851, 0.1082, 0.2804, 0.0539, 0.1835],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 190, 20256/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 1 1
Policy data: tensor([0.2444, 0.2946, 0.1558, 0.1276, 0.0000, 0.1776, 0.0000],
       device='cuda:0')
Policy pred: tensor([2.5045e-01, 2.8985e-01, 1.6603e-01, 1.3450e-01, 1.0158e-10, 1.5917e-01,
        2.6377e-09], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 190, 27008/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 6 6
Policy data: tensor([0.1430, 0.1383, 0.1454, 0.1419, 0.1454, 0.1336, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1432, 0.1401, 0.1469, 0.1415, 0.1466, 0.1317, 0.1500],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.007299525197595358
 
[Iteration 5] Process ID: 181441 [Epoch: 191,  6752/ 27057 points] total loss per batch: 2.019
Policy (actual, predicted): 4 4
Policy data: tensor([0.1310, 0.1310, 0.1196, 0.1434, 0.1872, 0.1310, 0.1569],
       device='cuda:0')
Policy pred: tensor([0.1288, 0.1411, 0.1269, 0.1316, 0.1941, 0.1162, 0.1614],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 191, 13504/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 4 4
Policy data: tensor([0.1164, 0.1527, 0.1527, 0.1669, 0.1989, 0.0728, 0.1396],
       device='cuda:0')
Policy pred: tensor([0.1296, 0.1605, 0.1463, 0.1663, 0.1974, 0.0569, 0.1430],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 191, 20256/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 4 4
Policy data: tensor([0.1454, 0.1442, 0.1348, 0.1383, 0.1500, 0.1442, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1406, 0.1431, 0.1393, 0.1434, 0.1505, 0.1364, 0.1468],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.15068261325359344
 
[Iteration 5] Process ID: 181441 [Epoch: 191, 27008/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 4 4
Policy data: tensor([0.1076, 0.0000, 0.0558, 0.0846, 0.3815, 0.1713, 0.1991],
       device='cuda:0')
Policy pred: tensor([1.0156e-01, 1.8615e-08, 5.6145e-02, 9.0142e-02, 3.8569e-01, 1.7968e-01,
        1.8679e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999982118606567
 
[Iteration 5] Process ID: 181441 [Epoch: 192,  6752/ 27057 points] total loss per batch: 2.014
Policy (actual, predicted): 6 6
Policy data: tensor([0.1089, 0.0993, 0.1089, 0.1193, 0.1861, 0.0681, 0.3094],
       device='cuda:0')
Policy pred: tensor([0.0989, 0.1024, 0.1110, 0.1252, 0.1834, 0.0675, 0.3116],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9999995827674866
 
[Iteration 5] Process ID: 181441 [Epoch: 192, 13504/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 4 4
Policy data: tensor([0.1689, 0.1413, 0.1291, 0.0891, 0.2013, 0.1413, 0.1291],
       device='cuda:0')
Policy pred: tensor([0.1777, 0.1346, 0.1384, 0.0867, 0.1913, 0.1374, 0.1338],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 192, 20256/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 0 0
Policy data: tensor([0.3580, 0.2641, 0.1811, 0.1397, 0.0000, 0.0571, 0.0000],
       device='cuda:0')
Policy pred: tensor([3.5361e-01, 2.7901e-01, 1.8051e-01, 1.2471e-01, 3.1011e-08, 6.2161e-02,
        1.2706e-06], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 192, 27008/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 4 4
Policy data: tensor([0.0776, 0.1128, 0.1617, 0.1029, 0.2494, 0.1928, 0.1029],
       device='cuda:0')
Policy pred: tensor([0.0797, 0.1195, 0.1405, 0.1014, 0.2770, 0.1941, 0.0878],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 193,  6752/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 6 6
Policy data: tensor([0.1407, 0.1395, 0.1407, 0.1430, 0.1465, 0.1336, 0.1559],
       device='cuda:0')
Policy pred: tensor([0.1415, 0.1428, 0.1470, 0.1428, 0.1470, 0.1306, 0.1484],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.00418691523373127
 
[Iteration 5] Process ID: 181441 [Epoch: 193, 13504/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 4 4
Policy data: tensor([0.0939, 0.2212, 0.1293, 0.2052, 0.2565, 0.0939, 0.0000],
       device='cuda:0')
Policy pred: tensor([8.9598e-02, 2.1286e-01, 1.2698e-01, 2.0804e-01, 2.7200e-01, 9.0529e-02,
        2.9742e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 193, 20256/ 27057 points] total loss per batch: 2.014
Policy (actual, predicted): 1 3
Policy data: tensor([0.1542, 0.2740, 0.1874, 0.2740, 0.0000, 0.1103, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.4004e-01, 2.6537e-01, 2.0679e-01, 2.7590e-01, 1.3611e-07, 1.1190e-01,
        7.5583e-08], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 193, 27008/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 2 2
Policy data: tensor([0.0718, 0.2333, 0.2906, 0.1081, 0.1481, 0.1481, 0.0000],
       device='cuda:0')
Policy pred: tensor([7.6277e-02, 2.3459e-01, 2.7252e-01, 1.0305e-01, 1.6243e-01, 1.5113e-01,
        3.1251e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 194,  6752/ 27057 points] total loss per batch: 2.035
Policy (actual, predicted): 3 3
Policy data: tensor([0.0496, 0.0000, 0.0694, 0.2983, 0.2777, 0.0817, 0.2233],
       device='cuda:0')
Policy pred: tensor([6.2416e-02, 9.7430e-10, 8.2989e-02, 2.9037e-01, 2.6702e-01, 7.7530e-02,
        2.1967e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 194, 13504/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 1 1
Policy data: tensor([0.1328, 0.2897, 0.0838, 0.1588, 0.1328, 0.0692, 0.1328],
       device='cuda:0')
Policy pred: tensor([0.1218, 0.2894, 0.0871, 0.1686, 0.1323, 0.0660, 0.1347],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 194, 20256/ 27057 points] total loss per batch: 2.014
Policy (actual, predicted): 4 4
Policy data: tensor([0.1430, 0.1407, 0.1419, 0.1395, 0.1500, 0.1383, 0.1465],
       device='cuda:0')
Policy pred: tensor([0.1409, 0.1438, 0.1393, 0.1440, 0.1466, 0.1416, 0.1437],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9999954104423523
 
[Iteration 5] Process ID: 181441 [Epoch: 194, 27008/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 0 4
Policy data: tensor([0.1465, 0.1442, 0.1442, 0.1336, 0.1465, 0.1395, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1407, 0.1451, 0.1425, 0.1398, 0.1472, 0.1388, 0.1461],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9995421171188354
 
[Iteration 5] Process ID: 181441 [Epoch: 195,  6752/ 27057 points] total loss per batch: 2.021
Policy (actual, predicted): 4 4
Policy data: tensor([0.1454, 0.1383, 0.1419, 0.1419, 0.1500, 0.1372, 0.1454],
       device='cuda:0')
Policy pred: tensor([0.1405, 0.1451, 0.1409, 0.1404, 0.1480, 0.1410, 0.1441],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 0.9968121647834778
 
[Iteration 5] Process ID: 181441 [Epoch: 195, 13504/ 27057 points] total loss per batch: 2.020
Policy (actual, predicted): 1 6
Policy data: tensor([0.0769, 0.2268, 0.0928, 0.1117, 0.1909, 0.0928, 0.2081],
       device='cuda:0')
Policy pred: tensor([0.0743, 0.2097, 0.0907, 0.1044, 0.1888, 0.1074, 0.2247],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 195, 20256/ 27057 points] total loss per batch: 2.036
Policy (actual, predicted): 3 4
Policy data: tensor([0.1442, 0.1442, 0.1430, 0.1454, 0.1419, 0.1383, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1403, 0.1442, 0.1410, 0.1422, 0.1459, 0.1416, 0.1448],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.1666698157787323
 
[Iteration 5] Process ID: 181441 [Epoch: 195, 27008/ 27057 points] total loss per batch: 2.019
Policy (actual, predicted): 6 6
Policy data: tensor([0.1430, 0.1419, 0.1466, 0.1454, 0.1442, 0.1265, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1439, 0.1403, 0.1470, 0.1404, 0.1464, 0.1316, 0.1506],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 0.0 0.003567541018128395
 
[Iteration 5] Process ID: 181441 [Epoch: 196,  6752/ 27057 points] total loss per batch: 2.032
Policy (actual, predicted): 4 4
Policy data: tensor([0.1907, 0.0000, 0.1907, 0.0000, 0.4280, 0.1907, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.8127e-01, 3.9410e-12, 1.7370e-01, 2.5817e-11, 4.5338e-01, 1.9165e-01,
        3.2310e-10], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 196, 13504/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 6 6
Policy data: tensor([0.1466, 0.1430, 0.1419, 0.1419, 0.1466, 0.1277, 0.1524],
       device='cuda:0')
Policy pred: tensor([0.1405, 0.1411, 0.1455, 0.1404, 0.1479, 0.1335, 0.1510],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.18011024594306946
 
[Iteration 5] Process ID: 181441 [Epoch: 196, 20256/ 27057 points] total loss per batch: 2.014
Policy (actual, predicted): 1 1
Policy data: tensor([0.0965, 0.2635, 0.0000, 0.1437, 0.1955, 0.1329, 0.1678],
       device='cuda:0')
Policy pred: tensor([1.1017e-01, 2.6557e-01, 3.3445e-06, 1.3290e-01, 2.0281e-01, 1.4145e-01,
        1.4710e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 196, 27008/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 6 6
Policy data: tensor([0.1407, 0.1419, 0.1407, 0.1430, 0.1501, 0.1289, 0.1547],
       device='cuda:0')
Policy pred: tensor([0.1455, 0.1474, 0.1338, 0.1431, 0.1378, 0.1328, 0.1596],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 197,  6752/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 4 6
Policy data: tensor([0.1454, 0.1477, 0.1313, 0.1395, 0.1524, 0.1348, 0.1489],
       device='cuda:0')
Policy pred: tensor([0.1374, 0.1469, 0.1339, 0.1397, 0.1518, 0.1351, 0.1552],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 197, 13504/ 27057 points] total loss per batch: 2.030
Policy (actual, predicted): 4 4
Policy data: tensor([0.1395, 0.1430, 0.1430, 0.1430, 0.1489, 0.1395, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1413, 0.1457, 0.1423, 0.1400, 0.1486, 0.1385, 0.1437],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 0.09121488779783249
 
[Iteration 5] Process ID: 181441 [Epoch: 197, 20256/ 27057 points] total loss per batch: 2.013
Policy (actual, predicted): 6 6
Policy data: tensor([0.1299, 0.1422, 0.1422, 0.1422, 0.1422, 0.0985, 0.2026],
       device='cuda:0')
Policy pred: tensor([0.1164, 0.1417, 0.1428, 0.1602, 0.1456, 0.0990, 0.1944],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 197, 27008/ 27057 points] total loss per batch: 2.019
Policy (actual, predicted): 0 1
Policy data: tensor([0.1454, 0.1454, 0.1430, 0.1407, 0.1454, 0.1395, 0.1407],
       device='cuda:0')
Policy pred: tensor([0.1401, 0.1486, 0.1412, 0.1400, 0.1471, 0.1384, 0.1447],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 198,  6752/ 27057 points] total loss per batch: 2.024
Policy (actual, predicted): 4 6
Policy data: tensor([0.1419, 0.1348, 0.1407, 0.1407, 0.1524, 0.1383, 0.1512],
       device='cuda:0')
Policy pred: tensor([0.1431, 0.1393, 0.1368, 0.1406, 0.1541, 0.1308, 0.1551],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 198, 13504/ 27057 points] total loss per batch: 2.014
Policy (actual, predicted): 6 6
Policy data: tensor([0.0602, 0.0800, 0.2517, 0.0878, 0.1262, 0.0449, 0.3493],
       device='cuda:0')
Policy pred: tensor([0.0745, 0.0882, 0.2316, 0.0886, 0.1440, 0.0480, 0.3251],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 198, 20256/ 27057 points] total loss per batch: 2.022
Policy (actual, predicted): 4 4
Policy data: tensor([0.1264, 0.1806, 0.0872, 0.0872, 0.2149, 0.1383, 0.1654],
       device='cuda:0')
Policy pred: tensor([0.1274, 0.1753, 0.0884, 0.0928, 0.1981, 0.1462, 0.1718],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 198, 27008/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 6 6
Policy data: tensor([0.1454, 0.1430, 0.1383, 0.1407, 0.1466, 0.1313, 0.1547],
       device='cuda:0')
Policy pred: tensor([0.1409, 0.1427, 0.1434, 0.1420, 0.1488, 0.1312, 0.1509],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9987276792526245
 
[Iteration 5] Process ID: 181441 [Epoch: 199,  6752/ 27057 points] total loss per batch: 2.027
Policy (actual, predicted): 1 1
Policy data: tensor([0.1596, 0.3608, 0.1225, 0.0000, 0.2345, 0.1225, 0.0000],
       device='cuda:0')
Policy pred: tensor([1.8046e-01, 3.2913e-01, 1.1461e-01, 8.2607e-07, 2.4058e-01, 1.3522e-01,
        7.7796e-07], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 199, 13504/ 27057 points] total loss per batch: 2.013
Policy (actual, predicted): 4 4
Policy data: tensor([0.1419, 0.1442, 0.1407, 0.1442, 0.1500, 0.1372, 0.1419],
       device='cuda:0')
Policy pred: tensor([0.1418, 0.1438, 0.1398, 0.1427, 0.1469, 0.1408, 0.1442],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.12005538493394852
 
[Iteration 5] Process ID: 181441 [Epoch: 199, 20256/ 27057 points] total loss per batch: 2.023
Policy (actual, predicted): 4 4
Policy data: tensor([0.1080, 0.1297, 0.1698, 0.1184, 0.2023, 0.1420, 0.1297],
       device='cuda:0')
Policy pred: tensor([0.1128, 0.1229, 0.1661, 0.1196, 0.2071, 0.1336, 0.1380],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 199, 27008/ 27057 points] total loss per batch: 2.025
Policy (actual, predicted): 6 6
Policy data: tensor([0.1395, 0.1477, 0.1395, 0.1383, 0.1501, 0.1313, 0.1535],
       device='cuda:0')
Policy pred: tensor([0.1426, 0.1412, 0.1419, 0.1435, 0.1493, 0.1317, 0.1497],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.9929595589637756
 
[Iteration 5] Process ID: 181441 [Epoch: 200,  6752/ 27057 points] total loss per batch: 2.019
Policy (actual, predicted): 1 4
Policy data: tensor([0.1383, 0.1477, 0.1442, 0.1430, 0.1442, 0.1395, 0.1430],
       device='cuda:0')
Policy pred: tensor([0.1408, 0.1428, 0.1413, 0.1427, 0.1479, 0.1401, 0.1445],
       device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): -1.0 -0.1810922920703888
 
[Iteration 5] Process ID: 181441 [Epoch: 200, 13504/ 27057 points] total loss per batch: 2.026
Policy (actual, predicted): 0 0
Policy data: tensor([0.2920, 0.1735, 0.1176, 0.0722, 0.2176, 0.0000, 0.1272],
       device='cuda:0')
Policy pred: tensor([3.1834e-01, 1.7680e-01, 1.0372e-01, 6.8723e-02, 2.1366e-01, 1.5102e-06,
        1.1875e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 200, 20256/ 27057 points] total loss per batch: 2.018
Policy (actual, predicted): 1 1
Policy data: tensor([0.1838, 0.2375, 0.2229, 0.0000, 0.0000, 0.1722, 0.1838],
       device='cuda:0')
Policy pred: tensor([1.9207e-01, 2.5219e-01, 2.0438e-01, 1.4300e-07, 9.3599e-09, 1.8388e-01,
        1.6748e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
[Iteration 5] Process ID: 181441 [Epoch: 200, 27008/ 27057 points] total loss per batch: 2.028
Policy (actual, predicted): 1 1
Policy data: tensor([0.1159, 0.3071, 0.0000, 0.1071, 0.1159, 0.0468, 0.3071],
       device='cuda:0')
Policy pred: tensor([1.2846e-01, 3.0739e-01, 6.5365e-11, 1.0180e-01, 1.1324e-01, 5.0068e-02,
        2.9904e-01], device='cuda:0', grad_fn=<SelectBackward0>)
Value (actual, predicted): 1.0 1.0
 
